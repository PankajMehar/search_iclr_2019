Under review as a conference paper at ICLR 2019
INTEGRATED STEGANOGRAPHY AND STEGANALYSIS WITH GENERATIVE ADVERSARIAL NETWORKS
Anonymous authors Paper under double-blind review
ABSTRACT
Recently, generative adversarial network is the hotspot in research areas and industrial application areas. It's application on data generation in computer vision is most common usage. This paper extends its application to data hiding and security area. In this paper, we propose the novel framework to integrate steganography and steganalysis processes. The proposed framework applies generative adversarial networks as the core structure. The discriminative model simulate the steganalysis process, which can help us understand the sensitivity of cover images to semantic changes. The steganography generative model is to generate stego image which is aligned with the original cover image, and attempts to confuse steganalysis discriminative model. The introduction of cycle discriminative model and inconsistent loss can help to enhance the quality and security of generated stego image in the iterative training process. Training dataset is mixed with intact images as well as intentional attacked images. The mix training process can further improve the robustness and security of new framework. Through the qualitative, quantitative experiments and analysis, this novel framework shows compelling performance and advantages over the current state-of-the-art methods in steganography and steganalysis benchmarks.
1 INTRODUCTION
Imaging that you are an enthusiastic shutterbug. You are on the trip to New Orleans and took a nice photo of St. Louis Cathedral. You want to send the beautiful photo and reveal the romantic feelings to your girlfriend. As your girlfriend is the Ph.D candidate of computer vision, so you want to share the romantic words in her professional manner. You embed the words by changing the least significant bits of the photograph, because this method can hide the romantic words in nearly invisible way. As a social media network fan, you share this photo on Facebook. Many friends leave the messages to express their love of this photo. And your girlfriend write the following sentence under your photo. "Wonderful photo. By the way, I like the clever idea. I think I am the first audience who have read the hidden words. I love you, too." You will be in a cheerful mood, and appreciate the clever communication method that only you and your girlfriend can "see" the secret information inside the photograph.
This is a simple scenario to show the basic workflow of steganography and steganalysis. Steganography is defined as the art and science of hiding information in ways that prevent the detection of hidden messages (Obaid, 2015). Steganography literally means "covered writing" and is usually interpreted to hide information in other information. In the simple scenario aforementioned, you apply steganography to hide the romantic information into the photo of New Orleans. The romantic information is called the secret message, while the original photo of New Orleans is called the cover image. Steganalysis as the counterpart, is an attack to the steganography. Its main idea is to analyze whether the received information contains any hidden information, and recovering the hidden information if possible (Volkhonskiy et al., 2017). In the simple scenario aforementioned, the social network plays the role of the public channel, and the posted photo is called stego image (Dong et al., 2018), which contains the secret message. Your girlfriend applies steganalysis to discover and recover the secret information you embedded. Since their birth, steganography and steganalysis promote the progress of each other.
1

Under review as a conference paper at ICLR 2019
Steganography is widely used in secret information transmission (Shi et al., 2017), watermark (Yu, 2016), copyright certification (Mun et al., 2017), forgery detection (Wolfgang & Delp, 1996) applications. In this paper, we propose an integrated steganography and steganalysis framework with generative adversarial networks, and use ISS-GAN to represent it. ISS-GAN combines the steganalysis's evaluation metrics of secure steganography with the advantages in latest GAN principle, and integrate the counterparts into single framework. Firstly, we will simulate the steganalysis process with discriminative model. It will help us to dynamically change the capacity of cover images, and understand their sensitivity to semantic change. Then with the fine-tuning adversarial training process of steganography generative model and steganalysis discriminative model, ISS-GAN can iteratively reduce the consistent loss between original cover images and generated stego images. Finally, when ISS-GAN gets the minimal consistent differences, the generated stego images can hardly be distinguished from original cover images. In the training process, we also involve some intentional attacks (noise, compression, etc.) in dataset. The mixture of training dataset can further improve the security of ISS-GAN. By comparing ISS-GAN with the state-of-the-art (SOTA) steganography methods in benchmark datasets, we can conclude that ISS-GAN has the advantages in improving the quality and security of generated stego images. In Figure 1, can you differentiate between Van Gogh's paintings in (a) and (b)? Or Monet's paintings in (e) and (f)? Actually, the images in (a) and (e) are the original version of drawing masters' works. The images in (b) and (f) are the stego version with ISS-GAN framework. The embedded secret legends are emblems of painters' nations: Netherland and France. The embedded info is kept imperceptible to ensure there is no influence on audience to appreciate paintings from fidelity aspect.
(a) (b) (c) (d)
(e) (f) (g) (h)
Figure 1: Illustration of ISS-GAN framework's steganographic experimental performance on the world-renowned art paintings. (a) Original version of The Starry Night painted by Van Gogh. (b) Stego version of The Starry Night. (c) Emblem of Netherland as the embedded secret legend. (e) Original version of The rose arches painted by Monet. (f) Stego version of The rose arches. (g) Emblem of France as the embedded secret legend. (d,h) Residual difference between original and stego versions. (We inverse the color to emphasize the difference.)
2 RELATED WORK
SOTA steganography approaches can be categorized into three types. Least Significant Bit Steganography The main strength of this category is that algorithms are theoretically simple and have low computational complexities. Secret information is embedded into cover image with the operations like shifting or replacing of pixels. In typical Least Significant Bit (LSB) algorithm, pixel values of cover image and secret messages are represented by binary
2

Under review as a conference paper at ICLR 2019
form. Stego image generation process is implemented by replacing the least significant bits of cover image with the most significant bits of secret information. In (Das et al., 2018), authors proposed to generate a LSB based hash function for image authentication process, which can provide good imperceptibility between original image and stego image with hash bits. Moreover, it can successfully identify tamper by a process of tamper localization.
Content Adaptive Steganography In this category, some sophisticated steganographic algorithms design a hand-crafted distortion function which is used for selecting the embedding localization of the image. These algorithms are the most secure image steganography in spatial domain, such as Wavelet Obtained Weights (WOW), Highly Undetectable Steganography (HUGO), S-UNIWARD, etc. WOW (Holub & Fridrich, 2012) embeds information into the cover image according to textural complexity of regions. In WOW algorithm, the more texturally complex the image region is, the more pixel values will be modified in this region. HUGO (Pevny` et al., 2010) defines a distortion function domain by assigning costs to pixels based on the effect of embedding some information within a pixel. It uses a weighted norm function to represent the feature space. S-UNIWARD (Holub et al., 2014) proposes a universal distortion function that is independent of the embedded domain. Despite the diverse implementation details, the ultimate goals are identical in this category. They are all devoted to minimize distortion functions, to embed the secret into the noisy area or complex textures, and to avoid the smooth regions of the cover images.
Deep Learning based Steganography As deep learning has brilliant capability in image processing and generation, researchers also attempt to utilize it in steganography. Paper (Volkhonskiy et al., 2017) introduces a new model for generating more steganalysis-secure cover images based on deep convolutional generative adversarial networks. Paper (Dong et al., 2018) proposes a steganography model which can conceal a gray secret image into a color cover image with the same size, and generate stego image which seems quite similar to cover image in semantics and color. Paper (Shi et al., 2017) wants to generate more secure covers for steganography. Based on Wasserstein GAN (Arjovsky et al., 2017), the proposed algorithm is efficient to generate cover images with higher visual quality. Their model is suitable for embedding secret with the random key.
3 FRAMEWORK OF ISS-GAN
3.1 PRINCIPLE OF ISS-GAN
In the proposal, ISS-GAN is a steganography framework to embed secret message into the source cover image. So here are two essential metrics to evaluate the steganographic algorithm.
· Secret info should remain imperceptible until it is extracted by specific authorized receiver.
· Stego image should be secure and intact to resist tampering and attacks.
In traditional SOTA frameworks, the imperceptibility is achieved by carefully choosing the LSB in pixel domain, or relied on hand-crafted distortion function in traditional steganography. So the features and algorithms need meticulous artificial design. Moreover, these designs heavily rely on the characteristics of target images. So it is very hard for these schemes to become general solutions in various applications. The artificial designed features are also vulnerable to intentional and hybrid attacks. For deep learning based steganography, the main focus is to generate the steganalysis-secure cover images. But in many real applications, the cover images are given. So how to fully utilize the given images to hide secret, and to improve the security of generated stego images are not answered.
After analysing the drawbacks of SOTA algorithms, we find GAN is very suitable for integrated steganography and steganalysis framework. Instead of artificial design, the generative network can learn from training samples and generate the suitable imperceptible features by itself. The discriminative network can simulate the function of steganalysis. The iterative adversarial training process can strength the capability if steganalysis model as well as steganography model. The stronger steganalysis model will stimulate the boost of steganography model, and vice versa. Moreover, how to resist the tampering can also be learned from attacked training samples.
For the first evaluation metric, let's imagine the following situation. An eavesdropper wants to check whether the image he obtained from public media contains secret info. So he needs to discriminate
3

Under review as a conference paper at ICLR 2019

the original cover image and received stego image. If these two images are perceptibly same, then the eavesdropper can hardly differentiate the stego image from the cover image.
For the purpose of steganography, we can accumulate the visual and statistic differences between cover and stego images. If the difference for each evaluation metric is small enough, we can regard this stego image as a high-quality steganography result. This aligns with the imperceptible evaluation criterion of steganography.
For the second evaluation metric, let's imagine the following situation. The eavesdropper wants to destroy the secret communication. So he makes intentional changes to the stego image, like rotate, clip, add noises and JPEG compression. Because he assume that even the image he obtained contains secret, these intentional changes will make the secret extraction method disabled. If the steganography framework is secure, and steganalysis algorithm is robust enough, the intentional changes are in vain. This aligns with the secure evaluation criterion of steganography.
GAN (Goodfellow et al., 2014) consists of the generative model and the discriminative model. The purpose of the generative model is to generate new samples which are very similar to the real samples, and attempts to confuse the discriminator. While the purpose of the discriminative model is to classify samples synthesized by the generative model and the real ones. The discriminative model will also estimate the probability that a specific sample comes from the generative model rather than the real ones. When the whole GAN model achieves Nash Equilibrium, that is to say, the generative model can generate the samples which exactly align with the character and distribution of real samples. And at the same time, the discriminative model returns the classification probability 0.5 for each pair of generated and real samples. Then this GAN model is well-trained and converged.
Cover Image Discriminative Model DCI

+

Stego Image Generative Model GSOI

Secret Image Generative Model GSTI

Cover Image: CI Secret Image Generative Model GSTI

Secret Image: STI

Stego Image: SOI Secret Image Cycle Discriminative Model DSTI
Inconsistent Loss Function

Extracted Secret Image: ESTI

Generated Secret Image: GSTI
Figure 2: Framework and workflow chart of ISS-GAN

To combine the purpose of steganography, steganalysis and GAN model, we propose the novel ISS-GAN framework. ISS-GAN also consists of the steganography generative and steganalysis discriminative model. The purpose of steganography generative model is to generate stego image which is aligned with the original cover image, and attempts to confuse steganalysis discriminative model. While the purpose of the discriminative model is to distinguish generated stego image from the cover image. When ISS-GAN achieves Nash Equilibrium, i.e., the generative model can generate stego image which exactly aligns with the character and distribution of cover image. And at the same time, the discriminative model returns the classification probability 0.5 for each pair of stego and cover image. This also aligns with the evaluation criterion of steganography and steganalysis. In conclusion, designing steganography and steganalysis framework is equal to make the ISS-GAN model well-trained and converged. The overall framework of ISS-GAN is shown in Figure. 2.
In ISS-GAN, there are two generative models and two discriminative models. Because steganography and steganalysis framework should contain secret info embedding and extraction processes, so it needs to learn the bijective mapping relationship between two image collections. For ISS-GAN, one image collection contains the original cover images, the other collection contains the secret images for embedding.
4

Under review as a conference paper at ICLR 2019

In the left part of Figure 2, the original cover image (CI) and the original secret image (STI) go through the stego image generative model GSOI , to produce the stego image (SOI). This is the secret embedding and stego image generation process, which can be expressed as follows.

SOI = GSOI (CI, ST I)

(1)

In the right part of Figure 2, the stego image (SOI) go through the secret image generative model

GST I , to get the extracted secret image (ESTI). This is the secret image extraction process, which can be expressed as follows.

EST I = GST I (SOI)

(2)

The cover image discriminative model DCI ensures that the distribution of images from CI is indistinguishable from the distribution SOI using an adversarial loss. This is the guarantee of the
imperceptible evaluation criterion in steganography.

For the purpose of refining secret extraction, we introduce the secret image cycle discriminative model DST I . Because generative model is learned to transform from a source image domain to a target image domain. Take the secret image generative model GST I as an example, the learned mapping relation is highly under-constrained, and cannot ensure the generated ESTI is indistinguishable from original STI (Zhu et al., 2017). So we couple this mapping relation with its inverse mapping GSOI , and introduce a cycle adversarial loss:

DST I (STI, ESTI)  0

(3)

That is equal to

GST I (SOI) = GST I (GSOI (CI, STI))  STI

(4)

Its goal is to ensure that the distribution of images from ESTI is indistinguishable from the distribution STI using cycle adversarial loss DST I . This is the guarantee of the secure and robust extraction criterion in steganography and steganalysis.

To refine steganalysis scheme, we introduce the extra inconsistent loss. To make the whole ISS-

GAN framework useable, we should ensure the secret can only be extracted from SOI. If we apply

the secret extraction process to CI, secret image should not be recovered. The inconsistent loss can

be expressed as follows:

max |GST I (CI) - GST I (SOI)|
GST I

(5)

3.2 LOSS FUNCTION DEFINITION

The overall loss function of ISS-GAN consists of three parts: the adversarial loss LGAN (GSOI , DCI ), the cycle adversarial loss LGAN (GST I , DST I ) and the inconsistent loss LIC . So the loss function is written as follows:

LOverall = LGAN (GSOI , DCI ) + LGAN (GST I , DST I ) + LIC [GST I (CI), GST I (SOI)], (6)

where  is the parameter to adjust the percentages between adversarial loss and inconsistent loss. The inconsistent loss needs to change to the minimization format as follows.

1 min GST I |GST I (CI) - GST I (SOI)|

(7)

In ISS-GAN framework, the quality of generated stego image SOI and extracted secret image ESTI

is judged by the difference from original cover image CI and original secret image STI, respectively.

In this paper, two quantitative image effect indicators are applied to measure the differences (Yu,

2017). Peak Signal to Noise Ratio (PSNR) indicator is applied to assess the effect difference from

the gray-level fidelity aspect. Structural Similarity (SSIM) (Wang et al., 2004) indicator which is an

image quality assessment indicator based on the human vision system is applied to assess the effect

difference from the structure-level fidelity aspect. The definitions of these two evaluation indicators

are as follows.

P SN R(x, y) = 10 log10

(MAXI )2 MSE (x, y)

,

(8)

5

Under review as a conference paper at ICLR 2019

where MAXI is the maximum possible pixel value of images: x and y. MSE(x,y) represents the Mean Squared Error (MSE) between images: x and y.

SSIM (x, y) = (2µxµy + C1) (2xy + C2) , µ2x + µ2y + C1 x2 + y2 + C2

(9)

where µx and µy represent the average grey values of images. Symbol x and y represent the vari-
ances of images. Symbol xy represents covariance between images. C1 and C1 are two constants which are used to prevent unstable results when either µ2x + µy2 or x2 + y2 is very close to 0.

3.3 ISS-GAN NETWORK STRUCTURE
For ISS-GAN, the resolution of cover image CI and secret image STI is 256×256. The network structure of stego image generative model GSOI includes a convolution layer (kernel size = 7, stride = 0, pad = 0), two convolution layers (kernel size = 3, stride = 2, pad = 1), nine residual blocks (He et al., 2016), and two deconvolution layers (kernel size = 3, stride = 2, pad = 1, outside pad = 1), and a convolution layer (kernel size = 7, stride = 0, pad = 0). Each convolution and deconvolution layer follows with an instance normalization layer and a ReLU layer. The structure of secret image generative model GST I is identical with GSOI .
The network structure of cover image discriminative model DCI is similar with PatchGAN model (Isola et al., 2017). Each time, it operates a image patch with 70×70 size, and classifies whether this patch is real or fake. The model will run across the whole image, and average all results in the 70×70 overlapping patches to provide the ensemble output. The architecture of such a patch-level discriminative model requires fewer parameters and runs faster than a full-image discriminator (Yi et al., 2017). Moreover, it has no constraints over the size of the input image. DC contains a convolution layer (kernel size = 4, stride = 2, pad = 1) follows with a leaky ReLU layer, three convolution layers (kernel size = 4, stride = 2, pad = 1) follows with an instance normalization layer and a leaky ReLU layer, a convolution layer (kernel size = 4, stride = 1, pad = 1) follows with an instance normalization layer and a leaky ReLU layer, a convolution layer (kernel size = 4, stride = 1, pad = 1) follows with a sigmoid layer to output a scalar output between [0, 1]. The structure of secret image cycle discriminative model DST I is identical with DCI .
Moreover, to improve the convergence performance, we use Adam optimizer (Kinga & Adam, 2015) instead of stochastic gradient descent (SGD) optimizer. In practice, Adam optimizer can be adaptive to the training of ISS-GAN. It is computationally efficient and has little memory requirements. The hyper-parameters of Adam optimizer are: 1=0.5, 2=0.999. The base learning rate is 0.0002.

4 EXPERIMENTAL RESULTS
4.1 STEGANOGRAPHY PERFORMANCE EXPERIMENTS
In the secret embedding and stego image generation performance experiments, we adopt the benchmark images as the cover images CI shown in the first row of Figure 3 to test the performance of proposed ISS-GAN framework. The generated stego images SOI are shown in the second row of Figure 3. The results shown in Figure 3 and Table. 1 can prove the high quality and difference imperceptibility of SOI in qualitative and quantitative aspects.

Table 1: Evaluation metrics of generated stego images SOI

Metrics/Images

Lena Airplane Baboon Fruits Peppers

PSNR

33.0170 33.0065 29.1163 33.9085 30.5124

SSIM

0.9390 0.9589 0.9335 0.9510 0.9034

4.2 STEGANALYSIS QUALITATIVE PERFORMANCE EXPERIMENTS
In the steganalysis qualitative experiments, we adopt the world-renowned art paintings shown in Figure 1 to test the performance of proposed ISS-GAN and its robustness to different patterns of noise attack. Several patterns of noises are adopted respectively to imitate the real-world noise
6

Under review as a conference paper at ICLR 2019
Figure 3: Stego images SOI generation performance of ISS-GAN. Row 1: Original cover images: Lena, Airplane, Baboon, Fruits and Peppers, Row 2: Corresponding generated stego images attacks. The extracted secret image ESTI are shown in Figure 4. The results shown in Figure 4 can prove the high quality of ESTI in qualitative aspect.
Figure 4: Extracted secret images after adding noise. Row 1: Multiplicative noise, Row 2: Salt and pepper noise, Row 3: Gaussian white noise, Row 4: Poisson noise 4.3 STEGANALYSIS QUANTITATIVE COMPARATIVE EXPERIMENTS We compare ISS-GAN with the state-of-the-art steganography methods in various image benchmarks. Here we use steganalysis process to extract secret images from stego images, and evaluate the security criteria of steganography algorithms. For LSB steganography algorithms, we choose LSB-TLH Das et al. (2018). For content adaptive steganography algorithms, we choose WOW Holub & Fridrich (2012), HUGO (Pevny` et al., 2010) and S-UNIWARD (Holub et al., 2014). For deep learning based steganography algorithms, we choose ISGAN Dong et al. (2018) and SSGAN Shi et al. (2017) for comparation. We make two group experiments. In the first group experiment, we use Lena as the original cover image, and the trolleybus image as the secret image. The results are shown in Figure 5. In the second group experiment, we use Lena as the original cover image, and the headline of ICLR conference as the secret image. The results are shown in Figure 6.
7

Under review as a conference paper at ICLR 2019

Figure 5: Extracted secret image of trolleybus after adding certain attacks. Row 1: Gaussian white noise, Row 2: Poisson noise, Row 3: Salt and pepper noise, Row 4: Salt noise, Row 5: Pepper noise, Row 6: Speckle noise, Row 7: JPEG compression. Column 1-7 are ESTI obtained by LSB-TLH, WOW, HUGO, S-UNIWARD, ISGAN, SSGAN and proposed ISS-GAN algorithms.

Table 2: PSNR metric for extracted secret images of trolleybus

Images/Algorithms
Gaussian noise Possion noise Salt & Pepper noise Salt noise Pepper noise Speckle noise
JPEG Compression

LSB-TLH
21.9184 28.0956 20.6125 19.7074 21.8021 27.9778
26.6862

WOW
22.5196 28.1163 22.3013 20.2493 22.4331 33.8242
30.4574

HUGO
25.4038 28.1097 22.3739 22.0935 22.5555 32.7279
31.0763

S-UNIWARD ISGAN
23.6964 21.0874 28.1035 28.0996 22.1683 20.2038 20.4663 19.6455 24.2972 21.7754 30.5234 28.8135
29.7196 27.9319

SSGAN
22.0219 28.1182 21.0407 19.7446 21.8409 29.6587
28.8819

ISS-GAN
28.5659 28.1181 23.3684 22.8699 25.0980 37.5805
31.6285

The PSNR and SSIM metrics for extracted secret image of trolleybus and ICLR conference headline are shown in Table 2 5, respectively. According to these metrics, the security of ISS-GAN outperforms all other state-of-the-art steganography algorithms in quantitative aspect.
In these two group experiments, PSNR and SSIM metrics, the closest competitors are content adaptive steganography algorithms. WOW, HUGO and S-UNIWARD have quite good performance on steganography security. But for PSNR metric, ISS-GAN can still achieve 1.01X1.12X relative improvement over the second highest PSNR algorithms with trolleybus secret image embedded, and achieve 1.01X1.81X relative improvement over the second highest PSNR algorithms with ICLR
8

Under review as a conference paper at ICLR 2019

Figure 6: Extracted secret image of ICLR conference headline after adding certain attacks. Row 1: Gaussian white noise, Row 2: Poisson noise, Row 3: Salt and pepper noise, Row 4: Salt noise, Row 5: Pepper noise, Row 6: Speckle noise, Row 7: JPEG compression. Column 1-7 are ESTI obtained by LSB-TLH, WOW, HUGO, S-UNIWARD, ISGAN, SSGAN and proposed ISS-GAN algorithms.

Table 3: SSIM metric for extracted secret images of trolleybus

Images/Algorithms
Gaussian noise Possion noise Salt & Pepper noise Salt noise Pepper noise Speckle noise
JPEG Compression

LSB-TLH
0.6548 0.8876 0.7338 0.7147 0.8119 0.8955
0.8909

WOW
0.6802 0.8878 0.8224 0.7384 0.8295 0.9635
0.9425

HUGO
0.7885 0.8878 0.8220 0.8096 0.8333 0.9542
0.9487

S-UNIWARD
0.7271 0.8877 0.8110 0.7476 0.8780 0.9304
0.9343

ISGAN
0.6182 0.8874 0.7190 0.7127 0.8100 0.9062
0.9304

SSGAN
0.6589 0.8880 0.7584 0.7156 0.8124 0.9206
0.9245

ISS-GAN
0.8772 0.8880 0.8464 0.8352 0.8941 0.9836
0.9538

conference headline secret image embedded. For SSIM metric, ISS-GAN can achieve 1.01X1.11X relative improvement over the second highest SSIM algorithms with trolleybus secret image embedded, and achieve 1.01X1.46X relative improvement over the second highest SSIM algorithms with ICLR conference headline secret image embedded.
The performance of SOTA deep learning steganography algorithms is not as good as expected. The main reason is the authors are more focus on generating the new cover images which are steganalysis-secure. But in our experiments, the cover images are fixed. So we can see the perfor-
9

Under review as a conference paper at ICLR 2019

Table 4: PSNR metric for extracted secret images of ICLR conference headline

Images/Algorithms
Gaussian noise Possion noise Salt & Pepper noise Salt noise Pepper noise Speckle noise
JPEG Compression

LSB-TLH
25.6366 27.2302 19.4886 30.3170 17.3986 26.8375
30.1590

WOW
24.5133 27.2400 20.8146 31.8986 17.8621 27.6863
32.1941

HUGO
27.9945 27.2332 24.3997 34.0030 18.3596 27.8516
32.6464

S-UNIWARD ISGAN
25.8188 22.8196 27.2281 27.2352 21.5674 19.5006 32.3590 31.3167 19.8744 16.4737 34.0109 24.5629
31.8712 30.9326

SSGAN
23.6139 27.2242 20.7629 31.7378 17.7617 25.3830
31.1552

ISS-GAN
30.0088 27.2497 36.4338 49.0843 35.9698 42.8481
32.7724

Table 5: SSIM metric for extracted secret images of ICLR conference headline

Images/Algorithms
Gaussian noise Possion noise Salt & Pepper noise Salt noise Pepper noise Speckle noise
JPEG Compression

LSB-TLH
0.7163 0.7706 0.6566 0.9900 0.5160 0.7422
0.9841

WOW
0.6647 0.7707 0.7352 0.9927 0.5455 0.7718
0.9888

HUGO
0.8084 0.7710 0.8839 0.9951 0.5834 0.7790
0.9892

S-UNIWARD
0.7228 0.7709 0.7664 0.9931 0.6775 0.9340
0.9880

ISGAN
0.5808 0.7709 0.6569 0.9918 0.4464 0.6461
0.9863

SSGAN
0.6200 0.7703 0.7362 0.9924 0.5428 0.6752
0.9877

ISS-GAN
0.8682 0.7716 0.9912 0.9998 0.9900 0.9904
0.9897

mance of SOTA deep learning steganography algorithms is just at the same level of LSB steganography algorithms, and is worse than content adaptive steganography algorithms.
Compare the results of first and second group experiments, we find ISS-GAN has better performance with the ICLR conference headline secret image. The amount of meaningful pixels and semantic info in ICLR conference headline image is much less than trolleybus image. This aligns with the principle of steganography, i.e., if more pixels are concealed into the cover image, then the security of stego image will be worse.
5 CONCLUSION AND FUTURE WORKS
In this paper, we integrate steganography and steganalysis into single framework. The good performance of ISS-GAN derives from the following factors.
· The discriminative network simulates the features of steganalysis. It helps to understand the sensitivity of cover images to semantic changes.
· The introduction of cycle discriminative model and inconsistent loss helps to enhance the quality and security of generated stego image.
· The mixture training dataset can further improve the robustness and security of ISS-GAN framework. How to resist the tampering can be learned from attacked training samples.
· The iterative adversarial training process can strength the capability if steganalysis model and steganography model at the same time. The stronger steganalysis model will stimulate the improvement of steganography model, and vice versa.
In the future, we will involve more types of intentional attacks, such as cropping, scaling, rotation, filtering, etc. And study their influence on ISS-GAN. We will also study the influence of color cover/secret image and the gray cover/secret image to the proposed ISS-GAN framework.

10

Under review as a conference paper at ICLR 2019
REFERENCES
Martin Arjovsky, Soumith Chintala, and Le´on Bottou. Wasserstein gan. arXiv preprint arXiv:1701.07875, 2017.
Ujjal Kumar Das, Shefalika Ghosh Samaddar, and Pankaj Kumar Keserwani. Digital forensic enabled image authentication using least significant bit (lsb) with tamper localization based hash function. In Intelligent Communication and Computational Technologies, pp. 141­155. Springer, 2018.
Shiqi Dong, Ru Zhang, and Jianyi Liu. Invisible steganography via generative adversarial network. arXiv preprint arXiv:1807.08571, 2018.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing systems, pp. 2672­2680, 2014.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770­778, 2016.
Vojtech Holub and Jessica Fridrich. Designing steganographic distortion using directional filters. In 2012 IEEE International workshop on information forensics and security (WIFS), pp. 234­239. IEEE, 2012.
Vojtech Holub, Jessica Fridrich, and Toma´s Denemark. Universal distortion function for steganography in an arbitrary domain. EURASIP Journal on Information Security, 2014(1):1, 2014.
Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with conditional adversarial networks. arXiv preprint, 2017.
D Kinga and J Ba Adam. A method for stochastic optimization. In International Conference on Learning Representations (ICLR), volume 5, 2015.
Seung-Min Mun, Seung-Hun Nam, Han-Ul Jang, Dongkyu Kim, and Heung-Kyu Lee. A robust blind watermarking using convolutional neural network. arXiv preprint arXiv:1704.03248, 2017.
Ali Hamzah Obaid. Information hiding techniques for steganography and digital watermarking. UDC 681.518 (04) INTERACTIVE S¡ STEMS: Problems of Human-Computer Interaction.­ Collection of scientific papers.- Ulyanovsk: USTU, 2015.- 306 p., pp. 63, 2015.
Toma´s Pevny`, Toma´s Filler, and Patrick Bas. Using high-dimensional image models to perform highly undetectable steganography. In International Workshop on Information Hiding, pp. 161­ 177. Springer, 2010.
Haichao Shi, Jing Dong, Wei Wang, Yinlong Qian, and Xiaoyu Zhang. Ssgan: Secure steganography based on generative adversarial networks. In Pacific Rim Conference on Multimedia, pp. 534­544. Springer, 2017.
Denis Volkhonskiy, Ivan Nazarov, Boris Borisenko, and Evgeny Burnaev. Steganographic generative adversarial networks. arXiv preprint arXiv:1703.05502, 2017.
Zhou Wang, Alan C Bovik, Hamid R Sheikh, and Eero P Simoncelli. Image quality assessment: from error visibility to structural similarity. IEEE transactions on image processing, 13(4):600­ 612, 2004.
Raymond B Wolfgang and Edward J Delp. A watermark for digital images. In Image Processing, 1996. Proceedings., International Conference on, volume 3, pp. 219­222. IEEE, 1996.
Zili Yi, Hao (Richard) Zhang, Ping Tan, and Minglun Gong. Dualgan: Unsupervised dual learning for image-to-image translation. In ICCV, pp. 2868­2876, 2017.
Chong Yu. Steganography of digital watermark based on artificial neural networks in image communication and intellectual property protection. Neural Processing Letters, 44(2):307­316, 2016.
11

Under review as a conference paper at ICLR 2019 Chong Yu. Steganography of digital watermark by arnold scrambling transform with blind source
separation morphological component analysis. Multimedia Tools and Applications, 76(5):6821­ 6842, 2017. Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. arXiv preprint, 2017.
12

