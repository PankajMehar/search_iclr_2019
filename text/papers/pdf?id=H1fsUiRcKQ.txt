Under review as a conference paper at ICLR 2019
FAST ADVERSARIAL TRAINING FOR SEMI-SUPERVISED
LEARNING
Anonymous authors Paper under double-blind review
ABSTRACT
In semi-supervised learning, Bad GAN approach is one of the most attractive method due to the intuitional simplicity and powerful performances. Bad GAN learns a classifier with bad samples distributed on complement of the support of the input data. But Bad GAN needs additional architectures, a generator and a density estimation model, which involves huge computation and memory consumption cost. VAT is another good semi-supervised learning algorithm, which utilizes unlabeled data to improve the invariance of the classifier with respect to perturbation of inputs. In this study, we propose a new method by combining the ideas of Bad GAN and VAT. The proposed method generates bad samples of high-quality by use of the adversarial training used in VAT. We give theoretical explanations why the adversarial training is good at both generating bad samples and semi-supervised learning. An advantage of the proposed method is to achieve the competitive performances with much fewer computations. We demonstrate this advantage by analyzing three well known benchmark image datasets.
1 INTRODUCTION
Deep learning has accomplished unprecedented success due to the development of deep architectures, learning techniques and hardwares (Krizhevsky et al., 2012; Ioffe & Szegedy, 2015; Szegedy et al., 2015; Hinton et al., 2012; Kingma & Ba, 2014). However, deep learning has also suffered from collecting large amount of labeled data which requires both cost and time. Thus it becomes important to develop semi-supervised methodologies that learn a classifier (or discriminator) by using small labeled data and large unlabeled data.
Various semi-supervised learning methods have been proposed for deep learning. Weston et al. (2012) employs a manifold embedding technique using the pre-constructed graph of unlabeled data and Rasmus et al. (2015) uses a specially designed auto-encoder to extract essential features for classification. Variational auto encoder (Kingma & Welling, 2013) is also used in the context of semi-supervised learning by maximizing the variational lower bound of both labeled and unlabeled data (Kingma et al., 2014; Maaløe et al., 2016).
Recently, semi-supervised learning based on generative adversarial networks (GAN, Goodfellow et al. (2014a)) has received much attention. For K-class classification problems, Salimans et al. (2016) solves the (K + 1)-class classification problem where the additional (K + 1)th class consists of synthetic images made by a generator of the GAN learned by unlabeled data. Dai et al. (2017) notices that not a good generator but a bad generator which generates synthetic images much different from observed images is crucial for the success of semi-supervised learning. Dai et al. (2017) gives theoretic justifications of using a bad generator and develops a semi-supervised learning algorithm called Bad GAN which achieves the state-of-the-art performances over multiple benchmark datasets.
1

Under review as a conference paper at ICLR 2019
However, Bad GAN has several limitations. It needs additional two deep architectures beside the one for classifier, a bad generator and a pre-trained density estimation model. Learning these multiple deep architectures requires huge computation and memory consumption. In particular, the PixelCNN++ (Salimans et al., 2017) is used for the pre-trained density estimation model which needs very large computational resources.
Another difficulty in Bad GAN is that it requires a two-step learning procedure - the first step is to learn the PixelCNN++ model and the second step is to learn the classifier and the bad generator. The optimal learning of the first step may not be optimal for the second step and hence the regularization of the both steps would need special techniques.
In this study, we propose a new semi-supervised learning method which competes well with other stateof-the-art semi-supervised learning algorithms and yet needs much smaller amount of computational resources. The proposed method employs only one deep architecture and hence the corresponding learning phase is much easier and faster.
Our proposed method is motivated by close investigation of the VAT (Virtual Adversarial Training) method (Miyato et al., 2015; 2017). VAT tries to find a deep architecture which has a good prediction accuracy on training data and at the same time is less sensitive to data perturbation toward the adversarial direction. Here, the adversarial direction for a given datum is the direction to which the probabilities of each class change most. In Section 3, we prove that the perturbed data toward their adversarial directions can serve as `good' bad samples. By using the adversarial directions for both measuring the invariance and generating the bad samples, the proposed method combines the advantages of Bad GAN and VAT together. Note that only a deep architecture for classification is needed to calculate the adversarial directions and thus the corresponding learning procedure is cheaper, easier and faster. We call our proposed method FAT (Fast Adversarial Training).
Dai et al. (2017) proves that bad samples play a role to pull the decision boundary toward the low density regions of data. In Section 5, we give a theoretical explanation that VAT pushes the decision boundary away from the high density regions of data. That is, FAT accelerates the learning procedure by using both pushing and pulling operations simultaneously. In section 6, we show that FAT achieves almost the state-of-the-art performances with much fewer training epochs. Especially, for the MNIST dataset, FAT achieves similar test accuracies to those of Bad GAN and VAT with 5 times and 7 times fewer training epochs, respectively.
This paper is organized as follows. In Section 2, we review the Bad GAN and VAT methods briefly. In Section 3, the technique to generate bad samples using the adversarial directions is described, and our proposed semi-supervised learning method is presented in Section 4. Theoretical analysis of VAT is given in Section 5. Results of various numerical experiments are presented in Section 6 and conclusions follow in Section 7.
2 Bad GAN AND VAT
2.1 Bad GAN APPROACH
Bad GAN is a method that trains a good discriminator with a bad generator. This procedure trains a generator as well as a discriminator simultaneously. Let DG() be generated bad samples with a bad generator pG(·; ) parametrized by . Here, the `bad generator' means to generate samples different from observed data. Let ppt(·) be a pre-trained density estimation model. For a given discriminator with a feature vector v(x; ) of a given input x parameterized by , Bad GAN learns the bad generator by minimizing the following:
ExDG() log ppt(x)I(ppt(x) >  ) + ||ExUtr v(x; ) - ExDG()v(x; )||2
2

Under review as a conference paper at ICLR 2019

with respect to , where  > 0 is a tuning parameter, U tr is the unlabeled data and  is the current estimate of .

In turn, to train the discriminator, we consider the K-class classification problem as the (K + 1)-class classification problem where the (K + 1)-th class is an artificial label of the bad samples generated by the bad generator. We estimate the parameter  in the discriminator by minimizing the following:

K

-Ex,yLtr [log p(y|x, y  K; )] - ExUtr log

p(k|x; )

k=1

K

-ExDG() [log p(K + 1|x; )] - ExUtr

p(k|x; ) log p(k|x; )

k=1

(1)

for given , where Ltr is the labeled set. The second and the third terms in (1) are the cross-entropies between the unlabeled and the bad samples. The fourth term is the entropy of the unlabeled data which is usually helpful for semi-supervised learning (Grandvalet & Bengio, 2005). See Dai et al.

(2017) for details of the objective function (1).

2.2 VAT APPROACH

VAT is a regularization method which is inspired by the adversarial training (Goodfellow et al., 2014b). The regularization term of VAT is given as:

LVAT(; , x, ) = DKL p(·|x; )||p(·|x + radvr(x, ); )

K
= - p(k|x; ) log p(k|x + radvr(x, ); ) + C,
k=1

where

radvr(x, ) = argmaxDKL p(·|x; )||p(·|x + r; ) ,
r;||r||

(2)

> 0 is a tuning parameter,  is the parameter in the discriminator to train,  is the current estimate of  and C is a constant. Combining with the cross-entropy term of the labeled data, we get the final objective function of VAT:

-Ex,yLtr [log p(y|x; )] + ExUtr LVAT(; , x, ) .

(3)

3 GENERATION OF BAD SAMPLES BY ADVERSARIAL TRAINING
The key role of bad samples in Bad GAN is to enforce the decision boundary to be pulled toward the low density regions of the unlabeled data. To do this, bad samples must be located at the valleys of the distribution of the unlabeled data. In this section, we propose a novel technique to generate `good' bad samples by use of only a given classifier.
3.1 MOTIVATION
Let us consider the 2-class linear logistic regression model parametrized by  = {w, b}, that is,
-1
p(y = 1|x; ) = 1 + exp(-b - w x) . Note that the decision boundary is {x : b + w x = 0}, and for any given x, the distance between x and the decision boundary is |b + w x|/||w||. The key result is that moving x toward the adversarial direction radvr(x, ) is equivalent to moving x toward the decision boundary which is stated rigorously in the following proposition. The proof is in the appendix.

3

Under review as a conference paper at ICLR 2019

Figure 1: Demonstration of how the bad samples generated by the adversarial training are distributed. We consider two cases: one is a 3-class classification problem (Left) and the other is a 6-class classification problem. (Right) We generate labeled data in the 2-dimensional space which are linearly separable. Given a perfect discriminator, we generate bad samples by the adversarial training. True data and bad data are coloured by blue and orange, respectively. We can easily see that most of the bad samples are distributed between the supports of the labeled data.

Proposition 1 For a sufficiently small > 0, we have

sign(w x + b) · sign w radvr(x, ) = -1.

(4)

Proposition 1 implies that |b + w x|/||w|| > |b + w (x + radvr(x, )|/||w|| unless |b + w x| = 0. Hence, we can treat x + radvr(x, )/||radvr(x, )|| for appropriately choosing  > 0 as a bad sample (a sample closer to the decision boundary).

3.2 BAD SAMPLE GENERATION WITH GENERAL CLASSIFIER
Motivated by Proposition 1, we propose a bad sample generator as follows. Let  > 0 be fixed and  be the current estimate of . For a given input x and a classifier p(·|x; ), we calculate the adversarial direction radvr(x, ) for given by (2). Then, we consider xbad = x + radvr(x, )/ radvr(x. ) as a bad sample. We generate bad samples for all unlabeled data. In practice, we choose  based on the validation data accuracy.
It may happen that a bad sample is not sufficiently close to the decision boundary to be a 'good' bad sample, in particular when  is too large or too small. To avoid such a situation, we exclude xbad which satisfies the following condition:
max p(k|xbad; ) > 1 - 
k
for a prespecified  > 0. In our experiments, we set  to be 0.01.
In Figure 1, we illustrate how the bad samples generated by the proposed adversarial training perform for multi-class linear logistic regression models. We can clearly see that most bad samples are located well in the low density regions of the data.

4 FAST ADVERSARIAL TRAINING WITH BAD SAMPLES

Once we generate bad samples by the adversarial training, FAT updates  by minimizing the following objective function:

-Ex,yLtr [log p(y|x; )] + ExUtr Ltrue(; x) + ExDbad(,) Lfake(, x) +ExUtr LVAT(; , x, )

(5)

4

Under review as a conference paper at ICLR 2019

where Dbad(, ) is the set of generated bad samples with  and ,

K
Ltrue(; x) = -
k=1

1+

exp(gk(x; ))

K k =1

exp(gk

(x;

))

log

1

+

Lfake(; x) = - log 1+

1

K k=1

exp(gk

(x;

))

,

exp(gk(x; ))

K k =1

exp(gk

(x; ))

,

and g(x; )  RK is a pre-softmax vector of a given deep architecture. We treat and  as tuning parameters to be selected based on the validation data accuracy.

The objective function (5) differs from the objective function (1) of Bad GAN in the way that the second term of (1), the cross-entropy of not being a bad sample, is deleted and the regularization term of VAT is added. We delete the second term of (1) since we think that the roles of the second and the fourth terms in (1) are overlapped. The regularization term of VAT is indispensable to utilize the advantages of Bad GAN and VAT together. We minimize the objective function with one of the standard optimization algorithms such as Adam (Kingma & Ba, 2014) or RMSProp (Tieleman & Hinton, 2012).

Miyato et al. (2017) proposes the fast approximation method to calculate the adversarial direction by using the second-order Taylor expansion. Let us define H(x, ) = DKL p(·|x; )||p(·|x + r; ) |r=0. They claim that radvr emerges as the first dominant eigenvec-
tor u(x, ) of H(x, ) with magnitude . But there always exist two dominant eigenvectors, ±u(x, ), and the sign should be selected carefully. So, we slightly modify the approximation method of Miyato et al. (2017) by

radvr(x, ) = argmax DKL p(·|x; )||p(·|x + r; ) .
r{u(x,),-u(x,)}
This modification helps to improve convergence speed of the test accuracy.

5 ROLE OF VAT FOR SEMI-SUPERVISED LEARNING
Dai et al. (2017) nicely explains that the role of bad samples is to pull the decision boundary toward the low density regions of data. In this section, we give a similar explanation for the role of the regularization term of VAT in semi-supervised learning. We will show that the regularization term of VAT pushes the decision boundary from the high density regions of unlabeled data. As a result, FAT uses both pulling and pushing operations simultaneously, which makes it possible to accelerate the training process with improving accuracies.
5.1 THEORETICAL ANALYSIS OF VAT
Suppose that the domain X of the input vector x is a bounded convex set. Suppose that X is partitioned by (K + 1) mutually disjoint subsets Xk for k = 1, . . . , K + 1 such that y(x) = k for all x  Xk, k  K and p(x) = 0 for x  XK+1, where y(x) is the ground-truth label of x and p(x) is the true density of x. For a given feature map u : X  Rm and weight vectors w1, . . . , wk, let p(y = k|x)  exp(wku(x)) for k = 1, . . . , K and p(y = K + 1|x)  1. Let Ltr satisfy Xk  Ltr =  for k = 1, ...K. Suppose that (i) argmaxhp(y = h|x) = y for x  Ltr, (ii) argmaxhp(y = h|x)  K for x  Kk=1Xk and (iii) argmaxhp(y = h|x) = K + 1 for x  XK+1. Under these three conditions, Dai et al. (2017) proves that argmaxhp(y = h|x) = y(x) for all x  Kk=1Xk. This result implies that a classifier which fits the labeled data perfectly and predicts all bad samples and not bad samples correctly as bad samples and not bad samples, respectively, also

5

Under review as a conference paper at ICLR 2019

gives a correct decision boundary for all unlabeled data. That is, generating large `good' bad samples is helpful for classifying unlabeled data correctly only with a small amount of labeled data.
A similar result can be obtained for VAT under mild additional conditions.

Definition 1 We define a tuple (x, x ) is -connected iff d(x, x ) < , where d(·, ·) is a given metric. A finite subset A of X is called -connected iff for all x, x  A, there exists a finite path (x, x1, ..., xq, x ) such that xj  A for j = 1, . . . , q and (x, x1), (x1, x2), ..., (xq-1, xq), (xq, x ) are all -connected.
For given two subsets A1 and A2 of X , we define d(A1, A2) = minx1A1,x2A2 d(x1, x2). The following proposition is the main result of this section, whose proof is in the appendix.

Proposition 2 Assume that there exists > 0 such that 1) Uktr = U tr  Xk, k = 1, . . . , K are
-connected, 2) d(Xk, Xk )  2 for all k = k  K, and 3) for each k  K, there exists at least one (x, k)  Ltr such that d({x}, Uktr) < . Suppose that there exists a classifier f : X  {1, ..., K} such that f (x) = y for all (x, y)  Ltr and

f (x) = f (x ) for all x  B(x, )

(6)

for all x  Utr, where B(x, ) = {x : d(x, x )  }. Then, the function f classifies the unlabeled set perfectly, that is:

f (x) = y(x) for all x  U tr.

Condition 1) and 2) mean that the unlabeled data are dense enough and the supports of each class are separated sufficiently, respectively. Condition 3) assumes that at least one labeled instance exists near the supports of each class. The main condition of Proposition 2 is (6) which essentially assumes that the classifier f does not change much locally. That is, f is invariant with respect to all small perturbations of an input x. Note that the regularization term of VAT is devised to improve the invariancy of the classifier and Proposition 2 explains why improving the invariancy is helpful for semi-supervised learning.

5.2 INTERPRETATION OF VAT

Let f (x; ) = argmaxhp(y = h|x; ). Proposition 2 implies that it would be good to pursue a classifier which predicts the labeled data correctly and at the same time is invariant with respect to all local perturbations on the unlabeled data. For this purpose, a plausible candidate of the objective function is

E(x,y)Ltr [I(y = f (x; )] + ExUtr I f (x; ) = f (x ; ) for x  B(x, )

(7)

where the first term encourages a classifier to predict the labeled data correctly and the second term encourages a classifier to be invariant to local perturbations of the unlabeled data. Note that a classifier f which achieves 0 value of the objective function (7) satisfies the conditions of Proposition 2 and thus classifies all unlabeled data correctly.

The objective function (7) is not practically usable since neither optimizing the indicator function nor checking f (x; ) = f (x ; ) for all x in B(x, ) is possible. To resolve these problems, we replace the indicator functions in (7) with the cross-entropies, and the neighborhood B(x, ) in the second term with the adversarial direction. By doing so, we have the following alternative objective function:

K

- Ex,yLtr [log p(y|x; )] - ExUtr

p(k|x; ) log p(k|x + radvr(x, ); ) .

k=1

(8)

6

Under review as a conference paper at ICLR 2019
Figure 2: (Upper) 10 randomly sampled original MNIST data. (Middle) Bad samples obtained by the classifier learned without the regularization term of VAT. (Lower) Bad samples obtained by the classifier learned with the regularization term of VAT.
Figure 3: Examples of P (y = 1|x) of smooth (Left) and wiggle (Right) cases. We plot 3 points and their adversarial directions on each case.
Finally, we replace p(·|x; ) in the second term of (8) by p(·|x; ) to have the objective function of VAT (3). The condition (6) in Proposition 2 means that the decision boundary is not located inside the support Xk of each class. That is, the regularization term of VAT prevents the decision boundary from being located at the high density regions of data or equivalently pushes the decision boundary from the high density regions of data. 5.3 IMPROVEMENT OF BAD SAMPLES WITH VAT It is interesting that the regularization term of VAT is helpful not only to make the classifier invariant to local perturbation but also to generate bad samples. In Figure 2, we compare bad samples generated by the adversarial training with and without the regularization term of VAT for the MNIST data. While the bad samples generated without the regularization term of VAT are visually similar to the given input vectors, the bad samples generated with the regularization term of VAT look like mixtures of two different digits and thus serve as `better' bad samples. The adversarial direction obtained by maximizing the KL divergence is sensitive to local fluctuations of the class probabilities which is examplified in Figure 3. The regularization term of VAT is helpful to find a right adversarial direction which is toward the decision boundary by eliminating unnecessary local fluctuations of the class probabilities.
6 NUMERICAL EXPERIMENTS
We conduct a set of numerical experiments to compare FAT with other competitors. First we measure prediction accuracies over benchmark datasets. For the benchmark datasets, we consider the most widely used datasets: MNIST (LeCun et al., 1998), SVHN (Marlin et al., 2010) and CIFAR10
7

Under review as a conference paper at ICLR 2019

Table 1: Comparison of prediction accuracies of various semi-supervised learning algorithms for the three benchmark datasets.

Method
DGN (Kingma et al., 2014) Ladder (Rasmus et al., 2015) ALI (Donahue et al., 2016) GAN with FM (Salimans et al., 2016) Bad GAN (Dai et al., 2017) VAT (Miyato et al., 2017) CrossEnt (use all data) FAT

Test acc.(%)

MNIST SVHN CIFAR10

96.67 63.98

-

98.94

-

79.6

- 92.58 82.01

99.07 91.89 81.37

99.20 95.75 85.59

98.64 93.17 85.13

98.82 96.74 90.31

98.88 95.94 85.21

(Krizhevsky & Hinton, 2009). Secondly, we conduct in-depth qualitative analyses of bad samples generated by the adversarial training. With synthetic data and real data, we visualize how well FAT generates bad samples.
6.1 PREDICTION PERFORMANCES IN SEMI-SUPERVISED LEARNING
We compare prediction performances of FAT over the three benchmark datasets with other semisupervised learning algorithms. As in done by other works, we randomly sample 100, 1000 and 4000 labeled data from the MNIST, SVHN and CIFAR10 datasets, respectively and use them as the labeled data and the rest as the unlabeled data. For fair comparison, we use the same architectures as those used in Miyato et al. (2017) and conduct ZCA preprocessing only to the CIFAR10 dataset. The optimal tuning parameters ( , ) in FAT are chosen based on the validation data accuracy. We use Adam algorithm (Kingma & Ba, 2014) to update the parameters and do not use any data augmentation techniques. The results are summarized in Table 1, which shows that FAT achieves the state-of-the-art accuracy for SVHN dataset and competitive accuracies for other datasets.
6.2 COMPUTATIONAL EFFICIENCY
Note that many other semi-supervised learning methods require additional architectures such as a pre-trained density estimation model and a generator, which needs additional computation and thus leads to slow training. In contrast, FAT only needs a discriminator and thus is superior to other competitors in terms of not only prediction power but also computational efficiency.
Upper panel of Figure 4 draws the trace plots of the test accuracies of the three methods, FAT, Bad GAN and VAT, as the epoch increases. It can be clearly seen that the test accuracies of FAT increase most fast and arrive at high accuracies with a few epochs while VAT and Bad GAN need much more epochs until the test accuracies are saturated. We do not include the trace plots of Bad GAN for the SVHN and CIFAR10 datasets since the pre-trained PixelCNN++ models for SVHN and CIFAR10 are not publicly available.
To see the computational advantage of FAT more clearly, we draw the bar plots in lower panel of Figure 4 about the number of epochs for each method to arrive at the prespecified test accuracies (98%, 90% and 80% for MNIST, SVHN and CIFAR10, respectively), which again confirms the significant computational advantage of FAT. Note that each iteration of FAT needs more computation than VAT. However, this difference is negligible since the numbers of derivatives to be calculated at
8

Under review as a conference paper at ICLR 2019
Figure 4: Trace plots of the test accuracies and number of epochs to achieve the prespecified test accuracies with the three methods for (Left) MNIST, (Middle) SVHN and (Right) CIFAR10 datasets.
Figure 5: (Left) The scatter plot of synthetic data which consist of 1000 unlabeled data (gray) and 4 labeled data for each class (red and blue with black edge). (Right) Accuracies of unlabeled data for each epochs for VAT and FAT. We use 2-layered NN with 100 hidden units each. each iteration for FAT and VAT are the same. Training Bad GAN includes training the PixelCNN++ model as well as the bad generator, which requires huge amounts of memory and times, and hence comparison of computing time of FAT and Bad GAN is meaningless. 6.3 QUALITY OF BAD SAMPLES GENERATED BY ADVERSARIAL TRAINING We investigate how `good' bad samples generated by the adversarial training are. The left panel of Figure 5 is the scatter plot of the synthetic data consisting of 1000 unlabeled and 4 labeled data in each class. The right panel of Figure 5 is the trace plot of the test accuracies of FAT and VAT which clearly shows that FAT dominates VAT in prediction accuracy. Figure 6 draws the scatter plots with generated bad samples at various epochs. We can see that bad samples move to lower density regions as the epoch increases, which amply demonstrates that the adversarial training is good at generating bad samples. To sum up, the adversarial training produces `good' bad samples, which results in superior performance of FAT. We compare bad images of the MNIST data generated by FAT and Bad GAN in Figure 7. The bad images by FAT do not look like real images and do not seem to be collapsed, which indicates that FAT consistently generates diverse and good bad samples. Bad GAN also generates diverse bad samples but some `realistic' images can be found.
9

Under review as a conference paper at ICLR 2019
(1) After 20 epochs (2) After 40 epochs (3) After 60 epochs (4) After 80 epochs Figure 6: Bad samples and classified unlabeled data by colors at the different training epochs of FAT for the data in Figure 5.
Figure 7: 100 randomly sampled bad images using (Left) FAT and (Right) Bad GAN.
7 CONCLUSION
In this paper, we propose a new method called FAT for semi-supervised learning which generates bad samples only with a given classifier. The objective function of FAT is devised to compromise the advantages of Bad GAN and VAT together, which makes FAT be faster and more accurate. In numerical experiments, we show that FAT achieves almost the state-of-the-art performances with much fewer epochs. Unlike Bad GAN which requires an additional learning phase for estimating the density of unlabeled data, FAT only needs to learn a discriminator. Hence, it could be extended without much effort to other learning problems. For example, FAT can be modified easily for recurrent neural networks and hence can be applied to sequential data. We will leave this extension as a future work. It would be useful to combine FAT with a generative approach such as Bad GAN, in particular when labeled data are extremely small. Since FAT uses only a discriminator to generate bad samples, the initial estimate of the discriminator would be important. When labeled data are extremely small, using the generator model learned by large unlabeled data would be helpful to find a good initial estimate of the discriminator.
ACKNOWLEDGMENTS This work is supported by Samsung Electronics Co., Ltd.
10

Under review as a conference paper at ICLR 2019
REFERENCES
Zihang Dai, Zhilin Yang, Fan Yang, William W Cohen, and Ruslan R Salakhutdinov. Good semisupervised learning that requires a bad gan. In Advances in Neural Information Processing Systems, pp. 6513­6523, 2017.
Jeff Donahue, Philipp Krähenbühl, and Trevor Darrell. Adversarial feature learning. arXiv preprint arXiv:1605.09782, 2016.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing systems, pp. 2672­2680, 2014a.
Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, 2014b.
Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In Advances in neural information processing systems, pp. 529­536, 2005.
Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and Ruslan R Salakhutdinov. Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580, 2012.
Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.
Diederik P Kingma, Shakir Mohamed, Danilo Jimenez Rezende, and Max Welling. Semi-supervised learning with deep generative models. In Advances in Neural Information Processing Systems, pp. 3581­3589, 2014.
Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images. Technical report, Citeseer, 2009.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pp. 1097­1105, 2012.
Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278­2324, 1998.
Lars Maaløe, Casper Kaae Sønderby, Søren Kaae Sønderby, and Ole Winther. Auxiliary deep generative models. arXiv preprint arXiv:1602.05473, 2016.
Benjamin Marlin, Kevin Swersky, Bo Chen, and Nando Freitas. Inductive principles for restricted boltzmann machine learning. In Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, pp. 509­516, 2010.
Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, Ken Nakae, and Shin Ishii. Distributional smoothing with virtual adversarial training. arXiv preprint arXiv:1507.00677, 2015.
11

Under review as a conference paper at ICLR 2019
Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial training: a regularization method for supervised and semi-supervised learning. arXiv preprint arXiv:1704.03976, 2017.
Antti Rasmus, Mathias Berglund, Mikko Honkala, Harri Valpola, and Tapani Raiko. Semi-supervised learning with ladder networks. In Advances in Neural Information Processing Systems, pp. 3546­ 3554, 2015.
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. In Advances in Neural Information Processing Systems, pp. 2234­2242, 2016.
Tim Salimans, Andrej Karpathy, Xi Chen, and Diederik P Kingma. Pixelcnn++: Improving the pixelcnn with discretized logistic mixture likelihood and other modifications. arXiv preprint arXiv:1701.05517, 2017.
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1­9, 2015.
Tijmen Tieleman and Geoffrey Hinton. Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude. COURSERA: Neural networks for machine learning, 4(2):26­31, 2012.
Jason Weston, Frédéric Ratle, Hossein Mobahi, and Ronan Collobert. Deep learning via semisupervised embedding. In Neural Networks: Tricks of the Trade, pp. 639­655. Springer, 2012.
12

Under review as a conference paper at ICLR 2019

8 APPENDIX

8.1 PROOF OF PROPOSITION 1

Proof. Without loss of generality, we assume that w x+b > 0, that is, p(y = 1|x; ) > p(y = 0|x; ). We will show that there exists > 0 such that w r(x, ) < 0. Note that

argmax KL(x, r; ) =
r,||r|| ,w r>0

w ||w||

(=:

r1)

and

argmax KL(x, r; ) = -
r,||r|| ,w r<0

w ||w||

(=:

r2).

So all we have to do is to show

KL(x, r2; ) > KL(x, r1; ).

By simple calculation we can get the following:

K L(x,

r2;

) - K L(x,

r1; )

=

-

 p(y

=

1|x;

)w

(r2

-

r1)

-

log

exp exp

w (w

(x (x

+ +

r2) r1)

+ +

b b)

 +1
+1 

.

Using the Taylor's expansion up to the third-order, we obtain the following:

log exp w (x + r) + b + 1

= log exp w x + b + 1 + p(y = 1|x; )w r

1 +

p(y

=

1|x;

)p(y

=

0|x;

)r

ww

r

2

- 1 p(y = 1|x; )p(y = 0|x; ) {p(y = 1|x; ) - p(y = 0|x; )} 6

p

wiwj wkrirj rk

i,j,k=1

+o(||r||3).

So,

exp w (x + r2) + b + 1 log exp (w (x + r1) + b) + 1

=

p(y = 1|x; )w (r2 - r1)

+

1 p(y

=

1|x;

)p(y

=

0|x;

)

{p(y

=

1|x;

)

-

p(y

=

0|x;

)}

3||w||3 + o(

3).

3

Thus, we have the following equations:

KL(x, r2; ) - KL(x, r1; )

=

1 p(y = 1|x; )p(y = 0|x; ) {p(y = 1|x; ) - p(y = 0|x; )} 3||w||3 + o( 3) 3

= C · 3 + o( 3).

Therefore, there exists such that KL(x, r2; ) > KL(x, r1; )

8.2 PROOF OF PROPOSITION 2
Proof. It suffices to show that x, x  Uktr, f (x) = f (x ) for all k = 1, ..., K. For given Uktr, there exists (x~, y~)  Ltr such that d({x~}, Uktr) < . So Uktr  {x~} is -connected. That is, for any x  Uktr, there exists a path (x~, x1, ..., xq, x) such that (x~, x1), ..., (xq, x) are all -conncected. Therefore y(x) = y(x~) = y~ for x  Uktr, and the proof is done.

13

