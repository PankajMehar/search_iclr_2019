Under review as a conference paper at ICLR 2019
EDDI: EFFICIENT DYNAMIC DISCOVERY OF HIGH-VALUE INFORMATION WITH PARTIAL VAE
Anonymous authors Paper under double-blind review
ABSTRACT
Making decisions requires information relevant to the task at hand. Many real-life decision making situations allow acquiring further relevant information at a specific cost. For example, in assessing the health status of a patient we may decide to take additional measurements such as diagnostic tests or imaging scans before making a final assessment. More information that is relevant allows for better decisions but it may be costly to acquire all of this information. How can we trade off the desire to make good decisions with the option to acquire further information at a cost? To this end, we propose a principled framework, named EDDI (Efficient Dynamic Discovery of high-value Information), based on the theory of Bayesian experimental design. In EDDI we propose a novel partial variational autoencoder (Partial VAE), to efficiently handle missing data over varying subsets of known information. EDDI combines this Partial VAE with an acquisition function that maximizes expected information gain on a set of target variables. EDDI is efficient and demonstrates that dynamic discovery of high-value information is possible; we show cost reduction at the same decision quality and improved decision quality at the same cost in benchmarks and in two health-care applications. We believe there is great potential for realizing these gains in real-world decision support systems.
1 INTRODUCTION
Imagine that a person walks into a hospital with a broken arm. The first question from health-care personnel would be: "How did you break the arm?" instead of "Do you have a cold?", because the answer reveals relevant information for this patient. Human experts dynamically acquire information based on the current understanding of the situation. Automating this human expertise of asking relevant questions is difficult. In other applications such as online questionnaires for example, most existing online questionnaire system either present exhaustive questions (Lewenberg et al., 2017; Shim et al., 2018) or use extremely time-consuming human labeling work to manually build a decision tree for a reduced number of questions (Zakim et al., 2008). This wastes the valuable time of experts or users (patients). An automated solution for personalized dynamic acquisition of information has great potential to save much of this time in many real-life applications.
What are the technical challenges to build an intelligent information acquisition system? Missing data is a key issue: taking the questionnaire scenario as an example, at any point in time we only observe a small subset of answers yet have to reason about possible answers for the remaining questions. We thus need an accurate probabilistic model that can perform inference given a variable subset of observed answers. Another key problem is deciding what to ask next: this requires assessing the worth of each possible question or measurement, the exact computation of which is intractable. However, compared to current active learning methods we select individual features, not instances; therefore, existing methods are not applicable. In addition, these traditional methods are often not scalable to the large volume of data available in many practical cases (Settles, 2012).
We propose the EDDI (Efficient Dynamic Discovery of high-value Information) framework as a scalable information acquisition system for any given task. We assume that information acquisition is always associated with cost. Given a task, such as estimating the costumers' experience or assessing population health status, we dynamically decide which piece of information to acquire next. The framework is very general, and the information can be presented in any form such as answers to questions, or values of a lab test. Our contributions are:
1

Under review as a conference paper at ICLR 2019
· We propose a novel efficient information acquisition framework, EDDI (Section 3). To enable EDDI, we contribute technically: 1. A partial amortized inference method with different specifications for the inference network (Section 3.2). We extend a current amortized inference method, the variational autoencoder (VAE) (Kingma & Welling, 2014; Rezende et al., 2014), to account for partial observations. The resulting method, which we call Partial VAE, is inspired by the set formulation of the data (Qi et al., 2017; Zaheer et al., 2017). Partial VAE, as a probabilistic framework, is highly scalable, and serves as the base for the EDDI framework. However, Partial VAE itself is generic and can be used on its own as a non-linear probabilistic framework for missing-data imputation. 2. An information theoretic acquisition function with an efficient approximation, yielding a novel variable-wise active learning method (Section 3.3). Based on the partial VAE, we select the unobserved variable which contributes most to the task, such as health assessment, evaluated using the mutual information. This acquisition function does not have an analytical solution and we derive an efficient approximation.
· We demonstrate the performance of EDDI on various settings, and apply it in real-life health-care scenarios (Section 4). 1. We first show the superior performance of the Partial VAE framework on an image inpainting task (Section 4.1). 2. We then use 7 different datasets from the Machine Learning repository of University of Irvine (UCI) (Dheeru & Karra Taniskidou, 2017) to demonstrate the behavior of EDDI, comparing with multiple baseline methods (Section 4.2). 3. Finally, we evaluate EDDI on two real-life health-care applications: risk assessment in intensive care (Section 4.3) and public health assessment with national survey (Section 4.4), where traditional methods without amortized inference do not scale. EDDI shows clear improvements in these two applications.
2 RELATED WORK
EDDI requires a method that handles partially observed data to enable dynamic variable wise active learning. We thus review related methods for handling partial observation and doing active learning.
2.1 PARTIAL OBSERVATION
Missing data entries are common in many real-life applications, which has created a long history of research on the topic of dealing with missing data (Rubin, 1976; Dempster et al., 1977). We describe existing methods below:
Traditional methods without amortization Prediction based methods have shown advantages for missing value imputation (Scheffer, 2002). Efficient matrix factorization based methods have been recently applied (Keshavan et al., 2010; Jain et al., 2010; Salakhutdinov & Mnih, 2008), where the observations are assumed to be able to decompose as multiplication of low dimensional matrices. In particular, many probabilistic frameworks with various distribution assumptions (Salakhutdinov & Mnih, 2008; Blei et al., 2003) have been used for missing value imputation (Yu et al., 2016; Hamesse et al., 2018) and also recommender systems where unlabeled items are predicted (Stern et al., 2009; Wang & Blei, 2011; Gopalan et al., 2014).
The probabilistic matrix factorization method has been used in the active variable selection framework, the dimensionality reduction active learning model (DRAL),(Lewenberg et al., 2017). These traditional methods suffer from limited model capacity since they are commonly linear. Additionally, they do not scale to large volumes of data and thus are usually not applicable in real-world applications. For example, Lewenberg et al. (2017) test the performance of their method with a single user due to the heavy computational cost of traditional inference methods for probabilistic matrix factorization.
Utilizing Amortized Inference The amortized inference (Kingma & Welling, 2014; Rezende et al., 2014; Zhang et al., 2017) has significantly improved the scalability for probabilistic models such as variational autoencoders (VAEs). In the case of partially observed data, amortized inference is particularly of interest due to the need of speeding up test time applications. Wu et al. (2018) employ
2

Under review as a conference paper at ICLR 2019

traditional non-amortized inference in order to perform partial inference of a pretrained VAE during test time. Amortized inference is only used during training, assuming the training dataset is fully observed. During test time, the traditional inference is used to infer missing data entries from the partially observed dataset using the pre-trained model. In this way, only training time is reduced. The model is restrictive since it is not scalable in the test time and the fully observed training set is not available for many applications.
Nazabal et al. (2018) uses zero imputation for amortized inference for both training and test sets with missing data entries. Zero imputation is a generic and straightforward method that first fills the missing data with zeros, and then feeds the imputed data as input for the inference network. The drawback of zero imputation is that it introduces bias when the data are not missing completely at random which leads to not well-learned model. We also observe artifacts when using it for the image inpainting task. In the end, independent of our work, Garnelo et al. (2018) explore interpreting variational autoencoder (amortized inference) as stochastic processes, which also handles partial observation per se.
2.2 ACTIVE LEARNING
Traditional Active Learning Active learning, also referred to as experimental design, aims to obtain optimal performance with fewer selected data (or experiments) (Lindley, 1956; MacKay, 1992; Settles, 2012). Traditional active learning aims to select the next data point to label. Many information theoretical approaches have shown promising results in various settings with different acquisition functions (MacKay, 1992; McCallumzy & Nigamy, 1998; Houlsby et al., 2011). These methods commonly assume that there exist fully observed data, and the acquisition decision is instance wise. Little work has dealt with missing values within instances. Zheng & Padmanabhan (2002) deal with missing data values by imputing with traditional non-probabilistic methods (Little & Rubin, 1987) first. It is still an instance-wise active learning framework.
Different from traditional active learning, our proposed framework aims to for perform variable-wise active learning for each instance. In this setting, information theoretical acquisition functions need a new design as well as non-trivial approximations. The most closely related work is the aforementioned DRAL (Lewenberg et al., 2017), which deals with variable-wise active learning for each instance.
Sequential variable selection Active sequential feature selection is of great need, especially in cost-sensitive applications. Thus, many methods have also been applied. Melville et al. (2004); Saar-Tsechansky et al. (2009) have designed objectives to select any feature from any instance to minimize the cost to archive high accuracy. The proposed framework is very general. However, the realization of these framework relies on various heuristics and suffer from limited scalability. Most recently, Shim et al. (2018) employ reinforcement learning for sequential feature selection, where an agent takes feature selection actions or stop the decision.

3 METHOD

In this section, we first formalize the active variable selection problem that we aim to solve. Then, we present our Partial VAE to model and perform inference on partial observations. Finally, we complete the EDDI framework by presenting our acquisition function and estimation method.

3.1 PROBLEM FORMULATION

The core problem that we address in this paper is the following active variable selection problem.

Let x = [x1, . . . , x|I|] be a set of random variables with probability density p(x). Furthermore, let a

subset of the variables xO, O  I, be observed while the variables xU , U = I \ O, are unobserved. We assume that we can query the value of variables xi for i  U. The goal of active variable selection

is to query a sequence of variables in U with the goal of predicting a quantity of interest f (x), as

accurately as possible while simultaneously performing as little queries as possible, where f (·) can

be any (random) function. This problem, in the simplified myopic setting, can be formalized as that

of proposing the next variable xi to be queried by maximizing a reward function R, i.e.

i = arg max R(i | xO)
iU

(1)

where R(i | xO) quantifies the merit of our prediction of f (·) given x0 and xi. Furthermore, the reward can quantify other properties important to the problem, e.g. the cost of acquiring xi.

3

Under review as a conference paper at ICLR 2019

First recurrent step

(|O|, M + 1)

e1 x1 e2 x2 ... ...
e3 x3 e4 x4

h(1) h(1) shared h(1) h(1)

g

(1, K) c(1)

concatenate

Second recurrent step

(|O|, M + 1 + K) e1 x1 c(1) e2 x2 c(1) ... ... ...
e3 x3 c(1) e4 x4 c(1)

h(2) h(2) shared h(2) h(2)

g

(1, K) c(2)

Figure 1: Illustration of recurrent PN architecture. We show the example using 2 recurrent steps. The
output c(2) is directly connected to the rest of the inference network in this case. One can use more steps. To form the input for the i + 1 recurrent step, we concatenate the c(i) to the input.

3.2 PARTIAL AMORTIZATION OF INFERENCE QUERIES

We first introduce how to establish a generative probabilistic model of random variables x, that is capable of handling unobserved (missing) variables xU with variable size. Our approach to this, named the Partial VAE, is based on the Variational autoencoder (VAE), which enables inference to scale to large volumes of data. A VAE uses a generative model (decoder) p(x, z) = p(x|z)p(z) that generates observations x given latent variables z, and an inference model (encoder) q(z|x) that infers the latent state z given data x. A VAE is trained by maximizing an evidence lower bound (ELBO),
which is equivalent to minimize the KL divergence between p and q.

VAE is not directly applicable to data with missing values. Consider a partitioning that divides the
variables into observed variables xO and unobserved variables xU . In this setting, we would like to efficiently and accurately infer p(z|xO) and p(xU |xO). One challenge in the above setting is that there are many possible partitioning of {U, O}. Therefore, classic approaches to train a VAE with
variational bound and amortize inference networks are no longer directly applicable. We propose to
extend amortization to our partial inference situation.

Partial VAE In a VAE, we assume a factorized structure for p(x|z), i.e.

p(x|z) =  pi(xi|z). i

(2)

This implies that given z, the observed variables xO are conditionally independent of xU . Therefore,

p(xU |xO, z) = p(xU |z),

(3)

and inferences about xU can be reduced to inference about z. Therefore, the key object of interest in this setting is p(z|xO), i.e., the posterior over the shared latent variables z given the observed
variables xO. Once knowledge about z is obtained, we can draw correct inferences about xU . To approximate p(z|xO) we introduce an auxiliary variational inference network q(z|xO) and define a
partial variational upper bound,

DKL(q(z|xO) p(z|xO)) = Ezq(z|xO)[log q(z|xO) - log p(z|xO)]
 Ezq(z|xO)[log q(z|xO) - log p(xO|z) - log p(z)]  Lp. (4)
This bound, Lp, depends only on the observation xO, which could vary between different data points. We call the auxiliary distribution q(z|xO) the partial inference net since it takes a set of partially observed variables xO whose length may vary. Specifying q(z|xO) requires distribution over random partitioning {O,U}.

Amortized Inference with partial observations Inspired by the Point Net (PN) approach for point
cloud classification (Qi et al., 2017; Zaheer et al., 2017), we specify the approximate distribution q(z|xO) by a permutation invariant set function encoding, given by:

c(xO) := g(h(s1), h(s2), ..., h(s|O|)),

(5)

where |O| is the number of the observed variables, sd = [ed, xd], ed is the indicator vector of the dth feature. There are many ways to define ed. Naively, it could be the coordinates for points in the point cloud, and one-hot embedding of the number of questions in a questionnaire. With different problem
settings, it can be beneficial to learn e as an embedding of the identity of the variable, either with

4

Under review as a conference paper at ICLR 2019

or without an naive encoding as input. In this work, we treat e as an unknown embedding, which is optimized during training process.
We use a neural network h(·) to map input s from RM+1 to RK, where M is the dimension of each ed, xd is a scalar, and K is the latent space size. Key to the PN structure is the permutation invariant aggregation operation g(·), such as max-pooling or summation. In this way, the mapping c(xO) is invariant to permutations of elements of xO and xO can have arbitrary length. Finally, the fixed-size code c(xO) is fed into an ordinary amortized inference net, that transforms the code into the statistics of a multivariate Gaussian distribution to approximate p(z|xO). The procedure is illustrated in the first dashed box in Figure 1, which is our basic Partial VAE method.
We further generalize this basic Partial VAE method in two ways: First, we generalize the specification of the input s. Existing set based methods construct input s as the concatenation of the feature value and feature identity embedding. We propose to construct s = ed  xd instead of concatenation. This formulation generalizes naive Zero Imputation (ZI) VAE (Nazabal et al., 2018) and the aforementioned Point net parameterizations (PN) Partial VAE. We call this approach Pointnet Plus (PNP) specification of Partial VAE. The theoretical consideration of relating ZI to PNP is presented in Appendix C.1.
Moreover, we generalize PN and PNP by recurrently reuse the code c to enlarge the capacity of PN. Figure 1 shows the mechanism of the recurrent PN with two recurrent steps using concatenated s(1)d = [ed, xd] as an example. The first step is the same as the PN setting with the K dimensional output c(1), where (1) is the recurrent step index. For the second step, we concatenate the learned c(1) to s(1) to form the new input for the next recurrent step s(2)d = [s(1)d, c(1)]. There can be arbitrary number of recurrent steps using the input s(n)d = [s(n-1)d, c(n-1)]. Within each recurrent step, the parameters for the neural network h(n) are shared, however, different steps have different parameters. When n = 1, we recover the basic PN partial VAE setting. Thus, for the rest of the paper, when using PN, we will be always referring to our recurrent generalization.

3.3 EFFICIENT DYNAMIC DISCOVERY OF HIGH-VALUE INFORMATION

We now cast the active variable selection problem (1) as adaptive Bayesian experimental design, utilizing p(xU |xO) inferred by Partial VAE. Algorithm 1 summarize the EDDI framework.

Information Reward We designed a variable selection acquisition function in an information theoretical way following Bayesian experimental design (Lindley, 1956; Bernardo, 1979). Lindley (1956) provides a generic formulation of Bayesian experimental design by maximizing the expected Shannon information. Bernardo (1979) generalizes it by considering the decision task context.
For a given task, we may be interested in statistics of some variables x , where x  xU . Given a new instance (user), assume we have observed xO so far for this instance, and we need to select the next variable xi (an element of xU\ ) to observe. Following Bernardo (1979), We select xi by maximizing:

R(i, xO) = Exip(xi|xO)DKL p(x |xi, xO) p(x |xO) .

(6)

In our paper, we mainly consider the case that a subset of interesting observations represents the
statistics of interest x . Sampling xi  p(xi|xo) is approximated by xi  p^(xi|xo), where p^(xi|xo) is defined by the following process in Partial VAE. It is implemented by first sampling z  q(z|xo), and then xi  p(xi|z). The same applies for p(xi, x |z) appeared in Equation 9.

Efficient approximation of the Information reward The Partial VAE allows us to sample xi  p(xi|xo). However, the KL term in Equation 6,

DKL

p(x |xi, xo)||p(x |xo)

=-

x

p(x |xi, xo) log

p(x |xo) , p(x |xi, xo)

(7)

is intractable to evaluate since both p(x |xi, xo) and p(x |xo) are intractable. For high dimensional x , entropy estimation could be difficult. The entropy term x p(x |xi, xo) log p(x |xi, xo) depends
on i hence cannot be ignored. In the following, we show how to approximate this expression.

Our proposal is based on the observation that analytic solutions of KL-divergences are available under specific variational distribution families of q(z|xO) (such as the Gaussian distribution commonly used in VAEs). Instead of calculating information reward in x space, we have shown that one can

5

Under review as a conference paper at ICLR 2019

Algorithm 1 EDDI: Algorithm Overview
Require: Training dataset xtrn, which is partially observed; Test dataset xtst without any observation; Indices  of target variables.
1: Train Partial VAE by optimizing partial variational bound with xtrn (cf. Section 3.2) 2: Actively acquire feature value xi to estimate x for each test point (cf. Section 3.3)
for each test instance do xO  0/ (no variable value has been observed for any test point) repeat Choose variable xi from U \  to maximize the information reward (Equation 9) xO  xi  xO until Stopping criterion reached (e.g. the time budget)
end for

Table 1: Comparing models trained on partially observed MNIST. VAE-full is an ideal reference.

Method
Train ELBO Test ELBO (Rnd) Test ELBO (Reg)

VAE-full
-95.05 -101.46 -101.46

ZI
-113.64 -116.01 -130.61

ZI-m
-117.29 -118.61 -123.87

PN
-126.30 -125.37 -128.02

PNP
-113.64 -114.01 -113.19

equivalently perform calculations in z space (cf. Appendix A.1):

R(i, xo) = Exip(xi|xo)DKL [p(z|xi, xo)||p(z|xo)] - Ex ,xip(x ,xi|xo)DKL p(z|x , xi, xo)||p(z|x , xo) .

(8)

Note that Equation 8 is exact. Additionally, we use partial VAE approximation p(z|x , xi, xo)  q(z|x , xi, xo), p(z|xo)  q(zi|xo) and p(z|xi, xo)  q(zi|xi, xo). This leads to the final approximation
of the information reward:

R^(i, xo) =Exip^(xi|xo)DKL [q(z|xi, xo)||q(z|xo)] - Ex ,xip^(x ,xi|xo)DKL q(z|x , xi, xo)||q(z|x , xo) .

(9)

With this approximation, the divergence between q(z|xi, xo) and q(z|xo) can often computed analytically in Partial VAE setting, for example, under Gaussian parameterization. The only Monte Carlo sampling required is the one set of samples x , xi  p(x , xi|xo) that can be shared across different KL terms in Equation 9.

4 EXPERIMENTS

We evaluate our proposed EDDI framework with various settings. We first assess the Partial VAE component of EDDI alone on an image inpainting task both qualitatively and quantitatively (Section 4.1). We compare our proposed two PN-based Partial VAE with the zero-imputing (ZI) VAE (Nazabal et al., 2018). We use 5 recurrent steps for PN setting, and 1 recurrent steps for PNP setting to report, as they provide the best performance (cf. Appendix B.1). The same applies in the rest of the paper. Additionally, we modify ZI VAE to use s mask matrix indicating which variables are currently observed as input. We name this method ZI-m VAE.
We then demonstrate the performance of the entire EDDI framework on datasets from the UCI repository (Section 4.2 ), as well as in two real-life application scenarios: Risk assessment in intensive care (Section 4.3) and public health assessment with national health survey (Section 4.4). We compare the performance of EDDI, using four different Partial VAE settings, with two baselines. The first baseline is the random active feature selection strategy (denoted as RAND) which randomly picks the next variable to observe. The second baseline method is the single best strategy (denoted as SING) which finds a single global optimal order of picking up variables. This order is then applied to all data points. SING uses the objective function as in Equation (9) to find the optimal ordering by averaging over all the data.
4.1 IMAGE INPAINTING WITH PARTIAL VAE
Inpaint Random Missing Values We demonstrate our method using a partially observed MNIST dataset (LeCun, 1998). The same setting are used for all methods (see Appendix B.1 for details).

6

Under review as a conference paper at ICLR 2019

(a) Input

(b) ZI

(c) ZI-m

(d) PN

(e) PNP

Figure 2: Image inpainting example with MNIST dataset using Partial VAE with four settings.

(a) Boston Hosing

(b) Energy

(c) Wine

Figure 3: Information curves of active variable selection, demonstrated on three UCI datasets (based
on PNP parameterization of Partial VAE). This displays negative test log likelihood (y axis, the lower the better) during the course of active selection (x.-axis).

During training, We remove a random portion (uniformly sampled between 0% and 70%) of pixels. The first two rows in Table 1 show training and test ELBOs for all algorithms using this partially observed MNIST dataset. Additionally, we show ordinary VAE (VAE-full) trained on the fully observed dataset as an ideal reference. Among all Partial VAE methods tested, the PNP approach performs best.
Inpaint Regions We then consider inpainting large contiguous regions of images. It aims to evaluate the capability of the Partial VAEs to produce all possible outcomes with well-calibrated uncertainties. With the same trained model as before, we remove the region of the upper 60% pixels of the image in the test set. We then evaluate the average likelihoods of the models. The last row of Table 1 shows the results of the test ELBO in this case. PNP based Partial VAE performs better than other settings. Given only the lower half of a digit, the number cannot be identified uniquely. ZI (Figure 2(b)) fails to cover the different possible modes due to its limitation in posterior inference. ZI-m (Figure 2(c)) is capable of producing multiple modes. However, some of the generated samples are not consistent with the given part (i.e., some digits of 2 are generated). Our proposed PN (Figure 2(d)) and PNP Figure 2(e)) are capable of recovering different modes, and are consistent with observations.
4.2 EDDI ON UCI DATASETS
Given the effectiveness of our proposed Partial VAE, we now demonstrate the performance of our proposed EDDI framework in comparison with random selection (RAND) and single optimal ordering (SING). We first apply EDDI on 6 different UCI datasets (cf. Appendix B.2) (Dheeru & Karra Taniskidou, 2017). We report the results of EDDI with all these four different specifications of Partial VAE (ZI, ZI-m, PN, PNP).
All Partial VAE are first trained on partially observed UCI datasets where a random portion of variables is removed. We actively select variable for each test point starting with empty observation xo = 0/ . In all UCI datasets, We randomly sample 10% of the data as the test set. All experiments repeated for ten times.
Taking PNP based setting as an example, Figure 3 shows the negative test log likelihood on x for each variable selection step with three different datasets, where x is defined by the UCI task. We call this curve the information curve (IC). We see that EDDI can obtain information efficiently. It archives the same negative test log likelihood with less than half of the variables. Single optimal

7

Under review as a conference paper at ICLR 2019

Table 2: Average ranking of AUIC over 6 UCI datasets.

Method
EDDI Random Single best

ZI
4.75 (0.02 ) 7.12 (0.03 ) 8.00 (0.02 )

ZI-m
4.60 (0.02 ) 7.22 (0.03 ) 7.78 (0.02 )

PNP
4.42 (0.02 ) 6.97 (0.03 ) 7.68 (0.02 )

PN
4.55 (0.02) 7.08 (0.03 ) 7.77 (0.02 )

Method Time
DRAL 2747.16 EDDI 2.64

Figure 4: First four decision steps on Boston Housing test data. EDDI is "personalized" comparing SING. Full names of the variables are listed in the Appendix B.2.

Figure 5: Comparison of DRAL (Lewenberg et al., 2017) and EDDI on Boston Housing dataset. EDDI out performs DRAL significantly regarding test log likelihood in every step.

Table 3: Test CPU time (in seconds) per test point for active variable selection using EDDI and DRAL. EDDI is 103 times more computation efficient than DRAL (Lewenberg et al., 2017).

ordering also improves upon random ordering. However, it is less efficient compared with EDDI since EDDI perform active learning for each data instance which is "personalized". Figure 4 shows an example of the decision processes using EDDI and SING. The first step of EDDI overlaps largely with SING. From the second step, EDDI makes "personalized" decisions.

We also present the average performance among all datasets with different settings. The area under

the information curve (AUIC), t - log p(x |xOt ), can then be used to compare the performance across models and strategies. Smaller AUIC value (could be positive or negative) indicates better

performance. We present the AUIC for each dataset in Appendix B.2.2. However, due to different

datasets have different scales of test likelihoods and different numbers of variables (indicated by

steps), it is not fair to average the AUIC across datasets to compare overall performances. We thus

defining average ranking of AUIC compares 12 methods (indexed by i) averaging these datasets as:

ri

=

1 j Nj

7j=1

Nj
k=1

ri

jk

,

i = 1, .., 12. These 12 methods are with cross combinations of four Partial

VAE models with three variable selection strategies. ri is the final ranking of ith combination, ri jk

is the ranking of the ithe combination (based on AUIC value) regarding the kth test data point in

the jth UCI dataset, and Nj the size of the jth UCI dataset. Table 2 summarize the average ranking results. EDDI outperforms other variable selection order in all different Partial VAE settings. Among

different partial VAE settings, PN-based settings perform better than ZI-based settings.

Compare with non-amortized methodAdditionally, we compare EDDI to DRAL (Lewenberg et al., 2017) which is the state-of-the-art method with the same problem setting. As discussed in Section 2, DRAL is linear and requires high computational cost. The DRAL paper only tested their method on a single test data point due to its limitation on computational efficiency. We compare DRAL with EDDI on Boston Housing dataset with ten randomly selected test points here. Results are shown in Figure 5, where EDDI significantly outperforms DARL thanks to more flexible Partial VAE model. Additionally, EDDI is 1000 times more efficient than DARL as shown in Table 3.

4.3 RISK ASSESSMENT WITH MIMIC-III

We now apply EDDI to risk assessment tasks using the Medical Information Mart for Intensive Care (MIMIC III) database (Johnson et al. (2016)). MIMIC III is the most extensive publicly available clinical database, containing real-world records from over 40,000 critical care patients with 60,000 ICU stays. The risk assessment task is to predict the final mortality. We preprocess the data for this task following Harutyunyan et al. (2017) 1. This results in a dataset of 21139 patients. We treat the final mortality of a patient as a Bernoulli variable. For our task, we focus on variable selection, which corresponds to medical instrument selection. We thus further process the time series variables into static variables based on temporal averaging.

1https://github.com/yerevann/mimic3-benchmarks

8

Under review as a conference paper at ICLR 2019

Figure 6: Information curves of active variable selection on risk assessment task on MIMIC III, produced with PNP setting.

Figure 7: Information curves of active (grouped) variable selection on risk assessment task on NHANES, produced with PNP setting.

Method
ZI ZI-m PN5 PNP

EDDI
5.20 (0.01) 5.54 (0.01) 5.93 (0.01) 4.99 (0.01)

Random
6.95 (0.02) 7.75 (0.01) 8.31 (0.01) 7.60 (0.01)

Single best
6.20 (0.01) 6.54 (0.01) 6.93 (0.01) 5.99 (0.01)

Table 4: Average ranking on AUIC of MIMIC III

Method
ZI ZI-m PN5 PNP

EDDI
6.12 (0.13) 7.82 (0.14) 5.13 (0.15) 4.21 (0.12)

Random
8.56 (0.13) 8.75 (0.13) 6.33 (0.14) 5.21 (0.13)

Single best
6.52 (0.11) 8.80 (0.14) 5.42 (0.15) 5.09 (0.12)

Table 5: Average ranking on AUIC of NHANES

Figure 6 shows the information curve of different strategies, using PNP based Partial VAE as an example (more results in Appendix B.3). Table 4 shows the average ranking of AUIC with different settings. In this application, EDDI significantly outperforms other variable selection strategies in all different settings of Partial VAE, and PNP based setting performs best.
4.4 PUBLIC HEALTH ASSESSMENT WITH NHANES
Finally, we apply our methods to public health assessment using NHANES 2015-2016 data cdc (2005). NHANES is a program with adaptable components of measurements, to assess the health and nutritional status of adults and children in the United States. Every year, approximately thousands individuals of all ages are interviewed in their homes and complete the health examination component of the survey. This 2015-2016 NHANES data contains three major sections, the questionnaire interview, examinations and lab tests for 9971 subjects in the publicly available version of this cycle. In our setting, we consider the whole set of lab test results (139 dimensions of variables) as the target variable of interest x since they are expensive and reflects the subject's health status, and we active select the questions from the extensive questionnaire (665 variables).
In NHANES, the entire questionnaire is divided into 73 different groups. In practice, questions in the same group are often examined together. Therefore, we perform active variable selection on the group level: at each step, the algorithm will be selecting one group to observe. This is more challenging than the experiments in previous sections since it requires the generative model to simulate a group of unobserved data in Equation (9) at the same time. When evaluating test likelihood on the target variable of interest, we treat variables in each group equally. For a fair comparison, the calculation of the area under the information curve (AUIC) is weighted by the size of the group chosen by the algorithms. Specifically, AUIC is calculated after spline interpolation. The information curve plots in Figure 7, together with Table 5 of AUIC statistics show that our EDDI outperforms other baselines. This experiment shows that EDDI is capable of performing active selection on a large pool of grouped variables to estimate a high dimensional target.
5 CONCLUSION
In this paper, we present EDDI, a novel and efficient framework for dynamic active variable selection for each instance. Within the EDDI framework, we propose Partial VAE which performs amortized inference to handle missing data. Partial VAE alone can be used as a non-linear computational efficient probabilistic imputation method. Based on Partial VAE, we design a variable wise acquisition function for EDDI and derived corresponding approximation method. EDDI has demonstrated its effectiveness on active variable selection tasks across multiple real-world applications. In the future, we would extend the EDDI framework to handle more complicated scenarios, such as time-series, or the cold-start situation.

9

Under review as a conference paper at ICLR 2019
REFERENCES
National health and nutrition examination survey, 2005. URL https://www.cdc.gov/nchs/ nhanes/.
José M Bernardo. Expected information as expected utility. The Annals of Statistics, pp. 686­690, 1979.
David M Blei, Andrew Y Ng, and Michael I Jordan. Latent dirichlet allocation. Journal of Machine Learning Research, 3(Jan):993­1022, 2003.
Arthur P Dempster, Nan M Laird, and Donald B Rubin. Maximum likelihood from incomplete data via the em algorithm. Journal of the Royal Statistical Society. Series B (methodological), pp. 1­38, 1977.
Dua Dheeru and Efi Karra Taniskidou. UCI machine learning repository, 2017. URL http: //archive.ics.uci.edu/ml.
Marta Garnelo, Dan Rosenbaum, Chris J Maddison, Tiago Ramalho, David Saxton, Murray Shanahan, Yee Whye Teh, Danilo J Rezende, and SM Eslami. Conditional neural processes. arXiv preprint arXiv:1807.01613, 2018.
Prem K Gopalan, Laurent Charlin, and David Blei. Content-based recommendations with poisson factorization. In Advances in Neural Information Processing Systems, pp. 3176­3184, 2014.
Charles Hamesse, Paul Ackermann, Hedvig Kjellström, and Cheng Zhang. Simultaneous measurement imputation and outcome prediction for achilles tendon rupture rehabilitation. In ICML/IJCAI Joint Workshop on Artificial Intelligence in Health, 2018.
Hrayr Harutyunyan, Hrant Khachatrian, David C Kale, and Aram Galstyan. Multitask learning and benchmarking with clinical time series data. arXiv preprint arXiv:1703.07771, 2017.
Neil Houlsby, Ferenc Huszár, Zoubin Ghahramani, and Máté Lengyel. Bayesian active learning for classification and preference learning. arXiv preprint arXiv:1112.5745, 2011.
Prateek Jain, Raghu Meka, and Inderjit S Dhillon. Guaranteed rank minimization via singular value projection. In Advances in Neural Information Processing Systems, 2010.
Alistair EW Johnson, Tom J Pollard, Lu Shen, H Lehman Li-wei, Mengling Feng, Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G Mark. Mimic-iii, a freely accessible critical care database. Scientific Data, 3:160035, 2016.
Raghunandan H Keshavan, Andrea Montanari, and Sewoong Oh. Matrix completion from noisy entries. Journal of Machine Learning Research, 2010.
Diederik P. Kingma and Jimmy Lei Ba. Adam: a method for stochastic optimization. In International Conference on Learning Representations, pp. 1­13, 2015.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. In International Conference on Learning Representation, 2014.
Yann LeCun. The mnist database of handwritten digits. http://yann. lecun. com/exdb/mnist/, 1998.
Yoad Lewenberg, Yoram Bachrach, Ulrich Paquet, and Jeffrey S Rosenschein. Knowing what to ask: A bayesian active learning approach to the surveying problem. In AAAI, pp. 1396­1402, 2017.
Dennis V Lindley. On a measure of the information provided by an experiment. The Annals of Mathematical Statistics, pp. 986­1005, 1956.
RJA Little and DB Rubin. Statistical analysis with missing data. Technical report, J. Wiley, 1987.
David JC MacKay. Information-based objective functions for active data selection. Neural computation, 4(4):590­604, 1992.
10

Under review as a conference paper at ICLR 2019
Andrew Kachites McCallumzy and Kamal Nigamy. Employing em and pool-based active learning for text classification. In International Conference on Machine Learning, pp. 359­367. Citeseer, 1998.
Prem Melville, Maytal Saar-Tsechansky, Foster Provost, and Raymond Mooney. Active feature-value acquisition for classifier induction. In International Conference on Data Mining, pp. 483­486. IEEE, 2004.
Alfredo Nazabal, Pablo M Olmos, Zoubin Ghahramani, and Isabel Valera. Handling incomplete heterogeneous data using vaes. arXiv preprint arXiv:1807.03653, 2018.
Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas. Pointnet: Deep learning on point sets for 3d classification and segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 652­660, 2017.
Rajesh Ranganath, Dustin Tran, and David Blei. Hierarchical variational models. In International Conference on Machine Learning, pp. 324­333, 2016.
Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate inference in deep generative models. In Interantional Conference on Machine Learning, 2014.
Donald B Rubin. Inference and missing data. Biometrika, 63(3):581­592, 1976.
Maytal Saar-Tsechansky, Prem Melville, and Foster Provost. Active feature-value acquisition. Management Science, 55(4):664­684, 2009.
Ruslan Salakhutdinov and Andriy Mnih. Bayesian probabilistic matrix factorization using markov chain monte carlo. In International conference on Machine learning, pp. 880­887. ACM, 2008.
Judi Scheffer. Dealing with missing data. 2002.
Burr Settles. Active learning. Synthesis Lectures on Artificial Intelligence and Machine Learning, 6 (1):1­114, 2012.
Hajin Shim, Sung Ju Hwang, and Eunho Yang. Joint active feature acquisition and classification with variable-size set encoding. In Advances in Neural Information Processing Systems, 2018.
David Stern, Ralf Herbrich, and Thore Graepel. Matchbox: Large scale bayesian recommendations. In International World Wide Web Conference, 2009.
Chong Wang and David M Blei. Collaborative topic modeling for recommending scientific articles. In International Conference on Knowledge Discovery and Data Mining, pp. 448­456. ACM, 2011.
Ga Wu, Justin Domke, and Scott Sanner. Conditional inference in pre-trained variational autoencoders via cross-coding. arXiv preprint arXiv:1805.07785, 2018.
Hsiang-Fu Yu, Nikhil Rao, and Inderjit S Dhillon. Temporal regularized matrix factorization for high-dimensional time series prediction. In Advances in Neural Information Processing Systems, pp. 847­855, 2016.
Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan R Salakhutdinov, and Alexander J Smola. Deep sets. In Advances in Neural Information Processing Systems, pp. 3394­3404, 2017.
David Zakim, Niko Braun, Peter Fritz, and Mark Dominik Alscher. Underutilization of information and knowledge in everyday medical practice: Evaluation of a computer-based solution. BMC Medical Informatics and Decision Making, 8(1):50, 2008.
Cheng Zhang, Judith Butepage, Hedvig Kjellstrom, and Stephan Mandt. Advances in variational inference. arXiv preprint arXiv:1711.05597, 2017.
Zhiqiang Zheng and Balaji Padmanabhan. On active learning for data acquisition. In International Conference on Data Mining, pp. 562­569. IEEE, 2002.
11

Under review as a conference paper at ICLR 2019
A ADDITIONAL DERIVATIONS
A.1 INFORMATION REWARD APPROXIMATION
In our paper, given the VAE model p(x|z) and a partial inference network q(z|xo), the experimental design problem is formulated as maximization of the information reward:
R(i, xo) = Exip(xi|xo)[DKL(p(x |xi, xo)||p(x |xo))] Where p(x |xi, xo) = z p(x |z)q(z|xi, xo), p(x |xo) = z p(x |z)q(z|xo) and q(z|xo) are approximate condition distributions given by partial VAE models. Now we consider the problem of directly approximating R(i, xo). Applying the chain rule of KL-divergence, we have:
DKL(p(x |xi, xo)||p(x |xo)) = DKL(p(x , z|xi, xo)||p(x , z|xo)) - Ex p(x |xi,xo) DKL(p(z|x , xi, xo)||p(z|x , xo)) ,
Using again the KL-divergence chain rule on DKL(p(x , z|xi, xo)||p(x , z|xo)), we have: DKL(p(x , z|xi, xo)||p(x , z|xo)) = DKL(p(z|xi, xo)||p(z|xo)) + DKL(p(x |z, xi, xo)||p(x |z, xo)) = DKL(p(z|xi, xo)||p(z|xo)) + DKL(p(x |z)||p(x |z)) = DKL(p(z|xi, xo)||p(z|xo)).
The KL-divergence term in the reward formula is now rewritten as follows, DKL(p(x |xi, xo)||p(x |xo)) = DKL(p(z|xi, xo)||p(z|xo)) - Ex p(x |xi,xo) DKL(p(z|x , xi, xo)||p(z|x , xo)) .
One can then plug in the partial VAE inference approximation: p(z|x , xi, xo)  q(z|x , xi, xo), p(z|xi, xo)  q(z|xi, xo), p(z|xo)  q(z|xo)
Finally, the information reward is now approximated as: R(i, xo)  Exip(xi|xo) [DKL(q(z|xi, xo)||q(z|xo))] - Exip(xi|xo)Ex p(x |xi,xo) DKL(q(z|x , xi, xo)||q(z|x , xo)) = Exip(xi|xo) [DKL(q(z|xi, xo)||q(z|xo))] - Ex ,xip(x ,xi|xo) DKL(q(z|x , xi, xo)||q(z|x , xo)) = R^(i, xo).
This new objective tries to maximize the shift of belief on latent variables z by introducing xi, while penalizing the information that cannot be absorbed by x (by the penalty term DKL(q(z|x , xi, xo)||q(z|x , xo))). Moreover, it is more computationally efficient since one set of samples x , xi  p(x , xi|xo) can be shared across different terms, and the KL-divergence between common parameterizations of encoder (such as Gaussians and normalizing flows) can be computed exactly without the need for approximate integrals. Note also that under approximation
p(z|x , xi, xo)  q(z|x , xi, xo), p(z|xi, xo)  q(z|xi, xo), p(z|xo)  q(z|xo) , sampling xi  p(xi|xo) is approximated by xi  p^(xi|xo), where p^(xi|xo) is defined by the following process in Partial VAE. It is implemented by first sampling z  q(z|xo), and then xi  p(xi|z). The same applies for p(xi, x |z).
B ADDITIONAL EXPERIMENTAL RESULTS
B.0.1 PN/PNP MODEL STRUCTURE DETERMINATION USING MNIST
In this section, we briefly discuss how we specify the model structure of our two PN-based model, PN and PNP. We focus on choosing the recurrent steps for recurrent PN and recurrent PNP (shown in Figure 1). For this purpose, we perform plot runs of PN1, PN2, PN5, PNP1, PNP1, PNP2, PNP5
12

Under review as a conference paper at ICLR 2019
Figure 8: Negative test log likelihoods of pilot runs for (recurrent) PN-based methods on MNIST dataset. we perform plot runs of PN1, PN2, PN5, PNP1, PNP1, PNP2, PNP5 (PN-x stands for x recurrent steps of PN) on MNIST dataset for 300 iterations.All curves has been smoothed for clear comparison.
(PN-x stands for PN model with x recurrent steps) on MNIST dataset for 300 iterations. Other model settings are consistent with Section B.1.1. Results of negative test log likelihoods are shown in Figure 8: Based on Figure 8, the conclusion is clear that by increasing the recurrent steps of PN, the performance is increased. Therefore, for the rest of paper, we choose PN5 as the PN model structure. Meanwhile, we can observe that increasing the recurrent steps does not significantly improve PNP. Therefore, we will use PNP1 as our PNP structure in the rest of our paper. B.1 IMAGE INPAINTING B.1.1 PREPROCESSING AND MODEL DETAILS For our MNIST experiment, we randomly draw 10% of the whole data to be our test set. Partial VAE models (ZI, ZI-m, PNP and PNs) share the same size of architecture with 20 dimensional diagonal Gaussian latent variables: the generator (decoder) is a 20-200-500-500 fully connected neural network with ReLU activations (where D is the data dimension, D = 784). The inference nets (encoder) share the same structure of D-500-500-200-40 that maps the observed data into distributional parameters of the latent space. For the PN-based parameterizations, we use a 500 dimensional feature mapping h parameterized by a single layer neural network, and 20 dimensional ID vectors ei (see Section 3.2) for each variable. We choose the symmetric operator g to be the basic summation operator. During training, we apply Adam optimization (Kingma & Ba, 2015) with default hyperparameter setting, learning rate of 0.001 and a batch size of 100. We generate partially observed MNIST dataset by adding artificially missingness at random in the training dataset during training. We first draw a missing rate parameter from a uniform distribution U (0, 0.7) and randomly choose variables as unobserved. This step is repeated at each iteration. We train our models for 3K iterations. B.1.2 IMAGE GENERATION OF PARTIAL VAES B.2 UCI DATASETS We applied EDDI on 6 UCI datasets; Boston Housing, Concrete compressive strength, energy efficiency, wine quality, Kin8nm, and Yacht Hydrodynamics. The variables of interest x are chosen to be the target variables of each UCI dataset in the experiment.
13

Under review as a conference paper at ICLR 2019

(a) (b) (c) (d)
Figure 9: Random images generated using (a) naive zero imputing, (b) zero imputing with mask, (c) point net 5 and (d) PNP, respectively.

B.2.1 PREPROCESSING AND MODEL DETAILS

All data are normalized and then scaled between 0 and 1. For each of the 10 - in total- repetitions, we randomly draw 10% of the data to be our test set. Partial VAE models (ZI, ZI-m, PNP and PNs) share the same size of architecture with 10 dimensional diagonal Gaussian latent variables: the generator (decoder) is a 10-50-100-D neural network with ReLU activations (where D is the data dimensions). The inference nets (encoder) share the same structure D-100-50-20 that maps the observed data into distributional parameters of the latent space. For the PN-based parameterizations, we further use a 20 dimensional feature mapping h parameterized by a single layer neural network and 10 dimensional ID vectors ei (please refer to section 3.2) for each variable. We choose the symmetric operator g to be the basic summation operator.

As in the image inpainting experiment, we apply Adam optimization during training with default hyperparameter setting, and a batch size of 100 and ingest random missingness as before. We trained our models for 3K iterations.

During active learning, we draw 50 samples in order to estimate the expectation under x , xi 

p(x , xi|xo) in Equation (8). Negative likelihoods of the target variable is also estimated using 50

samples

of

x



p(x

|xo)

through

p(x

|xo)



1 M

mM=1

p(x

|zm),

where

zm



q(z|xo).

B.2.2 TABLES ON AREA UNDER THE INFORMATION CURVE (AUIC)

The area under the information curve (AUIC) on each dataset can then be used to compare the performance across models and strategies. AUIC is defined to be t - log p(x |xOt ), where xOt is the basket of variables observed at step t. By definition, smaller AUIC value (could be positive or
negative) indicates better performance. We present the AUIC for each dataset in Table 6, 7, 8, 9, 10,
and 11.

Table 6: Average AUIC over Boston Housing dataset

Method
EDDI Random Single best

ZI
-25.03 (0.09 ) -23.85 (0.14 ) -24.77 (0.12 )

ZI-m
-24.74 (0.15 ) -24.52 (0.08 ) -23.62 (0.20 )

PNP
-24.49 (0.24 ) -23.36 (0.18 ) -23.71 (0.15 )

PN
-24.54 (0.10) -23.43 (0.14 ) -23.82 (0.17 )

Table 7: Average AUIC over Concrete dataset

Method
EDDI Random Single best

ZI
-12.07 (0.04 ) -11.00 (0.09 ) -12.03 (0.06 )

ZI-m
-12.07 (0.05 ) -12.03 (0.03 ) -11.13 (0.10 )

PNP
-12.09 (0.07 ) -11.17. (0.07 ) -12.07 (0.06 )

PN
-12.15 (0.06) -12.07 (0.06 ) -12.11 (0.04 )

14

Under review as a conference paper at ICLR 2019

Method
EDDI Random Single best

Table 8: Average AUIC over Energy dataset

ZI
-13.63 (0.06 ) -9.89 (0.15 ) -12.79 (0.07 )

ZI-m
-14.56 (0.07 ) -14.53 (0.06 ) -11.62 (0.08 )

PNP
-14.49 (0.06 ) -11.49. (0.16 ) -14.36 (0.09 )

PN
-14.65 (0.08) -11.67 (0.17 ) -14.56 (0.08 )

Method
EDDI Random Single best

Table 9: Average AUIC over Wine dataset

ZI
-14.24 (0.06 ) -11.07 (0.20 ) -13.85 (0.10 )

ZI-m
-15.04 (0.02 ) -15.10 (0.05 ) -12.55 (0.10 )

PNP
-15.04 (0.05 ) -12.38 (0.9 ) -15.02 (0.05 )

PN
-15.13 (0.05) -12.57 (0.14 ) -14.99 (0.03 )

Table 10: Average AUIC over kin8nm dataset

Method
EDDI Random Single best

ZI
-20.31 (0.02 ) -19.40 (0.04 ) -20.28 (0.02 )

ZI-m
-20.25 (0.01 ) -20.24 (0.02 ) -19.35 (0.04 )

PNP
-20.18 (0.04 ) -19.29 (0.04 ) -20.23 (0.03 )

PN
-20.20 (0.02) -19.41 (0.02 ) -20.19 (0.01 )

Method
EDDI Random Single best

Table 11: Average AUIC over Yacht dataset

ZI
-14.37 (0.02 ) -12.83 (0.03 ) -14.43 (0.03 )

ZI-m
-14.50 (0.02 ) -14.50 (0.02 ) -12.91 (0.03 )

PNP
-14.57 (0.02 ) -13.03 (0.04 ) -14.57 (0.02 )

PN
-14.53 (0.02) -12.93 (0.04 ) -14.50 (0.03 )

B.2.3 ADDITIONAL PLOTS OF PN, ZI AND ZI-M ON UCI DATASETS
Here we present additional plots of the information curve at we actively choose the variables to consider. Figure 10 presents the results for the Boston Housing, the Energy and the Wine datasets and for the three approaches, i.e. PN, ZI and masked ZI.
15

Under review as a conference paper at ICLR 2019

Boston Housing

Energy

Wine

Figure 10: Information curves of active variable selection for the three UCI datasets and the three approaches, i.e. (First row) PointNet (PN), (Second row) Zero Imputing (ZI), and (Third row) Zero Imputing with mask (ZI-m). Green: random strategy; Black: EDDI; Pink: Single best ordering. This displays negative test log likelihood (y axis, the lower the better) during the course of active selection (x-axis).
B.2.4 ILLUSTRATION OF DECISION PROCESS OF EDDI (BOSTON HOUSING AS EXAMPLE)
The decision process facilitated by the active selection of the variables (for the EDDI framework) is efficiently illustrated in Figure 11 and Figure 12 for the Boston Housing dataset and for the PNP and PNP with single best ordering approaches, respectively. For completeness, we provide details regarding the abbreviations of the variables used in the Boston dataset and appear both figures.
CR - per capita crime rate by town PRD - proportion of residential land zoned for lots over 25,000 sq.ft. PNB - proportion of non-retail business acres per town. CHR - Charles River dummy variable (1 if tract bounds river; 0 otherwise) NOC - nitric oxides concentration (parts per 10 million) ANR - average number of rooms per dwelling AOUB - proportion of owner-occupied units built prior to 1940 DTB - weighted distances to five Boston employment centres ARH - index of accessibility to radial highways TAX - full-value property-tax rate per $10,000 OTR - pupil-teacher ratio by town
16

Under review as a conference paper at ICLR 2019 PB - proportion of blacks by town LSP - % lower status of the population
(a) (b)
(c) (d)
(e) (f)
(g) (h) Figure 11: Information reward estimated during the first 4 active variable selection steps on a randomly chosen Boston Housing test data point. Model: PNP, strategy: EDDI. Each row contains two plots regarding the same time step. Bar plots on the left show the information reward estimation of each variable on the y-axis. All unobserved variables start with green bars, and turns purple once selected by the algorithm. Right: violin plot of the posterior density estimations of remaining unobserved variables.
. 17

Under review as a conference paper at ICLR 2019
(a) (b)
(c) (d)
(e) (f)
(g) (h) Figure 12: Information reward estimated during the first 4 active variable selection steps on a randomly chosen Boston Housing test data point. Models: PNP, strategy: single ordering. Each row contains two plots regarding the same time step. Bar plots on the left show the information reward estimation of each variable on the y-axis. All unobserved variables start with green bars, and turns purple once selected by the algorithm. Right: violin plot of the posterior density estimations of remaining unobserved variables.
. B.3 MIMIC-III Here we provide additional results of our approach on the MIMIC-III dataset.
18

Under review as a conference paper at ICLR 2019

B.3.1 PREPROCESSING AND MODEL DETAILS

For our active learning experiments on MIMIC III datasets, we chose the variable of interest x to be the binary mortality indicator of the dataset. All data (except the binary mortality indicator) are normalized and then scaled between 0 and 1. We transformed the categorical variables into real-valued using the dictionary deduced from (Johnson et al., 2016) that makes use of the actual medical implications of each possible values. The binary mortality indicator are treated as Bernoulli variables and Bernoulli likelihood function is applied. For each repetition (of the 5 in total), we randomly draw 10% of the whole data to be our test set. Partial VAE models (ZI, ZI-m, PNP and PNs) share the same size of architecture with 10 dimensional diagonal Gaussian latent variables: the generator (decoder) is a 10-50-100-D neural network with ReLU activations (where D is the data dimensions). The inference nets (encoder) share the same structure of D-100-50-20 that maps the observed data into distributional parameters of the latent space. Additionally, for PN-based parameterizations, we further use a 20 dimensional feature mapping h parameterized by a single layer neural network, and 10 dimensional ID vectors ei (please refer to section 3.2) for each variable. We choose the symmetric operator g to be the basic summation operator.

Adam optimization and random missingness is applied as in the previous experiments. We trained

our models for 3K iterations. During active learning, we draw 50 samples in order to estimate the

expectation under x , xi  p(x , xi|xo) in Equation (8). Negative likelihoods of the target variable

is

also

estimated

using

50

samples

of

x



p(x |xo)

through

p(x |xo)



1 M

mM=1

p(x |zm),

where

zm  q(z|xo).

B.3.2 ADDITIONAL PLOTS OF ZI, PN AND ZI-M ON MIMIC III

Figure 13 shows the information curves of active variable selection on the risk assessment task for MIMIC-III as produced by the three approaches, i.e. ZI, PN and masked ZI.

(a) (b) (c)
Figure 13: Information curves of active variable selection on risk assessment task on MIMIC III, produced from: (a) Zero Imputing (ZI), (b) PointNet (PN) and (c) Zero Imputing with mask (ZI-m). Green: random strategy; Black: EDDI; Pink: Single best ordering. This displays negative test log likelihood (y axis, the lower the better) during the course of active selection (x-axis)
.
B.4 NHANES
B.4.1 PREPROCESSING AND MODEL DETAILS
For our active learning experiments on NHANES datasets, we chose the variable of interest x to be the lab test result section of the dataset. All data are normalized and scaled between 0 and 1. For categorical variables, these are transformed into real-valued variables using the code that comes with the dataset, which makes use of the actual ordering of variables in questionnaire. Then, for each repetition (of the 5 repetitions in total), we randomly draw 8000 data as training set and 100 data to be test set. All partial VAE models (ZI, ZI-m, PNP and PNs) uses gaussian likelihoods, with an diagonal Gaussian inference model (encoder). Partial VAE models share the same size of architecture with 20 dimensional diagonal Gaussian latent variables: the generator (decoder) is a 20-50-100-D neural network. The inference nets (encoder) share the same structure of D-100-50-20 that maps the observed data into distributional parameters of the latent space. Additionally, for PN-based parameterizations, we further use a 20 dimensional feature mapping h parameterized by a single layer
19

Under review as a conference paper at ICLR 2019
neural network, and 100 dimensional ID vectors ei (please refer to section 3.2) for each variable. We choose the symmetric operator g to be the basic summation operator.
Adam optimization and random missingness is applied as in the previous experiments. We trained all models 1K iterations. During active learning, 10 samples were drawn to estimate the expectation in Equation (9). Negative likelihoods of the target variable is also estimated using 10 samples.
C ADDITIONAL THEORETICAL CONTRIBUTIONS
C.1 ZERO IMPUTING AS A POINT NET
Here we present how the zero imputing (ZI) and PointNet (PN) approaches relate.
Zero imputation with inference net In ZI, the natural parameter of  (e.g., Gaussian parameters in variational autoencoders) is approximated using the following neural network:
L
f (x) := w(l1) (w(l0)xT ) l=1
, where L is the number of hidden units, x is the input image with xi be the value of the ith pixel. To deal with partially observed data x = xo  xu, ZI simply sets all xu to zero, and use the full inference model f (x) to perform approximate inference.
PointNet parameterizationThe PN approach approximates the natural parameter  by a permutation invariant set function
g(h(s1), h(s2), ..., h(sO)), where si = [xi, ei], ei is the I dimensional embedding/ID/location vector of the ith pixel, g(·) is a symmetric operation such as max-pooling and summation, and h(·) is a nonlinear feature mapping from RI+1 to RK (we will always refer h as feature maps ). In the current version of the partial-VAE implementation, where Gaussian approximation is used, we set K = 2H with H being the dimension of latent variables. We set g to be the element-wise summation operator, i.e. a mapping from RKO to RK defined by:
g(h(s1), h(s2), ..., h(sO)) =  h(si). iO
This parameterization corresponds to products of multiple Exp-Fam factors iO exp{- h(si),  }.
From PN to ZI To derive the PN correspondence of the above ZI network we define the following PN functions:
h(si) := ei  xi
I
g(h(s1), h(s2), ..., h(sO)) :=  k (  hk(si)), k=1 iO
where hk(·) is the kth output feature of h(·). The above PN parameterization is also permutation invariant; setting L = I, l = wl(1),(wl(0))i = (ei)l the resulting PN model is equivalent to the ZI neural network.
Generalizing ZI from PN perspective In the ZI approach, the missing values are replaced with zeros. However, this ad-hoc approach does not distinguish missing values from actual observed zero values. In practice, being able to distinguish between these two is crucial for improving uncertainty estimation during partial inference. One the other hand, we have found that PN-based partial VAE experiences difficulties in training. To alleviate both issues, we proposed a generalization of the ZI approach that follows a PN perspective. One of the advantages of PN is setting the feature maps of the unobserved variables to zero instead of the related weights. As discussed before, these two approaches are equivalent to each other only if the factors are linear. More generally, we can parameterize the PN by:
h(1)(si) := ei  xi h(2)(hi(1)) := NN1(hi(1))
20

Under review as a conference paper at ICLR 2019
g(h(s1), h(s2), ..., h(sO)) := NN2( ( hk(2)(hi(1)))), iO
where NN1 is a mapping from RI to RK defined by a neural network, and NN2 is a mapping from RK to R2H defined by another neural network.
C.2 APPROXIMATION DIFFICULTY OF THE ACQUISITION FUNCTION
Traditional variational approximation approaches provide wrong approximation direction when applied in this case (resulting in an upper bound of the objective R (i, xO) which we maximize). Justification issues aside, (black box) variational approximation requires sampling from approximate posterior q(z|xO), which leads to extra uncertainties and computations. For common proposals of approximation:
· Directly estimate entropy via sampling  problematic for high dimensional target variables · Using reversed information reward Exip(xi|xo)[DKL(p(x |xo)||p(x |xo, xi))], and then apply
ELBO (KL-divergence)  This does not make sense mathematically, since this will result in upper bound approximation of the (reversed) information objective, this is in the wrong direction. · Ranganath's bound (Ranganath et al., 2016) on estimating entropy gives upper bound of the objective, wrong direction. · All the above methods also needs samples from latent space (therefore second level approximation needed).
C.3 CONNECTION OF EDDI INFORMATION REWARD WITH BALD
We briefly discuss connection of EDDI information reward with BALD (Houlsby et al., 2011) and. MacKay's work (MacKay, 1992). Assuming the model is correct, i.e. q = p, we have
R(i, xo) = Exip(xi|xo) [DKL(p(z|xi, xo)||p(z|xo))] - Exip(xi|xo)Ex p(x |xi,xo) DKL(p(z|x , xi, xo)||p(z|x , xo)) .
Note that based on McKay's relationship between entropy and KL-divergence reduction, we have: Exip(xi|xo) [DKL(p(z|xi, xo)||p(z|xo))]
=Exip(xi|xo) [H(p(z|xi, xo)) - H(p(z|xo))]] .
Similarly, we have Exip(xi|xo)Ex p(x |xi,xo) DKL(p(z|x , xi, xo)||p(z|x , xo))
=Ex p(x |xo)Exip(xi|x ,xo) DKL(p(z|x , xi, xo)||p(z|x , xo)) =Ex p(x |xo)Exip(xi|x ,xo) H(p(z|x , xi, xo)) - H(p(z|x , xo)) =Exip(xi|xo)Ex p(x |xi,xo) H(p(z|x , xi, xo)) - Ex p(x |xo)Exip(xi|x ,xo) H(p(z|x , xo)) =Exip(xi|xo)Ex p(x |xi,xo) H(p(z|x , xi, xo)) - Ex p(x |xo) H(p(z|x , xo)) , where MacKay's result is applied to Exip(xi|x ,xo) DKL(p(z|x , xi, xo)||p(z|x , xo)) . Putting everything together, we have
R(i, xo) = Exip(xi|xo) [H(p(z|xi, xo)) - H(p(z|xo))]] - Exip(xi|xo)Ex p(x |xi,xo) H(p(z|x , xi, xo)) + Ex p(x |xo) H(p(z|x , xo)) = Exip(xi|xo) [H(p(z|xi, xo))] - Exip(xi|xo)Ex p(x |xi,xo) H(p(z|x , xi, xo)) - Exip(xi|xo) [H(p(z|xo))] - Ex p(x |xo) H(p(z|x , xo)) .
21

Under review as a conference paper at ICLR 2019

We can show that

H(p(z|xi, xo)) - Ex p(x |xi,xo) H(p(z|x , xi, xo))

= - p(z|xi, xo) log p(z|xi, xo)dz + p(z, x |xi, xo) log p(z|x , xi, xo)
z z,x

=

z,x

p(z, x |xi, xo) log

p(z, x |xi, xo) p(z|xi, xo)p(x |xi, xo)

=I z, x |xi, xo ,

which is exactly the conditional mutual information I z, x |xi, xo used in BALD. Therefore, our chain rule representation of reward function leads us to

R(i, xo) = Exip(xi|xo)I z, x |xi, xo - Exip(xi|xo)I z, x |xo .

22

