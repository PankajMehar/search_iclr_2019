Under review as a conference paper at ICLR 2019
ROBUSTNESS CERTIFICATION WITH REFINEMENT
Anonymous authors Paper under double-blind review
ABSTRACT
We present a novel approach for verification of neural networks which combines scalable over-approximation methods with precise (mixed integer) linear programming. This results in significantly better precision than state of the art verifiers on feed forward neural networks with piecewise linear activation functions.
1 INTRODUCTION
Neural networks are increasingly applied in critical domains such as autonomous driving Bojarski et al. (2016), medical diagnosis Amato et al. (2013), and speech recognition Hinton et al. (2012). However, it has been shown by Goodfellow et al. (2014) that neural networks can be non-robust against adversarial attacks, i.e., small input perturbations cause neural networks to misclassify. To address this challenge and prove a network is free of adversarial examples (usually, in a region around a given input), recent work has started investigating the use of verification techniques. Current verifiers can be broadly classified in complete or incomplete ones.
Complete verifiers are exact, i.e., if the verifier fails to check a property then the network is nonrobust and vice-versa. Existing complete verifiers are based on Mixed Integer Linear Programming (MILP) Lomuscio & Maganti (2017); Fischetti & Jo (2018); Dutta et al. (2018); Cheng et al. (2017); Tjeng & Tedrake (2017), SMT Katz et al. (2017); Ehlers (2017), or input refinement Wang et al. (2018). Although precise, these verifies have limited scalability and can only handle networks with a small number of layers and neurons. To scale, incomplete verifiers usually employ overapproximation methods and hence they are sound (no false negatives) but may fail to verify a robust network. Incomplete verifiers are based on methods such as duality Raghunathan et al. (2018); Dvijotham et al. (2018), abstract interpretation Gehr et al. (2018), linear approximations Weng et al. (2018); Wong & Kolter (2018), combination of linear and non-linear approximation Xiang et al. (2017), or search space discretization Huang et al. (2017). Incomplete verifiers are more scalable than complete ones, but can suffer from precision loss. In principle, incomplete verifiers can be trivially made complete by iteratively refining the input space; however, at the limit, this eliminates any scalability gains and defeats the purpose of using over-approximations in the first place.
This work. A key challenge then is to design a verifier which improves both, the precision of incomplete verifiers and the scalability of complete ones. In this work, we take a step towards addressing this challenge. We present a verification method that is fast and exact for small networks, yet can analyze larger networks beyond the reach of complete verifiers and compute more precise bounds than incomplete ones. Our method is based on two key ideas: (i) a combination of stateof-the-art over-approximation methods used in incomplete verifiers together with MILP solvers and LP relaxations often employed in complete verifiers; (ii) a novel heuristic which points to neurons whose over-approximation bounds should be refined. Taken together, these ideas result in a significant precision increase for deeper networks (up to 9 layers and 1,800 neurons) over state-of-the-art incomplete verifiers (no complete verifier can handle these networks, even when run for days).
Main contributions. Our main contributions are:
· A refinement-based approach for verifying neural network robustness that combines the strengths of over-approximation methods with MILP solvers and LP relaxations.
· A novel heuristic for selecting neurons whose bounds should be further refined. · An evaluation showing our system is more precise than existing incomplete verifiers on
larger networks and faster (while being complete) than complete ones on small networks.
1

Under review as a conference paper at ICLR 2019

x^1 = 0.5 +0.5 · 1
l1 = 0 u1 = 1

[0,1] x1

1 1

1

x^3 = 1

x^5 = 1

+0.5 · 1

+0.5 · 1

+0.5 · 2

+0.5 · 2

l3 = 0

l5 = 0

u3 = 2

u5 = 2

0 max(0, x3)
x3 x5

1

1

x^7 = 1.75

x^9 = 1.75

+0.25 · 1

+0.25 · 1

+0.75 · 2

+0.75 · 2

-0.25 · 3

-0.25 · 3

l7 = 1

l9 = 1

u7 = 3

u9 = 3

1 max(0, x7)
x7 x9

1

2

x^11 = 4.875

x^13 = 4.875

+0.625 · 1

+0.625 · 1

+1.875 · 2

+1.875 · 2

-0.625 · 3

-0.625 · 3

+0.25 · 4

+0.25 · 4

l11 = 3.25

l13 = 3.25

u11 = 8.25

u13 = 8.25

1.25

max(0, x12)

x11

x13

-1 1

x2 [0,1]
x^2 = 0.5 +0.5 · 2
l2 = 0 u2 = 1

x4 x6 -1 max(0, x4)
0

x^4 = 0.5 · 1

x^6 = 0.25

-0.5 · 2

+0.25 · 1

l4 = -1

-0.25 · 2

u4 = 1

+0.25 · 3

l6 = -0.5

u6 = 1

x8

x10

x12

x14

-1 max(0, x8)

-1 max(0, x13)

-1 1

x^8 = -0.25

x^8 = 0.125

x^12 = 2.625

x^14 = 2.625

+0.25 · 1

+0.125 · 1

+0.125 · 1

+0.125 · 1

+0.75 · 2

+0.375 · 2

+0.375 · 2

+0.375 · 2

-0.25 · 3

-0.125 · 3

-0.125 · 3

-0.125 · 3

l8 = -1

+0.25 · 4

-0.25 · 4

-0.25 · 4

u8 = 1

l10 = -0.5

l12 = 2

l14 = 2

u10 = 1

u12 = 3

u14 = 3

Figure 1: Robustness analysis of neural network using refinement. The analysis results for the neurons in the blue box are refined using MILP whereas for those in green are refined using LP.

2 OVERVIEW

We now demonstrate how our refinement based approach improves precision on a simple example. Our goal is to provide an intuitive understanding of the approach; full formal details are provided in the following section.
Consider the simple fully connected neural network with ReLU activations shown in Fig. 1. There are two inputs to the network which are both in the range [0, 1]. The network consists of an input layer, two hidden layers and one output layer. Each layer consist of two neurons each. For our explanation, we separate each neuron into two parts: one represents the output of the affine transformation while the other captures the output of the ReLU activation. The weights for the affine transformation are represented by weights on the edges. The bias for each node is shown above or below it. Our goal is to verify that for any input in [0, 1] × [0, 1], the output at neuron x13 is greater than the output at x14.
We now demonstrate our analysis for this network. We assume that the analysis results after the second affine transformation are refined using a MILP formulation of the network whereas the results after the third affine transformation are refined by an LP formulation of the network. In the next section, we will explain our heuristic for selecting either MILP or LP for each neuron. Our analysis leverages the Zonotope domain Ghorbal et al. (2009) transformers also used in AI2 Gehr et al. (2018), a state of the art analyzer for neural networks. The Zonotope domain associates an affine form with each neuron x in the network:
p
x^ := [0, 0] + [i, i] · i
i=1
Here, 0, 0, i, i  R are real coefficients and i  [ai, bi]  [-1, 1] are the noise symbols which are shared between the affine forms for different neurons, which makes the domain relational. An element in our analysis is an intersection between a Zonotope (given as conjunction of affine forms) and a bounding box. Thus, for each neuron x, we keep the affine form x^ and an interval [lx, ux].

First layer. and

Our analysis starts by setting: x^1 = 0.5 + 0.5 · 1, l1 = 0, u1 = 1
x^2 = 0.5 + 0.5 · 2, l2 = 0, u2 = 1

2

Under review as a conference paper at ICLR 2019 ReLU (x^)

lx lx

ux ux

x^

Figure 2: ReLU transformers for computing the affine form of the output. Here lx, ux are the original

bounds whereas lx, ux are the refined bounds. The slope of the two non-vertical parallel blue lines

is  =

ux ux -lx

whereas

slope

of

the

two

non-vertical

parallel

green

lines

is



=

.ux
ux -lx

The blue

parallelogram is used to compute the output affine form in AI2 whereas the green parallelogram is

used to compute the output of the refined ReLU transformer considered in this work.

representing the inputs at x1 and x2 respectively. Next, an affine transformation is applied on the inputs resulting in the output:
x^3 = x^1 + x^2 = 1 + 0.5 · 1 + 0.5 · 2, l3 = 0, u3 = 2
and x^4 = x^1 - x^2 = 0.5 · 1 - 0.5 · 2, l4 = -1, u4 = 1.
The Zonotope affine transformer is exact for this transformation so we do not need any refinement here. Next, the Zonotope ReLU transformer is applied. We note that as l3  0, the neuron x3 provably takes only positive values. Thus, the ReLU Zonotope transformer outputs x^5 = x^3, l5 = l3, u5 = l3 which is the exact result. For x4, l4 < 0 and u4 > 0 and thus neuron x4 can take both positive and negative values. The corresponding output does not have a closed affine form and hence the approximation in blue shown in Fig. 2 is used to compute the result, introducing a new noise symbol 3  [-1, 1]. The result is:
x^6 = 0.25 + 0.25 · 1 - 0.25 · 2 + 0.25 · 3, l6 = -0.5, u6 = 1.
Note that due to approximation x6 can take negative values. In contrast, the exact output only takes positive values. This approximation typically accumulates as the analysis progresses deeper into the network, resulting in overall imprecision and failure to prove properties that actually hold.
MILP based refinement at second layer. Next, the analysis handles the second affine transformation and computes:
x^7 = x^5 - x^6 + 1 = 1.75 + 0.25 · 1 + 0.75 · 2 - 0.25 · 3, l7 = 0.5, u7 = 3
and
x^8 = x^5 - x^6 - 1 = -0.25 + 0.25 · 1 + 0.75 · 2 - 0.25 · 3, l8 = -1.5, u8 = 1.
Due to the approximation for x6, the bounds for x7 and x8 are imprecise. Thus, in our method we now refine the bounds by formulating the network up to the second affine transformation as a MILP instance based on a formulation from Tjeng & Tedrake (2017) and compute bounds for x7 and x8, respectively. The MILP solver improves the lower bounds for x7 and x8 to 1 and -1, respectively, which then updates the corresponding lower bounds. Next, the ReLU transformer is applied. Since x7 is provably positive, we get x^9 = x^7, l9 = l7, u9 = u7. We note that x8 can take both positive and negative values and is therefore approximated. However, the ReLU transformer now uses the refined bounds instead of the original bounds and thus the approximation shown in green from Fig. 2 is used. This approximation has lesser area in the input-output plane compared to the blue one and thus reduces the approximation. The result is:
x^10 = 0.125 + 0.125 · 1 + 0.375 · 2 - 0.125 · 3 + 0.25 · 4, l8 = -0.5, u8 = 1.
3

Under review as a conference paper at ICLR 2019

LP based refinement at final layer. Continuing with the analysis, we now process the final affine transformation, which yields
x^11 = 4.875 + 0.625 · 1 + 1.875 · 2 - 0.625 · 3 + 0.25 · 4, l11 = 1.75, u11 = 8.25
and
x^12 = 2.625 + 0.125 · 1 + 0.375 · 2 + -0.125 · 3 - 0.25 · 4, l12 = 1.75, u12 = 3.5.
Due to the approximations from previous layers the computed values can be imprecise. Thus, we refine the bounds by encoding the network up to the third affine transformation using the LP formulation from Ehlers (2017) and compute the bounds for x11 and x12, respectively. This leads to the following results: l11 = 3.25, l12 = 2, and u12 = 3. As both x13 and x14 are provably positive, the subsequent ReLU transformation sets x^13 = x^11, l13 = l11, u13 = u11 and x^14 = x^12, l14 = l12, u14 = u12.
Proving robustness. Since the lower bound l13 for x13 is greater than the upper bound u14 for x14, our analysis can prove that the given neural network provides the same label for all inputs in [0, 1] × [0, 1] and is thus robust. In contrast, AI2 without our refinement would compute
x^13 = 4.95 + 0.6 · 1 + 1.8 · 2 - 0.6 · 3 + 0.3 · 4, l13 = 1.65, u13 = 8.25
and x^14 = 2.55 + 0.45 · 1 - 0.15 · 2 - 0.3 · 3, l14 = 1.5, u14 = 2.6.
As a result, AI2 fails to prove that x13 is greater than x14, and thus fails to prove robustness.

3 OUR APPROACH

In this section we describe our approach in more formal terms. As illustrated earlier, the key idea will be to combine abstract interpretation with exact and inexact MILP formulation of the network which is then solved using a solver so to compute more precise results for neuron bounds. We begin by describing the abstract interpretation ingredients.

Let An be an abstract domain (i.e., some set whose elements can be encoded symbolically) with a bottom element   An. We further assume the following:

· A concretization function n : An  P(Rn) that associates with each abstract element a  An a set of concrete vectors from Rn. In particular, n() = . ( is not required to be computable.)

· An abstraction function n : P(Rn)  An, where X  n(n(X)) for all X  P(Rn). We assume that n( i[li, ui]) can be computed for all l, u  Rn.
· A bounding box function n : An  Rn × Rn, where n(a)  i[li, yi] for (l, u) = n(a) for all a  An.

· A meet operation a L for each a  An and linear constraints L over n real variables, where {x  n(a) | L(x)}  n(a L).

· An affine abstract transformer Tx#Ax+b : Am  An for each affine transformation (x  Ax + b) : Rm  Rn, where {Ax + b | x  n(a)}  n(Tx#Ax+b) for all a  Am.

·

A ReLU abstract transformer TR#eLU|

: An
i [li ,ui ]

 An, where {ReLU(x)

|

x

(a) 

i[li, ui]}  TR#eLU| bounds l, u  Rn on

(a) for all abstract
i [li ,ui ]
input activations.

elements

a



An

and

for

all

lower

and

upper

Abstract interpretation. As first shown by Gehr et al. (2018), any such abstract domain induces a method for robustness certification of classification based neural networks with ReLU activations.
For example, assume that we want to certify that a given neural network f : Rm  Rn considers class i more likely than class j for all inputs x with ||x -x||  for a given x and . We can first use the function  to compute a symbolic over-approximation of the set of possible input activations x , namely
ain = m({x  Rm | ||x - x||  }).

4

Under review as a conference paper at ICLR 2019

Given that the neural network can be written as a composition of affine functions and ReLU layers
we can then propagate the abstract element ain through the corresponding abstract transformers to obtain a symbolic over-approximation aout of the output activations of the neural network.

For example, if the neural network is a single-layer perceptron f (x) = A ·ReLU(Ax+b)+b with

h hidden neurons, we first compute a = Tx#Ax+b(ain), which is a symbolic over-approximation of the input to the ReLU activation function. We then compute (l, u) = h(a ) to obtain opposite corners of a bounding box of all possible ReLU input activations, such that we can apply the ReLU

abstract transformer:

a

= TR#eLU|

(a ).
i [li ,ui ]

Finally, we apply the affine abstract transformer again to obtain aout = Tx#A x+b (a ). Using our
assumptions, we can conclude that the set n(aout) contains all output activations that f can possibly produce when given any of the inputs x . Therefore, if aout (yi  yj) = , we have successfully
proved our property: for all x , the neural network considers class i more likely than class j.

Incompleteness. While this approach is sound (i.e., whenever we prove the property, it actually holds), it is incomplete (i.e., we might not prove the property, even if it holds), because the abstract transformers produce a superset of the set of possible activations. This is particularly quite imprecise for deep neural networks, because the over-approximations introduced in each layer accumulate.

Refinement. To combat spurious over-approximation, we use mixed integer linear programming (MILP) to compute refined lower and upper bounds l, u after applying each abstract transformer (except the first). We then refine the abstract element using the meet operator and the linear constraints li  xi  ui for all input activations i, i.e., we replace the current abstract element a by a = a ( i li  xi  ui), and continue analysis with the refined abstract element.
Furthermore, and importantly, for ReLU, we obtain a refined abstract transformer using the new (and tighter) lower and upper bounds.
To enable refinement, we augment each abstract element with variables and constraints. There is one variable for each neuron, and the constraints fully capture the behaviour of the neural network up to the last layer whose abstract transformer has been executed. We write x(ik) to denote the variable corresponding to the activation of the i-th neuron in the k-th layer, where the input layer has k = 0. Similarly, we will write li(k) and u(ik) to denote the best derived lower and upper bounds for this neuron.
From the input layer, we get constraints of the form a  xi(0)  b, from affine layers, we get constraints of the form x(ik) = a0 + j ajx(jk-1) and from ReLU layers we get constraints of the form x(ik) = ReLU(x(ik-1)).

MILP. Let (k) denote the conjunction of all constraints up to and including those from layer k. To obtain the best possible lower and upper bounds for layer k with p neurons, we need to solve the following 2p optimization problems:

li(k) =

min
x(10) ,...,x(pk)

xi(k), for i = 1, . . . , p,

s.t. (k)(x1(0),...,xp(k-1))

u(ik) =

max
x(10) ,...,x(pk)

x(ik), for i = 1, . . . , p.

s.t. (k)(x(10),...,xp(k-1))

As was shown by Tjeng & Tedrake (2017), those optimization problems can be encoded exactly as MILPs, such that the bounds can be computed with off-the-shelf MILP solvers. Note that the encoding of subsequent layers depends on the bounds computed in previous layers, where tighter bounds produce simpler MILP instances.
5

Under review as a conference paper at ICLR 2019
LP relaxation. While not introducing any approximation, unfortunately, current MILP solvers do not scale to larger deep neural networks. However, for soundness it is not crucial that the produced bounds are the best possible: for example, plain abstract interpretation uses sound bounds produced by the bounding box function  instead. We explore the trade-off between precision and scalability by also considering an intermediate method, which is faster than exact MILP, but also more precise than abstract interpretation. We relax a subset of the constraints in (k) in the same way as Ehlers (2017) to obtain a set of weaker linear constraints L(kP). We then use the solver to solve the relaxed optimization problems that are constrained by L(kP) instead of (k), producing possibly looser bounds l(k) and u(k). Note that the encoding of subsequent layers depends on the bounds computed in previous layers, where tighter bounds reduce the amount of newly introduced approximation.
Anytime MILP relaxation. The MILP solvers usually provide the option to provide an explicit timeout after which the solver must terminate. In return, the solver may not be able to solve the instance exactly, but it will instead provide lower and upper bounds on the objective function in a best-effort fashion. This provides another way to compute sound but inexact bounds l(k) and u(k).
In practice, we choose a fraction   (0, 1] of neurons in a given layer k and compute bounds for them using MILP with a timeout T in a first step. In the second step, for a fraction   [0, 1 - ] of neurons in the layer, we set the timeout to  · T , where T is the average time taken by the MILP solver to solve one of the instances from the first step and   [0, 1] is a parameter.
Neuron selection heuristic. To select the -fraction of neurons for the first step of the anytime MILP relaxation for the k-th layer, we rank the neurons. If the next layer is a ReLU layer, we first ignore all neurons whose activations can be proven to be non-positive using abstract interpretation (i.e., using the bounds produced by ), because in this case it is already known that ReLU will map the activation to 0. The remaining neurons are ordered in up to two different ways, once by width (i.e. neuron i has key u(ik) - li(k)), and possibly once by the sum of absolute output weights. i.e., if the next layer is a fully connected layer x  Ax + b, the key of neuron i is j |Ai,j|. If the next layer is a ReLU layer, we skip the ReLU layer and use the weights from the fully connected layer that follows it (if any). The two ranks of a neuron in both orders are added, and the -fraction with smallest rank sum is selected and their bounds refined with a timeout of T whereas the next -fraction of neurons are refined with a timeout of  · T .
End-to-end approach. To certify robustness of deep neural networks, we combine MILP, LP relaxation, and abstract interpretation. We first pick numbers of layers kMILP, kLP, kAI that sum to the total number of layers of the neural network. For the analysis of the first kMILP layers, we refine bounds using anytime MILP relaxation with the neuron selection heuristic. As an optimization, we do not perform refinement after the first abstract transformer in case it is an affine transformation and the abstract domain computes the tightest possible bounding box for an affine transformation of a box (this is always the case in our experiments). For the kLP layers after that, we refine bounds using both MILP and LP relaxation, i.e., the first kMILP layers are encoded as MILP and the next kLP use the LP relaxation. For the final kAI layers, we use abstract interpretation without additional refinement (however, this also benefits from refinement that was performed in previous layers), and compute the bounds using .
Final property verification. In case the refined abstract interpretation is already able to verify the final property on its own, we terminate. Otherwise, we can encode the final verification problem using L(kP). If we want to prove that class i is assigned a higher probability than class j, it suffices to show that the constraints L(kP)(x(10), . . . , xp(k))  x(ik)  x(jk) are unsatisfiable, where k is the index of the last layer and p is the number of output classes. If this fails as well, one can resort to complete verification using MILP: the property is satisfied if and only if (k)(x(10), . . . , xp(k))  xi(k)  xj(k) is unsatisfiable.
6

Under review as a conference paper at ICLR 2019
4 EVALUATION
We now evaluate the effectiveness of our approach for the problem of robustness verification of ReLU-based feed forward neural networks. We implemented our approach in the form of a Python analyzer which we call RefineAI. RefineAI uses the Zonotope and Interval implementation from the ELINA eli; Singh et al. (2017) library. Gurobi gur is used for solving MILP instances.
Evaluation datasets. We used the popular MNIST Lecun et al. (1998) dataset of hand-written digits for our experiments. The dataset includes a training set of 60 000 and a testing set of 10 000 gray scale images. All images are of size 28 × 28 pixels.
Neural networks. We use 5 different feed forward networks (FNNs) with the ReLU activation function trained for the MNIST dataset. The sizes of the FNNs are: (a) 3 layers with 50 units each, (b) 5 layers with 100 units each, (c) 6 layers with 100 units each, (d) 6 layers with 200 units each, and (e) 9 layers with 200 units each.
Among these, the 5 × 100 network is trained to be robust using the adversarial training from Mirman et al. (2018) whereas the other networks were taken from Gehr et al. (2018) and are not trained to be robust.
Robustness properties. We consider the adversarial region defined by the L-norm Carlini & Wagner (2017) perturbation. The region is parameterized by  R and contains all images in which each pixel xi has a distance of at most from the corresponding pixel xi in the original input image x. Our goal is to verify that the neural network produces the same label on all images in the adversarial region as on the original image. The adversarial attack considered here is untargeted and therefore stronger than the targeted attack in Weng et al. (2018); Tjeng & Tedrake (2017) where the goal is to prove that the score for the correct label is more than some other label on all images in the adversarial region.
Benchmarks. We selected the first 100 images from the MNIST test set. Any image on which the neural network misclassified without perturbation was not considered for evaluation.
Experimental setup. All experiments for the 3 × 50 FNN were carried out on a 2.6 GHz Intel Xeon CPU E5-2690 with 512 GB of main memory; the remaining FNNs were evaluated on a 3.3 GHz 10 Core Intel i9-7900X Skylake CPU with a main memory of 64 GB. For each network, we chose an for which AI2 verified < 40% of all candidate images. We used a time limit of 40 minutes per run in our experiments. We experimented with different values of the analysis parameters kMILP, kLP, kAI, , , , T and chose those values that offered the best tradeoff between performance and precision for the robustness verification of larger neural networks.
Complete verification of small network. We first consider the exact robustness verification of 3 × 50 networks against L-norm attack with = 0.03. AI2 verifies 37% of images in the test set for this value of . RefineAI runs the analysis with AI2 on the whole network collecting the bounds for all neurons in the network. If AI2 does not verify the property then the bounds from AI2 are used to encode the robustness verification as a MILP problem as discussed in section 3. We compare RefineAI against the approach from Tjeng & Tedrake (2017) (state-of-the-art for complete verifiers) which also uses a MILP formulation and uses a presolve analysis to formulate the verification as a MILP problem. We implemented the Interval analysis and LP-based analysis to determine the initial bounds. We note that LP analysis is the default presolve in Tjeng & Tedrake (2017). If LP analysis (or Interval analysis) can already verify an image then the MILP solver is not called. All complete verifiers verify 85% of images. The average runtimes of RefineAI, MILP with presolve bounds from Interval analysis, and MILP with bounds from LP analysis are 28, 123, and 35 seconds respectively.
Incomplete verification of larger networks. Complete verification does not scale for the remaining networks. We note that running LP analysis to determine initial bounds for the network does not scale for larger networks whereas the bounds from the Interval analysis are quite imprecise. The values of considered for the L-norm attack on 5 × 100, 6 × 100, 6 × 200, and 9 × 200 are 0.07, 0.02, 0.015, and 0.015 respectively. For all networks, we set kMILP = 3, kLP = n - kMILP - 1, kAI =
7

Under review as a conference paper at ICLR 2019

1, T = 1s,  = 0.5 (n is the number of layers). The value of  for the first two layers is equal to
number of neurons in the layer that can take positive values. For the remaining layers, we choose
a fraction of neurons taking positive values for MILP refinement with timeout T . The remaining  neurons with positive values are refined with MILP using a timeout of  · T . In Fig. 3, we compare the precision and the average runtime (in log scale) of RefineAI against AI2 per image for different neural networks. It can be seen that RefineAI is significantly more precise than AI2. RefineAI verifies > 2x more images than AI2 on 3 out of 4 neural networks. Specifically, for the largest 9 × 200 neural network, AI2 manages to verify the robustness of only 12% of all images. In contrast, Re-
fineAI verifies 35% of images to be robust. The average runtime per image of RefineAI is < 20
minutes for all neural networks.

Verified robustness
100% 80%

Time (s)

AI 2 RefineAI

103

AI 2 RefineAI

60%

102

40%

20%

101

0% 5 × 100

6 × 100 6 × 200
(a)

9 × 200

5 × 100

6 × 100 6 × 200
(b)

9 × 200

Figure 3: Verified robustness based on L norm by RefineAI vs AI2 on the MNIST FNNs. The values of for 5 × 100, 6 × 100, 6 × 200, and 9 × 200 FNNs are 0.07, 0.02, 0.015, and 0.015
respectively.

Effect of neuron selection heuristic. Refining all neurons in a layer with MILP can significantly slow down the analysis. We use the neuron selection heuristic from section 3 to determine neurons which need to be refined more than others. To check whether our heuristic is able to identify important neurons, we ran the analysis on the 6 × 100 FFN by keeping all analysis parameters the same, except instead of selecting the neurons with the smallest rank sum first we selected the neurons with the largest rank sum first (thus refining unimportant neurons as per our heuristic more). With this change the modified analysis loses precision and verifies 62% of images instead of 65% that the analysis refining with our neuron selection heuristics verifies. Although the number of images verified change by only 3%, the analysis with our heuristic produces tighter output bounds on all images than without it.
5 CONCLUSION
In this paper we presented a refinement based approach for increasing the precision of incomplete verifiers for feed forward neural networks with ReLU activations. This enabled us to verify robustness properties that existing state-of-the-art complete verifiers cannot handle (due to scalability issues) whereas state-of-the-art incomplete verifiers could not prove due to using over-approximations which are too coarse. We believe the direction of combining the strengths of over-approximation methods with that of mixed integer linear programming as done in this work is a promising direction for advancing the state-of-the-art in neural network verification.
8

Under review as a conference paper at ICLR 2019
REFERENCES
ELINA,: Eth library for numerical analysis.
Gurobi, optimization. http://www.gurobi.com/.
Filippo Amato, Alberto Lpez, Eladia Mara Pea-Mndez, Petr Vahara, Ale Hampl, and Josef Havel. Artificial neural networks in medical diagnosis. Journal of Applied Biomedicine, 11(2):47 ­ 58, 2013.
Mariusz Bojarski, Davide Del Testa, Daniel Dworakowski, Bernhard Firner, Beat Flepp, Prasoon Goyal, Lawrence D. Jackel, Mathew Monfort, Urs Muller, Jiakai Zhang, Xin Zhang, Jake Zhao, and Karol Zieba. End to end learning for self-driving cars. CoRR, abs/1604.07316, 2016.
Nicholas Carlini and David A. Wagner. Towards evaluating the robustness of neural networks. In Proc. IEEE Symposium on Security and Privacy (SP), pp. 39­57, 2017.
Chih-Hong Cheng, Georg Nu¨hrenberg, and Harald Ruess. Maximum resilience of artificial neural networks. In Automated Technology for Verification and Analysis (ATVA), 2017.
Souradeep Dutta, Susmit Jha, Sriram Sankaranarayanan, and Ashish Tiwari. Output range analysis for deep feedforward neural networks. In NASA Formal Methods (NFM), 2018.
Krishnamurthy Dvijotham, Robert Stanforth, Sven Gowal, Timothy A. Mann, and Pushmeet Kohli. A dual approach to scalable verification of deep networks. CoRR, abs/1803.06567, 2018.
Ru¨diger Ehlers. Formal verification of piece-wise linear feed-forward neural networks. In Automated Technology for Verification and Analysis (ATVA), 2017.
Matteo Fischetti and Jason Jo. Deep neural networks and mixed integer linear optimization. Constraints, 23(3):296­309, 2018.
T. Gehr, M. Mirman, D. Drachsler-Cohen, P. Tsankov, S. Chaudhuri, and M. Vechev. Ai2: Safety and robustness certification of neural networks with abstract interpretation. In Proc. IEEE Symposium on Security and Privacy (SP), volume 00, pp. 948­963, 2018.
Khalil Ghorbal, Eric Goubault, and Sylvie Putot. The zonotope abstract domain taylor1+. In Proc. Computer Aided Verification (CAV), pp. 627­633, 2009.
Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, abs/1706.07351, 2014.
G. Hinton, L. Deng, D. Yu, G. E. Dahl, A. Mohamed, N. Jaitly, A. Senior, V. Vanhoucke, P. Nguyen, T. N. Sainath, and B. Kingsbury. Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. IEEE Signal Processing Magazine, 29(6):82­97, 2012.
Xiaowei Huang, Marta Kwiatkowska, Sen Wang, and Min Wu. Safety verification of deep neural networks. In Computer Aided Verification (CAV), pp. 3­29, 2017.
Guy Katz, Clark Barrett, David L. Dill, Kyle Julian, and Mykel J. Kochenderfer. Reluplex: An efficient smt solver for verifying deep neural networks. In Computer Aided Verification (CAV), pp. 97­117, 2017.
Yann Lecun, Lon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. In Proc. of the IEEE, pp. 2278­2324, 1998.
Alessio Lomuscio and Lalit Maganti. An approach to reachability analysis for feed-forward relu neural networks. CoRR, 2017.
Matthew Mirman, Timon Gehr, and Martin Vechev. Differentiable abstract interpretation for provably robust neural networks. In Proc. International Conference on Machine Learning (ICML), volume 80, pp. 3575­3583, 2018.
9

Under review as a conference paper at ICLR 2019
Aditi Raghunathan, Jacob Steinhardt, and Percy Liang. Certified defenses against adversarial examples. CoRR, abs/1801.09344, 2018.
Gagandeep Singh, Markus Pu¨schel, and Martin Vechev. Fast polyhedra abstract domain. In Proc. Principles of Programming Languages (POPL), pp. 46­59, 2017.
Vincent Tjeng and Russ Tedrake. Verifying neural networks with mixed integer programming. CoRR, abs/1711.07356, 2017.
Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana. Formal security analysis of neural networks using symbolic intervals. In USENIX Security Symposium (USENIX Security 18), pp. 1599­1614, 2018.
Lily Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Luca Daniel, Duane Boning, and Inderjit Dhillon. Towards fast computation of certified robustness for ReLU networks. In Proc. International Conference on Machine Learning (ICML), volume 80, pp. 5276­5285, 2018.
Eric Wong and Zico Kolter. Provable defenses against adversarial examples via the convex outer adversarial polytope. In Proc. International Conference on Machine Learning (ICML), volume 80, pp. 5286­5295, 2018.
Weiming Xiang, Hoang-Dung Tran, and Taylor T. Johnson. Output reachable set estimation and verification for multi-layer neural networks. CoRR, abs/1708.03322, 2017.
10

