Under review as a conference paper at ICLR 2019
RANDOM MESH PROJECTORS FOR INVERSE PROBLEMS
Anonymous authors Paper under double-blind review
ABSTRACT
We propose a new learning-based approach to solve ill-posed inverse problems in imaging. We address the case where ground truth training samples are rare and the problem is severely ill-posed--both because of the underlying physics and because we can only get few measurements. This setting is common in geophysical imaging and remote sensing.We show that in this case the common approach to directly learn the mapping from the measured data to the reconstruction becomes unstable. Instead, we propose to first learn an ensemble of simpler mappings from the data to projections of the unknown image into random piecewise-constant subspaces. We then combine the projections to form a final reconstruction by solving a deconvolution-like problem. We show experimentally the proposed method is more robust to measurement noise and corruptions not seen during training than a directly learned inverse.
1 INTRODUCTION
A variety of imaging inverse problems can be discretized to a linear system y = Ax +  where y  RM is the measured data, A  RM×N the imaging or forward operator, x  X  RN the object being probed by applying A (often called the model), and  the noise. Depending on the application, the set of plausible reconstructions X could model natural, seismic, or biomedical images. In many cases the resulting inverse problem is ill-posed, either because of the poor conditioning of A (a consequence of the underlying physics) or because M N .
A classical approach to solve ill-posed inverse problems is to minimize an objective functional regularized via a certain norm (e.g. 1, 2, total variation (TV) seminorm) of the model. These methods promote general properties such as sparsity or smoothness of reconstructions, sometimes in combination with learned synthesis or analysis operators, or dictionaries Sprechmann et al. (2013).
In this paper, we address situations with very sparse measurement data (M N ) so that even a coarse reconstruction of the unknown model is hard to get with traditional regularization schemes. Unlike scenarios where applying a regularized pseudoinverse of the imaging operator already brings out considerable structure, we look at applications where standard techniques cannot produce a reasonable image (Figure 1). This highly unresolved regime is common in geophysics and requires alternative, more involved strategies (Galetti et al. (2017)).
An appealing alternative to classical regularizers is to use deep neural networks. For example, generative models (GANs) based on neural networks have recently achieved impressive results in regularization of inverse problems (Bora et al. (2018), Lunz et al. (2018)). However, a difficulty in geophysical applications is that there are very few examples of ground truth models available for training (sometimes none at all). Since GANs require many, they cannot be applied to such problems. This suggests to look for methods that are not very sensitive to the training dataset. Conversely, it means that the sought reconstructions are less detailed than what is expected in data-rich settings; for an example, see the reconstructions of the Tibetan plateau (Yao et al. (2006)).
In this paper, we propose a two-stage method to solve ill-posed inverse problems using random low-dimensional projections and convolutional neural networks. We first decompose the inverse problem into a collection of simpler learning problems of estimating projections into random (but structured) low-dimensional subspaces of piecewise-constant images. Each projection is easier to learn in terms of generalization error (Cooper (1995)) thanks to its lower Lipschitz constant.
1

Under review as a conference paper at ICLR 2019

Model, x

Moderate Parallel beam tomography with 25 view angles

Data Rx

Reconstructions

Non-negative

TV

Pseudoinverse least squares regularization

NN direct inversion

Severe Traveltime tomography with 25 sensors and insufficient ground truth samples

Fx

Figure 1: We reconstruct an image x from its tomographic measurements. In moderately ill-posed problems, conventional methods based on the pseudoinverse and regularized non-negative least squares (x  [0, 1]N , N is image dimension) give correct structural information. In fact, total variation (TV) approaches give very good results. A neural network (Jin et al. (2016)) can be trained to directly invert and remove the artifacts (NN). In a severely ill-posed problem on the other hand (explained in Figure 4) with insufficient ground truth training data, neither the classical techniques nor a neural network recover salient geometric features.

In the second stage, we solve a new linear inverse problem that combines the estimates from the different subspaces. We show that this converts the original problem with possibly non-local (often tomographic) measurements into an inverse problem with localized measurements, and that in fact, in expectation over random subspaces the problem becomes a deconvolution. Intuitively, projecting into piecewise-constant subspaces is equivalent to estimating local averages--a simpler problem than estimating individual pixel values. Combining the local estimates lets us recover the underlying structure. We believe that this technique is of independent interest in addressing inverse problems.
We test our method on linearized seismic traveltime tomography (Bording et al. (1987); Hole (1992)) with sparse measurements and show that it outperforms learned direct inversion in quality of achieved reconstructions, robustness to measurement errors, and (in)sensitivity to the training data. The latter is essential in domains with insufficient ground truth images.
2 RELATED WORK
Although neural networks have long been used to address inverse problems (Ogawa et al. (1998); Hoole (1993); Schiller and Doerffer (2010)), the past few years have seen the number of related deep learning papers grow exponentially. The majority address biomedical imaging (Güler and Übeyli (2005); Hudson and Cohen (2000)) with several special issues1 and review papers (Lucas et al. (2018); McCann et al. (2017)) dedicated to the topic. All these papers address reconstruction from subsampled or low-quality data, often motivated by reduced scanning time or lower radiation doses. Beyond biomedical imaging, machine learning techniques are emerging in geophysical imaging (Araya-Polo et al. (2017); Lewis et al. (2017); Bianco and Gertoft (2017)), though at a slower pace, perhaps partly due to the lack of standard open datasets.
Existing methods can be grouped into non-iterative methods that learn a feed-forward mapping from the measured data y (or some standard manipulation such as adjoint or a pseudoinverse) to the model x (Jin et al. (2016); Pelt and Batenburg (2013); Zhu et al. (2018); Wang (2016); Antholzer et al. (2017); Han et al. (2016); Zhang et al. (2016)); and iterative energy minimization methods, with either the regularizer being a neural network (Li et al. (2018)), or neural networks replacing various iteration components such as gradients, projectors, or proximal mappings (Kelly et al. (2017); Adler and Öktem (2017b;a); Rick Chang et al. (2017)). These are further related to the notion of plug-and-play regularization (Venkatakrishnan et al. (2013)), as well as early uses of neural nets to unroll and adapt standard sparse reconstruction algorithms (Gregor and LeCun (2010); Xin et al. (2016)). An advantage of the first group of methods is that they are fast; an advantage of the second group is that they are better at enforcing data consistency.
1IEEE Transactions on Medical Imaging, May 2016 (Greenspan et al. (2016)); IEEE Signal Processing Magazine, November 2017, January 2018 (Porikli et al. (2017; 2018)).
2

Under review as a conference paper at ICLR 2019

Stage 1
Projector 1 Projector 2 Projector 3
Projector (-1) Projector 

Stage 2
Reformulated inverse problem
solver

Figure 2: Regularization by  random projections: 1) each projector is approximated by a convolutional neural network which maps from a non-negative least squares reconstruction of an image to its projection onto a lower dimension subspace of Delaunay triangulations; 2) projections are combined to estimate the original image using regularized least squares.

Generative models A rather different take was proposed in the context of compressed sensing where the reconstruction is constrained to lie in the range of a pretrained generative network (Bora et al. (2017; 2018)). Their scheme achieves impressive results on random sensing operators and comes with theoretical guarantees. However, training generative networks requires many examples of ground truth and the method is inherently subject to dataset bias. Here, we focus on a setting where ground-truth samples are very few or impossible to obtain.
There are connections between our work and sketching (Gribonval et al. (2017); Pilanci and Wainwright (2016)) where the learning problem is also simplified by random low-dimensional projections of some object--either the data or the unknown reconstruction itself (Yurtsever et al. (2017)). This also exposes natural connections with learning via random features (Ali Rahimi (2008; 2009)).

3 REGULARIZATION BY RANDOM MESH PROJECTIONS

The two stages of our method are (i) decomposing a "hard" learning task of directly learning an unstable operator into an ensemble of "easy" problems of estimating projections of the unknown model into low-dimensional subspaces; and (ii) combining these projection estimates to solve a reformulated inverse problem for x. The two stages are summarized in Figure 2. While in principle our method can be applied to continuous and non-linear settings, we focus here on the linear finitedimensional case.

3.1 DECOMPOSING THE LEARNING PROBLEM

Statistical learning theory tells us that the number of samples required to learn a K-variate L-Lipschitz function to a given sup-norm accuracy is O(LK) (Cooper (1995)). While this result is proved for scalar-valued multivariate functions, it is reasonable to expect that the same scaling in L should hold for vector-valued maps. This motivates us to study Lipschitz properties of the projected inverse maps.
We wishto reconstruct x, an N -pixel image from X  RN where N is large (we think of x as an N × N discrete image). Suppose that the map from x  X to y  RM is injective so that it is
invertible on its range, and that there exists an L-Lipschitz (generally non-linear) inverse G, 2
G(y1) - G(y2)  L y1 - y2 .
Due to ill-posedness, L is typically large.
Consider now the map from the data y to a projection of the model x into some K-dimensional subspace S, where K N (this map exists by construction). Denote the projection by P Sx and assume S  RN is chosen uniformly at random.3 We want to evaluate the expected Lipschitz constant of the map from y to P Sx, noting that it can be written as P S · G:

E P S · G(y1) - P S · G(y2) 

E P S · G(y1) - P S · G(y2) 2 

K N

L

y1 - y2

2Existence of G can be showed for a variety of low-dimensional structures X . 3One way to construct the corresponding projection matrix is as P S = W W , where W  RN×K is a
matrix with standard iid Gaussian entries.

3

Under review as a conference paper at ICLR 2019

where the first inequality is Jensen's inequality, and the second one follows from

E P Sx 2 = E x P S P Sx = x E(P S P S)x

and

the

observation

that

EPSPS

=

K N

I

N

.

In

other

words,

random

projections

reduce

the

Lipschitz

constant by a factor of K/N on average. Since learning requires O(LK) samples, this allows us to

work with exponentially fewer samples and makes the learning task easier. Conversely, given a fixed

training dataset, it gives more accurate estimates.

3.1.1 THE CASE FOR DELAUNAY TRIANGULATIONS

The above example uses unstructured random subspaces. For many inverse problems, such as inverse

scattering (Beretta et al. (2013); Di Cristo and Rondi (2003)), a judicious choice of subspace family

can give exponential improvements in Lipschitz stability. In particular, it is favorable to consider

piecewise-constant images: x =

K k=1

xk k ,

with

k

being

an

indicator

function

of

some

domain

subset.

Motivated by this observation, we use piecewise-constant subspaces over random Delaunay triangle meshes. The Delaunay triangulations enjoy a number of desirable learning-theoretic properties. For function learning it was shown that given a set of vertices, piecewise linear functions on Delaunay triangulations achieve the smallest sup-norm error among all triangulations (Omohundro (1989)).

We sample  sets of points in the image domain from a uniform-density Poisson process and construct  (discrete) Delaunay triangulations with those points as vertices. Let S = {S | 1    } be the collection of  subspaces of piecewise-constant functions on these triangulations. Let further G be the map from y to the projection of the model into subspace S, Gy = P S x. Instead of learning the "hard" inverse mapping G, we propose to learn an ensemble of simpler mappings {G}=1.
We approximate each G by a convolutional neural network, ()(y) : RN  RN , parameterized by a set of trained weights (). Similar to Jin et al. (2016), we do not use the measured data y  RM directly as this would require the network to first learn to map y back to the image domain; we rather warm-start the reconstruction by a non-negative least squares reconstruction, y  RN , computed from y. The weights are chosen by minimizing empirical risk:

1J

() = arg min



J
j=1

()(yj ) - P S xj

2,
2

(1)

where

(xj, yj)

J j=1

is

a

set

of

J

training

models

and

non-negative

least

squares

measurements.

3.2 THE NEW INVERSE PROBLEM

By learning projections onto random subspaces, we transform our original problem into that of estimating x from ()(y) =1. To see how this can be done, ascribe to the columns of B  RN×K a natural orthogonal basis for the subspace S, B = [,1, . . . , ,K ], with ,k being the indicator function of the kth triangle in mesh . Denote by q d=ef q(y) the mapping from the data y to an estimate of the expansion coefficients of x in the basis for S:
q(y) d=ef B ()(y)
Let B d=ef B1 B2 . . . B  RN×K, and q d=ef q(y) d=ef q1 , q2 , . . . , q  RK; then we can estimate x using the following reformulated problem:

q  B x,

and the corresponding regularized reconstruction:

x = G(y) d=ef arg min

2
q(y) - B x + (x),

x[0,1]N

(2)

with (x) chosen as the TV-seminorm x TV. Note that solving the original problem directly using x TV regularizer fails to recover the structure of the model (Figure 1).

4

Under review as a conference paper at ICLR 2019

Subspaces stacked per trial ()

30
Kmax = 0.04
2

50
Kmax = 0.05

70
Kmax = 0.07

90
Kmax = 0.09

Triangles per subspace (K)

100
Kmax = 0.09

30

50

Kmax = 0.08
10

Kmax = 0.11

Kmax = 0.12

Kmax = 0.15

Kmax = 0.15

Kmax = 0.18
50

Kmax = 0.21

Kmax = 0.26

Kmax = 0.29

Kmax = 0.30

70

90 100

Figure 3: Illustration of the expected kernel (u, v) with varying subspace dimension, K, and number of subspaces, . Left: reconstruction of a sparse three-pixel image; right: reconstruction of the cameraman image.
3.3 STABILITY OF THE REFORMULATED PROBLEM AND "CONVOLUTIONALIZATION"
Since the true inverse map G has a large Lipschitz constant, it would seem reasonable that as the number of mesh subspaces  grows large (and their direct sum approaches the whole ambient space RN ), the Lipschitz properties of G should deteriorate as well.
Denote the unregularized inverse mapping in (2) y  x by G. Then we have the following estimate: 
G(y1) - G(y2) = (BT )q(y1) - (BT )q(y2)  min(B)-1 LK y1 - y2 ,
with min(B) the smallest (non-zero) singular value of B and LK the Lipschitz constant of the stable projection mappings q. Indeed, we observe empirically that min(B)-1 grows large as the number of subspaces increases which reflects the fact that although individual projections are easier to learn, the full-resolution reconstruction remains ill-posed.
Estimates of the individual subspace projections give correct local information. They convert possibly non-local measurements (e.g. integrals along curves in tomography) into estimates of local averages. The key is that these local averages--the coefficients of subspace projections--can be estimated accurately (see Section 4).
To further illustrate what we mean by correct local information, consider a simple numerical experiment with our reformulated problem, q = BT x, where x is an all-zero image with a few pixels "on". For the sake of clarity we assume the coefficients q are perfect. Recall that B is a block matrix comprising  subspace bases stacked side by side. It is a random matrix because the subspaces are generated at random, and therefore the reconstruction x = (B )q is also random. We approximate E x by simulating a large number of -tuples of meshes and averaging the obtained reconstructions.
Results are shown in Figure 3 for different numbers of triangles per subspace, K, and subspaces per reconstruction, . As  or K increase, the expected reconstruction becomes increasingly localized around non-zero pixels. The following proposition (proved in Appendix A) tells us that this phenomenon can be modeled by convolution.4 Proposition 1. Let x be the solution to q = B x given as (B )q. Then there exists a kernel (u), with u a discrete index, such that E x = x  . Furthermore, (u) is isotropic.
While Figure 3 suggests that more triangles are better, we note that this increases the subspace dimension which makes getting correct projection estimates harder. Instead we choose to stack more meshes with a smaller number of triangles.
Intuitively, since every triangle average depends on many measurements, this averaging makes the estimates more robust than the direct inversion. Proposition 1 tells us that this can be modeled as a convolution with an isotropic kernel. Consistent local averages enable us to recover the geometric structure while being more robust to data errors (Section 4).
4We note that this result requires adequate handling of boundary conditions; for the lack of space we omit the straightforward details.
5

Under review as a conference paper at ICLR 2019

Figure 4: Linearized traveltime tomography illustration: On the left we show a sample model, with

red crosses indicating 25 sensor locations and dashed blue lines indicating linearized travel paths; on

the right we show a reconstruction from

25 2

= 300 measurements by non-negative least squares.

4 NUMERICAL RESULTS

4.1 APPLICATION: TRAVELTIME TOMOGRAPHY

To demonstrate our method's benefits we consider linearized traveltime tomography (Hole (1992); Bording et al. (1987)), but we note that the method applies to any inverse problem with scarce data.

In traveltime tomography, we measure

N 2

wave travel times between N sensors as in Figure 4.

Travel times depend on the medium property called slowness (inverse of speed) and the task is to

reconstruct the spatial slowness map. Image intensities are a proxy for slowness maps--the lower

the image intensity the higher the slowness. In the straight-ray approximation, the problem data is

modeled as integral along line segments:

1
y(si, sj) = x(tsi + (1 - t)sj) dt,  si = sj
0

(3)

where x : R2  R+ is the continuous slowness map and si, sj are sensor locations. In our experiments, we use a 128 × 128 pixel grid with 25 sensors (300 measurements) placed uniformly in
an inscribed circle, and corrupt the measurements with zero-mean iid Gaussian noise.

4.1.1 ARCHITECTURES AND RECONSTRUCTION
We generate random Delaunay meshes each with 50 triangles. The corresponding projector matrices compute average intensity over triangles to yield a piecewise constant approximation P S x of x. We test two distinct architectures: (i) ProjNet, tasked with estimating the projection into a single subspace; and (ii) SubNet, tasked with estimating the projection over multiple subspaces.5
The ProjNet architecture is inspired by the FBPConvNet (Jin et al. (2016)) and the U-Net (Ronneberger et al. (2015)) as shown in Figure 8a in the appendix. Crucially, we constrain the network output to live in S by fixing the last layer of the network to be a projector, P S (Figure 8a). A similar trick in a different context was proposed in (Sønderby et al. (2016)).
We combine projection estimates from many ProjNets by regularized linear least-squares (2) to get the reconstructed model (cf. Figure 2) with the regularization parameter  determined on five held-out images. A drawback of this approach is that a separate ProjNet must be trained for each subspace. This motivates the SubNet (shown in Figure 8b). Each input to SubNet is the concatenation of a non-negative least squares reconstruction and 50 basis functions, one for each triangle forming a 51-channel input. This approach scales to any number of subspaces which allows us to get visually smoother reconstructions without any further regularization as in (2). On the other hand, the projections are less precise which can lead to slightly degraded performance.
As a quantitative figure of merit we use the signal-to-noise ratio (SNR). The input SNR is defined as 10 log10(s2ignal/n2oise) where s2ignal and n2oise are the signal and noise variance; the output SNR is defined as supa,b 20 log10( x 2/ x - ax^ - b 2) with x the ground truth and x^ the reconstruction.
130 ProjNets are trained for 130 different meshes with measurements at various SNRs. Similarly, a single SubNet is trained with 350 different meshes and the same noise levels. We compare the ProjNet and SubNet reconstructions with a direct U-net baseline convolutional neural network that
5Code available at https://github.com/_____

6

Under review as a conference paper at ICLR 2019

Average SNR over 102 x-ray images
Testing 10 dB SNR  dB

Direct 13.51 13.78

10 dB ProjNets
14.49 15.38

Training SNR
SubNet Direct 13.92 10.34 14.04 16.67

 dB ProjNets
12.88 17.23

SubNet 12.85 16.86

Table 1: Average reconstruction SNR for various training and testing SNR combinations.

reconstructs images from their non-negative least squares reconstructions. The direct baseline has the same architecture as SubNet except the input is a single channel non-negative least squares reconstruction like in ProjNet and the output is the target reconstruction. Such an architecture was proposed by (Jin et al. (2016)) and is used as a baseline in recent learning-based inverse problem works (Lunz et al. (2018); Ye et al. (2018)) and is inspiring other architectures for inverse problems (Antholzer et al. (2017)). We pick the best performing baseline network from multiple networks which have a comparable number of trainable parameters to SubNet.

Robustness to corruption To demonstrate that our method is robust against arbitrary assumptions made at training time, we consider two experiments. First, we corrupt the data with zero-mean iid Gaussian noise and reconstruct with networks trained at different input noise levels. In Figures 5a, 9 and Table 1, we summarize the results with reconstructions of geo images taken from the BP2004 dataset6 and x-ray images of metal castings (Mery et al. (2015)). The networks are trained on the arbitrarily chosen LSUN bridges dataset (Yu et al. (2015)). Our method reports better SNRs compared with the baseline. We note that direct reconstruction is unstable when trained on clean and tested on noisy measurements as it often hallucinates details that are artifacts of the training data. For applications in geophysics it is important that our method correctly captures the shape of the cavities unlike the direct inversion which can produce sharp but wrong geometries (see outlines in Figure 5a).

a) b) p = 1/8 p = 1/10 p = 1/12
Training SNR

10dB

 dB

Direct

Direct ProjNets SubNet Direct ProjNets SubNet

4.89

5.35

6.17

Testing SNR

10dB
11.05

11.62

11.53

9.03

10.26

11.21

ProjNets

8.66

9.45

10.21

 dB
8.77

11.56

11.17

10.08

12.51

13.62

SubNet
7.98

9.79

10.59

Figure 5: a) Reconstructions for different combinations of training and testing input SNR. The output

SNR is indicated for each reconstruction. Our method stands out when the training and testing

noise levels do not match; b) reconstructions with erasures with probability

1 8

,

1 10

and

1 12

.

The

reconstructions are obtained from networks which are trained with input SNR of 10 dB. The direct

network cannot produce a reasonable image in any of the cases.

Second, we consider a different corruption mechanism where traveltime measurements are erased (set

to zero) independently with probability p 

1 12

,

1 10

,

1 8

, and use networks trained with 10 dB input

SNR on the LSUN dataset to reconstruct. Figure 5b and Table 2 summarizes our findings. Unlike

with Gaussian noise (Figure 5a) the direct method completely fails to recover coarse geometry in all

test cases. In our entire test dataset of 102 x-ray images there is not a single example where the direct

network captures a geometric feature that our method misses. This demonstrates the strengths of our

approach. For more examples of x-ray images please see Appendix D.

Robustness against dataset overfitting Figure 6 illustrates the influence of the training data on reconstructions. Training with LSUN, CelebA (Liu et al. (2015)) and a synthetic dataset of random overlapping shapes (see Figure 12 in Appendix for examples) all give comparable reconstructions--a desirable property in applications where real ground truth is unavailable.
6http://software.seg.org/datasets/2D/2004_BP_Vel_Benchmark/

7

Under review as a conference paper at ICLR 2019

Average SNR over 102 x-ray images
Direct ProjNets SubNet

p

=

1 8

9.03 11.09

11.33

p

=

1 10

9.62 11.70

11.74

p

=

1 12

10.06 12.08

11.99

Non-negative Original least squares

LSUN

CelebA

Shapes

Table 2: Average SNR values for reconstructions from measurements with erasure probability, p. All networks were trained for 10dB noisy measurements on the LSUN bridges dataset. Refer to Appendix D for actual reconstructions.

Figure 6: Reconstructions of networks trained on non-negative least squares reconstructions of different datasets (LSUN, CelebA and Shapes) with 10dB training SNR.

Original

Non-negative least squares

Direct
10.00

7.00

9.67

6.73

11.44

13.69

13.11

13.23

9.40

12.96

10.96

15.36

ProjNets
12.03

6.53

11.48

6.92

13.30

15.07

14.33

14.35

10.52

13.62

12.57

16.52

SubNet
10.25

6.71

10.06

6.49

13.14

14.59

13.94

15.16

10.81

12.79

11.93

15.08

Figure 7: Reconstructions on checkerboards and x-rays with 10dB measurement SNR tested on 10dB trained networks. The red annotations highlight where the direct fails to reconstruct correct geometry.

We complement our results with reconstructions of checkerboard phantoms (standard resolution tests) and x-rays of metal castings in Figure 7. We note that in addition to better SNR, our method produces more accurate geometry estimates, as per the annotations in the figure.
5 CONCLUSION
We proposed a new approach to regularize ill-posed inverse problems in imaging, the key idea being to decompose an unstable inverse mapping into a collection of stable mappings which only estimate low-dimensional projections of the reconstruction. By using piecewise-constant Delaunay subspaces, we showed that the projections can indeed be accurately recovered. Combining the projections leads to a deconvolution-like problem. Compared to directly learning the inverse map, our method is more robust against noise and corruptions. We also showed that reconstructing the projections of the model instead of the model itself allows our method to generalize across training datasets. We get reconstructions that are better both quantitatively in terms of SNR and qualitatively in the sense that they estimate correct geometric features. When the data is corrupted in ways not seen at training time, our method still produces good results while the directly learned inversion breaks down altogether. Future work involves getting precise estimates for projected Lipschitz constants for various inverse problems, studying extensions to non-linear problems and developing concentration bounds for the equivalent convolution kernel.

8

Under review as a conference paper at ICLR 2019
REFERENCES
Jonas Adler and Ozan Öktem. Solving ill-posed inverse problems using iterative deep neural networks. arXiv preprint arXiv:1704.04058v2, April 2017a.
Jonas Adler and Ozan Öktem. Learned Primal-dual Reconstruction. arXiv preprint arXiv:1707.06474v1, July 2017b.
Benjamin Recht Ali Rahimi. Random features for large-scale kernel machines. Advances in Neural Information and Processing (NIPS), 2008.
Benjamin Recht Ali Rahimi. Weighted Sums of Random Kitchen Sinks: Replacing minimization with randomization in learning. Advances in Neural Information and Processing (NIPS), pages 1313­1320, 2009.
Stephan Antholzer, Markus Haltmeier, and Johannes Schwab. Deep Learning for Photoacoustic Tomography from Sparse Data. arXiv preprint arXiv:1704.04587v2, April 2017.
Mauricio Araya-Polo, Joseph Jennings, Amir Adler, and Taylor Dahlke. Deep-learning tomography. The Leading Edge, December 2017.
Elena Beretta, Maarten V de Hoop, and Lingyun Qiu. Lipschitz Stability of an Inverse Boundary Value Problem for a Schrödinger-Type Equation. SIAM J. Math. Anal., 45(2):679­699, March 2013.
Michael Bianco and Peter Gertoft. Sparse travel time tomography with adaptive dictionaries. arXiv preprint arXiv:1712.08655, 2017.
Ashish Bora, Ajil Jalal, Eric Price, and Alexandros G Dimakis. Compressed sensing using generative models. arXiv preprint arXiv:1703.03208, 2017.
Ashish Bora, Eric Price, and Alexandros G Dimakis. Ambientgan: Generative models from lossy measurements. In International Conference on Learning Representations (ICLR), 2018.
R Phillip Bording, Adam Gersztenkorn, Larry R Lines, John A Scales, and Sven Treitel. Applications of seismic travel-time tomography. Geophysical Journal International, 90(2):285­303, 1987.
Duane A Cooper. Learning lipschitz functions. International Journal of Computer Mathematics, 59 (1-2):15­26, 1995.
Michele Di Cristo and Luca Rondi. Examples of exponential instability for inverse inclusion and scattering problems. Inverse Problems, 19(3):685, 2003.
Erica Galetti, Andrew Curtis, Brian Baptie, David Jenkins, and Heather Nicolson. Transdimensional Love-wave tomography of the British Isles and shear-velocity structure of the East Irish Sea Basin from ambient-noise interferometry. Geophys. J. Int., 208(1):36­58, January 2017.
Hayit Greenspan, Bram van Ginneken, and Ronald M Summers. Deep Learning in Medical Imaging: Overview and Future Promise of an Exciting New Technique. IEEE Trans. Med. Imag., 35(5): 1153­1159, may 2016.
Karol Gregor and Yann LeCun. Learning fast approximations of sparse coding. In Proceedings of the 27th International Conference on International Conference on Machine Learning, pages 399­406. Omnipress, 2010.
Rémi Gribonval, Gilles Blanchard, Nicolas Keriven, and Yann Traonmilin. Compressive statistical learning with random feature moments. arXiv preprint arXiv:1706.07180, 2017.
Inan Güler and Elif Derya Übeyli. ECG beat classifier designed by combined neural network model. Pattern Recognition, 38(2):199­208, 2005.
Yo Seob Han, Jaejun Yoo, and Jong Chul Ye. Deep Residual Learning for Compressed Sensing CT Reconstruction via Persistent Homology Analysis. arXiv preprint arXiv:1611.06391, November 2016.
9

Under review as a conference paper at ICLR 2019
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Identity mappings in deep residual networks. In European Conference on Computer Vision, pages 630­645. Springer, 2016a.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the Conference on Computer Vision and Pattern Recognition, pages 770­778. IEEE, 2016b.
John Hole. Nonlinear high-resolution three-dimensional seismic travel time tomography. Journal of Geophysical Research: Solid Earth, 97(B5):6553­6562, 1992.
S R H Hoole. Artificial neural networks in the solution of inverse electromagnetic field problems. IEEE Trans. Magn., 29(2):1931­1934, March 1993.
Donna L Hudson and Maurice E Cohen. Neural networks and artificial intelligence for biomedical engineering. Wiley Online Library, 2000.
Kyong Hwan Jin, Michael T McCann, Emmanuel Froustey, and Michael Unser. Deep Convolutional Neural Network for Inverse Problems in Imaging. arXiv preprint arXiv:1611.03679v1, November 2016.
Brendan Kelly, Thomas P Matthews, and Mark A Anastasio. Deep Learning-Guided Image Reconstruction from Incomplete Data. arXiv preprint arXiv:1709.00584, September 2017.
Winston Lewis, Denes Vigh, et al. Deep learning prior models from seismic images for fullwaveform inversion. In SEG International Exposition and Annual Meeting. Society of Exploration Geophysicists, 2017.
Housen Li, Johannes Schwab, Stephan Antholzer, and Markus Haltmeier. NETT: Solving Inverse Problems with Deep Neural Networks. arXiv preprint arXiv:1803.00092v1, February 2018.
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In Proceedings of International Conference on Computer Vision (ICCV), December 2015.
Alice Lucas, Michael Iliadis, Rafael Molina, and Aggelos K Katsaggelos. Using Deep Neural Networks for Inverse Problems in Imaging: Beyond Analytical Methods. IEEE Signal Process. Mag., 35(1):20­36, 2018.
Sebastian Lunz, Ozan Öktem, and Carola-Bibiane Schönlieb. Adversarial regularizers in inverse problems. arXiv preprint arXiv:1805.11572, 2018.
Michael T McCann, Kyong Hwan Jin, and Michael Unser. Convolutional neural networks for inverse problems in imaging: A review. IEEE Signal Process. Mag., 34(6):85­95, 2017.
Domingo Mery, Vladimir Riffo, Uwe Zscherpel, Germán Mondragón, Iván Lillo, Irene Zuccar, Hans Lobel, and Miguel Carrasco. GDXray: The Database of X-ray Images for Nondestructive Testing. Journal of Nondestructive Evaluation, 34, 11 2015.
Takehiko Ogawa, Yukio Kosugi, and Hajime Kanada. Neural network based solution to inverse problems. In Neural Networks Proceedings, 1998. IEEE World Congress on Computational Intelligence. The 1998 IEEE International Joint Conference on, volume 3, pages 2471­2476. IEEE, 1998.
S M Omohundro. The Delaunay triangulation and function learning, 1989.
Daniel Maria Pelt and Kees Joost Batenburg. Fast tomographic reconstruction from limited data using artificial neural networks. IEEE Trans. on Image Process., 22(12):5238­5251, 2013.
Mert Pilanci and Martin J Wainwright. Iterative hessian sketch: Fast and accurate solution approximation for constrained least-squares. The Journal of Machine Learning Research, 17(1):1842­1879, 2016.
Fatih Porikli, Shiguang Shan, Cees Snoek, Rahul Sukthankar, and Xiaogang Wang. Deep Learning for Visual Understanding [From the Guest Editors]. IEEE Signal Process. Mag., 34(6):24­25, nov 2017.
10

Under review as a conference paper at ICLR 2019
Fatih Porikli, Shiguang Shan, Cees Snoek, Rahul Sukthankar, and Xiaogang Wang. Deep Learning for Visual Understanding: Part 2 [From the Guest Editors]. IEEE Signal Process. Mag., 35(1): 17­19, jan 2018.
JH Rick Chang, Chun-Liang Li, Barnabas Poczos, BVK Vijaya Kumar, and Aswin C Sankaranarayanan. One Network to Solve Them All­Solving Linear Inverse Problems Using Deep Projection Models. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5888­5897, 2017.
Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical Image Computing and ComputerAssisted Intervention, pages 234­241. Springer, 2015.
Helmut Schiller and Roland Doerffer. Neural network for emulation of an inverse model operational derivation of Case II water properties from MERIS data. International Journal of Remote Sensing, November 2010.
Casper Kaae Sønderby, Jose Caballero, Lucas Theis, Wenzhe Shi, and Ferenc Huszár. Amortised map inference for image super-resolution. arXiv preprint arXiv:1610.04490, 2016.
Pablo Sprechmann, Roee Litman, Tal Ben Yakar, Alexander M Bronstein, and Guillermo Sapiro. Supervised sparse analysis and synthesis operators. In Advances in Neural Information Processing Systems, pages 908­916, 2013.
Singanallur V Venkatakrishnan, Charles A Bouman, and Brendt Wohlberg. Plug-and-play priors for model based reconstruction. In Global Conference on Signal and Information Processing (GlobalSIP), 2013 IEEE, pages 945­948. IEEE, 2013.
Ge Wang. A perspective on deep imaging. IEEE Access, 4:8914­8924, 2016. Bo Xin, Yizhou Wang, Wen Gao, David Wipf, and Baoyuan Wang. Maximal sparsity with deep
networks? In Advances in Neural Information Processing Systems, pages 4340­4348, 2016. Huajian Yao, Robert D van Der Hilst, and Maarten V De Hoop. Surface-wave array tomography in
se tibet from ambient seismic noise and two-station analysis--i. phase velocity maps. Geophysical Journal International, 166(2):732­744, 2006. Jong Chul Ye, Yoseob Han, and Eunju Cha. Deep convolutional framelets: A general deep learning framework for inverse problems. SIAM Journal on Imaging Sciences, 11(2):991­1048, 2018. Fisher Yu, Yinda Zhang, Shuran Song, Ari Seff, and Jianxiong Xiao. LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop. arXiv preprint arXiv:1506.03365, 2015. Alp Yurtsever, Madeleine Udell, Joel A Tropp, and Volkan Cevher. Sketchy decisions: Convex low-rank matrix optimization with optimal storage. arXiv preprint arXiv:1702.06838, 2017. Hanming Zhang, Liang Li, Kai Qiao, Linyuan Wang, Bin Yan, Lei Li, and Guoen Hu. Image Prediction for Limited-angle Tomography via Deep Learning with Convolutional Neural Network. arXiv preprint arXiv:1607.08707v1, July 2016. Bo Zhu, Jeremiah Z Liu, Stephen F Cauley, Bruce R Rosen, and Matthew S Rosen. Image reconstruction by domain-transform manifold learning. Nature, 555(7697):487, March 2018.
11

Under review as a conference paper at ICLR 2019

A PROOF OF PROPOSITION 1

Proof. The reconstruction of the new inverse problem can be written as x = BB x where the columns of B = (B ) form a biorthogonal basis to the columns of B. Thus

K
x = x, bp bp.
p=1

Using the definition of the inner product and rearranging, we get

K

x(u) =

bp(·)bp(u), x d=ef (u, ·), x

p=1

where (u, v) d=ef

K p=1

bp(v)bp(u).

Now, the probability distribution of triangles around any

point u is both shift- and rotation-invariant because a Poisson process in the plane is shift- and

rotation-invariant. It follows that E (u, v) = ( u - v ) for some , meaning that

(E x)(u) = E (u, ·), x = ( u - · ), x = (x  )(u)

which is a convolution of the original model with a rotationally invariant (isotropic) kernel.

B NETWORK ARCHITECTURES
Figure 8 explains the network architecture used for ProjNet and SubNet. The network consists of a sequence of downsampling layers followed by upsampling layers, with skip connections (He et al. (2016b;a)) between the downsampling and upsampling layers. Each ProjNet output is constrained to a single subspace by applying a subspace projection operator, P S . We train 130 such networks and reconstruct from the projection estimate using (2). SubNet is a single network that is trained over multiple subspaces. To do this, we change its input to be [y B]. Moreover, we apply the same projection operator as ProjNet to the output of the SubNet. Each SubNet is trained to give projection estimates over 350 random subspaces. This approach allows us to scale to any number of subspaces without training new networks for each. Moreover, this allows us to build an over-constrained system q = Bx to solve. Even though SubNet has almost as many parameters as the direct net, reconstructing via the projection estimates allows SubNet to get higher SNR and more importantly, get better estimates of the coarse geometry than the direct inversion. All networks are trained with the Adam optimizer.
a)

128 64 32x32

256 16x16

512 8x8

256 16x16

128 32x32

64

64x64

64x64

3x3 conv + ReLU + batch norm

32 channels

2x2 max pool

32

128x128

2x2 upsampling

128x128

64 channels 128x128

skip connection concatenation

64 128x128

b) 1x1 conv + ReLU + batch norm

128 128

64x64 256 32x32

512 16x16

1024 8x8

512 16x16

256 64x64 32x32

concatenate as one input
Figure 8: a) ProjNet architecture; b) SubNet architecture. In both cases, the input is a non-negative least squares reconstruction and the network is trained to reconstruct a projection into one subspace. In SubNet, the subspace basis is concatenated to the non-negative least squares reconstruction.
12

Under review as a conference paper at ICLR 2019

C FURTHER RECONSTRUCTIONS

We showcase more reconstructions on actual geophysics images taken from the BP2004 dataset in Figure 9. Note that all networks were trained on the LSUN bridges dataset.

Training SNR

10dB

 dB

Direct ProjNets SubNet Direct ProjNets SubNet

Testing SNR

10dB
14.32

15.38

11.18

11.71

14.83

11.16

 dB

13.97

16.11

10.38

17.09

18.60

Training SNR

13.67

10dB

 dB

Direct ProjNets SubNet Direct ProjNets SubNet

Testing SNR

10dB
13.19

14.72

13.77

13.32

13.66

12.60

 dB

11.15

14.52

11.79

14.31

16.00

Training SNR

15.74

10dB

 dB

Direct ProjNets SubNet Direct ProjNets SubNet

Testing SNR

10dB
9.48

10.91

14.39

9.38

10.52

13.26

 dB
10.15

11.23

12.68

13.02

12.38

17.56

Figure 9: Geophysics image patches taken from BP2004 dataset. Our method especially gets correct global shapes with better accuracy even when tested on noise levels different from training.

D ERASURE RECONSTRUCTIONS

We

show

additional

reconstructions

for

the

largest

corruption

case,

p

=

1 8

,

for

x-ray

images

(Figure

10) and geo images (Figure 11). Our method consistently has better SNR. More importantly we note

that there is not a single instance where the direct reconstruction gets a feature that our methods

do not. The majority of times, the direct network misses a feature of the image. This is highly

undesirable in settings such as geophysical imaging.

E SHAPES DATASET
The shapes dataset was generated using random ellipses, circle and rectangle patches. See Figure 12 for examples. This dataset was used in Figure 6.

13

Under review as a conference paper at ICLR 2019

Original

Direct
10.59

9.02

6.12

6.43

6.49

8.90

7.42

5.65

5.50

6.25

9.64

5.53

8.52

ProjNets
14.23

12.01

12.94

11.48

10.09

11.22

12.00

8.82

9.57

11.03

11.50

8.69

14.05

SubNet
14.43

12.59

11.59

10.46

9.76

11.29

12.04

8.12

8.72

11.88

12.12

8.10

12.97

Figure

10:

Reconstructions

from

erasures

on

x-ray

images

with

erasure

probability

p

=

1 8

.

Original

Direct
9.83

4.76

8.08

5.51

ProjNets
11.48

8.66

13.76

9.36

SubNet
11.74

7.98

13.00

9.21

Figure

11:

Reconstructions

from

erasures

on

geo

images

with

erasure

probability

p

=

1 8

.

Figure 12: Examples from the random shapes dataset which is used in Figure 6. 14

