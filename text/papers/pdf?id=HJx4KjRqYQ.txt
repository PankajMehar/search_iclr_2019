Under review as a conference paper at ICLR 2019
ERGODIC MEASURE PRESERVING FLOWS
Anonymous authors Paper under double-blind review
ABSTRACT
Training probabilistic models with neural network components is intractable in most cases and requires to use approximations such as Markov chain Monte Carlo (MCMC), which is not scalable and requires significant hyper-parameter tuning, or mean-field variational inference (VI), which is biased. While there has been attempts at combining both approaches, the resulting methods have some important limitations in theory and in practice. As an alternative, we propose a novel method which is scalable, like mean-field VI, and, due to its theoretical foundation in ergodic theory, is also asymptotically accurate, like MCMC. We test our method on popular benchmark problems with deep generative models and Bayesian neural networks. Our results show that we can outperform existing approximate inference methods.
1 INTRODUCTION
Approximate statistical inference with unnormalised density functions is fundamentally important problem both Bayesian and frequentist inference. In particular, the successes of many sophisticated generative models in machine learning rely on power inference algorithms. Markov chain Monte Carlo (MCMC) methods and variational inference (VI), originally developed in statistics and physics, are two most important approximate inference methods in machine learning, which has been widely used in all kinds of probabilistic models, like latent topic models (Blei et al., 2003), Boltzmann machines (Hinton, 2002; Salakhutdinov & Larochelle, 2010), Bayesian non-parametric models (Neal, 2000; Kurihara et al., 2007). However, they are facing great challenges in the recent research on probabilistic modelling with deep neural networks (NNs). In particular, Bayesian deep neural networks become popular in recent works, because it exploits the Bayesian framework to overcome the overfitting and data demanding problems in deep learning (Neal, 2012). Another interesting research direction is to use deep neural networks in latent variable models to transform the simple latent random variables into complex distribution, which is also known as to Deep Generative Models (DGM). DGMs have been proved to be very powerful generative models. Inspired by DGMs, many recent works on variational inference adopted NN to construct flexible approximate distributions. In particular, variational autoencoders (Kingma & Welling, 2014) and normalising flows (Rezende & Mohamed, 2015) are two most influential works in this direction. However, due to lack of understanding of the convergence of specific NNs, the research of NNbased inference is focused on engineering the architecture of inference NNs based on experiments and heuristics. In this work, we propose a novel approximate inference method based on the classic inference theory of MCMC. Our method is inspired by the idea of parallel simulations of MCMC and the recent advances in variational inference with NNs. Like these variational methods, it is straightforward to accelerate the computation of our method using parallelised simulations on Graphical Processing Units. More importantly, with solid theoretical foundations in the theory of MCMC, the proposed method guarantees asymptotic convergence to arbitrary distributions of interest. It is a great advantage over variational inference, because of the approximation bias in variational methods. Our method is also attractive to a wide range of probabilistic models without NNs and Bayesian NNs.
1

Under review as a conference paper at ICLR 2019

2 BACKGROUND
2.1 BAYESIAN NEURAL NETWORKS
Given data D = {xn, yn}nN=1 formed by feature vectors xn and corresponding scalar targets yn, we can assume that each yn is obtained as yn = f (xn; ) + n, where f (·; ) is the output of a deep neural network with weights  and the n are independent noise variables with n  N (0, 2). This model specifies a likelihood function p(y1, . . . , yn|x1, . . . , xn, ) which can be combined with a Gaussian prior on  to obtain a posterior distribution p(|D). Predictions for the y corresponding to a new feature vector x are then obtained by using the predictive distribution p(y |x , D) =
p(y |x , )p(|D) d. However, integrating with respect to the posterior distribution p(|D) is intractable and approximations have to be performed in practice, with the most popular methods for this being VI and MCMC.

2.2 DEEP GENERATIVE MODELS
Generative models extract intrinsic structure from data by making use of latent variables. Let D be a dataset with n data points {xn}nN=1. Given a latent representation z, the data point x is assumed to be sampled from the conditional distribution p(x|z), which is specified in terms of some parameters . This conditional distribution is often refered to as the decoder. Given a prior distribution p(z) over the latent variables, the joint distribution of data and latent variables is p(x, z) = p(z)p(x|z). The marginal probability of data x under the model is then p(x) = p(z)p(x|z)dz.
Until recenlty, p(x|z) was typically specified using a simple distributional family, e.g. generalized linear models (Murphy, 2012; Bishop, 2006). However, more recently, deep generative models (DGMs) use deep neural networks with weights  to specify the decoder (Kingma & Welling, 2014; Goodfellow et al., 2014).
Maximum likelihood is a straightforward way to train probabilistic models with latent variables. However, the marginal likelihood p(x) is intractable to compute in DGMs and approximations are needed in practice. As before, the most popular methods for this are based on VI and MCMC. We briefly describe these methods in the following sections.

2.3 VARIATIONAL INFERENCE AND NORMALIZING FLOWS

VI approximates a complex posterior distribution with another simpler parametric distribution which
is found by optimizing a lower bound on the marginal likelihood. Let the complex posterior be p(z|x), with associated marginal likelihood p(x), and let q(z), parameterized by , be a simpler tractable distribution. The lower bound of the marginal likelihood is then defined as

log p(x)  Eq [log p(x, z) - log q(z)] ,

(1)

which is often known as the evidence lower bound (ELBO). The more flexible the parametric family q, the better the approximation quality to the true posterior and the tighter the value of the ELBO.
Mean-field VI uses a form for q(z) which assumes independence between random variables. This reduces the computational cost of the optimization problem but often leads to poor performance with complex posterior distributions, such as the ones arising in DGMs or in Bayesian neural networks.

Amortization can be used to accelerate convergence and reduce computational cost when multiple inference problems have to be solved simultaneously. The optimization of (1) can be amortized by making q depend explicitly on the data x. In this case, q(z) is replaced with q(z|x), where  are now the weights of a neural network which computes the parameteres of a tractable parametric distribuion on z from x. In this manner, for any new value of x, we can readily obtain a correspoding variational approximation given by q(z|x).
Variational auto-encoders (VAEs) (Kingma & Welling, 2014) are DGMs trained by using mean-field VI with a Gaussian parametric distribuion and amortization. Rezende & Mohamed (2015) improve over this method by using a more flexible variational family called normalizing flows (NFs). The NF family is obtained by applying L invertible non-linear transformations f1, . . . , fL to a random variable z0 with tractable density q0(z0) and exact simulation. The resulting output is a random

2

Under review as a conference paper at ICLR 2019

variable zL = fL  · · ·  f1(z0) with density q(zL|x) = q0(z0|x)

L l=1

|fl(zl-1)/zl-1|-1

and

with  being the parameters of f1, . . . , fL.

Stochastic gradient descent (SGD), in combination with the reparameterisation trick (Kingma &
Welling, 2014), can be used for the scalable optimization of the ELBO in VAEs and NFs. However,
the main limitation of VAEs and NFs is the bias present in their variational approximations. This bias can be quite high, even in the case of NFs, since the transformations f1, . . . , fL have to be rather simple to ensure invertibility and to reduce computational costs.

2.4 MARKOV CHAIN MONTE CARLO

Markov chain Monte Carlo (MCMC) is an approximate inference method which does not have the
aforementioned bias problem. MCMC works by simulating a stationary Markov chain that generates
asymptotically unbiased samples from the distributions of interest. Formally, a Markov chain is a sequence of random variables z0, z1, . . . in which the transition from state zl to zl+1 is defined by the conditional probability distribution of zl+1 given zl, denoted by K(zl, zl+1). Markov chains in MCMC methods have the following strong stationary property: if one state zl of the chain follows the stationary distribution , so does the next state zl+1. In particular,

(zl+1) = (zl)K(zl, zl+1) dzl .

(2)

If zl follows a distribution l that is different from the stationary one, then the distribution of zl+1

l+1(zl+1) = l(zl)K(zl, zl+1) dzl ,

(3)

is guaranteed to be closer to  than l. This property implies that, with sufficiently many transitions, the distribution l of zl converges to  irrespectively of the distribution the initial state z0.
Despite beign asymptotically unbiased, MCMC methods are less popular than VI for two reasons. First, they are computationally more expensive and second, they typically include hyper-parameters in the Markov kernel K which are highly problem dependent and are hard to tune in practice.

3 ERGODIC MEASURE PRESERVING FLOWS
In this section, we describe an inference method that combines the strengths of MCMC and VI and avoids their drawbacks. The idea is to use the output distribution of a MCMC chain, given by (3), as the variational distribution and optimize a simple to evaluate objective function for tuning MCMC parameters. Since MCMC converges to the target asymptotically, our variational approximation can be arbitrarily accurate. The result is a computationally efficient method which avoids the bias of parametric approximations and which can do automatic tuning of hyper-parameters.
3.1 DEFINITIONS
Given the target distribution  with unnormalised density function , we define an approximate distribution q by a mixture of sequential deterministic transformations that preserves the measure . We call such approximate distributions measure preserving flows (MPFs). The transformations preserving a given measure  are formally defined as follows (Billingsley, 1986). Definition 3.1. Measure Preserving Transformation (MPT). Let (, F , P ) be a probability space and µ be a consistent measure with P . A mapping T :    is a measure preserving transformation if T is measurable in both the input filed F and the output field F and µ(A) = µ(T -1(A)) for all A  F . If T is a one-to-one mapping onto , then T preserves µ: µ(A) = µ(T -1T A) = µ(T A).
An example of MPT is any transformation with Jacobian determinant equal to 1, which preserves the Lebesgue measure. In practice, it is straightforward to verify if a transformation T preserves the measure with density function  with the following conditions:
(i) Bijection: T is invertible, (ii) Preservation of density function: (z) = (T (z)) for all z.

3

Under review as a conference paper at ICLR 2019

(iii) Preservation of base measure: the Jacobian determinant is one if the Lebesgue measure is the base measure.

In probability theory, MPTs are often used within the area of ergodic stochastic processes since many of these processes can be reformulated as a composition of MPTs. In particular, MCMC kernels are MPTs and stationary Markov chains in MCMC are ergodic processes (Robert & Casella, 2005).

The joint probability of states in a MCMC chain is q(z0, z1, . . . , zL) = q0(z0)

L l=1

K (zl-1 ,

zl),

where q0 is the distribution of the initial state z0. The density of the last state zL is then obtained by

integrating out all the previous states:

L

qL(zL) = q0(z0) K(zl-1, zl) dz0 dz1 . . . dzL-1 .

(4)

l=1

If the Markov chain is ergodic, qL converges to the stationary distribution  in total variation distance as the length L of the chain increases (Robert & Casella, 2005).

We define a measure preserving flow (MPF) as a representation of (4) in which the kernel K becomes
a deterministic transformation Tr : Z  Z with stochastic auxiliary input r following distribution µ. We can then define zL as the result of applying these deterministic transformations to z0, that is, zL = TrL  · · ·  Tr1 (z0). By following the rule of changing variables, it is then straightforward to derive the density of zL as

qL(zL) = q(zL, r1:L)dr1:L = q(z0)µ(r1:L)(zL - TrL  · · ·  Tr1 (z0)) dz0 dr1:L , (5)

where  denotes the Dirac delta function. Note that there is no Jacobian term in (5) because of the
preservation of the Lebesgue measure. Because MPFs are equivalent to ergodic Markov chains, the density obtained at the output of an MPF, that is, qL, will converge to the stationary distribution  as L increases.

Hamiltonian Monte Carlo (HMC) is one of the most successful MCMC methods, which also can be interpreted as an MPF. Given the target random variable z  Rd with unnormalised density function , the HMC kernel is essentially applying a deterministic transformation H to the previous state zi with an auxiliary random variable r  Rn with the density function µ(·). The transformation H is
given by the solution of Hamiltonian dynamics

z (t) = rK(r), r (t) = -zU (z) ,

(6)

where z denotes the derivative of z w.r.t. the time of the dynamics t, U (z) = - log (z) and K(r) = - log µ(r). The preservation of total Hamiltonian energy, H(z, r) = U (z) + K(r), is the characteristic property of Hamiltonian dynamics, which can be easily verified by H (z, r) = 0 using (6). It is straightforward to see that H preserves the joint measure (z)µ(r). In particular, H is a

bijective transformation because the dynamics are deterministic and time reversible (Neal, 2010) and

the preservation of the Hamiltonian energy implies the preservation of density. Finally, the volume preservation of H in the space of (z, r) is a well known property of Hamiltonian dynamics, which can be proved by Liouville's theorem (Leimkuhler & Reich, 2004; Neal, 2010).

We can write the marginal distribution of the last sample generated by HMC as an MPF:

q(zL) = q(zL, r1:L)dr1:L = q(z0)µ(r)(zL - HrL  · · ·  Hr1 (z0)) dz0 dr1:L . We call the MPF generated by Hamiltonian dynamics a Hamiltonian MPF (HMPF).

(7)

3.2 UNDERSTANDING MEASURE PRESERVING CONDITIONS
We would like to address a common misunderstanding on the preservation of volume condition stated by (iii) in Section 3.1. Note that we are interested in sampling the random variable z, but the Hamiltonian dynamics preserve the joint measure (z, r) rather than (z). Following the conditions of MPTs in Section 3.1, it seems necessary to show that, for any specific value of r, any Tr used within an MPF should preserve volume in z space. However, this is not the case since the measure preservation conditions in the augmented space (z, r) are enough to guarantee the preservation of the marginal distribution in z space. Formally, we have the following proposition:

4

Under review as a conference paper at ICLR 2019

Proposition 1. Let T : Z × E  Z × E preserve the distribution (z, r). Then, if r is sampled from (r) = (z, r) dr, the marginal distribution
(z) = (z, r) dr
is also preserved by the projection of T in the space of z, that is, by Tr : Z  Z.
Proposition 1 gives us some insights on the difference between MPFs and normalising flows (NFs). As mentioned earlier, NFs also use a sequence of transformations Tr : Z  Z. However, these do not preserve the distribution of z and, consequently, they require the computation of Jacobian determinants by the rule of changing variables. By contrast, Proposition 1 implies that, in MPFs, Tr preserves the marginal (z) if T preserves the joint, which means that there is no need to include any Jacobian computations. For this reason, the transformations used in MPFs can be much more complicated than those used in NFs. For example, in Hamiltonian MPFs, for a given r, the Jacobian of Hr can be very complicated.

3.3 VARIATIONAL INFERENCE WITH MPFS

Given an unormalized posterior distribution p(x, z) for z, we can construct an MPF that preserves p(x, z)µ(r), where µ(r) is a simple distribution with tractable density and sampling algorithm. Let T l be the l-th transformation in the flow, where l are hyper-parameters. This transformation maps the state of the flow from (zl-1, rl) to (zl, rl) = T l (zl-1, rl). Similarly, the composition T L  · · ·  T 1 (z0, r1:L), which we denote by T , transforms (z0, r1:L) to (zL, r1:L). By the preservation of density and the preservation of Lebesgue measure of T , as given by conditions (ii)
and (iii) in Section 3.1), we have the following equalities

LL

L

p(x, z0) µ(rl) = p(x, z1)µ(r1) µ(rl) = · · · = p(x, zL) µ(rl),

l=1 l=2

l=1

(8)

LL
q0(z0) µ(rl) = qL(z1, r1; 1) µ(rl) = · · · = qL(zL, r1, r2 . . . , rL; ) ,
l=1 l=2

(9)

where q0(z0) is an initial proposal distribution and  = (1, . . . , L) are the transformation hyperparameters. It is important to clarify that, according to (9), the joint density of zL, r1, r2, . . . , rL is known, but the marginal density for these variables is intractable to compute in general.

Following (1), we can obtain the ELBO for the initial proposal distribution q0(z0) as

L(x; ) =

log

p(x, z0) q0(z0)

q0(z0)

dz0

.

(10)

We call this expression the simple ELBO. We can then multiplying by the density of the auxiliary

variables µ(r1:L) =

L l=1

µ(rl)

to

obtain

L(x; ) =

log p(x, z0) q0(z0)

L l=1

µ(rl

L l=1

µ(rl)

)

q0(z0

)

L l=1

µ(rl)

dz0

dr1:L

.

(11)

We can then replace (z0, r1:L) with (zL, r1:L) in (11) by making use of using transformation T , (8) and (9). The result is

L(x; , ) =

log

p(x, zL) qL(zL,

L l=1

µ(rl

r1:L; )

)

qL(zL,

r1:L;

)

dzL

dr1:L

,

(12)

where we have omitted the dependence of (zL, r1:L) on , since these variables are determined by the hyper-parameters of the MPTs. We call (12) the reparameterised ELBO.

3.4 ERGODIC LOWER BOUND AND ERGODIC INFERENCE
The reparameterised ELBO is of limited use, because it can only be as tight as the ELBO with initial proposal distribution q0. This seems to erase the benefits of using an ergodic MPF, which we know

5

Under review as a conference paper at ICLR 2019

will converge to the target posterior distribution given a sufficiently long flow. To overcome the drawback of the reparameterised ELBO, we propose another ELBO tailored to the MPF framework, which becomes arbitrarily tight as the length of the flow grows. We call such an ELBO ergodic lower bound (ERLBO).

To derive ERLBO, we first rewrite (12) as

L(x; , ) = =

log

p(x, zL) qL(zL; )

qL(zL;

)

dzL

+

log

L l=1

µ(rl)

qL(r1:L|zL; )

qL(zL,

r1:L;

)

dzL

dr1:L

log

p(x, zL) qL(zL; )

qL(zL;

)

dzL

-

DKLL

.

(13)

where DKLL is the Kullback-Liebler divergence between qL(zL, r1:L; ) and qL(zL; )

L l=1

µ(rl

).

It is straightforward to show that the first term on the RHS in (13) is a lower bound of the marginal

likelihood by Jensen's inequality. This leads to the ERLBO given by

L~(x; , ) =

log

p(x, zL) qL(zL; )

qL

(zL;

)

dzL

=

L(x;

, )

+

DKLL

.

(14)

This is a tighter lower bound than the simple ELBO because the difference between L~(x; , ) and L(x; ) in (10) is DKLL  0. Moreover, the ERLBO can be shown to monotonically increase w.r.t. L.
Proposition 2. The lower bound L~(x; , ) in (14) becomes tighter and tighter as L increases, that is, L~(x; , 1:L)  L~(x; , 1:L-1) and the equality holds if and only if DKLL = 0.

The complete proof is included in appendix.

Recall that qL(zL; ) is obtained by a sequence of transformations that preserve the probability measure p(z|x). It is well-known that MCMC chains have a unique invariant distribution and so do
the MCMC-equivalent MPFs. Therefore, we know that if L~(x; , 1:L) stops growing, qL(zL; ) must converge to p(z|x). This is formally described by the following theorem.

Theorem 1. Given an ergodic measure preserving flow with invariant measure , the ergodic lower bound L~(x; , ) increases in the length of the flow L and becomes an unbiased estimator of the
marginal log p(x) as L increases to infinity.

We could tune  by optimizing the ERLBO. To better understand the values of  that would be
favored by this optimisation process, we can rewrite the ERLBO by making explicit its dependence on the entropy of qL(zL; ), which we denote by H[qL(zL; )] = - log qL(zL; )qL(zL; ) dzL. In particular,

L~(x; , ) = EqL(zL;) [log p(x, zL)] + H[qL(zL; )] .

(15)

When optimizing this quantity w.r.t. , the first term in the RHS will encourage qL(zL; ) to have high density in regions where p(x, zL) is high, while the second term will favor high entropy solutions and will prevent qL(zL; ) from converging to a Dirac delta centered at the maximizer of log p(x, zL). Note that the first term in the RHS of (15) can be easily approximated by Monte Carlo, while the second term is intractable because qL(zL; ) is not available. However, since qL(zL; ) converges to p(z|x) as L increases, we expect the effect of H[qL(zL; )] on  to be small and that most of the similarity of qL(zL; ) to p(z|x) will be captured by the first term in
the RHS of (15). Therefore, we propose to tune  by optimizing the tractable objective given by the
first term, that is,

F~(x; , ) = EqL(zL;) [log p(x, zL)] .

(16)

If with the initial flow parameter 0, the objective F~ < Ep(x,z) [log p(x, z)], we expect optimising F~ produces faster convergence of qL(zL; ) towards p(x, z). Importantly, the model parameters  can also be adjusted by optimizing F~ because the omitted H[qL(zL; )] does not depend on  and, consequently, optimizing F~(x; , ) and L~(x; , ) w.r.t.  are equivalent operations.

3.5 IMPLEMENTATION OF HMPFS
The hyper-parameters to be tuned in a HMPF include the parameters of q0 and the transformation parameters for the Hamiltonian simulation, that is,  = (1, . . . , L). A natural choice for q0

6

Under review as a conference paper at ICLR 2019

is multivariate Gaussian with mean µ = (µ1 . . . , µd) and diagonal covariance matrix with entries 2 = (12, . . . , d2), where d is the dimensionality of the sample space. The most popular algorithm for simulating Hamiltonian dynamics is the vanilla Leapfrog integrator. We refer to the tutorial of Neal (2010) for more detailed description of the implementation of this algorithm. Leapfrog is a numeric integrator that approximates the Hamiltonian dynamics (6) by an iterative procedure with discretized time t, that is,

x(t + t) = x(t) + trK(r(t)) ,

r(t + t) = r(t) - txU (x(t)) . (17)

For the flow parameters, we consider the total simulation time T . Given a fixed number of Leapfrog iterations m, the simulation time T can be reparameterized as the time step size t = T /m. Neal (2010) shows that it is possible to use different t for each dimension of the sample space to improve the quality of Leapfrog. Therefore, we consider the parameters of the l-th Hamiltonian simulation in the flow to be l = (tl,1, . . . , tl,d). The pseudo code for ergodic inference with HMPFs is shown in Algorithm 1.

Algorithm 1: Ergodic Inference on Hamiltonian Measure Preserving Flow.

input : potential function U (z; x, ), dataset D and large L output: optimal decoder and flow parameters  and 

initialize  and ;

while not converged do x - sample one data point from D; z0  N (µ, diag(2));
/* Start of simulation of HMPF for l = 1, . . . , L do

*/

r  N (0, 1);

zl - H(zl-1, r; U (z; x, ), l);

/* Leapfrog simulation */

end

/* End of simulation of HMPF

*/

obj - U (zL; x, ); /* one sample Monte Carlo Approx. of F~(x; , ) */

 - AdamUpdate(, obj);

 - AdamUpdate(, obj);

end

We do not include any Metropolis-Hastings (MH) correction steps in our method since this is not necessary. The MH steps are included in MCMC methods to ensure asymptotic convergence to the correct target with an unlimited number of transitions. By contrast, MPFs are in the finite-length regime and the main concern is to accelerate the convergence of MPFs to be as close as possible to the target measure. In this setting, it is not immediately clear that MH steps would be helpful. In particular, in Section 4.1 we provide empirical evidence of how HMPFs can converge to the correct target without MH steps.
Due to the composition of the MPTs, computing the gradient can be expensive when the flow is long. To speed up training, we stop the gradient computations when evaluating -zU (z) in the Leapfrog steps. This trick leads to incorrect gradients. However, we noticed that the optimization was not significantlly affected by this and still worked very well in practice. Finally, note that working with incorrect gradients does not affect the convergence of the flow to the correct target distribution because that is guaranteed by the convergence of the ERLBO as we mentioned in previous section.

4 EXPERIMENTS
We provide empirical evidence of HMPFs in three inference tasks. Our goal is to show that HMPFs can provide better approximations than other approximate inference methods.
4.1 DEMONSTRATION OF CONVERGENCE
To verify the theoretical results on the convergence of MPFs in Section 3.4, we test HMPFs on 8 bivariate distributions. The full list of benchmark distributions and results are included in the

7

Under review as a conference paper at ICLR 2019

appendix. Here, we focus on two multimodal benchmarks. The first testing target distribution is a bimodal moon shaped distribution as shown in Figure 2a. We call this target dual moon. Dual moon is one of the benchmarks in normalising flows (Rezende et al., 2014). The second testing target is a mixture of 6 Gaussian distributions placed in a circle. We use 15 Hamiltonian transformations with 5 Leapfrog steps each. The architecture detail of HMPFs 1 can be found in Section D.1. The initial state of MPFs is sampled from a standard Gaussian distribution. The gradient of the objective function is estimated using 1000 samples from HMPFs.
To illustrate the convergence of HMPFs to the target distribution, figures 1c and 1d show histograms of samples as a function of the flow length and the training iterations. To confirm the convergence numerically, we compute the ERLBO using a numeric method for the estimation of the entropy. Plots for the ERLBO and the ground truth log normalization constants are show in figures 1a and 1b

4.2 DEEP GENERATIVE MODELS
MNIST is a standard benchmark for testing approximate inference algorithms for training deep generative models. This dataset contains 60,000 grey level 28×28 images of handwritten digits. For fair comparison with previous work, we use the 10,000 prebinarised MNIST test images from (Burda et al., 2015)2. Our benchmark deep generative model is based on the deconvolutional network used by Salimans et al. (2015) for testing Hamiltonian variational inference (HVI). In particular, the decoder p(x, z) consists of 32 dimensional latent variables z with isotropic Gaussian prior p(z) = N (0, I) and a deconvolutional network with the architecture from top to bottom including a single fully-connected layer with 500 RELU hidden units, then three deconvolutional layers with 5 × 5 filters, [16, 32, 32] feature maps and RELU activations and the final output layer is simply element-wise logistic activation functions. In the convolutional VAE, the encoder network mirrors the architecture of the decoder.
The code for HVI (Salimans et al., 2015) is not publicly available. Nevertheless, we reimplemented their convolutional VAE and were able to reproduce the marginal likelihood reported by Salimans et al. (2015), as shown in Table 1. This verifies that our implementation of the convolutional VAE is correct and that our results are comparable to the ones reported originally by Salimans et al. (2015). We also implemented HVI following Salimans et al. (2015). We used a single hidden layer network with 640 hidden units and RELU activations as the reverse model for the HMC transitions. We also implemented another VI method similar to HVI and called the Hamiltonian variational encoder (HVAE) (Caterini et al., 2018). Unlike HVI, HVAE does not use a reverse model. This method optimizes instead a bound derived from the stationary distribution of reverse momenta. Futhermore, HVAE uses tempering Hamiltonian dynamics that requires additional Jacobian corrections. In our implementation of HVAE, we simply ignore the temperature for computational efficiency.

Encoders
Conv VAE(nh=300) (Salimans et al., 2015) HVI(1HMPF-16LF, nh=800) (Salimans et al., 2015) HVAE(1HMPF-20LF, nh = 300)(Caterini et al., 2018)
Conv VAE(nh=500) (Baseline) HVI(1HMPF-16LF, nh=800) HVAE(1HMPF-16LF, nh=500)
HMPF(30HMPT-5LF, nh=500, no encoder network) HMPF(30HMPT-5LF, nh=500, no encoder network) HMPF(30HMPT-5LF, nh=500, no encoder network) HMPF(30HMPT-5LF, nh=500, no encoder network)

Training hours -
6.00 6.00 6.00 1.65 3.00 6.00 12.00

Training Epochs -
3000 360 360 54 100 200 400

Test log(x) -83.20 -81.94 -84.78 -83.57 -83.68 -84.22 -83.17 -82.76 -82.65 -81.43

ESS 50 48 48 48 46 45 38

Table 1: Comparison in terms of compuational efficiency and approximate test log-likelihood. For fair comparison, we implemented the deconvolutional decoder network in (Salimans et al., 2015) to test HVI. In (Salimans et al., 2015), the test likelihood is estimated using importence-weighted samples from the encoder network. In our experiment, we use a more reliable estimation method based on Hamiltonian annealled importance sampling and report the effective sample size (ESS).

1The code of HMPFs for all three experiments will be available at https://github.com/ firstauthor/hmpfs
2https://github.com/yburda/iwae

8

Under review as a conference paper at ICLR 2019

(a) Dual Moon

0

T1 <latexit sha1_base64="L/D5BPxeQEqeV25drgL7NXStlaw=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRi8cKTVtoQ9lsN+3SzSbsToQS+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST+7nfeeLaiES1cJryIKYjJSLBKFrJbw1ybzao1ty6uwBZJ15BalCgOah+9YcJy2KukElqTM9zUwxyqlEwyWeVfmZ4StmEjnjPUkVjboJ8ceyMXFhlSKJE21JIFurviZzGxkzj0HbGFMdm1ZuL/3m9DKPbIBcqzZArtlwUZZJgQuafk6HQnKGcWkKZFvZWwsZUU4Y2n4oNwVt9eZ20r+qeW/cer2uNuyKOMpzBOVyCBzfQgAdogg8MBDzDK7w5ynlx3p2PZWvJKWZO4Q+czx+ZJo6I</latexit>

10

T2 <latexit sha1_base64="5hh7LnP/wW0qHB8ygQs8xXHBDLw=">AAAB7HicbVBNS8NAEJ34WetX1aOXxSJ4KkkR9Fj04rFC0xbaUDbbSbt0swm7G6GE/gYvHhTx6g/y5r9x2+agrQ8GHu/NMDMvTAXXxnW/nY3Nre2d3dJeef/g8Oi4cnLa1kmmGPosEYnqhlSj4BJ9w43AbqqQxqHATji5n/udJ1SaJ7JlpikGMR1JHnFGjZX81iCvzwaVqltzFyDrxCtIFQo0B5Wv/jBhWYzSMEG17nluaoKcKsOZwFm5n2lMKZvQEfYslTRGHeSLY2fk0ipDEiXKljRkof6eyGms9TQObWdMzVivenPxP6+Xmeg2yLlMM4OSLRdFmSAmIfPPyZArZEZMLaFMcXsrYWOqKDM2n7INwVt9eZ206zXPrXmP19XGXRFHCc7hAq7AgxtowAM0wQcGHJ7hFd4c6bw4787HsnXDKWbO4A+czx+aq46J</latexit>

T3 <latexit sha1_base64="fAA/6ZfzyWT9s1dcLKPtMeUq/R4=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lU0GPRi8eK/YI2lM120i7dbMLuRiihP8GLB0W8+ou8+W/ctjlo64OBx3szzMwLEsG1cd1vp7C2vrG5Vdwu7ezu7R+UD49aOk4VwyaLRaw6AdUouMSm4UZgJ1FIo0BgOxjfzfz2EyrNY9kwkwT9iA4lDzmjxkqPjf5lv1xxq+4cZJV4OalAjnq//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMT3vgZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3sNVpXabx1GEEziFc/DgGmpwD3VoAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH9fRjX4=</latexit>

T4 <latexit sha1_base64="UNK7UyZqgdAUkMH9awLUEh/q0QQ=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48V+wVtKJvtpF262YTdjVBCf4IXD4p49Rd589+4bXPQ1gcDj/dmmJkXJIJr47rfTmFjc2t7p7hb2ts/ODwqH5+0dZwqhi0Wi1h1A6pRcIktw43AbqKQRoHATjC5m/udJ1Sax7Jppgn6ER1JHnJGjZUem4PaoFxxq+4CZJ14OalAjsag/NUfxiyNUBomqNY9z02Mn1FlOBM4K/VTjQllEzrCnqWSRqj9bHHqjFxYZUjCWNmShizU3xMZjbSeRoHtjKgZ61VvLv7n9VIT3vgZl0lqULLlojAVxMRk/jcZcoXMiKkllClubyVsTBVlxqZTsiF4qy+vk/ZV1XOr3kOtUr/N4yjCGZzDJXhwDXW4hwa0gMEInuEV3hzhvDjvzseyteDkM6fwB87nD9lVjX8=</latexit>

T5 <latexit sha1_base64="MowWjkDNqlqsDOzcI0xwQYBRpyM=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0WPRi8eK/YI2lM120i7dbMLuRiihP8GLB0W8+ou8+W/ctjlo64OBx3szzMwLEsG1cd1vp7C2vrG5Vdwu7ezu7R+UD49aOk4VwyaLRaw6AdUouMSm4UZgJ1FIo0BgOxjfzfz2EyrNY9kwkwT9iA4lDzmjxkqPjf5Vv1xxq+4cZJV4OalAjnq//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMT3vgZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3sNlpXabx1GEEziFc/DgGmpwD3VoAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH9rZjYA=</latexit>

(b) Circular Gaussian Mixture

Flow direction (the order of HMPTs)

T6 <latexit sha1_base64="GcbK6HhP/SP6dLH3Gwdd0734D60=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE1GPRi8eK/YI2lM120i7dbMLuRiihP8GLB0W8+ou8+W/ctjlo64OBx3szzMwLEsG1cd1vp7C2vrG5Vdwu7ezu7R+UD49aOk4VwyaLRaw6AdUouMSm4UZgJ1FIo0BgOxjfzfz2EyrNY9kwkwT9iA4lDzmjxkqPjf5Vv1xxq+4cZJV4OalAjnq//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMT3vgZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3sNlpXabx1GEEziFc/DgGmpwD3VoAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH9xdjYE=</latexit>

T7 <latexit sha1_base64="xMQbwlMHl3qQCyq0kk45jjuZIiU=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEqMeiF48V+wVtKJvtpF262YTdjVBCf4IXD4p49Rd589+4bXPQ1gcDj/dmmJkXJIJr47rfTmFjc2t7p7hb2ts/ODwqH5+0dZwqhi0Wi1h1A6pRcIktw43AbqKQRoHATjC5m/udJ1Sax7Jppgn6ER1JHnJGjZUem4PaoFxxq+4CZJ14OalAjsag/NUfxiyNUBomqNY9z02Mn1FlOBM4K/VTjQllEzrCnqWSRqj9bHHqjFxYZUjCWNmShizU3xMZjbSeRoHtjKgZ61VvLv7n9VIT3vgZl0lqULLlojAVxMRk/jcZcoXMiKkllClubyVsTBVlxqZTsiF4qy+vk/ZV1XOr3sN1pX6bx1GEMziHS/CgBnW4hwa0gMEInuEV3hzhvDjvzseyteDkM6fwB87nD93hjYI=</latexit>

T8 <latexit sha1_base64="qN2VbyAHbCvxbsOrPYaB3Bg+6A8=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEsMeiF48V+wVtKJvtpF262YTdjVBCf4IXD4p49Rd589+4bXPQ1gcDj/dmmJkXJIJr47rfTmFjc2t7p7hb2ts/ODwqH5+0dZwqhi0Wi1h1A6pRcIktw43AbqKQRoHATjC5m/udJ1Sax7Jppgn6ER1JHnJGjZUem4PaoFxxq+4CZJ14OalAjsag/NUfxiyNUBomqNY9z02Mn1FlOBM4K/VTjQllEzrCnqWSRqj9bHHqjFxYZUjCWNmShizU3xMZjbSeRoHtjKgZ61VvLv7n9VIT1vyMyyQ1KNlyUZgKYmIy/5sMuUJmxNQSyhS3txI2pooyY9Mp2RC81ZfXSfuq6rlV7+G6Ur/N4yjCGZzDJXhwA3W4hwa0gMEInuEV3hzhvDjvzseyteDkM6fwB87nD99ljYM=</latexit>

T9 <latexit sha1_base64="L4NJcCW+Bn6ouesZpObQpHdIEu0=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG9FLx4r9gvaUDbbSbt0swm7G6GE/gQvHhTx6i/y5r9x2+agrQ8GHu/NMDMvSATXxnW/ncLa+sbmVnG7tLO7t39QPjxq6ThVDJssFrHqBFSj4BKbhhuBnUQhjQKB7WB8N/PbT6g0j2XDTBL0IzqUPOSMGis9Nvo3/XLFrbpzkFXi5aQCOer98ldvELM0QmmYoFp3PTcxfkaV4UzgtNRLNSaUjekQu5ZKGqH2s/mpU3JmlQEJY2VLGjJXf09kNNJ6EgW2M6JmpJe9mfif101NeO1nXCapQckWi8JUEBOT2d9kwBUyIyaWUKa4vZWwEVWUGZtOyYbgLb+8SloXVc+teg+XldptHkcRTuAUzsGDK6jBPdShCQyG8Ayv8OYI58V5dz4WrQUnnzmGP3A+fwDg6Y2E</latexit>

T10 <latexit sha1_base64="wFvqZM+t9/hg6a45uscwx0N/jfY=">AAAB7XicbVDLSgNBEOz1GeMr6tHLYBA8hV0R9Bj04jFCXpAsYXbSScbMziwzs0JY8g9ePCji1f/x5t84SfagiQUNRVU33V1RIrixvv/tra1vbG5tF3aKu3v7B4elo+OmUalm2GBKKN2OqEHBJTYstwLbiUYaRwJb0fhu5reeUBuuZN1OEgxjOpR8wBm1TmrWe1ngT3ulsl/x5yCrJMhJGXLUeqWvbl+xNEZpmaDGdAI/sWFGteVM4LTYTQ0mlI3pEDuOShqjCbP5tVNy7pQ+GSjtSloyV39PZDQ2ZhJHrjOmdmSWvZn4n9dJ7eAmzLhMUouSLRYNUkGsIrPXSZ9rZFZMHKFMc3crYSOqKbMuoKILIVh+eZU0LyuBXwkersrV2zyOApzCGVxAANdQhXuoQQMYPMIzvMKbp7wX7937WLSuefnMCfyB9/kDCHCOwg==</latexit>

T11 <latexit sha1_base64="RYnNRjXkWWb9ARdd44MYi1fQPxM=">AAAB7XicbVBNSwMxEJ2tX7V+VT16CRbBU9mIUI9FLx4r9AvapWTTbBubTZYkK5Sl/8GLB0W8+n+8+W9M2z1o64OBx3szzMwLE8GN9f1vr7CxubW9U9wt7e0fHB6Vj0/aRqWashZVQuluSAwTXLKW5VawbqIZiUPBOuHkbu53npg2XMmmnSYsiMlI8ohTYp3Ubg4yjGeDcsWv+gugdYJzUoEcjUH5qz9UNI2ZtFQQY3rYT2yQEW05FWxW6qeGJYROyIj1HJUkZibIFtfO0IVThihS2pW0aKH+nshIbMw0Dl1nTOzYrHpz8T+vl9roJsi4TFLLJF0uilKBrELz19GQa0atmDpCqObuVkTHRBNqXUAlFwJefXmdtK+q2K/ih+tK/TaPowhncA6XgKEGdbiHBrSAwiM8wyu8ecp78d69j2VrwctnTuEPvM8fCfWOww==</latexit>

T12 <latexit sha1_base64="CeAqyifvgzZ82ONIqNMLngdc4Mg=">AAAB7XicbVBNSwMxEJ2tX7V+VT16CRbBU9kUQY9FLx4r9AvapWTTbBubTZYkK5Sl/8GLB0W8+n+8+W9M2z1o64OBx3szzMwLE8GN9f1vr7CxubW9U9wt7e0fHB6Vj0/aRqWashZVQuluSAwTXLKW5VawbqIZiUPBOuHkbu53npg2XMmmnSYsiMlI8ohTYp3Ubg4yXJsNyhW/6i+A1gnOSQVyNAblr/5Q0TRm0lJBjOlhP7FBRrTlVLBZqZ8alhA6ISPWc1SSmJkgW1w7QxdOGaJIaVfSooX6eyIjsTHTOHSdMbFjs+rNxf+8XmqjmyDjMkktk3S5KEoFsgrNX0dDrhm1YuoIoZq7WxEdE02odQGVXAh49eV10q5VsV/FD1eV+m0eRxHO4BwuAcM11OEeGtACCo/wDK/w5invxXv3PpatBS+fOYU/8D5/AAt6jsQ=</latexit>

T13 <latexit sha1_base64="Z5OvuKOOxNNqkPGYvpDKFMMvMvw=">AAAB7XicbVBNSwMxEJ2tX7V+VT16CRbBU9mooMeiF48V+gXtUrJpto3NJkuSFcrS/+DFgyJe/T/e/Dem7R609cHA470ZZuaFieDG+v63V1hb39jcKm6Xdnb39g/Kh0cto1JNWZMqoXQnJIYJLlnTcitYJ9GMxKFg7XB8N/PbT0wbrmTDThIWxGQoecQpsU5qNfoZvpz2yxW/6s+BVgnOSQVy1Pvlr95A0TRm0lJBjOliP7FBRrTlVLBpqZcalhA6JkPWdVSSmJkgm187RWdOGaBIaVfSorn6eyIjsTGTOHSdMbEjs+zNxP+8bmqjmyDjMkktk3SxKEoFsgrNXkcDrhm1YuIIoZq7WxEdEU2odQGVXAh4+eVV0rqoYr+KH64qtds8jiKcwCmcA4ZrqME91KEJFB7hGV7hzVPei/fufSxaC14+cwx/4H3+AAz/jsU=</latexit>

T14 <latexit sha1_base64="vSoJN93oCgKVYidfKqVyMbJjz18=">AAAB7XicbVBNSwMxEJ2tX7V+VT16CRbBU9lIQY9FLx4r9AvapWTTbBubTZYkK5Sl/8GLB0W8+n+8+W9M2z1o64OBx3szzMwLE8GN9f1vr7CxubW9U9wt7e0fHB6Vj0/aRqWashZVQuluSAwTXLKW5VawbqIZiUPBOuHkbu53npg2XMmmnSYsiMlI8ohTYp3Ubg4yXJsNyhW/6i+A1gnOSQVyNAblr/5Q0TRm0lJBjOlhP7FBRrTlVLBZqZ8alhA6ISPWc1SSmJkgW1w7QxdOGaJIaVfSooX6eyIjsTHTOHSdMbFjs+rNxf+8XmqjmyDjMkktk3S5KEoFsgrNX0dDrhm1YuoIoZq7WxEdE02odQGVXAh49eV10r6qYr+KH2qV+m0eRxHO4BwuAcM11OEeGtACCo/wDK/w5invxXv3PpatBS+fOYU/8D5/AA6EjsY=</latexit>

20

30 40 50

60 70 80

Training iterations

0

T1 <latexit sha1_base64="L/D5BPxeQEqeV25drgL7NXStlaw=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0GPRi8cKTVtoQ9lsN+3SzSbsToQS+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST+7nfeeLaiES1cJryIKYjJSLBKFrJbw1ybzao1ty6uwBZJ15BalCgOah+9YcJy2KukElqTM9zUwxyqlEwyWeVfmZ4StmEjnjPUkVjboJ8ceyMXFhlSKJE21JIFurviZzGxkzj0HbGFMdm1ZuL/3m9DKPbIBcqzZArtlwUZZJgQuafk6HQnKGcWkKZFvZWwsZUU4Y2n4oNwVt9eZ20r+qeW/cer2uNuyKOMpzBOVyCBzfQgAdogg8MBDzDK7w5ynlx3p2PZWvJKWZO4Q+czx+ZJo6I</latexit>

10

20

30 40 50

60 70 80

T2 <latexit sha1_base64="5hh7LnP/wW0qHB8ygQs8xXHBDLw=">AAAB7HicbVBNS8NAEJ34WetX1aOXxSJ4KkkR9Fj04rFC0xbaUDbbSbt0swm7G6GE/gYvHhTx6g/y5r9x2+agrQ8GHu/NMDMvTAXXxnW/nY3Nre2d3dJeef/g8Oi4cnLa1kmmGPosEYnqhlSj4BJ9w43AbqqQxqHATji5n/udJ1SaJ7JlpikGMR1JHnFGjZX81iCvzwaVqltzFyDrxCtIFQo0B5Wv/jBhWYzSMEG17nluaoKcKsOZwFm5n2lMKZvQEfYslTRGHeSLY2fk0ipDEiXKljRkof6eyGms9TQObWdMzVivenPxP6+Xmeg2yLlMM4OSLRdFmSAmIfPPyZArZEZMLaFMcXsrYWOqKDM2n7INwVt9eZ206zXPrXmP19XGXRFHCc7hAq7AgxtowAM0wQcGHJ7hFd4c6bw4787HsnXDKWbO4A+czx+aq46J</latexit>

T3 <latexit sha1_base64="fAA/6ZfzyWT9s1dcLKPtMeUq/R4=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lU0GPRi8eK/YI2lM120i7dbMLuRiihP8GLB0W8+ou8+W/ctjlo64OBx3szzMwLEsG1cd1vp7C2vrG5Vdwu7ezu7R+UD49aOk4VwyaLRaw6AdUouMSm4UZgJ1FIo0BgOxjfzfz2EyrNY9kwkwT9iA4lDzmjxkqPjf5lv1xxq+4cZJV4OalAjnq//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMT3vgZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3sNVpXabx1GEEziFc/DgGmpwD3VoAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH9fRjX4=</latexit>

T4 <latexit sha1_base64="UNK7UyZqgdAUkMH9awLUEh/q0QQ=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkoMeiF48V+wVtKJvtpF262YTdjVBCf4IXD4p49Rd589+4bXPQ1gcDj/dmmJkXJIJr47rfTmFjc2t7p7hb2ts/ODwqH5+0dZwqhi0Wi1h1A6pRcIktw43AbqKQRoHATjC5m/udJ1Sax7Jppgn6ER1JHnJGjZUem4PaoFxxq+4CZJ14OalAjsag/NUfxiyNUBomqNY9z02Mn1FlOBM4K/VTjQllEzrCnqWSRqj9bHHqjFxYZUjCWNmShizU3xMZjbSeRoHtjKgZ61VvLv7n9VIT3vgZl0lqULLlojAVxMRk/jcZcoXMiKkllClubyVsTBVlxqZTsiF4qy+vk/ZV1XOr3kOtUr/N4yjCGZzDJXhwDXW4hwa0gMEInuEV3hzhvDjvzseyteDkM6fwB87nD9lVjX8=</latexit>

T5 <latexit sha1_base64="MowWjkDNqlqsDOzcI0xwQYBRpyM=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE0WPRi8eK/YI2lM120i7dbMLuRiihP8GLB0W8+ou8+W/ctjlo64OBx3szzMwLEsG1cd1vp7C2vrG5Vdwu7ezu7R+UD49aOk4VwyaLRaw6AdUouMSm4UZgJ1FIo0BgOxjfzfz2EyrNY9kwkwT9iA4lDzmjxkqPjf5Vv1xxq+4cZJV4OalAjnq//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMT3vgZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3sNlpXabx1GEEziFc/DgGmpwD3VoAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH9rZjYA=</latexit>

(c) Dual moon Mixture

Flow direction (the order of HMPTs)

T6 <latexit sha1_base64="GcbK6HhP/SP6dLH3Gwdd0734D60=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE1GPRi8eK/YI2lM120i7dbMLuRiihP8GLB0W8+ou8+W/ctjlo64OBx3szzMwLEsG1cd1vp7C2vrG5Vdwu7ezu7R+UD49aOk4VwyaLRaw6AdUouMSm4UZgJ1FIo0BgOxjfzfz2EyrNY9kwkwT9iA4lDzmjxkqPjf5Vv1xxq+4cZJV4OalAjnq//NUbxCyNUBomqNZdz02Mn1FlOBM4LfVSjQllYzrErqWSRqj9bH7qlJxZZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMT3vgZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTsiF4yy+vktZF1XOr3sNlpXabx1GEEziFc/DgGmpwD3VoAoMhPMMrvDnCeXHenY9Fa8HJZ47hD5zPH9xdjYE=</latexit>

T7 <latexit sha1_base64="xMQbwlMHl3qQCyq0kk45jjuZIiU=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEqMeiF48V+wVtKJvtpF262YTdjVBCf4IXD4p49Rd589+4bXPQ1gcDj/dmmJkXJIJr47rfTmFjc2t7p7hb2ts/ODwqH5+0dZwqhi0Wi1h1A6pRcIktw43AbqKQRoHATjC5m/udJ1Sax7Jppgn6ER1JHnJGjZUem4PaoFxxq+4CZJ14OalAjsag/NUfxiyNUBomqNY9z02Mn1FlOBM4K/VTjQllEzrCnqWSRqj9bHHqjFxYZUjCWNmShizU3xMZjbSeRoHtjKgZ61VvLv7n9VIT3vgZl0lqULLlojAVxMRk/jcZcoXMiKkllClubyVsTBVlxqZTsiF4qy+vk/ZV1XOr3sN1pX6bx1GEMziHS/CgBnW4hwa0gMEInuEV3hzhvDjvzseyteDkM6fwB87nD93hjYI=</latexit>

T8 <latexit sha1_base64="qN2VbyAHbCvxbsOrPYaB3Bg+6A8=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEsMeiF48V+wVtKJvtpF262YTdjVBCf4IXD4p49Rd589+4bXPQ1gcDj/dmmJkXJIJr47rfTmFjc2t7p7hb2ts/ODwqH5+0dZwqhi0Wi1h1A6pRcIktw43AbqKQRoHATjC5m/udJ1Sax7Jppgn6ER1JHnJGjZUem4PaoFxxq+4CZJ14OalAjsag/NUfxiyNUBomqNY9z02Mn1FlOBM4K/VTjQllEzrCnqWSRqj9bHHqjFxYZUjCWNmShizU3xMZjbSeRoHtjKgZ61VvLv7n9VIT1vyMyyQ1KNlyUZgKYmIy/5sMuUJmxNQSyhS3txI2pooyY9Mp2RC81ZfXSfuq6rlV7+G6Ur/N4yjCGZzDJXhwA3W4hwa0gMEInuEV3hzhvDjvzseyteDkM6fwB87nD99ljYM=</latexit>

T9 <latexit sha1_base64="L4NJcCW+Bn6ouesZpObQpHdIEu0=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG9FLx4r9gvaUDbbSbt0swm7G6GE/gQvHhTx6i/y5r9x2+agrQ8GHu/NMDMvSATXxnW/ncLa+sbmVnG7tLO7t39QPjxq6ThVDJssFrHqBFSj4BKbhhuBnUQhjQKB7WB8N/PbT6g0j2XDTBL0IzqUPOSMGis9Nvo3/XLFrbpzkFXi5aQCOer98ldvELM0QmmYoFp3PTcxfkaV4UzgtNRLNSaUjekQu5ZKGqH2s/mpU3JmlQEJY2VLGjJXf09kNNJ6EgW2M6JmpJe9mfif101NeO1nXCapQckWi8JUEBOT2d9kwBUyIyaWUKa4vZWwEVWUGZtOyYbgLb+8SloXVc+teg+XldptHkcRTuAUzsGDK6jBPdShCQyG8Ayv8OYI58V5dz4WrQUnnzmGP3A+fwDg6Y2E</latexit>

T10 <latexit sha1_base64="wFvqZM+t9/hg6a45uscwx0N/jfY=">AAAB7XicbVDLSgNBEOz1GeMr6tHLYBA8hV0R9Bj04jFCXpAsYXbSScbMziwzs0JY8g9ePCji1f/x5t84SfagiQUNRVU33V1RIrixvv/tra1vbG5tF3aKu3v7B4elo+OmUalm2GBKKN2OqEHBJTYstwLbiUYaRwJb0fhu5reeUBuuZN1OEgxjOpR8wBm1TmrWe1ngT3ulsl/x5yCrJMhJGXLUeqWvbl+xNEZpmaDGdAI/sWFGteVM4LTYTQ0mlI3pEDuOShqjCbP5tVNy7pQ+GSjtSloyV39PZDQ2ZhJHrjOmdmSWvZn4n9dJ7eAmzLhMUouSLRYNUkGsIrPXSZ9rZFZMHKFMc3crYSOqKbMuoKILIVh+eZU0LyuBXwkersrV2zyOApzCGVxAANdQhXuoQQMYPMIzvMKbp7wX7937WLSuefnMCfyB9/kDCHCOwg==</latexit>

T11 <latexit sha1_base64="RYnNRjXkWWb9ARdd44MYi1fQPxM=">AAAB7XicbVBNSwMxEJ2tX7V+VT16CRbBU9mIUI9FLx4r9AvapWTTbBubTZYkK5Sl/8GLB0W8+n+8+W9M2z1o64OBx3szzMwLE8GN9f1vr7CxubW9U9wt7e0fHB6Vj0/aRqWashZVQuluSAwTXLKW5VawbqIZiUPBOuHkbu53npg2XMmmnSYsiMlI8ohTYp3Ubg4yjGeDcsWv+gugdYJzUoEcjUH5qz9UNI2ZtFQQY3rYT2yQEW05FWxW6qeGJYROyIj1HJUkZibIFtfO0IVThihS2pW0aKH+nshIbMw0Dl1nTOzYrHpz8T+vl9roJsi4TFLLJF0uilKBrELz19GQa0atmDpCqObuVkTHRBNqXUAlFwJefXmdtK+q2K/ih+tK/TaPowhncA6XgKEGdbiHBrSAwiM8wyu8ecp78d69j2VrwctnTuEPvM8fCfWOww==</latexit>

T12 <latexit sha1_base64="CeAqyifvgzZ82ONIqNMLngdc4Mg=">AAAB7XicbVBNSwMxEJ2tX7V+VT16CRbBU9kUQY9FLx4r9AvapWTTbBubTZYkK5Sl/8GLB0W8+n+8+W9M2z1o64OBx3szzMwLE8GN9f1vr7CxubW9U9wt7e0fHB6Vj0/aRqWashZVQuluSAwTXLKW5VawbqIZiUPBOuHkbu53npg2XMmmnSYsiMlI8ohTYp3Ubg4yXJsNyhW/6i+A1gnOSQVyNAblr/5Q0TRm0lJBjOlhP7FBRrTlVLBZqZ8alhA6ISPWc1SSmJkgW1w7QxdOGaJIaVfSooX6eyIjsTHTOHSdMbFjs+rNxf+8XmqjmyDjMkktk3S5KEoFsgrNX0dDrhm1YuoIoZq7WxEdE02odQGVXAh49eV10q5VsV/FD1eV+m0eRxHO4BwuAcM11OEeGtACCo/wDK/w5invxXv3PpatBS+fOYU/8D5/AAt6jsQ=</latexit>

T13 <latexit sha1_base64="Z5OvuKOOxNNqkPGYvpDKFMMvMvw=">AAAB7XicbVBNSwMxEJ2tX7V+VT16CRbBU9mooMeiF48V+gXtUrJpto3NJkuSFcrS/+DFgyJe/T/e/Dem7R609cHA470ZZuaFieDG+v63V1hb39jcKm6Xdnb39g/Kh0cto1JNWZMqoXQnJIYJLlnTcitYJ9GMxKFg7XB8N/PbT0wbrmTDThIWxGQoecQpsU5qNfoZvpz2yxW/6s+BVgnOSQVy1Pvlr95A0TRm0lJBjOliP7FBRrTlVLBpqZcalhA6JkPWdVSSmJkgm187RWdOGaBIaVfSorn6eyIjsTGTOHSdMbEjs+zNxP+8bmqjmyDjMkktk3SxKEoFsgrNXkcDrhm1YuIIoZq7WxEdEU2odQGVXAh4+eVV0rqoYr+KH64qtds8jiKcwCmcA4ZrqME91KEJFB7hGV7hzVPei/fufSxaC14+cwx/4H3+AAz/jsU=</latexit>

T14 <latexit sha1_base64="vSoJN93oCgKVYidfKqVyMbJjz18=">AAAB7XicbVBNSwMxEJ2tX7V+VT16CRbBU9lIQY9FLx4r9AvapWTTbBubTZYkK5Sl/8GLB0W8+n+8+W9M2z1o64OBx3szzMwLE8GN9f1vr7CxubW9U9wt7e0fHB6Vj0/aRqWashZVQuluSAwTXLKW5VawbqIZiUPBOuHkbu53npg2XMmmnSYsiMlI8ohTYp3Ubg4yXJsNyhW/6i+A1gnOSQVyNAblr/5Q0TRm0lJBjOlhP7FBRrTlVLBZqZ8alhA6ISPWc1SSmJkgW1w7QxdOGaJIaVfSooX6eyIjsTHTOHSdMbFjs+rNxf+8XmqjmyDjMkktk3S5KEoFsgrNX0dDrhm1YuoIoZq7WxEdE02odQGVXAh49eV10r6qYr+KH2qV+m0eRxHO4BwuAcM11OEeGtACCo/wDK/w5invxXv3PpatBS+fOYU/8D5/AA6EjsY=</latexit>

Training iterations

(d) Circular Gaussian Mixture
Figure 1: The demonstration of the convergence of measure preserving flows. Figure (a) and (b) show ergodic lower bounds to the true log normalising constant of ergodic measure preserving flows with 14 transformations. The lower bound is estimated after each transformation as indicated by the axis 'flow length'. The legend 'ERLBO-0' indicates the ERLBO of the flow with the initial randomized flow parameters and the legend 'ERLBO-80' indicates the ERLBO of the flow after 80 training iterations of the flow parameters. Figure (c) and (d) show how the histograms of the 50000 samples from the flow evolve after each transformation (flow direction axis) and every 10 training iterations (training iterations axis).
9

Under review as a conference paper at ICLR 2019

For HMPF encoder, we use 30 HMPTs with 5 Leapfrog steps per HMPT. The initial distribution q0 is 32 dimensional independent Gaussian. More detailed description of the architecture of HMPFs is in the appendix Section D.1. We optimise the HMPF encoder and the decoder jointly using Adam. The the initial state of the flow is sampled from independent Gaussian. The mean and variance of the initial Gaussian is also optimised jointly with flow and model parameters and their gradients are computed by back propagation given the value of momenta. However, we noticed that with sufficient number of transformations, the effect of optimising initial Gaussian distribution is not significant. Table 1 shows the marginal likelihood of HMPFs and other methods estimated using 100 Hamiltonian annealled importance samples (HAIS) (Wu et al., 2017). We also report the effective sample size (ESS). Overall, HMPFs produce better results and are faster than the baselines.
We also tested the same decoder with HMPFs and convolutional encoder on dynamically binarised Fashion-MNIST (Xiao et al., 2017). The results of test marginal likelihood can be found Table 2.

Encoders

Training hours Training Epochs Test log(x) ESS

Conv VAE(nh=500) HMPF(30HMPT-5LF, nh=500, no encoder)

6.00 6.00

3000 200

-104.90 26.3 -103.087 16.2

Table 2: The comparison of log marginal likelihood on fashion MNIST between convolutional VAE and HMPFs. We also evaluate HMPFs with different setting of HAIS that gives higher effective sample size (ESS), but the result of test log likelihood is roughly the same.

4.3 BAYESIAN NEURAL NETWORKS

In our final experiment we approximate the posterior distribution of Bayesian neural networks. We use four UCI datasets and compare HMPFs with relevant stochastic gradient Hamilton Monte Carlo (SGHMC) methods from (Springenberg et al., 2016). The networks used in these experiments have 50 hidden layers and 1 real valued output unit, as stated in (Springenberg et al., 2016). The HMPFs contain 50 HMC transformation with 3 Leapfrog steps each. The distribution the initial state of the flow is independent Gaussian with mean and variance parameters obtained by fitting a variational Gaussian proposal q0 with Adam optimiser for 200 iterations. To reduce the cost of the Leapfrog iterations, we split training data into 19 mini-batches and only use one random sampled mini-batch for computing the gradient of the potential energy. We train our HMPFs for 10 epochs and the stationary distribution of the flow is chosen as approximate posterior on a random sampled minibatch. The resulting test log-likelihoods are shown in Table 3. Overall, HMPFs produce significantly better results than SGHMC.

Method/Dataset

Boston

Yacht Concrete Wine

SGHMC (best average) (Springenberg et al., 2016) -3.47±0.51 -13.58±0.98 -4.87±0.05 -1.82±0.75

SGHMC (tuned per dataset) (Springenberg et al., 2016) -2.49±0.15 -1.75±0.19 -4.16±0.72 -1.29±0.28

SGHMC (scale-adapted) (Springenberg et al., 2016) -2.54±0.04 -1.11±0.08 -3.38±0.24 -1.04±0.17

HMPFs

-2.17±0.07 -0.47±0.06 -2.71±0.03 -0.71±0.03

Table 3: The test log-likelihood of Bayesian neural networks on UCI datasets averaged over 20 splits with 100 sampled network parameters from HMPFs.

5 SUMMARY
We have proposed a novel method for approximate inference that combines advantages of variational inference and MCMC methods. We call this method ergodic measure preserving flows (EMPFs). Different from most previous works combining HMC and variational inference, EMPFs enjoy the same asymptotic convergence as HMC and can tune sampling hyper-parameters by optimizing a tractable objective function at a low computational cost. We have shown that EMPFs achieve better results than existing baselines on standard benchmarks. For future work, it will be interesting to study the convergence rate of EMPFs to the target distribution with increasing flow length. Finally, the proposed method can be easily extended to consider recent Riemannian-manifold HMC methods (Zhang & Sutton, 2014; Girolami & Calderhead, 2011) for the construction of the flow.
10

Under review as a conference paper at ICLR 2019
REFERENCES
Patrick Billingsley. Probability and Measure. John Wiley and Sons, third edition, 1986.
Christopher M. Bishop. Pattern Recognition and Machine Learning (Information Science and Statistics). Springer-Verlag, Berlin, Heidelberg, 2006. ISBN 0387310738.
David M Blei, Andrew Y Ng, and Michael I Jordan. Latent dirichlet allocation. Journal of machine Learning research, 3(Jan):993­1022, 2003.
Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov. Importance Weighted Autoencoders. arXiv preprint arXiv:1509.00519, 2015.
A. L. Caterini, A. Doucet, and D. Sejdinovic. Hamiltonian Variational Auto-Encoder. ArXiv e-prints, May 2018.
Mark Girolami and Ben Calderhead. Riemann manifold langevin and hamiltonian monte carlo methods. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 73(2):123­214, 2011. ISSN 1467-9868. doi: 10.1111/j.1467-9868.2010.00765.x. URL http://dx.doi.org/10.1111/j. 1467-9868.2010.00765.x.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative Adversarial Nets. In Advances in neural information processing systems, pp. 2672­2680, 2014.
Geoffrey E Hinton. Training products of experts by minimizing contrastive divergence. Neural computation, 14(8):1771­1800, 2002.
Diederik Kingma and Max Welling. Auto-Encoding Variational Bayes. In The International Conference on Learning Representations (ICLR), 2014.
Kenichi Kurihara, Max Welling, and Yee Whye Teh. Collapsed variational dirichlet process mixture models. In IJCAI, volume 7, pp. 2796­2801, 2007.
Benedict Leimkuhler and Sebastian Reich. Simulating hamiltonian dynamics, volume 14. Cambridge university press, 2004.
Kevin P. Murphy. Machine Learning: A Probabilistic Perspective. The MIT Press, 2012. ISBN 0262018020, 9780262018029.
Radford M. Neal. Markov chain sampling methods for dirichlet process mixture models. Journal of Computational and Graphical Statistics, 9(2):249­265, 2000.
Radford M. Neal. MCMC using Hamiltonian Dynamics. 2010.
Radford M Neal. Bayesian learning for neural networks, volume 118. Springer Science & Business Media, 2012.
Danilo Jimenez Rezende and Shakir Mohamed. Variational Inference with Normalizing Flows. In Proceedings of the 32Nd International Conference on International Conference on Machine Learning - Volume 37, ICML'15, pp. 1530­1538, 2015.
Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate inference in deep generative models. arXiv preprint arXiv:1401.4082, 2014.
Christian P. Robert and George Casella. Monte Carlo Statistical Methods (Springer Texts in Statistics). Springer-Verlag New York, Inc., Secaucus, NJ, USA, 2005. ISBN 0387212396.
Ruslan Salakhutdinov and Hugo Larochelle. Efficient learning of deep boltzmann machines. In Proceedings of the thirteenth international conference on artificial intelligence and statistics, pp. 693­700, 2010.
Tim Salimans, Diederik Kingma, and Max Welling. Markov Chain Monte Carlo and Variational Inference: Bridging the Gap. In International Conference on Machine Learning, pp. 1218­1226, 2015.
Jost Tobias Springenberg, Aaron Klein, Stefan Falkner, and Frank Hutter. Bayesian Optimization with Robust Bayesian Neural Networks. In D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett (eds.), Advances in Neural Information Processing Systems 29, pp. 4134­4142. Curran Associates, Inc., 2016. URL http://papers.nips.cc/paper/ 6117-bayesian-optimization-with-robust-bayesian-neural-networks.pdf.
11

Under review as a conference paper at ICLR 2019 Yuhuai Wu, Yuri Burda, Ruslan Salakhutdinov, and Grosse Roger. On the Quantitative Analysis of Deep Belief
Networksnalysis of Decoder-based Generative Models. In ICLR. 2017. Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine
learning algorithms, 2017. Yichuan Zhang and Charles Sutton. Semi-separable hamiltonian monte carlo for inference in bayesian hier-
archical models. In Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger (eds.), Advances in Neural Information Processing Systems 27. Curran Associates, Inc., 2014.
12

Under review as a conference paper at ICLR 2019

A THE PROOF OF PROPOSITION 1

Proof. Because T preserves the probability measure (x, ), then for any measurable set A in Borel

set Bx × B , we have

(A) = (T -1A).

Given a set B  Bx, the set Ax generated by B × E, is measurable under  with the measure

(Ax) = (B, )d ,

that is essentially a probability measure in the space of x, also known as the marginal probability
(B) = (Ax). Because T preserves the joint measure, applying T on Ax gives
T Ax = T (B, E) = T B × E, where T B denotes the projection of T Ax in the space of x. Follow the definition of measure preserving transformations, we have

(Ax) = (B, )d = (T -1B, )d = (T -1Ax),

where T -1 denotes the preimage of B under T . Because (Ax) is essentially the marginal probability (B), B  Bx, we know the marginal distribution (x) is preserved by T because
(B) = (Ax) = (T -1Ax) = (T -1B).
This implies that the marginal distribution (x) is preserved by the stochastic mapping
T : X  X,  ( ),
where ( ) = (x, )dx. If T is invertible for any , we have

(B) = (B, )d = (T B, )d = (T B),

where T B denotes the projection of T Ax in the space of x. Therefore, we know that if we sample from (x, ) and apply T on x, then the marginal distribution (x) is preserved.

B THE PROOF OF PROPOSITION 2

Proof. Let µ be the probability measure of auxiliary variable R. Following equation 14, the difference of ERLBO in each measure preserving transformation TL is given by

dLz(x; , 1:L) = Lz(x; , 1:L) - Lz(x; , 1:L-1)

= DKL QL Q^L - DKL QL-1 Q^L-1 ,

(18)

where QL denotes QL(ZL, R1:L) and Q^L denotes QL(ZL)

L l=1

µ(Rl).

The

KL

divergence

can

be written as the integral

DKL QL Q^L =

log

qL(zL, qL(zL; )

r1:L; )

L l=1

µ(rl

())

qL(zL,

r1:L;

)dzLdr1:L.

(19)

Because (zL, rL) is generated from (zL-1, rL) by the deterministic transformation TL that preserves Lebesgue measure in the phase space, we have the equality

qL(zL, r1:L) = qL-1(zL-1, r1:L-1)µ(rL).

Using the reparameterisation

(zL, rL) = T (zL-1, rL),

13

Under review as a conference paper at ICLR 2019

we can rewrite the second KL term in equation 18 as

DKL QL-1 Q^L-1 =

log

qL-1(zL-1, qL-1(zL-1; )

r1:L-1; )

L-1 l=1

µ(rl

())

qL-1(zL-1,

r1:L-1;

)dzL-1dr1:L-1

=

log

qL-1(zL-1, r1:L-1; )µ(rL)

qL-1(zL-1; )µ(rL)

L-1 l=1

µ(rl

())

qL-1(zL-1,

r1:L-1;

)µ(rL)dzL-1dr1:L-1drL

=

log

qL(zL, qL(zL, rL; )

r1:L; )

L-1 l=1

µ(rl

())

qL(zL,

r1:L;

)dzLdr1:L,

where qL(zL, rL; ) comes from qL-1(zL-1; )µ(rL) by the rule of changing variables

(20)

qL-1(zL-1; )µ(rL) = qL-1(zL-1, r1:L-1; )µ(rL)dr1:L-1

= qL(zL, r1:L; )dr1:L-1

= qL(zL, rL; ).

Subtract equation 20 from equation 19, then we have the difference in KL as

dLz(x; , 1:L) =

log

hqLh(zhL , hr1:hL ;hh)

qL(zL; )

L l=1

µ(rl

())

qL(zL,

r1:L;

)dzLdr1:L

-

log

hqLh(zhL , hr1:hL ;hh)

qL(zL, rL; )

L-1 l=1

µ(rl

())

qL(zL,

r1:L;

)dzLdr1:L

= log qL(qzLL(;zL),µr(Lr;L()X))XlLX=-1XXlL1=-µX1X1(rµXXl((rXXlX)()XX)) qL(zL, r1:L; )dzLdr1:L

=

log

qL

qL(zL, rL; ) (zL; )µ(rL())

qL

(zL

,

r1:L;

)dzLdr1:L

=

log

qL

qL(zL, rL; ) (zL; )µ(rL())

qL

(zL

,

rL;

)dzLdrL.

(21)

From equation 21, it is easy to see that dLz(x; , 1:L) is essentially KL divergence between

qL(zL, rL; ) and qL(zL; )µ(rL()). This verifies that

dLz(x; , 1:L) = Lz(x; , 1:L) - Lz(x; , 1:L-1)  0.

This implies that the ergodic lower bound stops increasing if and only if the KL divergence between qL(zL, rL; ) and qL(zL; )µ(rL()) is equal to 0.

C PROOF OF THEOREM 1

Proof. Because the flow is ergodic with invariant distribution p(z|x), with sufficient many transfor-

mations, qL(z) can converge to p(z|x) in total variation distance, that is

lim
L

||qL(z)

-

p(z|x)||TV

=

0.

This is implied by the monotonic convergence of flow marginal qL(x) to (x) in total variation

simply follows monotonic convergence of MCMC chains in total variation distance by Theorem

6.51 and Proposition 6.52 in (Robert & Casella, 2005).

Then, we have

lim Lz(x; , L) = lim

L

L

log

p (x, qL(z;

z) )

qL(z;

)dz

=

log

p(x, z) q(z; )

q(z;

)dz

=

log

p(x, z) p (z|x)

p (z|x)dz

= log p(x).

14

Under review as a conference paper at ICLR 2019
D EXPERIMENTAL RESULTS
D.1 CONFIGURATION OF HMPFS
The HMPFs in all the experiments share the following common configuration. The initial distribution of HMPF q0(x) is given by independent Gaussian N (µ, 2), where 2 = (12, . . . , n2 ) is the vector of variance. We implement Hamiltonian measure preserving transformation (HMPT) fr using vanilla Leapfrog integrator for simulating Hamiltonian dynamics H and independent Gaussian momentum variable r. The implementation of Leapfrog algorithm follows the tutorial of Neal (Neal, 2010). The momentum variables in each HMPT are independent and the each momentum variable has different variance. We consider separate step size = ( 1, . . . , n) for each dimension of x. Neal (Neal, 2010) shows that tuning leapfrog step size per dimension in HMC is equivalent to tuning the variance vector of momentum variables. So, we generate momentum variables from standard normal and assign an independent Leapfrog step size l for each HMPT fl. The number of iterations in Leapfrog integrator is a fixed parameters based manual tuning. We found that 5 to 10 Leapfrog iterations are often good enough. More Leapfrog steps than that do not give better results. This is consistent with the practice of tuning HMC (Neal, 2010). The intuitive explanation to this is that because Hamiltonian dynamics often have strong oscillation, the longer simulation does not lead to further exploration in sample space.
D.2 THE TRUE HISTOGRAM OF 2D BENCHMARKS

(a) Dual Moon

(b) Circular Gaussian Mixture

Figure 2: The histogram of perfect samples from the targets using rejection sampling.

D.3 PLOTS OF MNIST AND FASHION MNIST

15

Under review as a conference paper at ICLR 2019
gen.pdf

gen.pdf

(a) Generation mean image (VAE)

(b) Generation mean image (HMPF)

Figure 3: Random generated images on fashion MNIST. There is no significant visaul difference in the generated images.

gen.pdf

gen.pdf

(a) VAE

(b) HMPF

Figure 4: Random generated images on fashion MNIST. It is clear that VAE generates many fashion articles that can almost fill up the whole image, like tops, bags and shirts. In contrast, the generation from the generative model trained using HMPF can generate much diverse products in different size and shapes, like shoes, pants and skirts.

16

Under review as a conference paper at ICLR 2019

test_origin

recon

recon

(a) Binarised test image

(b) VAE

(c) HMPF

Figure 5: The reconstructions on MNIST. On the left is dynamically binarised test image. Both convolutional VAE and HMPF reconstruct from the same prebinariesd test image (a) and the generated real valued images are shown as (b) and (c).

test_origin

recon

recon

(a) Binarised test image

(b) VAE

(c) HMPF

Figure 6: The reconstructions on fashion MNIST. On the left is dynamically binarised test image. Both convolutional VAE and HMPF reconstruct from the same prebinariesd test image (a) and the generated real valued images are shown as (b) and (c).

17

