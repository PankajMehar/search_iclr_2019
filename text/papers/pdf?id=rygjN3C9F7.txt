Under review as a conference paper at ICLR 2019
THE VARIATIONAL DEFICIENCY BOTTLENECK
Anonymous authors Paper under double-blind review
ABSTRACT
We introduce a bottleneck method for learning data representations based on channel deficiency, rather than the more traditional information sufficiency. A variational upper bound allows us to implement this method efficiently. The bound itself is bounded above by the variational information bottleneck objective, and the two methods coincide in the regime of single shot Monte Carlo approximations. The notion of deficiency provides a principled way of approximating complicated channels by relatively simpler ones. The deficiency of one channel w.r.t. another has an operational interpretation in terms of the optimal risk gap of general decision problems, capturing classification as a special case. Unsupervised generalizations are possible, such as the deficiency autoencoder, which also can be formulated in a variational form. Experiments demonstrate that the deficiency bottleneck can provide advantages in terms of minimal sufficiency as measured by information bottleneck curves, while retaining a good test performance in classification and reconstruction tasks. Keywords: Variational Information Bottleneck, Blackwell Sufficiency, Le Cam Deficiency, Information Channel
1 INTRODUCTION
The information bottleneck (IB) is an approach to learning data representations based on a notion of minimal sufficiency. The general idea is to map an input source into a representation that retains as little information as possible about the input (minimality), but retains as much information as possible in relation to a target variable of interest (sufficiency). See Figure 1. For example, in a classification problem the target variable could be the class label of the input data. In a reconstruction problem, the target variable could be a denoised reconstruction of the input. Intuitively, a representation which is minimal in relation to a given task, will discard nuisances in the inputs that are irrelevant to the task, and hence distill more meaningful information and allow for a better generalization.
In a typical bottleneck paradigm, an input variable X is first mapped to an intermediate representation variable Z, and then Z is mapped to an output variable of interest Y . We call the mappings, resp., a representation model (encoder) and an inference model (decoder). The channel  models the true relation between the input X and the output Y . In general, the channel  is unknown, and only accessible through a set of examples (x(i), y(i))iN=1. We would like to obtain an approximation of  using a probabilistic model that comprises of the encoder-decoder pair.
The IB methods (Witsenhausen & Wyner, 1975; Tishby et al., 1999; Harremoe¨s & Tishby, 2007; Hsu et al., 2018) have found numerous applications, e.g., in representation learning, clustering, classification, generative modelling, reinforcement learning, neural networks, among others (see, e.g., Shamir et al., 2008; Gondek & Hofmann, 2003; Alemi et al., 2016).
In the traditional IB, minimality and sufficiency are measured in terms of the mutual information. Computing the mutual information can be challenging in practice. Various recent works have formulated more tractable functions by way of variational bounds on the mutual information (Chalk et al., 2016; Alemi et al., 2016; Kolchinsky et al., 2017), sandwiching the objective function of interest.
Instead of approximating the sufficiency term of the IB, we formulate a new bottleneck method that minimizes deficiency. Deficiencies provide a principled way of approximating complicated channels by relatively simpler ones. The deficiency of a decoder with respect to the true channel between
1

Under review as a conference paper at ICLR 2019

 XY
ed
Z
Figure 1: The Bottleneck paradigm: The general idea of a bottleneck method is to first map an input X to an intermediate representation Z, and then map Z to an output Y . We call the mappings, resp., an encoder (e) and a decoder (d). The channel  models the true relation between the input X and the output Y . In general, the channel  is unknown, and only accessible through a set of training examples. We would like to obtain an approximation of .

input and output variables quantifies the extent to which any pre-processing of the decoder (by way of randomized encodings) can be used to approximate the true channel (in the KL-distance sense). Deficiencies have a rich heritage in theory of comparison of statistical experiments (Blackwell, 1953; Le Cam, 1964; Torgersen, 1991). From this angle, the formalism of deficiencies has been used to obtain bounds on optimal risk gaps of statistical decision problems. As we show, the deficiency bottleneck minimizes a regularized risk gap. Moreover, the proposed method has an immediate variational formulation and that can be easily implemented as a modification of the Variational Information Bottleneck (VIB) (Alemi et al., 2016). In fact, both method coincide in the limit of single-shot Monte Carlo approximations. We call our method the Variational Deficiency Bottleneck (VDB).
As we show in Proposition 2, perfect optimization of the IB sufficiency corresponds to perfect minimization of the DB deficiency. However, when working over a parametrized model and adding the bottleneck regularizer, both methods have different preferences, with the DB being closer to the optimal risk gap. Experiments on basic data sets show that the VDB is able to obtain more compressed representations than the VIB while performing equally well or better in terms of test accuracy.
We describe the details of our method in Section 2. We elaborate on the theory of deficiencies in Section 3. Experimental results with the VDB are presented in Section 4.

2 THE VARIATIONAL DEFICIENCY BOTTLENECK (VDB)

Let X denote an observation or input variable and Y an output variable of interest. Let p(x, y) = (x)(y|x) be the true joint distribution, where the conditional distribution or channel (y|x) de-
scribes how the output depends on the input. We consider the situation where the true channel is unknown, but we are given a set of N independent and identically distributed (i.i.d.) samples (x(i), y(i))iN=1 from p. Our goal is to use this data to learn a more structured version of the channel , by first "compressing" the input X to an intermediate representation variable Z and subsequently mapping the representation back to the output Y . The presence of an intermediate
representation can be regarded as a bottleneck, a model selection problem, or as a regularization
strategy.

We define a representation model and an inference model using two parameterized families of channels e(z|x) and d(y|z). We will refer to e(z|x) and d(y|z) as an encoder and a decoder. The encoder-decoder pair induces an equivalent model (y|x) = d(y|z)e(z|x)dz. Equivalently, we write  = d  e.

Given a representation, we want the decoder to be as powerful as the original channel  in terms of ability to recover the output. The deficiency of a decoder d w.r.t.  quantifies the extent to which any pre-processing of d (by way of randomized encodings) can be used to approximate  (in the KL-distance sense). Let M(X ; Y) denote the space of all channels from X to Y. We define the deficiency of d w.r.t.  as follows.

Definition 1. Given the channel   M(X ; Y) from X to Y , and a decoder d  M(Z; Y) from some Z to Y , the deficiency of d w.r.t.  is defined as

(d, ) = min DKL( d  e|).
eM(X ;Z)

(1)

2

Under review as a conference paper at ICLR 2019

Here DKL(· ·|·) is the conditional KL divergence (Csisza´r & Ko¨rner, 2011). The definition is similar in spirit to Lucien Le Cam's notion of weighted deficiencies of one channel w.r.t. another (Le Cam,
1964), (Torgersen, 1991, Section 6.2) and its recent generalization by Raginsky Raginsky (2011).

We propose to train the model by minimizing the deficiency of d w.r.t.  subject to a regularization that penalizes complex representations. The regularization is achieved by limiting the rate I(Z; X), the mutual information between the representation and the raw inputs. We call our method the Deficiency Bottleneck (DB). The DB minimizes the following objective over all tuples (e  M(X ; Z), d  M(Z; Y)).

LDB(e, d) := (d, ) + I(Z; X).

(2)

The parameter   0 allows us to adjust the level of regularization.

For any distribution r(z), the rate term admits a simple variational upper bound (Csisza´r & Ko¨rner, 2011, Eq. (8.7)).

I(Z; X) 

p(x,

z)

log

e(z|x) r(z)

dx

dz

.

(3)

Let p^data be the empirical distribution of the data (input-output pairs). By noting that (d, )  DKL( de|) for any e  M(X ; Z), and ignoring (unknown) data-dependent constants, we obtain the following optimization objective which we call the Variational Deficiency Bottleneck (VDB)
objective.

LV DB(e, d) := E(x,y)p^data [- log d  e(y|x) + DKL(e(Z|x) r(Z))] .

(4)

The computation is simplified by defining r(z) to be a standard multivariate Gaussian distribution N (0, I) and using an encoder that outputs a Gaussian distribution. More precisely, we consider an encoder of the form e(z|x) = N (z|f(x)), where f is a neural network that outputs the parameters of a Gaussian distribution. Using the reparametrization trick (Kingma & Welling, 2013; Rezende et al., 2014), we then write e(z|x)dz = p( )d , where z = f (x, ) is a function of x and
the realization of a standard normal distribution. This allows us to do stochastic backpropagation through a single sample z. The KL term admits an analytic expression for a choice of Gaussian r(z)
and encoders. We train the model by minimizing the following empirical objective.



1 N

N

-

log(

1 M

M
[d(y(i)|f (x(i),

(j)))]) + DKL(e(Z|x(i)) r(Z)) .

i=1 j=1

(5)

For batch training, we choose a mini-batch size of N = 100. For Monte Carlo estimates of the expectation inside the log, we choose M = 3, 6, 12 samples from the encoding distribution.

We note that the Variational Information Bottleneck (VIB) (Alemi et al., 2016) leads to a similarlooking objective function, with the only difference that the sum over j is outside of the log. By Jensen's inequality, the VIB loss is an upper bound to our loss. If one uses a single sample from the encoding distribution (i.e., M = 1), the VDB and the VIB objective functions coincide.

The average log-loss and the rate term in the VDB objective equation 4 are the two fundamental quantities that govern the probability of error when the model is a classifier. For a detailed discussion of these relations see Appendix A.

3 BLACKWELL SUFFICIENCY AND CHANNEL DEFICIENCY
In this section, we discuss an intuitive geometric interpretation of the deficiency in the space of probability distributions over the output variable. We also give an operational interpretation of the deficiency as a deviation from Blackwell sufficiency (in the KL-distance sense). Finally, we discuss its relation to the log-loss.
3.1 DEFICIENCY AND DECISION GEOMETRY
We first formulate the learning task as a decision problem. We show that (d, ) quantifies the gap in the optimal risks of decision problems when using the channel d rather than .

3

Under review as a conference paper at ICLR 2019

Let X , Y denote the space of possible inputs and outputs and let PY be the set of all distributions on Y. For every x  X , define x  PY as x(y) = (y|x), y  Y. Nature draws x   and y  x. The learner observes x and quotes a distribution qx  PY that expresses her uncertainty about the true value y. The quality of a quote qx in relation to y is measured by an extended realvalued loss function called the score : Y × PY  R. For a background on such special kind of loss functions (see, e.g., Gru¨nwald et al., 2004; Gneiting & Raftery, 2007; Parry et al., 2012). Ideally, the quote qx should to be as close as possible to the true conditional distribution x. This is achieved by minimizing the expected loss L(x, qx) := Eyx (y, qx), for all x  X . The score is called proper if x  arg minqxPY L(x, qx). Define the Bayes act against x as the optimal quote
qx := arg min L(x, qx).
qx PY
If multiple Bayes acts exist then select one arbitrarily. Define the Bayes risk for the distribution pXY (x, y) = (x)(y|x) as R(pXY , ) := ExL(x, qx). A score is strictly proper if the Bayes act is unique. An example of a strictly proper score is the log-loss function defined as L(y, q) := - log q(y). For the log-loss, the Bayes act is qx = x and the Bayes risk is just the conditional entropy.
R(pXY , L) = ExEyx - log qx(y) = ExEyx - log x(y) = H(Y |X). (6)

Given a representation z  Z (output by some encoder), when using the decoder channel d, the
learner is constrained to quote a distribution from a subset of PY which is the convex hull of the points {dz}zZ  PY . Let C = conv({dz : z  Z})  PY . The Bayes act against dz is

qxZ

:=

arg min
qx C PY

Eyx

- log qx(y) .

(7)

qxZ has an interpretation as the reverse I-projection of x to the convex set of probability measures C  PY (Csisza´r & Matus, 2003)1. We call the associated Bayes risk as the projected
Bayes risk RZ (pXY , L) and the associated conditional entropy as the projected conditional entropy HZ (Y |X).

RZ (pXY , L) = ExEyx - log qxZ (y) = HZ (Y |X).

(8)

The gap in the optimal risks, R := RZ (pXY , L) - R(pXY , L) when making a decision based on an intermediate representation and a decision based on the input data is just the deficiency. This
follows from noting that

R = HZ (Y |X) - H(Y |X) = (x) min DKL(x qx)

xX

qx C PY

= min

(x)DKL(x d  ex)

eM(X ;Z)

xX

= min DKL( d  e|) = (d, ).
eM(X ;Z)

(9)

R vanishes if and only if the optimal quote against dz, qxZ matches x for all x, y. This gives an intuitive geometric interpretation of a vanishing deficiency in the space of distributions over Y.
Given a decoder channel d, since (d, )  DKL( d  e|) for any e  M(X ; Z), the loss term in the VDB objective is a variational upper bound on the projected conditional entropy HZ(Y |X). However, this loss is still a lower bound to the standard cross-entropy loss in the VIB objective (Alemi et al., 2016), i.e.,

E(x,y)p^data [- log d  e(y|x)]  E(x,y)p^data [-e(z|x) log d(y|z)] . This follows simply from the convexity of the negative logarithm function.

(10)

1Such a projection exists and is not necessarily unique since the set we are projecting onto is not log-convex. If nonunique, we arbitrarily select one of the minimizers as the Bayes act.

4

Under review as a conference paper at ICLR 2019

3.2 DEFICIENCY AS A KL-DISTANCE FROM INPUT-BLACKWELL SUFFICIENCY
In a seminal paper (Blackwell, 1953), David Blackwell asked the following question: if a learner wishes to make an optimal decision about some target variable of interest and she can choose between two channels with a common input alphabet, which one should she prefer? She can rank the channels by comparing her optimal risks: she will always prefer one channel over another if her optimal risk when using the former is at most that when using the latter for any decision problem. She can also rank the variables purely probabilistically: she will always prefer the former if the latter is an output-degraded version of the former, in the sense that she can simulate a single use of the latter by randomizing at the output of the former. Blackwell showed that these two criterias are equivalent.
Very recently, Nasser (2017) asked the same question, only now the learner has to choose between two channels with a common output alphabet. Given two channels,   M(Z; Y) and d  M(X ; Y), we say that  is input-degraded from d and write d Y  if  = d  e for some e  M(X ; Z). Stated in another way, d can be reduced to  by applying a randomization at its input. Nasser (2017) gave a characterization of input-degradedness that is similar to Blackwell's theorem (Blackwell, 1953). We say, d is input-Blackwell sufficient for  if d Y .
Input-Blackwell sufficiency induces a preorder on the set of all channels with the same output alphabet. In practice, most channels are uncomparable, i.e., one cannot be reduced to another by a randomization. When such is the case, our deficiency quantifies how far the true channel  is from being a randomization (by way of all input encodings) of the decoder d. This is similar in spirit with Le Cam's notion of weighted channel deficiencies (Le Cam, 1964; Torgersen, 1991) and its recent generalization by Raginsky (Raginsky, 2011). See Appendix B for a brief summary of Le Cam theory which provides a principled way of approximating complicated channels by relatively simpler ones.

3.3 DEFICIENCY AND THE LOG-LOSS

When Y - X - Z is a Markov chain, the conditional mutual information I(Y ; X|Z) is the Bayes risk gap for the log-loss. This is apparent from noting that I(Y ; X|Z) = H(Y |Z) - H(Y |XZ) = H(Y |Z) - H(Y |X) = R(pZY , L) - R(pXY , L). This risk gap is closely related to Blackwell's original notion of sufficiency. Since the log-loss is strictly proper, a vanishing I(Y ; X|Z) implies that the risk gap is zero for all loss functions. This suggests that minimizing the log-loss risk gap under a suitable regularization constraint is a potential recipe for constructing representations Z that are approximately sufficient for X w.r.t. Y , since in the limit when I(Y ; X|Z) = 0 one would achieve I(Y ; Z) = I(Y ; X). This is indeed the basis for the IB algorithm (Tishby et al., 1999) and related generalizations, clustering with Bregman divergences (Banerjee et al., 2005) and lossinsensitive feature learning (Van Rooyen & Williamson, 2014).
One can also approximate a sufficient statistic by minimizing deficiencies instead. This follows from noting the following equivalence. The proof is in Appendix C.
Proposition 2. When Y - X - Z is a Markov chain, (d, ) = 0  I(Y ; X|Z) = 0.

In general, for the bottleneck paradigms involving the conditional mutual information (IB) and the deficiency (DB), we have the following relationship.

min I(X; Z)  min I(X; Z).

e(z|x): I(Y ;X|Z)

e(z|x): (d,)

(11)

It is clear from Proposition 2 that the representations are going to be the same only in the limit of exact sufficiency. Our experiments corroborate that for achieving the same level of sufficiency, one needs to store less information about the input X when minimizing the deficiencies than when minimizing the conditional mutual information.

4 EXPERIMENTS
We present some experiments on the MNIST dataset (LeCun & Cortes, 2010). Classification on MNIST is a very well studied problem. The main objective of our experiments is to evaluate the

5

Under review as a conference paper at ICLR 2019

Accuracy

1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1
10 -8
3.5

MNIST train test accuracy, VDB, L=1

M=1 M = 1 train M=3 M = 3 train M=6 M = 6 train M = 12 M = 12 train
10 -6

10 -4

10 -2

MNIST VDB curve train test

10 0

3

2.5
M=1 M = 1 train M=3 2 M = 3 train M=6 M = 6 train M = 12 M = 12 train
1.5 10-1 100 101 102 103 104 I(Z;X)

I(Z;X)

Accuracy

1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1
10 -8

MNIST train test accuracy, VDB, L=12

M=1 M = 1 train M=3 M = 3 train M=6 M = 6 train M = 12 M = 12 train
10 -6

10 -4

10 -2

10 4 10 3 10 2 10 1 10 0 10 -1 10 -2
10 -12

MNIST VDB IZX vs Beta curve train test

M=1 M = 1 train M=3 M = 3 train M=6 M = 6 train M = 12 M = 12 train

10 -10

10 -8

10 -6

10 -4

10 -2

10 0 10 0

I(Z;Y)

Figure 2: Effect of the regularization parameter . Accuracy on test data after training. Mutual information values after training. The curves are averages over 5 repetitions of the experiment. Each curve corresponds to one value of M = 1, 3, 6, 12. Notice the generalization gap in the lower right panel, which happens at small values of the regularization parameter . This indicates that the bottleneck regularization allows for a better generalization of the mutual informations between representation and label. The lower right panel shows a gap between the levels of compression depending on M . Higher values of M (our method) lead to a more compressed representation. Here L corresponds to the number of posterior samples (this is not used in training, but just at test time).

information theoretic properties of the representations learned by the VDB and whether it can match the classification accuracy provided by other bottleneck methods.
For the encoder we use a fully connected feedforward network with 784 input units 1024 ReLUs 1024 ReLUs 512 linear units. The deterministic output of this network is interpreted as the vector of means and variances of a 256 dimensional Gaussian distribution. The decoder is a simple logistic regression model with a softmax layer outputting 10-ary logits. These are the same settings of the model presented by Alemi et al. (2016). We implement the algorithm in Tensorflow and train for 200 epochs using the Adam optimizer.
As can be seen from Figure 2, the test accuracy improves with increasing M . We note that M = 1 is just the VIB model (Alemi et al., 2016). Our best test accuracy results are for  in the range of 10-5 and 10-4. Figures showing the dynamics of learning are provided in Appendix D.
The lower left panel of Figure 2 shows the information bottleneck curve. This is the comparison of mutual informations between representation and input vs representation and output, at the end of training, depending on the value of the regularization parameter . For orientation, lower values of  have higher values of I(Z; X) (towards the right of the plot). For small values of , when the effect of the regularization is negligible, the bottleneck allows more information from the input through the representation. For smaller values of , the mutual information between the representation and the label increases on the training set, but not necessarily on the test set. This gives a gap between train and test curves indicative of a degradation in generalization.
For  in the range between 10-8 and 10-4, we note that for the same level of sufficiency, setting M = 12 consistently achieves more compression of the input compared to the setting M = 1
6

Under review as a conference paper at ICLR 2019

(roughly 20 bits less). Moreover, we see that the generalization gap (in the lower left panel) is smaller for larger values of M (our method).
The dynamics of the information quantities during training are also interesting. We provide figures on these in Appendix D.

\M 1 10-1 10-3 10-5

1

epoch: 200 0.4

0.2

0.0

0.2

0.4
0.4 3

0.2 0.0 0.2 epoch: 200

0.4

2

1

0

1

2

33 2 1 0 1 2 3 epoch: 200
10

5

0

5

10 10
40

50

5

epoch: 200

10

20

0

20

40 40 20 0

20 40

3

epoch: 200
0.75 0.50 0.25 0.00 0.25 0.50 0.75
0.75 0.50 0.25 0.00 0.25 0.50 0.75 epoch: 200
3
2
1
0
1
2
3 3 2 10 1 2 3 epoch: 200
10

5

0

5

10 10
40

50

5

epoch: 200

10

20

0

20

40 40 20 0

20 40

6

1.00 0.75 0.50 0.25 0.00 0.25 0.50 0.75 1.00
1.0
3
2
1
0
1
2
3 3
10

epoch: 200

0.5 0.0

0.5

epoch: 200

2 10 1 2 epoch: 200

1.0 3

5

0

5

10 10
40

50

5

epoch: 200

10

20

0

20

40 40 20 0

20 40

12

1.00 0.75 0.50 0.25 0.00 0.25 0.50 0.75 1.00
1.0
3 2 1 0 1 2 3
3
10

epoch: 200

0.5 0.0

0.5

epoch: 200

2 10 1 2 epoch: 200

1.0 3

5

0

5

10 10
40
20

50

5

epoch: 200

10

0

20

40 40 20 0

20 40

Figure 3: We trained the VDB on MNIST with the basic encoder given by a fully connected network with two layers of ReLUs producing the means and variance of 2D independent Gaussian latent representation. Ellipses representing the posterior distributions of 1000 input images from in latent space after training with  = 100, 10-1, 10-3, 10-5 and M = 1, 3, 6, 12. Color corresponds to the class label.

In order to visualize the representations, we also train the VDB on MNIST with a 2 dimensional representation. Here, we use the same settings as before, with the only difference that the dimension of the output layer of the encoder is 4, with two coordinates representing the mean, and two coordinates representing a diagonal covariance matrix. The results are shown in Figure 3. For  = 10-5, the representations are well separated, depending on the class. For related figures in the setting of unsupervised learning see Appendix E. The dynamics of the mutual information and the learning curves in terms of classification accuracy are shown in Figure 4. The figure shows that, in terms of classification accuracy, higher values of M (our method) usually lead to better accuracy. An exception is when the number L of posterior samples for classification is very large. These have an interpretation in terms of a phase where the model is fitting the input-output relationship and hence increasing the mutual information I(Z; Y ), followed by a compression phase, where I(Z; X) is reduced, leading to a better generalization.

5 DISCUSSION
We have formulated a bottleneck method based on channel deficiencies. The deficiency of a decoder with respect to the true channel between the input and output quantifies how well a randomization at the decoder input (by way of stochastic encodings) can be used to simulate the true channel. The VDB has a natural variational formulation, which recovers the VIB in the limit of a single sample

7

Under review as a conference paper at ICLR 2019

I(Z;Y)

MNIST, K=2 2.6

MNIST, K=2, L=M1 NIST, K=2, L=1 11

test accuracy test accuracy

0.95

0.95

2.4

2.2

0.9

0.9 M = 1

M=1

M=3

M=3

M=6

M=6

M = 12

M = 12

0.85 0

0.85 50 100 15500 21000 150 200

2

epoch

epoch

MNIST, K=2, L=M6 NIST, K=2, L=6 11

1.8

test accuracy test accuracy

M=1

0.95

0.95

1.6 M = 3

M=6 M = 12

0.9

0.9 M = 1 M=3 M=6

M=1 M=3 M=6

1.4

M = 12

M = 12

40 60 80 100 120 140 160 180 0.85

0.85

0 50 100 15500 20100 150 200

I(Z;X)

epoch

epoch

test accuracy test accuracy

test accuracy test accuracy

MNIST, K=2, L=M3 NIST, K=2, L=3 11

0.95

0.95

0.9
0.85 0
1

0.9 M = 1 M=3 M=6 M = 12

M=1 M=3 M=6 M = 12

0.85 50 100 15500
epoch

21000 150 epoch

200

MNIST, K=2, L=M12NIST, K=2, L=12 1

0.95

0.95

0.9
0.85 0

0.9 M = 1 M=3 M=6 M = 12

M=1 M=3 M=6 M = 12

0.85 50 100 15500 20100 150

epoch

epoch

200

Figure 4: Learning curves for MNIST, where the encoder was a MLP of size 784­1024­1024­2K, the last layer being a K = 2 dimensional diagonal Gaussian. The decoder was simply a softmax with 10 classes. The left figure plots the mutual information between the representation at the last layer of the encoder and the input, I(Z; X), against the mutual information between representation and the class label, I(Z; Y ), as training progresses. The latter increases monotonically, while the former increases and then decreases.

of the encoder output. Experiments demonstrate that the VDB can learn more compressed representations while retaining the same discriminative capacity. The method has a statistical decisiontheoretic appeal. The resulting variational objective resembles the VIB and can be implemented as an easy modification of the former, with little to no computational overhead.
Given two channels that convey information about a target variable of interest, two different notions of deficiencies arise depending on whether the target resides at the common input or output of the given channels. When the target is at the common output of the two channels, as is in a typical bottleneck setting (see Figure 1), our Definition 1 has a natural interpretation as a KL-distance from input-Blackwell sufficiency (Nasser, 2017). Here sufficiency is achieved by applying a randomization at the input of the decoder with the goal of simulating the true channel. The notion of input-Blackwell sufficiency contrasts with Blackwell's original notion of sufficiency Blackwell (1953) in the sense that Blackwell's theory compares two channels with a common input. One can again define a notion of deficiency in this setting (see Appendix B for a discussion on deficiencies in the classical Blackwell setup). The associated channels (one from Y to Z and the other from Y to X ) do not however have a natural interpretation in a typical bottleneck setting. In contrast, the input-Blackwell setup appears to be much more intuitive in this context. This subtle distinction seems to have largely gone unnoticed in the literature (see e.g. Van Rooyen & Williamson, 2014; van Rooyen & Williamson, 2015).
The more detailed view of information emerging from this analysis explains various effects and opens the door to multiple generalizations. In the spirit of the VDB, one can formulate a VAE as well (see preliminary experiments in the Appendix). On a related note, we mention that the deficiency is a lower bound to a quantity called the Unique information (Bertschinger et al., 2014; Banerjee et al., 2018a) (see Appendix C to see a relation with the IB). An alternating minimization algorithm similar in spirit to the classical Blahut-Arimoto algorithm (Blahut, 1972) is proposed in Banerjee et al. (2018b) to compute this quantity. Such an algorithm however, is not feasible in a deep neural network implementation. In the limit   0, the VDB algorithm gives a means to estimating a lower bound to the unique information from data. This might be of independent interest in improving the practicality of the theory of information decompositions.

8

Under review as a conference paper at ICLR 2019
REFERENCES
Alexander A. Alemi, Ian Fischer, Joshua V. Dillon, and Kevin Murphy. Deep variational information bottleneck, 2016. URL http://arxiv.org/abs/1612.00410. ICLR17.
Arindam Banerjee, Srujana Merugu, Inderjit S Dhillon, and Joydeep Ghosh. Clustering with bregman divergences. Journal of machine learning research, 6(Oct):1705­1749, 2005.
Pradeep Kr Banerjee, Eckehard Olbrich, Ju¨rgen Jost, and Johannes Rauh. Unique informations and deficiencies. arXiv preprint arXiv:1807.05103, 2018a.
Pradeep Kr Banerjee, Johannes Rauh, and Guido Montu´far. Computing the unique information. In Proc. IEEE ISIT, pp. 141­145. IEEE, 2018b.
Nils Bertschinger and Johannes Rauh. The blackwell relation defines no lattice. In Proc. IEEE ISIT, pp. 2479­2483. IEEE, 2014.
Nils Bertschinger, Johannes Rauh, Eckehard Olbrich, Ju¨rgen Jost, and Nihat Ay. Quantifying unique information. Entropy, 16(4):2161­2183, 2014.
David Blackwell. Equivalent comparisons of experiments. The Annals of Mathematical Statistics, 24(2):265­272, 1953.
R. Blahut. Computation of channel capacity and rate-distortion functions. IEEE Transactions on Information Theory, 18(4):460­473, 1972.
Ste´phane Boucheron, Olivier Bousquet, and Ga´bor Lugosi. Theory of classification: A survey of some recent advances. ESAIM: probability and statistics, 9:323­375, 2005.
Matthew Chalk, Olivier Marre, and Gasper Tkacik. Relevant sparse codes with variational information bottleneck. In Advances in Neural Information Processing Systems, pp. 1957­1965, 2016.
Imre Csisza´r. A class of measures of informativity of observation channels. Periodica Mathematica Hungarica, 2(1-4):191­213, 1972.
Imre Csisza´r and Ja´nos Ko¨rner. Information theory: coding theorems for discrete memoryless systems. Cambridge University Press, 2011.
Imre Csisza´r and Frantisek Matus. Information projections revisited. IEEE Transactions on Information Theory, 49(6):1474­1490, 2003.
Tilmann Gneiting and Adrian E Raftery. Strictly proper scoring rules, prediction, and estimation. Journal of the American Statistical Association, 102(477):359­378, 2007.
David Gondek and Thomas Hofmann. Conditional information bottleneck clustering. In In 3rd IEEE International Conference on Data Mining, Workshop on Clustering Large Data Sets, 2003.
Peter D Gru¨nwald, A Philip Dawid, et al. Game theory, maximum entropy, minimum discrepancy and robust bayesian decision theory. the Annals of Statistics, 32(4):1367­1433, 2004.
Malte Harder, Christoph Salge, and Daniel Polani. A bivariate measure of redundant information. Physical Review E, 87:012130, Jan 2013.
Peter Harremoe¨s and Naftali Tishby. The information bottleneck revisited or how to choose a good distortion measure. In Proc. IEEE ISIT, pp. 566­570. IEEE, 2007.
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a constrained variational framework. 2016.
Hsiang Hsu, Shahab Asoodeh, Salman Salamatian, and Flavio P Calmon. Generalizing bottleneck problems. arXiv preprint arXiv:1802.05861, 2018.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.
9

Under review as a conference paper at ICLR 2019
Artemy Kolchinsky, Brendan D Tracey, and David H Wolpert. Nonlinear information bottleneck. arXiv preprint arXiv:1705.02436, 2017.
J. Ko¨rner and K. Marton. Comparison of two noisy channels. In Topics in information theory, volume 16, pp. 411­423. Colloquia Mathematica Societatis Jnos Bolyai, Keszthely (Hungary), 1975.
L Le Cam. Sufficiency and approximate sufficiency. The Annals of Mathematical Statistics, pp. 1419­1455, 1964.
Yann LeCun and Corinna Cortes. MNIST handwritten digit database. 2010. URL http://yann. lecun.com/exdb/mnist/.
Friedrich Liese and Igor Vajda. On divergences and informations in statistics and information theory. IEEE Transactions on Information Theory, 52(10):4394­4412, 2006.
Rajai Nasser. On the input-degradedness and input-equivalence between channels. In Proc. IEEE ISIT, pp. 2453­2457. IEEE, 2017.
Matthew Parry, A Philip Dawid, Steffen Lauritzen, et al. Proper local scoring rules. The Annals of Statistics, 40(1):561­592, 2012.
Maxim Raginsky. Shannon meets blackwell and le cam: Channels, codes, and statistical experiments. In Proc. IEEE ISIT, pp. 1220­1224. IEEE, 2011.
Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate inference in deep generative models. arXiv preprint arXiv:1401.4082, 2014.
Ohad Shamir, Sivan Sabato, and Naftali Tishby. Learning and generalization with the information bottleneck. In International Conference on Algorithmic Learning Theory, pp. 92­107. Springer, 2008.
N. Tishby, F. Pereira, and W. Bialek. The information bottleneck method. In Proceedings of the 37-th Annual Allerton Conference on Communication, Control and Computing, pp. 368­377, 1999.
Erik Torgersen. Comparison of statistical experiments, volume 36. Cambridge University Press, 1991.
Brendan Van Rooyen and Robert C Williamson. Le cam meets lecun: Deficiency and generic feature learning. arXiv preprint arXiv:1402.4884, 2014.
Brendan van Rooyen and Robert C Williamson. A theory of feature learning. arXiv preprint arXiv:1504.00083, 2015.
Mat´ias Vera, Pablo Piantanida, and Leonardo Rey Vega. The role of information complexity and randomization in representation learning. arXiv preprint arXiv:1802.05355, 2018.
H Witsenhausen and A Wyner. A conditional entropy bound for a pair of discrete random variables. IEEE Transactions on Information Theory, 21(5):493­501, 1975.
10

Under review as a conference paper at ICLR 2019

APPENDIX

A MISCLASSIFICATION ERROR AND THE AVERAGE LOG-LOSS

In a classification task, the goal is to use the training dataset to learn a classifier (y|x) that minimizes the probability of error under the true data distribution, defined as follows.

PE () := 1 - E(x,y)p [(y|x)] .

(12)

It is well known that the optimal classifier that gives the smallest probability of error is the Bayes
classifier (Boucheron et al., 2005). Since we do not know the true data distribution we try to
learn based on the empirical error. Directly minimizing the empirical probability of error over
the training dataset is in general a NP-hard problem. In practice, one minimizes a surrogate loss function that is a convex upper bound on PE . A natural surrogate is the average log-loss function E(x,y)p [- log (y|x)]. When the model is  = d  e, the following upper bounds are immediate from using Jensen's inequality.

PE ()  1 - exp - E(x,y)p [- log d  e(y|x)]  1 - exp - E(x,y)pEze(z|x) [- log d(y|z)]

(13)

The bound using the standard cross-entropy loss is evidently weaker than the average log-loss. A lower bound on the probability of error is controlled by a convex functional of the mutual information between the representation and the raw inputs I(Z; X) (Vera et al., 2018, see, e.g., Lemma 4). The average log-loss and the rate term in the VDB objective equation 4 are two fundamental quantities that govern the probability of error.

B CLASSICAL THEORY OF COMPARISON OF CHANNELS
In this section, we discuss the classical theory of comparison of channels due to Blackwell (1953) and its extension by Le Cam (1964); Torgersen (1991) and more recently by Raginsky (2011).
Suppose that a learner wishes to predict the value of a random variable Y that takes values in a set Y. She has a set of actions A. Each action incurs a loss (y, a) that depends on the true state y of Y and the chosen action a. Let Y encode the learners' uncertainty about the true state y. The tuple (Y , A, ) is called a decision problem. Before choosing her action, the learner observes a random variable X through a channel from Y to X . A channel is simply a family {y}yY of probability measures on X , one for each possible input y  Y. We write M(Y; X ) to denote the space of all channels from Y to X . An ideal learner chooses a strategy   M(X ; A) that minimizes her expected loss or risk R(Y , , , ) := EyY Eay (y, a). The optimal risk when using the channel  is R(Y , , ) := minM(X ;A) R(Y , , , ).
Suppose now that the learner has to choose between X and another random variable Z that she observes through a second channel µ  M(Y; Z) with common input Y . She can always discard X in favor of Z if, knowing Z, she can simulate a single use of X by randomly sampling a x  X after each observation z  Z.
Definition 3. We say that X is output-degraded from Z w.r.t. Y , denoted Z Y X, if there exists a random variable X such that the pairs (Y, X) and (Y, X ) are stochastically indistinguishable, and Y - Z - X is a Markov chain.
She can also discard X if her optimal risk when using Z is at most that when using X for any decision problem. Write Z Y X if R(Y , , )  R(Y , µ, ) for any decision problem. Blackwell (1953) showed the equivalence of these two relations.
Theorem 4. (Blackwell's Theorem) Z Y X  Z Y X.
Write µ Y  if  =   µ for some   M(Z; X ). If Y has full support, then it easy to check that µ Y   Z Y X (Bertschinger & Rauh, 2014, Theorem 4).
The learner can also compare  and µ by comparing the mutual informations I(Y ; X) and I(Y ; Z) between the common input Y and the channel outputs X and Z.

11

Under review as a conference paper at ICLR 2019

Definition 5. µ is said to be more capable than , denoted µ

mc Y

,

if

I (Y

; Z)



I (Y

;

X)

for

all

probability distribution on Y.

It follows from the data processing inequality that µ

Y  = µ

mc Y

.

However,

the

converse

implication is not true in general (Ko¨rner & Marton, 1975).

The relation Y is a preorder on observed variables. In general, one cannot expect two random variables to be comparable in the Blackwell sense, i.e., one can always be simulated by a random-
ization of the other. The converse to the Blackwell's theorem states that if the relation Z Y X does not hold, then there exists a set of actions A and a loss function (y, a)  RY×A such that R(Y , , ) < R(Y , µ, ). Le Cam introduced the concept of a deficiency of µ w.r.t.  to express this deficit in optimal risks (Le Cam, 1964) in terms of an approximation of  from µ via
Markov kernels.

Definition 6. The deficiency of µ w.r.t.  is

(µ, ) := inf sup   µy - y TV,
M(Z;X ) yY

(14)

where · TV denotes the total variation distance.

When the distribution of the common input to the channels is fixed, one can define a weighted deficiency (Torgersen, 1991, Section 6.2).

Definition 7. Given Y  Y , the weighted deficiency of µ w.r.t.  is

  (µ,

)

:=

inf
M(Z;X )

EyY

  µy - y TV.

(15)

Le Cam's randomization criterion (Le Cam, 1964) shows that deficiencies quantify the maximal gap in the optimal risks of decision problems when using the channel µ rather than .
Theorem 8 (Le Cam (1964)). Fix µ  M(Y; Z),   M(Y; Z) and a probability distribution Y on Y and write  = maxy,a (y, a). For every > 0, (µ, ) < if and only if R(Y , µ, ) - R(Y , , ) <  for any set of actions A and any bounded loss function .

Raginsky (2011) introduced a broad class of deficiency-like quantities using the notion of a generalized divergence between probability distributions that satisfies a monotonicity property w.r.t. data processing. The family of f -divergences due to Csisza´r belongs to this class (Liese & Vajda, 2006).

Definition 9. The f -deficiency of µ w.r.t.  is

f (µ, ) := inf sup Df (y   µy),
M(Z;X ) yY

(16)

Many common divergences, such as the Kullback-Leibler (KL) divergence, the reverse-KL divergence, and the total variation distance are f -divergences. When the channel µ is such that its output is constant, no matter what the input, the corresponding f -deficiency is called f informativity (Csisza´r, 1972). The f -informativity associated with the KL divergence is just the channel capacity which has a geometric interpretation as an "information radius".

We can also define a weighted f -deficiency of µ w.r.t. . Definition 10. The weighted f -deficiency of µ w.r.t.  is
f (µ, ) := inf Df (y   µy|Y ),
M(Z;X )

(17)

Specializing to the KL divergence, we have the following definition.

Definition 11. The weighted output deficiency of µ w.r.t.  is

o (µ,

)

:=

min
M(Z;X )

DKL(

  µ|Y ),

(18)

where the subscript o in o emphasizes the fact that the randomization is at the output of the channel µ.

Note that o(µ, ) = 0 if and only if Z Y X, which captures the intuition that if o(µ, ) is small, then X is approximately output-degraded from Z w.r.t. Y . Using Pinsker's inequality, we have

(µ, ) 

ln(2) 2

o

(µ,

).

(19)

12

Under review as a conference paper at ICLR 2019

C UNIQUE INFORMATION BOTTLENECK

In this section, we give a new perspective on the Information Bottleneck paradigm using nonnegative mutual information decompositions. The quantity we are interested in is the notion of Unique information proposed in (Bertschinger et al., 2014). Work in similar vein include (Harder et al., 2013) and more recently (Banerjee et al., 2018a) which gives an operationalization of the unique information.
Consider three random variables Y , X, and Z with joint distribution P . The mutual information between Y and X can be decomposed into information that X has about Y that is unknown to Z (we call this the unique information of X w.r.t. Z) and information that X has about Y that is known to Z (we call this the shared information).

I(Y ; X) = U I(Y ; X\Z) + SI(Y ; X, Z) .

(20)

unique X wrt Z shared (redundant)

Conditioning on Z destroys the shared information but creates complementary or synergistic information from the interaction of X and Z.

I(Y ; X|Z) = U I(Y ; X\Z) + CI(Y ; X, Z) .

(21)

unique X wrt Z complementary (synergistic)

Using the chain rule, the total information that the pair (X, Z) conveys about Y can be decomposed into four terms.

I(Y ; XZ) = I(Y ; X) + I(Y ; Z|X) = U I(Y ; X\Z) + SI(Y ; X, Z) + U I(Y ; Z\X) + CI(Y ; X, Z).

(22) (23)

U I, SI, and CI are nonnegative functions that depend continuously on the joint distribution of (Y, X, Z).
For completeness, we rewrite the information decomposition equations below.

I(Y ; X) = U I(Y ; X\Z) + SI(Y ; X, Z),

(24a)

I(Y ; Z) = U I(Y ; Z\X) + SI(Y ; X, Z),

(24b)

I(Y ; X|Z) = U I(Y ; X\Z) + CI(Y ; X, Z), I(Y ; Z|X) = U I(Y ; Z\X) + CI(Y ; X, Z),

(24c) (24d)

One can interpret the unique information as either the conditional mutual information without the synergy, or as the mutual information without the redundancy.
When Y - X - Z is a Markov chain, the information decomposition is

U I(Y ; Z\X) = 0, U I(Y ; X\Z) = I(Y ; X|Z) = I(Y ; X) - I(Y ; Z), SI(Y ; X, Z) = I(Y ; Z), CI(Y ; X, Z) = 0.

(25a) (25b) (25c) (25d)

The Information bottleneck (Tishby et al., 1999) minimizes the following objective

LIB(e) = I(Y ; X|Z) + I(X; Z),

(26)

over all encoders e  M(X ; Z) : Y -X -Z. From equation 25b, it follows that one can equivalently write the IB objective function as

LIB(e) = U I(Y ; X\Z) + I(X; Z).

(27)

From an information decomposition perspective, the original IB is actually minimizing just the unique information subject to a regularization constraint. This is a simple consequence of the fact

13

Under review as a conference paper at ICLR 2019

that the synergistic information CI = 0 (see equation 25d) when we have the Markov chain condition Y - X - Z. Hence, one might equivalently call the original IB as the Unique information bottleneck.
Given Y - X - Z, the sufficiency term in the IB objective, I(Y ; X|Z) depends only on the pairwise marginals (Y, X) and (Y, Z) and not on the full joint P . The minimality term depends on the (Y, Z)-marginal. For constructing an approximate sufficient statistic for X w.r.t. Z for Y , this dependence on the pairwise marginals avoids complicated synergies and clearly delineates the roles of the sufficiency and minimality terms. Utilizing tools from decision theory, Bertschinger et al.
(2014) defined the function U I based on the idea of approximating one channel from the other by a randomization at the output.
Definition 12. Let (Y, X, Z)  P , Y  Y and let   M(Y; X ), µ  M(Y; X ) be two channels with the same input alphabet such that PY X (y, x) = Y (y)y(x) and PY Z (y, z) = Y (y)µy(z). Define

P =

Q  PY×X ×Z : QY X (y, x) = Y (y)y(x),
QY Z (y, z) = Y (y)µy(z) , U I(Y ; X\Z) = min IQ(Y ; X|Z),
QP
U I(Y ; Z\X) = min IQ(Y ; Z|X),
QP
SI(Y ; X, Z) = I(Y ; X) - U I(Y ; X\Z), CI(Y ; X, Z) = I(Y ; X|Z) - U I(Y ; X\Z),

(28a) (28b)
(28c)
(28d) (28e)

where the subscript Q in IQ denotes that joint distribution on which the quantities are computed.

The functions U I, SI and CI give a nonnegative decomposition of the mutual information I(Y ; XZ).
The function U I satisfies the following intuitive property in relation to Blackwell's theorem 4.
Proposition 13. (Bertschinger et al., 2014, Lemma 6) U I(Y ; X\Z) = 0  Z Y X.
The equivalence in Proposition 2 follows from noting that (d, ) = 0  U I(Y ; X\Z) = 0 (Banerjee et al., 2018a, Proposition 28) and the fact that U I(Y ; X\Z) = I(Y ; X|Z) when Y - X - Z is a Markov chain.
Since in the IB setting, there is no complementary information equation 25, one can choose to minimize either U I(Y ; X\Z) which is in fact equal to I(Y ; X|Z) (the original IB objective) or minimize the deficiency (d, ). From the discussion above, it is clear that the results are going to be equivalent only in the limit of exact sufficiency since (d, ) = 0  I(Y ; X|Z) = 0. In all other cases, we expect to find something (subtly) different from IB. In general, for the bottlenecks, we have:

min I(X; Z)  min I(X; Z).

e(z|x): I(Y ;X|Z)

e(z|x): (d,)

(29)

Hence, for achieving the same level of sufficiency, one needs to store less information about the input X when minimizing the deficiencies than when minimizing the conditional mutual information.

14

Under review as a conference paper at ICLR 2019
D ADDITIONAL FIGURES ON VDB EXPERIMENTS
Figure 5: Evolution of mutual information between representation and input vs representation and output over 200 training epochs (dark to light color) on MNIST. The curves are averages over 20 repetitions of the experiment. At early epochs, training mainly effects fitting of the input-output relationship and an increase of I(Z; Y ). At later epochs, training mainly effects a decrease of I(Z; X), which corresponds to the representation increasingly discarding information from the input. An exception is when the regularization parameter  is very small. In this case the representation captures more information about the input, and longer training decreases I(Z; Y ), which is indicative of overfitting to the training data. Higher values of M (our method) lead to the representation capturing more information about the target, while at the same time discarding more information about the input. M = 1 corresponds to the Variational Information Bottleneck.
15

Under review as a conference paper at ICLR 2019

E UNSUPERVISED REPRESENTATION LEARNING USING THE VDB

In this section, we discuss some preliminary results on an unsupervised version of the VDB objective which bears some resemblance to the -VAE (Higgins et al., 2016). The cross entropy loss that appears in an autoencoder is similar to the cross entropy that appears in the information bottleneck. In the same spirit of the VDB, we can formulate a Deficiency Autoencoder. We call the unsupervised version the Variational Deficiency Autoencoder (VDAE).

The VDAE minimizes the following objective over all tuples (e  M(X ; Z), d  M(Z; Y), r  PZ).

LV DAE(e, d, r) := Ex [- log(d  e(x))] + ExDKL(e(Z|y) r(Z)).

(30)

The -VAE (Higgins et al., 2016) minimizes the following objective over all tuples (e  M(X ; Z), d  M(Z; Y), r  PZ ).

LV AE(e, d, r) := ExEze(Z|x) [- log d(y|z)] + ExDKL(e(Z|x) r(Z)).

(31)

We note that the -VAE has a similar-looking training objective as the VDAE, with the only difference that the expectation is outside the log.

The next figures show experiments on MNIST. The representations are optically comparable with results obtained in other works via the Variational Autoencoder.

Figure 6: The learned MNIST manifold for the VDAE with M = 3. The left part shows the representation (mean values of the posterior) for 5000 test examples. The right shows samples obtained from a grid of values of the latent variable.

16

Under review as a conference paper at ICLR 2019

M =1

M =2

M =3

M =6

Figure 7: Sampling grids in latent space for the VDAE. These plots show the geometric coherence in latent space of the decoder. The settings are as in Figure 6.

17

