Under review as a conference paper at ICLR 2019

IMPROVED GRADIENT ESTIMATORS FOR STOCHASTIC DISCRETE VARIABLES
Anonymous authors Paper under double-blind review
ABSTRACT
In many applications we seek to optimize an expectation with respect to a distribution over discrete variables. Estimating gradients of such objectives with respect to the distribution parameters is a challenging problem. We analyze existing solutions including finite-difference (FD) estimators and continuous relaxation (CR) estimators in terms of bias and variance. We show that the commonly used Gumbel-Softmax estimator is biased and propose a simple method to reduce it. We also derive a simpler piece-wise linear continuous relaxation that also possesses reduced bias. We demonstrate empirically that reduced bias leads to a better performance in variational inference and on binary optimization tasks.

1 INTRODUCTION

Discrete stochastic variables arise naturally in many applications including topic modeling, semisupervised learning, clustering, variational memory addressing and reinforcement learning. In many cases, the objective is to minimize an expectation of a function of discrete random variables with respect to the distribution parameters:

min L[],


where L[] = Eq f (z) =

q(z)f (z).

z

(1)

Here, z is a vector of discrete variables under a -parameterized distribution q(z). For example, in variational inference, f (z) is the variational lower bound and q(z) is the approximating posterior.
Eq. (1) is commonly minimized by gradient-based methods, which require estimating the gradient L[] (see Schulman et al. (2015) for an overview). For continuous random variables whose sampling can be reparameterized as a function of other parameter-independent random variables, the reparameterization trick (Kingma & Welling (2013), Rezende et al. (2014)) gives low variance gradient estimates. However, this trick is infeasible for discrete variables due to the discontinuous cumulative distribution function (CDF).
Extensions of the reparameterization trick to discrete distributions can be grouped into finitedifference (FD) estimators, and continuous relaxation (CR) estimators. We present a summary of three recent FD estimators (Tokui & Sato (2017); Yin & Zhou (2018); Lorberbom et al. (2018) to guide practitioners to the salient aspects of their bias-variance tradeoff and computational complexity. Most importantly, we propose a scalable (but still unbiased) variant of Tokui & Sato (2017) that trades decreased computation for slightly increased variance.
We examine CR estimators including the popular Gumbel-Softmax (Jang et al. (2016); Maddison et al. (2016)) in terms of the gradient bias and propose a new method to reduce the bias of all CR estimators for both binary and categorical variables. Based upon this understanding, we develop a piecewise-linear estimator for binary and categorical variables that is simpler and less biased than Gumbel-Softmax.
Lastly, we provide empirical evidence that these improved estimators allow for faster optimization when training variational autoencoders and when optimizing a continuous relaxation of a combinatorial optimization problem.

1

Under review as a conference paper at ICLR 2019

1.1 RELATED WORK
The most generic approximator of L[] is the score function (SF) estimator (a.k.a. REINFORCE Williams (1992), Glynn (1990)). SF suffers from high variance and many remedies have been proposed to reduce this variance (Mnih & Gregor (2014); Gregor et al. (2013); Gu et al. (2015); Mnih & Rezende (2016); Tucker et al. (2017); Grathwohl et al. (2017)). Unbiased estimators that require multiple function evaluations have also been proposed Tokui & Sato (2017), Titsias & La´zaroGredilla (2015), Lorberbom et al. (2018), Yin & Zhou (2018). These estimators have lower variance but can be computationally demanding. CR estimators often trade bias for variance and previous CR proposals include straight-through estimators (Bengio et al. (2013); Raiko et al. (2014)), the Gumbel-Softmax estimator (Jang et al. (2016); Maddison et al. (2016)), and overlapping smoothing (Vahdat et al. (2018b;a); Rolfe (2016)).

2 THE REPARAMETERIZATION AND MARGINALIZATION ESTIMATOR

We begin a summary of FD estimators with the reparameterization and marginalization (RAM)
method of Tokui & Sato (2017). For a single binary variable the expectation in Eq. (1) is enumerated as L = z q(z)f (z) = qf (1) + (1 - q)f (0), where q  q(z = 1). The gradient is:

L = q(f (1) - f (0)) = l q(1 - q)(f (1) - f (0)),

(2)

where q = (l) = (1 + e-l )-1 and l = logit(q). This derivative involves two function eval-

uations and contains a finite-difference of f (z). Eq. (2) is an unbiased zero-variance estimate since

the summation over z is done explicitly. The generalization to M factorially-distributed random

variables q(z) =

M i=1

q,i(zi)

is

L = q,i q(z\i)(f (zi = 1, z\i) - f (zi = 0, z\i)),
i z \i

(3)

where again the summation over zi is performed exactly and q,i  q,i(zi = 1). The summation

over z\i can be estimated with a single sample but the derivative requires M +1 function evaluations.

This limits the applicability of RAM to moderately-sized models. Note that both f (zi = 0, z\i)

and f (zi = 1, z\i) are evaluated at the same z\i which leads to a lower-variance estimator. For

hierarchical q(z) =

M i=1

q,i(zi|z

<i)

the

derivative

takes

the

form:

L =

q(z <i)q,i

q(z>i|1, z<i)f (z>i, 1, z<i) - q(z>i|0, z<i)f (z>i, 0, z<i) .

i z <i

z >i

z >i
(4)

where q,i  q,i(1|z<i). The key insight of Tokui & Sato (2017) is to use common random variates z>i when sampling from q(z>i|1, z<i) and q(z>i|0, z<i). This reduces both the variance and the
computational cost. Tokui & Sato (2017) show that this estimator is optimal because it exactly sums

over the binary variables whose probability distribution is being differentiated.

A RAM estimator can also be constructed for categorical variables. For a single one-hot encoded categorical variable y = (y0, ...yA-1), ya  {0, 1}, a ya = 1, the derivative of Eq. (1) is

L =  q(y)f (y) = (la ) qa qb (f a - f b),
y ab

(5)

where f a = f (ya = 1), and qa = ela / b elb . The generalization to many categorical variables
proceeds as for binary variables. For example, the derivative of a factorial categorical distribution over y = {yia | 0  a < A, 1  i  M } is

L =

q(y\i) (la ,i)qa ,iqb ,i f (yia = 1, y\i) - f (yib = 1, y\i) .

i y \i

a,b

(6)

This derivative can again be estimated with a single sample but requires M A function evaluations. Since RAM is unbiased and has the minimal variance (due to the explicit summation over the differentiated variable), we use it as a baseline to evaluate computationally cheaper alternatives.

2

Under review as a conference paper at ICLR 2019

2.1 SAMPLED REPARAMETERIZATION AND MARGINALIZATION

We propose a modification to RAM that allows us to trade decreased computational cost for increased variance. For binary variables, q,i = q,i(1 - q,i)l,i where q,i = (l,i), so that each term in Eq. (3) or (4) is proportional to q,i(1 - q,i). In many applications, we observe that the distribution of a large number of variables (q,i) are drawn to 0 or 1 early during optimization. Such variables have negligible contribution to the full derivative. We exploit this
observation to reduce the computational cost by including variable zi in the full gradient with probability pi = 4q,i(1-q,i)/, where  is an adjustable hyperparameter. This means that we replace the derivative in Eq. (3) with

L = Ep

(l,i)

i 4

q(z\i) f (zi = 1, z\i) - f (zi = 0, z\i) ,

i z \i

(7)

where i  {0, 1} are Bernoulli variables with probabilities pi indicating whether zi is included or not. We evaluate Eq. (7) by sampling  and only then evaluating non-zero terms. In Section 4 we show that in the context of variational inference on MNIST the number of function evaluations is reduced by an order of magnitude while still allowing for effective optimization. As always, this computational saving comes at the cost of increased gradient variance which slows training.

In the categorical case, each term in Eq. (6) is accompanied by qa,iqb ,i that can be used to assign
importance to the (a, b) edge of the simplex for variable yi. The computational cost M A can be reduced by keeping each term with probability pia,b = 4qa,iqb ,i/.

Appendices A and B summarize two other FD estimators, ARGMAX Lorberbom et al. (2018) and ARM Yin & Zhou (2018), by noting their bias-variance tradeoff and computational complexity.

3 CONTINUOUS RELAXATION ESTIMATORS
Unlike FD estimators that use multiple function evaluations to approximate the gradient, continuous relaxation estimators extend the reparameterization trick to discrete variables by approximating them with continuous variables: z   = g() for   U [0, 1], where  is a parameter that controls the approximation. The objective function L[] = z q(z)f (z) is replaced with L~[] = E f  = g() and the gradients are computed using chain rule

L~[] = E

i i f ( )i  =g(i;q,i(1| <i)) = E

i f ( )(qi i)(qi)  =g(i;qi)
i qi=q,i(1| <i)
(8)

These gradients can be computed efficiently by automatic differentiation libraries. However, because

the objective function is changed, CR estimators in Eq. (8) are biased. Nevertheless, in practice the

bias is often small enough to allow for effective optimization.

3.1 THE GUMBEL-SOFTMAX ESTIMATOR

The most popular CR estimator is Gumbel-Softmax (GSM) (Jang et al. (2016); Maddison et al. (2016))1. For binary variables, this relaxation takes the simple form

i =   -1 qi + -1(i) ,

(9)

where qi  q,i(1| <i). This relaxation and its derivative q are shown in Fig. 1(a).  controls the sharpness of the relaxation and tunes the trade-off between the bias (closeness of  to z) and
variance of q. We note that the slope of the relaxed () at  = 1/2 is   /[4q(1 - q)] and
thus becomes large when q approaches 0 or 1.

1More precisely, Maddison et al. (2016) considered problems in variational inference where f (z) is relaxed by replacing a generative distribution with its continuous relaxation. In contrast, Jang et al. (2016) directly relaxed discrete variables z   without changing the objective, thus replacing f (z)  f ( ). This does not produce a consistent objective for a probabilistic model, but as Jang et al. (2016) have shown, works well in practice. We work with generic f (z) and thus only consider the approach of Jang et al. (2016).

3

Under review as a conference paper at ICLR 2019

1.6
1.4 z
1.2 q 1.0 0.8 0.6 0.4

= 4q(1 q)

1.6
1.4 z
1.2 q 1.0 0.8 0.6 0.4

3.5 q 3.0 2.5 2.0 1.5 1.0

0.2 0.2 0.5

0.0 0.0 0.0

0.0 0.2 0.4 0.6 0.8 1.0

0.0 0.2 0.4 0.6 0.8 1.0

0.0 0.2 0.4 0.6 0.8 1.0

(a) Gumbel-Softmax

(b) Piecewise Linear

(c) q

Figure 1: Continuous relaxations at  = 2 to a Bernoulli random variable Ber(q = 0.8): (a) shows the GSM approximation and (b) shows a piece-wise linear approximation to the discontinuous CDF.
(c) shows the effect of a modification to GSM that reduces its bias.

3.2 IMPROVED CONTINUOUS RELAXATION ESTIMATORS

In this section, we analyze the bias introduced by Eq. (8) and propose a simple method to reduce
it. The bias of E [i f ( )i] has two sources: (a) the relaxation of j for j = i and (b) the relaxation of i. To characterize the latter bias, we start with a single binary variable and write the gradient as the following integral:

L = q f (1) - f (0)

= q

1
d  f () = q
0

1  0 d   f ().

(10)

Here, () is any continuous function satisfying (0) = 0 and (1) = 1. For a non-decreasing
function (), we can view  as a random variable with inverse CDF () and  as a uniform random variable   U[0, 1]. Given that the corresponding probability density function (PDF) is q() = (/)-1, we rewrite the derivative as

L = q Eq

1 q() f () .

(11)

This expectation can be estimated by sampling   q(). For smooth enough f (), the variance

of this estimate is controlled by var q()-1

=

1 0

d

q( )-1

-

1.

Thus, the more non-linear

() is, the higher will be the variance of estimate Eq. (11). This idea can be extended to factorial

q(z) =

M i=1

q,i(zi)

as

in

Eq.

(3):

L = q,i q(z \i)
i z \i

di

i i

i

f

(i,

z \i)

=

i

Eq (z \i ),q(i )

q,i q(i)

i

f

(i

,

z

\i

)

.

(12)

At this point there is no relationship between q(i) and q,i(zi), and Eq. (12) is just a higher variance version of Eq. (3). However, if we relax z\i   \i and choose j = g(j; qj) we obtain a biased

estimator

L 

i

Eq( )

i

f

(

)

i i



q,i

,

(13)

where the bias comes from the deviation of  \i from z\i in the function evaluations. In other words, Eq. (13) uses an unbiased form for the differentiated variable i and the only bias comes from relaxing the remaining variables  \i.

The variance of each term is controlled by var q(i)-1 and is reduced by making i(i) more
linear. The bias is reduced by making  closer z. Varying i(i) between linear (low variance) and step function (low bias) allows for a controllable trade-off. We call Eq. (13) the improved continuous relaxation (ICR) estimator. The original CR estimator of Eq. (8) for factorial q has the form

L~[] =

i

Eq( )

i

f

(

)

 

i qi



q,i

,

(14)

and comparing this to the ICR estimate in Eq. (13), we see that CR can be transformed into ICR
by the replacing qi i with i i. This change can be simply implemented using TensorFlow's stop gradient  sg notation by replacing

i(i, qi) with i i + qi - sg(qi), sg(qi)

(15)

4

Under review as a conference paper at ICLR 2019

in Eq. (8). We emphasize that the ICR estimator in Eq. (13) is less biased than the direct CR estimator because, in the case of a single variable, ICR is unbiased while CR is not. Further, this decrease in bias is not accompanied by an increase in variance. We show in Appendix C that similar benefits are obtained for hierarchical q.

3.3 PIECE-WISE LINEAR RELAXATION

Inspired by ICR and a better understanding of variance-bias trade-off, we propose a piece-wise
linear relaxation (PWL) depicted in Fig. 1(b). The linear part is centered at  = 1 - q so that the
corresponding binary variable is obtained by z = round(). The slope is given by  = /[4q(1-q)] similar to the Gumbel-Softmax slope 2. The explicit expression for PWL smoothing is

q() = 0.5 + ( - (1 - q)) 10,

(16)

where [x]01  min (1, max [0, x]) is the hard sigmoid function. This relaxation has several attractive properties. Firstly, we have qi i = i i, which means that the CR and ICR estimators coincide for PWL. Secondly, PWL has easily interpretable expressions for bias and variance. In

the case of a function of a single variable the variance is given by var() =  - 1 while the

bias in computing expectation z f (z) over the relaxed distribution is df (()) - z f (z) =

1 0

dxf

(x)

-

[f

(0)

+

f

(1)]/2

/. This clearly shows that  trades bias for variance.

Thirdly, we provide a qualitative motivation for the slope to have the form   1/[q(1 - q)]. We recall that the gradient in Eq. (13) has the form L  Eq() [ i i f ( )(i i)qi(1 - qi)l,i]. For smooth enough f ( ), the variance of this estimate arises mainly from the variance of i i and the relative size of the terms is controlled by qi(1 - qi). Since the variance of i i is given by var(i i) = i-1, to minimize the variance of the sum, we can choose var(i i)  1/[qi(1-qi)], leading to i  1/[qi(1 - qi)].
Finally, the PWL relaxation defined in Eq. (16) can be considered as the inverse CDF of the PDF:

q() = (1 - ) [(1 - q)() + q( - 1)] + U[0, 1], where = [4q(1 - q)]/. (17)

Eq. (17) is a mixture of two delta distributions centered at zero and one, and a uniform distribution defined in the interval [0, 1]. Samples from q() are in the continuous interval with probability [4q(1 - q)]/, and  = 0/1 have probability proportional to the probability of the binary states.

3.4 CATEGORICAL PIECE-WISE LINEAR RELAXATION

We now extend ICR estimators to categorical variables. For a single categorical variable we apply

the integral representation to each edge (a, b) of the simplex in Eq. (5) and relax this pair of variables

using PWL: y  ya,b = {ya =

0.5 + a,b a,b - qb/(qa + qb)

1 0

,

yb

=

1 - ya, yc=a,b

=

0}

where a,b  U [0, 1] and a,b is the slope. We replace the summation over the edges of the simplex

by sampling one edge at a time with probability pa,b = (qa + qb)/(A - 1). Details are found in

Appendix D and we provide the final result:

L = E(a,b)pa,b EU[0,1] f (y~a,b) ,

(18)

where y~a,b has the same value as ya,b but has the gradient scaled by a,b = (A - 1)(qa + qb).3
The probabilities of edge selection and the scale factor are chosen to give correct values for the
objective and its gradient. Extension of this categorical PWL estimator to multivariate distributions
is straightforward; For example, for factorial distributions one relaxes each categorical variable yi by sampling an edge with probability pai ,b = (qia + qib)(A - 1). The resulting gradient is unbiased for a single variable and introduces a bias in the multivariate case which makes it an ICR estimator.

2More generally, the slope of the linear part  can be chosen arbitrarily as long as   0.5/min(q, 1 - q)
so that both  = 0 and  = 1 have non-zero probability. 3In Tensorflow notation y~a,b  sg(ya,b) + sg(a,b)(ya,b - sg(ya,b)).

5

Under review as a conference paper at ICLR 2019

f( ) q(z = 1)
l

0.30 1.0

0.25 0.8
0.20 0.6 0.15 0.10 0.4
0.05 0.2

0.00 0.0

0.0 0.2 0.4 0.6 0.8 1.0

0

GSM IGSM PWL RAM ARM

500 S1t0e0p0s 1500

2000

(a) Relaxed function

(b) Probability q(z = 1)

0.05 0.04 0.03 0.02 0.01 0.00 0.01 0.02
0.0

GSM IGSM PWL RAM ARM
0.2

0.q4(z = 10).6

0.8

(c) Gradient lL

1.0

Figure 2: Convex, single binary-variable toy example: (a) The relaxed objectivef () = ( - 0.45)2. (b) The probability q(z = 1) during optimization. (c) The gradient lL of all estimators; the bias of GSM prevents proper minimization.

3.5 IMPROVED CATEGORICAL GUMBEL-SOFTMAX ESTIMATOR

The sampling done in the categorical PWL estimator leads to increased variance of the gradients. As an alternative, we suggest an improved version of the categorical Gumbel-Softmax estimator. Recall that the Gumbel-Softmax estimator for the categorical case has the form:

a(; q) = softmax( (log qa + log a)), where a =

log ua b log ub ,

ub



U[0, 1].

(19)

In Eq. (20), we propose a new version of this estimator by applying the same trick as in Eq. (15). This estimator remains biased but we empirically demonstrate that its bias is reduced.

(, q)  ( + q - sg(q), sg(q)).

(20)

4 EXPERIMENTS
In this section we compare the FD and CR estimators and their improved variants on a number of examples. We start with one-variable toy examples that illustrate the bias of GSM estimator and then move to the training of variational auto-encoders and a combinatorial optimization problem.
4.1 TOY EXAMPLE
We begin with an illustrative single-variable example (Tucker et al. (2017)) with objective L = z q(z)f (z) where f (z) = (z - 0.45)2. The relaxed convex function f () depicted in Fig. 2(a)
has two local maxima, one of which is the minimum over the discrete domain. We compare five gradient methods: RAM, Eq. (2); ARM (see Appendix B); PWL, Eq. (16); GSM, Eq. (9); and improved Gumbel-Softmax (IGSM), Eq. (15) (see Appendix E for experimental details). Fig. 2(b) shows the evolution of q(z = 1) during training which demonstrates the bias associated with GSM. To quantify this bias, we plot the value of the gradient of all estimators for different values of q(z = 1) in Fig. 2(c). We observe that the GSM gradient has the wrong sign for a large interval in q(z = 1) which prevents GSM from converging to the true minimum.
To understand the nature of the bias that GSM introduces, we plot the derivatives q and  corresponding to GSM and IGSM respectively in Fig. 1(c). We see that q is biased towards the value of z = round() that has the highest probability. This means that GSM in Eq. (14) will oversample the derivative f () from the most probable mode. In example Fig. 2(a) this results in oversampling the derivative from z = 0 mode which creates a gradient that pushes optimization away from the true minimum z = 0. The bias is reduced as  is increased.
In Appendix H.1 we consider an example for a concave function over a binary variable and observe similar effects. We also consider both concave and convex functions over a categorical variable in Appendix H.2. In all scenarios, the bias of GSM prevents its convergence to the correct minimum.
6

Under review as a conference paper at ICLR 2019

NELBO evaluations(%M)

120 118 116 114 112 110
0

RAM =1 =4
10S00teps(t2h0o00usand3s0)00 4000

100% 80% 60% 40% 20% 0% 0

RAM =1 =4
10S00teps(t2h0o00usand3s0)00 4000

(a) NELBO

(b) Evaluations per sample

Figure 3: NELBO of the RAM and sampled RAM estimators on MNIST trained using the 200H - 784V architecture having a linear decoder: (a) plots the decrease in training NELBO for RAM and two variants of sampled RAM. (b) shows the computational savings of sampled RAM.

4.2 DISCRETE VARIATIONAL AUTOENCODERS

Next, we test the estimators by training variational autoencoders Kingma & Welling (2013) with discrete priors. The objective is the negative expectation lower bound on the log-likelihood (NELBO):

L[, ] =

Ezq(z|x) [f,(z , x)] , where

xdata

f,(z

,

x)

=

-

log

p

(z)p (x|z) q (z |x )

.

(21)

Here, p (z) is the prior, p (x|z) is the decoder, and q(z|x) is the approximating posterior. L is minimized with respect to the  parameters of the generative model and the  parameters of the approximate posterior. The latter minimization corresponds to Eq. (1) and we can apply the various estimators to propagate -derivatives through discrete samples z. For CR estimators we replace z with  to compute L[, ]  xdata E [f,( , x)], where the expectation is evaluated with a single relaxed sample per data point x. The -derivative can be calculated directly from Eq. (21) using the discrete z variables. Thus, the  and  derivatives are evaluated separately requiring two passes through the computation graph with either relaxed or discrete samples. Jang et al. (2016) evaluate both derivatives in one pass (using  ) thereby introducing bias in the  derivatives. We refer to these two possibilities as one/two-pass training and compare their performance.

Following Maddison et al. (2016); Jang et al. (2016); Tucker et al. (2017), we consider four architectures with binary variables denoted by 200H - 784V, 200H - 200H - 784V, 200H  784V, and 200H  200H  784V (see Appendix E for details). First, we compare the sampled RAM estimator of Eq. (7) on 200H - 784V model for different values of , where probability of updating variable zi is pi = 4qi(1 - qi)/. Fig. 3(a) shows the NELBO on the training set. As expected, increased  leads to increased gradient variance which slows training. Fig. 3(b) shows the average
number of function evaluations performed in Eq. (7). Many units become deterministic early in
training leading to significant computational savings with the sampled RAM method.

In Fig. 4(a), we include several CR estimators on the same architecture and observe that the GSM estimator performs significantly worse than other estimators. With linear decoders, the objective function Eq. (21) is convex in zi. Thus, similar to the example in Fig. 2, GSM learns a distribution with higher entropy which leads to poorer performance. The entropy of all estimators during training is shown in Fig. 4(b). We also note that two-pass training performs better then one-pass training for all estimators. Although two-pass training requires twice the computation in the worst case, this overhead is negligible for these models due to GPU parallelization. We observe that ARM performs poorly confirming that its high variance impedes training. The PWL estimator with two-pass training performs on par with RAM, while being more computationally efficient. We used  = 2 in the above experiments, similar to Jang et al. (2016); Maddison et al. (2016). To understand the dependence on , we plot final train NELBO in Fig. 4(c). We find that improved estimators are less sensitive to the choice of .

In Fig. 5, we repeat the experiments for the non-linear architecture 200H  784V. The one-pass GSM estimator exhibits instability which is remedied by two-pass training. However, two-pass GSM still performs worse than IGSM and PWL due to its bias. Interestingly, one-pass training works better for IGSM/PWL. We observe this repeatedly in the nonlinear models. Unlike the linear case, the RAM estimator converges faster initially but later in training is outperformed by the highervariance IGSM, PWL and ARM. It is likely that additional noise prevents the latent units from being turned off early in training which is known to cause poor performance in VAEs. As in the linear case we plot the dependence of the final train NELBO on  in Fig. 5(b). The GSM estimator outperforms

7

Under review as a conference paper at ICLR 2019

NELBO q-entropy
NELBO

120 118 116 114 112 110
0

GSM IGSM PWL RAM ARM
10S00teps(t2h0o00usand3s0)00 4000

(a) train NELBO

120 100 80 60 40 20
00

GSM IGSM PWL RAM ARM
10S00teps(t2h0o00usand3s0)00 4000

(b) Entropy of q(z)

116 GSM

115

IGSM PWL

114

113

112

111

110 2 4 6 8 10

(c) Final train NELBO

Figure 4: MNIST training on the linear architecture 200H - 784V: (a) compares training NELBO of CR estimators (all estimators use  = 2). Solid/dashed lines correspond to one/two-pass training. (b) shows the entropy of the learned posterior approximations; the GSM bias induces much higher entropy. (c) dependence of the final trained NELBO on ; higher  corresponds to lower bias.

NELBO NELBO NELBO

106

GSM 112

GSM 112

GSM

104

IGSM 110 PWL 108

IGSM 110 PWL 108

IGSM PWL

102

RAM ARM

106 104

106 104

100 102 102

100 100 98 98 98

96 96

96 0 10S00teps(t2h0o00usand3s0)00 4000

2 4 6 8 10

2 4 6 8 10

(a) train NELBO

(b) Final train NELBO (c) Final train NELBO, KL anneal 10% of training

Figure 5: MNIST training on the non-linear architecture 200H  784V: (a) compares training NELBO of CR estimators (all estimators use  = 2). Solid/dashed lines correspond to one/two-pass training. (b) Final training NELBO for different , (c) Final training NELBO using KL annealing; explicit annealing erases the gains of GSM.

IGSM and PWL for   4 because its bias favors higher entropy approximating posteriors which inhibit latent units from turning off early in training. A well known resolution for inactive latent units is KL-annealing Bowman et al. (2016). Fig. 5(c) shows that KL annealing indeed improves IGSM and PWL by inhibiting over-pruning of latent units4. As with the linear case, the IGSM and PWL estimators are more stable with respect to the choice of .
Additional results for other VAE models and for categorical variables on both MNIST and OMNIGLOT are presented in Appendix H.3 with similar conclusions. Interested reader is referred to Appendix F for experimental results on training encoder part of a VAE with pretrained generative model. Appendix G compares estimators for solving the discrete maximum clique optimization problem analyzed in Patish & Ullman (2018).
5 CONCLUSION
We have reviewed several finite-difference (FD) and continuous relaxation (CR) estimators of the gradients of the objective Eq. (1). FD estimators like RAM Tokui & Sato (2017) can give unbiased low variance estimates but often require multiple function evaluations. We proposed a less expensive version of RAM estimator that requires order of magnitude fewer function evaluations with a controllable decrease in performance. On the other hand, CR estimators, like Gumbel-Softmax (GSM), require a single pass through the objective function and can be computed efficiently giving low variance but biased gradients. We analyzed the nature of the bias introduced by CR estimators and proposed a way to reduce it. This gives rise to improved CR (ICR) estimators, like improved GSM and piece-wise linear. These ICR estimators are unbiased for a single variable and less biased for many variables. Experiments on VAE training and discrete optimization confirm the theoretical predictions and illustrate the advantage of less-biased estimators.
4In other experiments, not reported here, we observe that the entropy regularizing benefits of the GSM bias can be achieved with explicit entropy regularization of the objective.
8

Under review as a conference paper at ICLR 2019
REFERENCES
Yoshua Bengio, Nicholas Le´onard, and Aaron Courville. Estimating or propagating gradients through stochastic neurons for conditional computation. arXiv preprint arXiv:1308.3432, 2013.
Samuel R Bowman, Luke Vilnis, Oriol Vinyals, Andrew Dai, Rafal Jozefowicz, and Samy Bengio. Generating sentences from a continuous space. In Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning, pp. 10­21, 2016.
Peter W Glynn. Likelihood ratio gradient estimation for stochastic systems. Communications of the ACM, 33(10):75­84, 1990.
Will Grathwohl, Dami Choi, Yuhuai Wu, Geoff Roeder, and David Duvenaud. Backpropagation through the void: Optimizing control variates for black-box gradient estimation. arXiv preprint arXiv:1711.00123, 2017.
Karol Gregor, Ivo Danihelka, Andriy Mnih, Charles Blundell, and Daan Wierstra. Deep autoregressive networks. arXiv preprint arXiv:1310.8499, 2013.
Shixiang Gu, Sergey Levine, Ilya Sutskever, and Andriy Mnih. Muprop: Unbiased backpropagation for stochastic neural networks. arXiv preprint arXiv:1511.05176, 2015.
Eric Jang, Shixiang Gu, and Ben Poole. Categorical reparameterization with Gumbel-Softmax. arXiv preprint arXiv:1611.01144, 2016.
David S Johnson and Michael A Trick. Cliques, coloring, and satisfiability: second DIMACS implementation challenge, October 11-13, 1993, volume 26. American Mathematical Soc., 1996.
Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.
Guy Lorberbom, Andreea Gane, Tommi Jaakkola, and Tamir Hazan. Direct optimization through arg max for discrete variational auto-encoder. arXiv preprint arXiv:1806.02867, 2018.
Chris J Maddison, Andriy Mnih, and Yee Whye Teh. The concrete distribution: A continuous relaxation of discrete random variables. arXiv preprint arXiv:1611.00712, 2016.
Andriy Mnih and Karol Gregor. Neural variational inference and learning in belief networks. arXiv preprint arXiv:1402.0030, 2014.
Andriy Mnih and Danilo Rezende. Variational inference for Monte Carlo objectives. In International Conference on Machine Learning, pp. 2188­2196, 2016.
Uri Patish and Shimon Ullman. Cakewalk sampling. arXiv preprint arXiv:1802.09030, 2018.
Tapani Raiko, Mathias Berglund, Guillaume Alain, and Laurent Dinh. Techniques for learning binary stochastic feedforward neural networks. arXiv preprint arXiv:1406.2989, 2014.
Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate inference in deep generative models. In International Conference on Machine Learning, pp. 1278­1286, 2014.
Jason Tyler Rolfe. Discrete variational autoencoders. arXiv preprint arXiv:1609.02200, 2016.
John Schulman, Nicolas Heess, Theophane Weber, and Pieter Abbeel. Gradient estimation using stochastic computation graphs. In Advances in Neural Information Processing Systems, pp. 3528­ 3536, 2015.
Michalis Titsias and Miguel La´zaro-Gredilla. Local expectation gradients for black box variational inference. In Advances in neural information processing systems, pp. 2638­2646, 2015.
Seiya Tokui and Issei Sato. Evaluating the variance of likelihood-ratio gradient estimators. In International Conference on Machine Learning, pp. 3414­3423, 2017.
9

Under review as a conference paper at ICLR 2019 George Tucker, Andriy Mnih, Chris J Maddison, John Lawson, and Jascha Sohl-Dickstein. Rebar:
Low-variance, unbiased gradient estimates for discrete latent variable models. In Advances in Neural Information Processing Systems, pp. 2624­2633, 2017. Arash Vahdat, Evgeny Andriyash, and William G Macready. DVAE#: Discrete variational autoencoders with relaxed Boltzmann priors. In Neural Information Processing Systems (NIPS), 2018a. Arash Vahdat, William G. Macready, Zhengbing Bian, Amir Khoshaman, and Evgeny Andriyash. DVAE++: Discrete variational autoencoders with overlapping transformations. In International Conference on Machine Learning (ICML), 2018b. Ronald J Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. In Reinforcement Learning, pp. 5­32. Springer, 1992. Mingzhang Yin and Mingyuan Zhou. Arm: Augment-reinforce-merge gradient for discrete latent variable models. arXiv preprint arXiv:1807.11143, 2018.
10

Under review as a conference paper at ICLR 2019

A ARGMAX

Lorberbom et al. (2018) proposed a FD estimator that we refer to as ARGMAX. For a single variable,

ARGMAX relies on an identity that approximates L = q[f (1) - f (0)] = (l)q[1 - q][f (1) - f (0)]. With q = (l), Lorberbom et al. (2018) show that

(l)[1

-

(l)][f (1)

-

f (0)]

=

lim
0

E



f (1) + l + -1() - 

f (0) + l + -1()

(22) where  is the Heaviside step function and   U[0, 1].5 Lorberbom et al. (2018) approximate the

right side of Eq. (22) by sampling  and evaluating at finite which introduces bias and variance.

Decreasing decreases bias but increases variance.

In the categorical case the gradient of Eq. (5) can correspondingly be written as

L =

la

lim
0

1

E

a

a = arg max( f b + lb + b) - a = arg max(lb + b)
bb

,

(23)

where b = - log(- log(b)) are Gumbel variables and [pred] is the indicator function (1 if pred is true and 0 otherwise). This derivative requires A function evaluations, similar to RAM. Lorberbom

et al. (2018) extend the single variable result to multivariate distributions similar to Eqs. (3) and

(4). ARGMAX has the same computational complexity as RAM, but is biased and has higher

variance than RAM. Thus, it is suboptimal to Eqs. (3) and (4) and for this reason we do not perform

experiments with ARGMAX.

B THE AUGMENT-REINFORCE-MERGE ESTIMATOR

FD estimators are computationally expensive and require multiple function evaluations per gradient. A notable exception is the Augment-REINFORCE-Merge (ARM) estimator introduced in Yin & Zhou (2018). ARM provides an unbiased estimate using only two function evaluations for the factorized multivariate distribution, regardless of the number of variables. For a single binary variable, the ARM derivative is given by

L = l q(1 - q)(f (1) - f (0)) = l EU[0,1][(f (z(2)) - f (z(1)))( - 0.5)],

z(1) = (q - ) z(2) = ( - 1 + q).

(24)

The expectation is approximated with a single sample . This estimator has a significantly lower variance than REINFORCE since the expectation contains the difference f (z(2)) - f (z(1)) rather then the function itself. For multivariate f and factorial q(z) the derivative is

L =

l,i

EU[0,1][(f (zi(2),

z (/1i))

-

f

(zi(1)

,

z

(1) /i

))(i

-

0.5)],

i

(25)

where zi(1) = (q,i - i) and zi(2) = (i - 1 + q,i). Yin & Zhou (2018) observed that one can replace f (zi(2), z/(1i))  f (zi(2), z(/2i)) without changing the expectation which allows evaluation by
a single sample and two function evaluations f (z(1)), f (z(2)) regardless of M :

L = l,i EU[0,1][(f (z (2)) - f (z (1)))(i - 0.5)].

(26)

i

However, this change comes at the cost of higher variance of the expectation6. Thus, while ARM

estimator provides a low-variance gradient estimate for a single variable, it introduces high variance

5We motivate this identity by noting that the non-zero contribution comes from the region (- f (1) - l)    (- f (0) - l) assuming f (1) > f (0). For small , samples land within this region with probability p  (l)(1 - (l)) [f (1) - f (0)] giving rise to the identity. The variance of Eq. (22) is Var Ber(p) / 2  (l)(1 - (l))[f (1) - f (0)]/ to leading order in 1/ .
6Denoting g(a)(z/i) = f (zi(a), z/i), a = 1, 2, we can write

VARz/i [g(2)(z /i) - g(1)(z /i)] = VARz/i [g(2)(z /i)] + VARz/i [g(1)(z /i)] - 2COVz/i [g(1)(z /i), g(2)(z /i)],

VARz/i,z/i [g(2)(z /i) - g(1)(z /i)] = VARz/i [g(2)(z /i)] + VARz/i [g(1)(z /i)].

(27)

If the functions g(a)(z/i) are highly correlated the ARM estimator will have a much higher variance than RAM.

11

Under review as a conference paper at ICLR 2019

for multivariate functions compared to RAM. The ARM estimator has straightforward extensions to hierarchical q(z) (similar to Eq. (4)) and to categorical variables Yin & Zhou (2018).

C IMPROVED CR ESTIMATOR FOR BAYESIAN NETWORKS
In this appendix we derive the improved CR estimator for a hierarchical q(z) = i q,i(zi|z<i). For simplicity, we do this for two variables q(z1, z2) = q,2(z2|z1)q,1(z1) with the gradient given in Eq. (4):

L = q,1

q,2(z2|1)f (1, z2) - q,2(z2|0)f (0, z2)

z2 z2

+ q,1(z1)q,2(1|z1) [f (z1, 1) - f (z1, 0)]
z1

where q,1 = q,1(z1 = 1). We denote the two contributions to L by L(1,2) and determine them separately. Using the integral trick (10) the second contribution can be written as

L(2) = q,1(z1)q,2(1|z1)
z1

d1

2 2

2

f

(z1,

2)



E



q,2

(1|1

)

2 2

2

f

(1

,

2

)

(28)

where 2 = g(2; q2(1|1)) and 1 = g(1; q1). The first term can be handled similarly:

L(1) = q,1

d1

1 1

1

q,2(z2|1)f (1, z2)
z2

 E



q,1

1 1

1

f

(1

,

2

)

(29)

Combining these contributions we arrive at an expression very similar to the reparameterization trick

with the replacement qi i  i i:

L  E [f (1, 2)]qi ii i

(30)

D CATEGORICAL PWL ESTIMATOR

Here, we derive the PWL estimator for categorical variables. The derivative for a single categorical variable y = (y0, ...yA-1) with ya  {0, 1} and a ya = 1 is given in Eq. (5) as

L =  q(y)f (y) = la qaqb(f a - f b),
y ab

(31)

We again apply the integral trick (10) to represent the difference f a - f b. To do that we relax the

variable y so that it interpolates between (ya, yb) = (1, 0) and (ya, yb) = (0, 1) as y  ya,b =

ya =

0.5 + a,b(a,b

- qb/(qa + qb))

1 0

,

yb

=

1 - ya, yc=a,b

=

0

where a,b  U [0, 1] and

a,b is the slope. The relaxed objective then takes the form

1
L=

da,b

wa,bf (ya,b),

0 a<b

a<b

(32)

where wa,b are weights to be determined. The gradient of this relaxed objective with respect to the logit la is



la L = E 

wa,ba,b f

(ya,b)

qaqb (qa + qb)2



=

wa,b

qaqb (qa + qb)2

(f

a

-

f

b).

b=a

b=a

(33)

Comparison with Eq. (31) gives wa,b = (qa + qb)2. However, computing the sum over the edges of
the simplex is prohibitively expensive, so we choose to replace it with sampling from the set of edges with probability pa,b = (qa + qb)/( a<b qa + qb) = (qa + qb)/(A - 1). The reason for choosing this distribution is that Eq. (32) must give correct value of the objective (not just the derivative) as

12

Under review as a conference paper at ICLR 2019

NELBO NELBO

120 GSM 118 IGSM
PWL 116 RAM
ARM
114

112

110

0

50Steps(t1h0o0usands15)0

200

(a) 200H - 784V

114 112 110 108 106 104 102 100 98 0

GSM IGSM PWL RAM ARM

20S0teps(th40o0usands6)00

800

(b) 200H  784V

Figure 6: Encoder training the with fixed pre-trained decoder on MNIST: (a) the linear architecture. (b) the non-linear architecture.

the relaxation parameter   , which requires the probability of each state ya = 1 to be equal to qa. For relaxed edge (a, b) the probability of ya = 1 is equal to qa/(qa + qb), and thus the total probability of ya = 1 is:

pa,b

qa

qa +

qb

=

qa + qb A-1

qa qa + qb

=

qa.

b=a

b=a

(34)

Finally, to get the correct weights wa,b we must rescale each term by a factor a,b = (A-1)(qa +qb) so that wa,b = a,bpa,b. In summary, the relaxed objective has the following form:

L = E(a,b)pa,b EU[0,1] f (y~a,b) ,

(35)

where y~a,b has the same value as ya,b but has the gradient scaled by a,b = (A - 1)(qa + qb).

E EXPERIMENTAL DETAILS
For the toy example of Section 4.1 we optimize L with respect to q(z = 1) using Adam (Kingma & Ba (2014)) for 2000 iterations with learning rate r = 0.01 using minibatches of size 100 to reduce the variance of gradients. We initialize q(z = 1) to the wrong maximum of the relaxed function by setting q(z = 1) = (5).
For VAE training experiments, following Maddison et al. (2016); Jang et al. (2016); Tucker et al. (2017), we consider four architectures with binary variables denoted by 200H - 784V, 200H - 200H - 784V, 200H  784V, and 200H  200H  784V. Here - denotes a linear layer, while  denotes two layers of 200 hidden units with tanh nonlinearity and batch normalization. In our experiments we use the Adam optimizer with default parameters and a fixed learning rate 0.0003, run for 4 · 106 steps with minibatches of size 100. We repeat each experiment 5 times with random seed and plot the mean.

F VAE ENCODER TRAINING
During training of VAEs, the encoder and decoder models interact in complex ways. To eliminate these effects to more directly identify the impact of better gradients, we use a fixed pre-trained decoder, and minimize Eq. (21) with respect to encoder parameters  only. As shown in Fig. 6, the conclusions from joint training remain unchanged: GSM underperforms due to its bias. Interestingly however, RAM still overfits early in training for the 200H  784V model, showing that better gradients can negatively affect optimization.

G OPTIMIZATION
We apply gradient estimators for discrete optimization. Following Patish & Ullman (2018) we study the NP-hard task of finding a maximal clique in a graph. To model this problem, the binary variable zi = 1/0 indicates the presence/absence of vertex i in a maximal clique. If Ai,j is the adjacency

13

Under review as a conference paper at ICLR 2019

clique size clique size clique size

70 70 70

60 60 60

50 GSM 50

50

40 IGSM 40

40

30 20

PWL Ground Truth

30 20

GSM 30 IGSM 20

GSM IGSM

10 0

10 0

PWL Ground Truth

10 0

PWL Ground Truth

0

100Steps(h2u00ndreds3)00

400

0

100Steps(h2u00ndreds3)00

400

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

(a)  = 0.1

(b)  = 0.9

(c) Final max clique size

Figure 7: Finding maximal cliques in the C1000.9 graph: (a) and (b) show the course of optimization for two settings of  and different gradient estimators. (c) plots the final maximal clique size across  for the estimators.

matrix of the graph and d = i zi is the size of the clique, then the objective function considered in Patish & Ullman (2018) is

f

(z)

=

-

ij ziAij zj d(d - 1 + )

,

(36)

where   [0, 1] is a hyperparameter. Patish & Ullman (2018) use factorial q(z) to minimize L[] = z q(z)f (z). At the end of optimization q(z) typically collapses to a single state corresponding to a clique. Most often this clique is a local minimum and not the maximal clique.
We illustrate the performance of CR estimators on a particular graph (1000 nodes, 450000 edges), labeled C1000.9 from the DIMACS data set Johnson & Trick (1996). We minimize f (z) using Adam with default settings, learning rate 0.01 for 40000 iterations. We perform 1000 minimizations in parallel and choose the best clique found at each iteration. Fig. 7(a),(b) show the size of clique found by each of the estimators for two values of the hyperparameter  = 0.1, 0.9. At  = 0.1 the bias of GSM causes trapping in the wrong minima but ICR converges to a good local minimum. In contrast, at  = 0.9 the GSM bias accelerates convergence to a good local minimum. Fig. 7(c) shows the dependence of the final clique size on ; unbiased estimators provide more stable results.

H ADDITIONAL EXPERIMENTS
H.1 BINARY CONCAVE TOY EXAMPLE
We evaluate performance on the concave function f () = -( - 0.45)2 shown in Fig. 8(a). The training setup is identical to Section 4.1 but with q(z = 1) initialized to (-5). Fig. 8(b) demonstrates that the GSM optimization gets trapped in the wrong minimum due to its bias towards the dominant mode  = 0.

f( ) q(z = 1)

0.00 0.05 0.10 0.15 0.20 0.25 0.30
0.0 0.2 0.4 0.6 0.8 1.0
(a) Concave relaxed function

1.0

0.8 GSM 0.6 IGSM
PWL 0.4 RAM
ARM
0.2

0.0 0

500 S1t0e0p0s 1500

2000

(b) Probability q(z = 1)

Figure 8: Single binary variable concave toy example. (a) Relaxed function f () = -( - 0.45)2 (b) Probability q(z = 1) during optimization

14

Under review as a conference paper at ICLR 2019

H.2 CATEGORICAL TOY EXAMPLE
We consider a categorical example with convex and concave functions of a single categorical variable y having 10 values. We take f (y) = ± a(ga - ya)2 such that g0 = 0.9, g1 = 1.1, and gi>1 = 1. The convex function has a minimum at y1 = 1, while the concave function is minimized at y0 = 1. We compare 4 estimators for minimizing this function: RAM of Eq. (5), PWL of Eq. (18), GSM of Eq. (19) and IGSM of Eq. (20). The probability of the true minimum is shown in Fig. 9. In both the convex and concave cases the GSM estimator exhibits a bias preventing it from finding the minimum. IGSM is less biased than GSM which allows it to find the true minimum. The PWL estimator is unbiased but has higher variance then IGSM which slows down its optimization.

q(y0 = 1) q(y1 = 1)

1.0

0.8

0.6

GSM IGSM

0.4

PWL RAM

0.2

0.0 0

500 S1t0e0p0s 1500

2000

(a) Concave function

1.0

0.8 GSM

0.6

IGSM PWL

0.4 RAM

0.2

0.0 0

500 S1t0e0p0s 1500

2000

(b) Convex function

Figure 9: The probability of the true minimum for a single categorical-variable toy example with (a) concave function f (y) = - a(ga - ya)2 and (b) convex function f (y) = a(ga - ya)2

H.3 DISCRETE VARIATIONAL AUTOENCODERS
Fig. 10 shows the results for all 4 architectures 200H-784V, 200H-200H-784V, 200H  784V, and 200H  200H  784V at  = 2. Hierarchical models with two layers of latent units in Fig. 10(b),(d) exhibit similar trends to the factorial case considered in the main text. The GSM estimator converges to a higher NELBO in the linear case and becomes unstable in the non-linear case.

NELBO

120 118 116 114 112 110
0

GSM IGSM PWL RAM ARM
10S00teps(t2h0o00usand3s0)00 4000

(a) 200H - 784V

106

GSM

104

IGSM PWL

102

RAM ARM

100

98

96 0 10S00teps(t2h0o00usand3s0)00 4000

(c) 200H  784V

NELBO

NELBO

114 112 110 108 106 104 102 100 98
0

GSM IGSM PWL 10S00teps(t2h0o00usand3s0)00 4000

(b) 200H - 200H - 784V

106

104

GSM IGSM

102 PWL

100

98

96

94

92 0 10S00teps(t2h0o00usand3s0)00 4000

(d) 200H  200H  784V

NELBO

Figure 10: MNIST training (CR estimators use  = 2). Solid/dashed lines correspond to one/twopass training.

We also compare the performance of GSM and IGSM estimators in the categorical case 20 × 10H - 784V with latent space being 20 categorical variables with 10 classes Fig. 11. We see that IGSM

15

Under review as a conference paper at ICLR 2019

outperforms GSM estimator when using two-pass training. This indirectly confirms that IGSM is less biased. The PWL estimator performs best indicating the advantages ICR estimators.

NELBO

116 114 112 110 108 106 104 0

GSM IGSM PWL RAM

10S00teps(t2h0o00usand3s0)00
(a)

4000

Figure 11: MNIST training on categorical linear architecture 20 × 10H - 784V (CR estimators use  = 2). Solid/dashed lines correspond to one/two-pass training.

For completeness we also show the training curves for OMNIGLOT dataset at  = 2 in Fig 12. Interestingly, one-pass training performs better in all cases. PWL estimator performs best among considered CR estimators.

NELBO

134 132 130 128 126 124 122 120 118 0

GSM IGSM PWL RAM ARM
10S00teps(t2h0o00usand3s0)00 4000

(a) 200H - 784V

122 GSM

120

IGSM PWL

118

RAM ARM

116

114

112 0

10S00teps(t2h0o00usand3s0)00 4000

(c) 200H  784V

NELBO

NELBO

128 126 124 122 120 118 116 114 112 0

GSM IGSM PWL 10S00teps(t2h0o00usand3s0)00 4000

(b) 200H - 200H - 784V
122 GSM 120 IGSM
PWL
118

116

114

112 0

10S00teps(t2h0o00usand3s0)00 4000

(d) 200H  200H  784V

NELBO

Figure 12: OMNIGLOT training (CR estimators use  = 2). Solid/dashed lines correspond to one/two-pass training.

16

