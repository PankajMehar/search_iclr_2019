Under review as a conference paper at ICLR 2019
MULTI-TURN DIALOGUE RESPONSE GENERATION IN AN ADVERSARIAL LEARNING FRAMEWORK
Anonymous authors Paper under double-blind review
ABSTRACT
We propose an adversarial learning approach to the generation of multi-turn dialogue responses. Our proposed framework, hredGAN, is based on conditional generative adversarial networks (GANs). The GAN's generator is a modified hierarchical recurrent encoder-decoder network (HRED) and the discriminator is a word-level bidirectional RNN that shares context and word embedding with the generator. During inference, noise samples conditioned on the dialogue history are used to perturb the generator's latent space to generate several possible responses. The final response is the one ranked best by the discriminator. The hredGAN shows major advantages over existing methods: (1) it generalizes better than networks trained using only the log-likelihood criterion, and (2) it generates longer, more informative and more diverse responses with high utterance and topic relevance even with limited training data. This superiority is demonstrated on the Movie triples and Ubuntu dialogue datasets in terms of perplexity, BLEU, ROUGE and Distinct n-gram scores.
1 INTRODUCTION
Recent advances in deep neural network architectures have enabled tremendous success on a number of difficult machine learning problems. While these results are impressive, producing a deployable neural network­based conversation model that can engage in open domain discussion still remains elusive. A dialogue system needs to be able to generate meaningful and diverse responses that are simultaneously coherent with the input utterance and the overall dialogue topic. Unfortunately, earlier conversation models trained with naturalistic dialogue data suffered greatly from limited contextual information (Sutskever et al., 2014; Vinyals & Le, 2015), and lack diversity (Li et al., 2016a). These problems often leads to generic and safe utterance in response to varieties of input utterance.
Serban et al. (2016) and Xing et al. (2017) proposed the Hierarchical Recurrent Encoder-Decoder (HRED) network to capture long temporal dependencies in multi-turn conversations to address the limited contextual information but the diversity problem remained. On the other hand, some HRED variants such as variational (Serban et al., 2017b) and multi-resolution (Serban et al., 2017a) HREDs attempt to alleviate the diversity problem by injecting noise at the utterance level and by extracting additional context to condition the generator on. While these approaches achieve certain measures of success over the basic HRED, generated responses are still mostly generic since they do not control the generator's output as the output conditional distribution is not calibrated. Li et al. (2016a), on the other hand, consider diversity promoting training objective but their model is for single turn conversations, cannot not be trained end-to-end and therefore achieves little.
The generative adversarial network (GAN) (Goodfellow et al., 2014) seems to be an appropriate solution to the diversity problem. GAN matches data from two different distributions by introducing an adversarial game between a generator and a discriminator. We explore hredGAN: conditional GANs for multi-turn dialogue models with HRED generator and discriminator. hredGAN combines both generative and retrieval-based multi-turn dialogue systems to improve their individual performances. This is achieved by sharing the context and word embedding between the generator and the discriminator allowing for joint end-to-end training using back-propagation. To the best of our knowledge, no existing work has applied conditional GANs to multi-turn dialogue models and es-
1

Under review as a conference paper at ICLR 2019

pecially with HRED generators and discriminators. We demonstrate the effectiveness of hredGAN for dialogue modeling with evaluations on the Movie triples and Ubuntu technical support datasets.

2 ADVERSARIAL FRAMEWORK FOR MULTI-TURN DIALOGUE

Consider a dialogue consisting of a sequence of N utterances, X = X1, X2, · · · , XN , where
each utterance Xi = Xi1, Xi2, · · · , XiMi contains a variable-length sequence of Mi word tokens such that Xij  V for vocabulary V . At any time step i, the dialogue history is given by Xi = X1, X2, · · · , Xi . The dialogue response generation task can be defined as follows: Given a
dialogue history Xi, generate a response Yi = Yi1, Yi2, · · · , YiTi , where Ti is the number of generated tokens. We also want the distribution of the generated response P (Yi) to be indistinguishable from that of the ground truth P (Xi+1) and Ti = Mi+1. Conditional GAN learns a mapping from an observed dialogue history, Xi, and a sequence of random noise vectors, Zi to a sequence of output tokens, Yi, G : {Xi, Zi}  Yi. The generator G is trained to produce output sequences that cannot be distinguished from the ground truth sequence by an adversarially trained discriminator D that is
trained to do well at detecting generator's fakes. The distribution of the generator output sequence
can be factored by the product rule:

Ti
P (Yi|Xi) = P (Yi1) P Yij |Yi1, · · · , Yij-1, Xi
j=2

(1)

P Yij |Yi1, · · · , Yij-1, Xi = PG Yi1:j-1, Xi

(2)

where Yii:j-1 = (Yi1, · · · , Yij-1) and G are the parameters of the generator model. PG Yii:j-1, Xi is an autoregressive generative model where the probability of the current token depends on the past generated sequence. Training the generator G with the log-likelihood criterion is unstable in practice, and therefore the past generated sequence is substituted with the ground truth, a method known as teacher forcing (Williams & Zipser, 1989), i.e.,

P Yij |Yi1, · · · , Yij-1, Xi  PG Xi1+:j1-1, Xi

(3)

Using equation 3 in relation to GAN, we define our fake sample as the teacher forcing output with

some input noise Zi

Yij  PG Xi1+:j1-1, Xi, Zi

(4)

and the corresponding real sample as ground truth Xij+1.

With the GAN objective, we can match the noise distribution, P (Zi) to the distribution of the ground truth response, P (Xi+1|Xi). Varying the noise input then allows us to generate diverse responses to the same dialogue history. Furthermore, the discriminator, since it is calibrated, is used during
inference to rank the generated responses, providing a means of controlling the generator output.

2.1 OBJECTIVES

The objective of a conditional GAN can be expressed as

LcGAN (G, D) = EXi,Xi+1 [log D(Xi+1, Xi)] + EXi,Zi [1 - log D(G(Xi, Zi), Xi)] (5)

where G tries to minimize this objective against an adversarial D that tries to maximize it:

G, D = arg min max LcGAN (G, D).
GD

(6)

Previous approaches have shown that it is beneficial to mix the GAN objective with a more traditional loss such as cross-entropy loss (Lamb et al., 2016; Li et al., 2017). The discriminator's job remains unchanged, but the generator is tasked not only to fool the discriminator but also to be near the ground truth Xi+1 in the cross-entropy sense:

LMLE (G) = EXi,Xi+1,Zi [-log PG Xi+1, Xi, Zi ].

(7)

Our final objective is,

G, D = arg min max GLcGAN (G, D) + M LMLE(G) .
GD

(8)

2

Under review as a conference paper at ICLR 2019

Figure 1: Right: The hredGAN architecture - The generator makes predictions conditioned on the dialogue history, hi, attention, Aij, noise sample, Zij, and ground truth, Xij+-11. Left: RNN-based discriminator that discriminates bidirectionally at the word level.

It is worth mentioning that, without Zi, the net could still learn a mapping from Xi to Yi, but would produce deterministic outputs and fail to match any distribution other than a delta function (Isola et al., 2017). This is one key area where our work is different from Lamb et al.'s and Li et al.'s. The schematic of the proposed hredGAN is depicted at the right hand side of Figure 1.

2.2 GENERATOR

We adopted an HRED dialogue generator similar to (Serban et al., 2016; 2017a;b; Xing et al., 2017).

The HRED contains three recurrent structures, i.e. the encoder (eRN N ), context (cRN N ), and

decoder (dRN N ) RNN. The conditional probability modeled by the HRED per output word token

is given by

PG Yij |Xi1+:j1-1, Xi = dRN N E(Xij+-11), hij-1, hi

(9)

where E(.) is the embedding lookup, hi = cRN N (eRN N (E(Xi), hi-1), eRN N (.) maps a sequence of input symbols into fixed-length vector, and h and h are the hidden states of the decoder
and context RNN, respectively.

In the multi-resolution HRED, (Serban et al., 2017a), high-level tokens are extracted and processed

by another RNN to improve performance. We circumvent the need for this extra processing by

allowing the decoder to attend to different parts of the input utterance during response generation

(Bahdanau et al., 2015; Luong et al., 2015). We introduce a local attention into equation 9 and en-

code the attention memory differently from the context through an attention encoder RNN (aRN N ),

yielding:

PG Yij |Xi1+:j1-1, Xi = dRN N E(Xij+-11), hji -1, Aji , hi

(10)

where Aij =

Mi m=1

h ,exp(m)

m

Mi m=1

exp(m )

i

him

=

aRN N (E(Xim), him-1),

h

is the hidden state of

the attention RNN and k is either a logit projection of (hij-1, him) in the case of Bahdanau et al.

(2015) or (hji-1)T · him in the case of Luong et al. (2015). The modified HRED architecture is

shown in Figure 2.

Noise Injection: We inject Gaussian noise at the input of the decoder RNN. Noise samples could be injected at the utterance or word level. With noise injection, the conditional probability of the decoder output becomes

PG Yij |Xi1+:j1-1, Zij , Xi = dRN N E(Xij+-11), hij-1, Aji , Zij , hi

(11)

where Zij  Ni(0, I), for utterance-level noise and Zij  Nij(0, I)), for word-level noise.

2.3 DISCRIMINATOR
The discriminator shares context and word embedding with the generator and can discriminate at the word level (Lamb et al., 2016). The word-level discrimination is achieved through a bidirectional RNN and is able to capture both syntactic and conceptual differences between the generator output

3

Under review as a conference paper at ICLR 2019

Figure 2: The HRED generator with local attention - The attention RNN ensures local relevance while the context RNN ensures global relevance. Their states are combined to initialize the decoder RNN and the discriminator BiRNN.

and the ground truth. The aggregate classification of an input sequence,  can be factored over word-level discrimination and expressed as

J

1 J

D(Xi, ) = D(hi, ) =

DRNN (hi, E(j ))

j=1

(12)

where DRNN (.) is the word discriminator RNN, hi is an encoded vector of the dialogue history Xi obtained from the generator's cRN N (.) output, and j is the jth word or token of the input sequence .  = Yi and J = Ti for the case of generator's decoder output,  = Xi+1 and J = Mi+1 for the case of ground truth. The discriminator architecture is depicted on the left hand side of Figure 1.

2.4 ADVERSARIAL GENERATION OF MULTI-TURN DIALOGUE RESPONSE

In this section, we describe the generation process during inference. The generation objective can

be mathematically described as

Yi

=

arg

max
l

P (Yi,l|Xi) + D(Xi, Yi,l)]

L l=1

(13)

where Yi,l = G(Xi, Zi,l), Zi,l is the lth noise samples at dialogue step i, and L is the number

of response samples. Equation 13 shows that our inference objective is the same as the training

objective (8), combining both the MLE and adversarial criteria. This is in contrast to existing work

where the discriminator is usually discarded during inference.

The inference described by equation 13 is intractable due to the enormous search space of Yi,l.

Therefore, we turn to an approximate solution where we use greedy decoding (MLE) on the first part

of the objective function to generate L lists of responses based on noise samples {Zi,l}lL=1. In order to facilitate the exploration of the generator's latent space, we sample a modified noise distribution,

Zij,l  Ni,l(0, I), or Zij,l  Nij,l(0, I)) where  > 1.0, is the exploration factor that increases

the noise variance. We then rank the L lists using the discriminator score,

D(Xi, Yi,l)]

L l=1

.

The

response with the highest discriminator ranking is the optimum response for the dialogue context.

3 TRAINING OF HREDGAN
We trained both the generator and the discriminator simultaneously as highlighted in Algorithm 1 with G = M = 1. GAN training is prone to instability due to competition between the generator and the discriminator. Therefore, parameter updates are conditioned on the discriminator performance (Lamb et al., 2016).
The generator consists of four RNNs with different parameters, that is, aRN N, eRN N, cRN N , and dRN N . aRN N and eRN N are both bidirectional, while cRN N and dRN N are unidirec-

4

Under review as a conference paper at ICLR 2019

Algorithm 1 Adversarial Learning of hredGAN

Require: A generator G with parameters G.

Require: A discriminator D with parameters D.

for number of training iterations do

Initialize cRN N to zero state, h0 Sample a mini-batch of conversations, X = {Xi}iN=1, Xi = (X1, X2, · · · , Xi) with N utterances. Each utterance mini batch i contains Mi word tokens.
for i = 1 to N - 1 do

Update the context state.

hi = cRN N (eRN N (E(Xi)), hi-1) Compute the generator output using equation 11.

PG Yi|, Zi, Xi = PG Yij |Xi1+:j1-1, Zij , Xi

Mi+1 j=1

Sample a corresponding mini batch of utterance Yi.

Yi  PG Yi|, Zi, Xi end for

Compute the discriminator accuracy Dacc over N - 1 utterances {Yi}iN=-11 and {Xi+1}iN=-11

if Dacc < accDth then Update D with gradient of the discriminator loss.

[D log D(hi, Xi+1) + D log 1 - D(hi, Yi) ]
i

end if

if Dacc < accGth then Update G with the generator's MLE loss only. [G log PG Yi|, Zi, Xi ]
i
else

Update G with both adversarial and MLE losses. [GG log D(hi, Yi) + M G log PG Yi|, Zi, Xi ]
i

end if

end for

tional. Each RNN has 3 layers, and the hidden state size is 512. The dRN N and aRN N are connected using an additive attention mechanism (Bahdanau et al., 2015).
The discriminator shares aRN N, eRN N , and cRN N with the generator. DRNN , is a stacked bidirectional RNN with 3 layers and a hidden state size of 512. The cRN N states are used to initialize the states of DRNN . The output of both the forward and the backward cells for each word are concatenated and passed to a fully-connected layer with binary output. The output is the probability that the word is from the ground truth given the past and future words of the sequence.
Others: All RNNs used are gated recurrent unit (GRU) cells (Cho et al., 2014). The word embedding size is 512 and shared between the generator and the discriminator. The initial learning rate is 0.5 with decay rate factor of 0.99, applied when the adversarial loss has increased over two iterations. We use a batch size of 64 and clip gradients around 5.0. As in Lamb et al. (2016), we find accDth = 0.99 and accGth = 0.75 to be good enough. All parameters are initialized with Xavier uniform random initialization (Glorot & Bengio, 2010). The vocabulary size V is 50, 000. Due to the large vocabulary size, we use sampled softmax loss (Jean et al., 2015) for MLE loss to expedite the training process. However, we use full softmax for evaluation. The model is trained end-to-end using the stochastic gradient descent algorithm.
4 EXPERIMENTS AND RESULTS
We consider the task of generating dialogue responses conditioned on the dialogue history and the current input utterance. We compare the proposed hredGAN model against some alternatives on publicly available datasets.
4.1 DATASETS
Movie Triples Corpus, (MTC) dataset (Serban et al., 2016). This dataset was derived from the Movie-DiC dataset by Banchs (2012). Although this dataset spans a wide range of topics with few spelling mistakes, its small size of only about 240,000 dialogue triples makes it difficult to train a dialogue model, as pointed out by Serban et al. (2016). We thought that this scenario would really benefit from the proposed adversarial generation.
Ubuntu Dialogue Corpus, (UDC) dataset (Serban et al., 2017b). This dataset was extracted from the Ubuntu Relay Chat Channel. Although the topics in the dataset are not as diverse as in the MTC,
5

Under review as a conference paper at ICLR 2019

the dataset is very large, containing about 1.85 million conversations with an average of 5 utterances per conversation.
We split both MTC and UDC into training, validation, and test sets, using 90%, 5%, and 5% proportions, respectively. We performed minimal preprocessing of the datasets by replacing all words except the top 50,000 most frequent words by an UNK symbol.

4.2 EVALUATION METRICS

Accurate evaluation of dialogue models is still an open challenge. There are no well-established automatic evaluation metrics, and human evaluation is expensive. Nevertheless, we employed some of the automatic evaluation metrics that are used in probabilistic language and dialogue models, and statistical machine translation. Although these metrics may not correlate well with human judgment of dialogue responses (Liu et al., 2016), they provide a good baseline for comparing dialogue model performance.

Perplexity - For a model with parameter , we define perplexity as:

exp

-

1 NW

K
log P(Y1, Y2, . . . , YNk-1)
k=1

(14)

where K is the number of conversations in the dataset, Nk is the number of utterances in conversa-

tion k, and NW is the total number of word tokens in the entire dataset. The lower the perplexity,

the better. The perplexity measures the likelihood of generating the ground truth given the model

parameters. While a generative model can generate a diversity of responses, it should still assign a

high probability to the ground truth utterance.

BLEU - The BLEU score, (Papineni et al., 2002) provides a measure of overlap between the generated response (candidate) and the ground truth (reference) using a modified n-gram precision. According to Liu et. al. (Liu et al., 2016), BLEU-2 score is fairly correlated with human judgment for non-technical dialogue (such as MTC).

ROUGE - The ROUGE score, (Lin, 2014) is similar to BLEU but it is recall oriented instead. It is used for automatic evaluation of text summarization and machine translation. To compliment the BLEU score, we use ROUGE-N with N = 2 for our evaluation.

Distinct n-gram - This is the fraction of unique n-grams in the generated responses. It provides a measure of diversity. Models with higher number of distinct n-grams tend to produce more diverse responses (Li et al., 2016a). For our evaluation, we use 1- and 2- grams.

Normalized Average Sequence Length (NASL) - This measures the average number of words in model generated responses normalized by the average number of words in the groundtruth.

4.3 BASELINE
We compare the performance of our model to (V)HRED (Serban et al., 2016; 2017b), since they are the closest to our approach in implementation and are the current state of the art in open-domain dialogue models. HRED is very similar to our proposed generator, but without the input utterance attention and noise samples. VHRED introduces a latent variable to the HRED between the cRN N and the dRN N and was trained using the variational lower bound on the log-likelihood. The VHRED can generate multiple responses per context like hredGAN, but has no specific criteria for selecting the best response.
The HRED and VHRED models are both trained using the Theano-based implementation obtained from https://github.com/julianser/hed-dlg-truncated. The training and validation sets used for UDC and MTC dataset were obtained directly from the authors1 of (V)HRED. For model comparison, we use a test set that is disjoint from the training and validation sets.

1UDC was obtained from http://www.iulianserban.com/Files/ UbuntuDialogueCorpus.zip, and the link to MTC was obtained privately.
6

Under review as a conference paper at ICLR 2019

Table 1: Generation and Discrimination Per- Table 2: Autoregressive Inference Performance

formance

Model

BLEU-2 ROUGE-2 DISTINCT-1/2 NASL

Model

Perplexity -log D(G(.)) MTC

MTC

HRED

0.0474 0.0384 0.0026/0.0056 0.535

HRED

31.92/36.00 NA

VHRED 0.0606 0.1181 0.0048/0.0163 0.831

VHRED 42.61/44.97 NA

hredGAN u 0.0493 0.2416 0.0167/0.1306 0.884

hredGAN u 23.57/23.54 6.85/6.81

hredGAN w 0.0613 0.3244 0.0179/0.1720 1.540

hredGAN w 24.20/24.14 13.35/13.40

UDC

UDC

HRED

0.0177 0.0483 0.0203/0.0466 0.892

HRED

69.39/86.40 NA

VHRED 0.0171 0.0855 0.0297/0.0890 0.873

VHRED 98.50/105.20 NA

hredGAN u 0.0137 0.0716 0.0260/0.0847 1.379

hredGAN u 56.82/57.32 10.09/10.08

hredGAN w 0.0216 0.1168 0.0516/0.1821 1.098

hredGAN w 47.73/48.18 8.37/8.36

4.4 RESULTS
We have two variants of hredGAN based on the noise injection approach, i.e., hredGAN with utterance-level (hredGAN u) and word-level (hredGAN w) noise injections.
We compare the performance of these two variants with HRED and VHRED models.
Perplexity: The average perplexity per word performance of all the four models on MTC and UDC datasets (validation/test) are reported in the first column on Table 1. The table indicates that both variants of the hredGAN model perform better than the HRED and VHRED models in terms of the perplexity measure. However, using the adversarial loss criterion (Eq. equation 8), the hredGAN u model performs better on MTC and worse on UDC. Note that, for this experiment, we run all models in teacher forcing mode.
Generation Hyperparameter: For adversarial generation, we perform a linear search for  between 1 and 20 at an increment of 1 using Eq. equation 13, with sample size L = 64, on validation sets with models run in autoregression. The optimum values of  for hredGAN u and hredGAN w for UDC are 7.0 and 9.0 respectively. The values for MTC are not convex, probably due to small size of the dataset, so we use the same  values as UDC. We however note that for both datasets, any integer value between 3 and 10 (inclusive) works well in practice.
Quantitative Generator Performance: We run autoregressive inference for all the models (using optimum  values for hredGAN models and selecting the best of L = 64 responses using a discriminator) with dialogue contexts from a unique test set. Also, we compute the average BLEU-2, ROUGE-2(f1), Distinct(1/2) and normalized average sequence length (NASL) scores for each model and summarize the results in Table 2. Distinct(1/2) largely agrees with the perplexity score. Most scores, similar to the perplexity, indicate that hredGAN models perform better than (V)HRED on both datasets. However, on the UDC and MTC, ROUGE and BLUE, respectively scores VHRED slightly better than hredGAN u but still worse than hredGAN w.
A good dialogue model should find the right balance between precision (BLEU) and diversity. We strongly believe that our adversarial approach is better suited to solving this problem. As hredGAN generators explore diversity, the discriminator ranking gives hredGAN an edge over (V)HRED because it helps detect responses that are out of context and the natural language structure (Table 3). Also, the ROGUE(f1) performance indicates that hredGAN w strikes a better balance between precision (BLEU) and diversity than the rest of the models. This is also obvious from the quality of generated responses.
Qualitative Generator Performance: In addition to the quantitative analysis of the performance, looking at the actual samples from the generator outputs in Table 6 shows that hredGAN especially hredGAN w performs better than (V)HRED. While other models produce short and generic utterances, hredGAN w mostly yields informative responses. For example, in the first dialogue in Table 6, when the speaker is sarcastic about "the man upstairs", hredGAN w responds with the most coherent utterance with respect to the dialogue history. We see similar behavior across other samples. We also note that although hredGAN u's responses are the longest on Ubuntu (in line with the NASL score), the responses are less informative compared to hredGAN w. We reckon this might be due to a mismatch between utterance-level noise and word-level discrimination or lack of capacity to
7

Under review as a conference paper at ICLR 2019

Table 3: Example of Discriminator Ranking Table 4: Sample responses of HRED, VHRED

with hredGAN w

and hredGAN.

Item D(G(.)) Utterance

MTC Context 0 NA
Context 1 NA
Response 0 0.996
Response 1 0.991
Response 2 0.315 Response 3 0.203

perhaps <person> had a word with the man upstairs . a word ? i ' m sure by now he ' s engineered a hostile takeover . <person> , i know what you ' re saying , <person> , that ' s not what i ' m saying . <person> , i know . i was just about to help the guy . <person> , i ' m sorry . <person> , i ' m a little out .

Context 0 NA
Context 1 NA
Response 0 0.998
Response 1 0.981
Response 2 0.690 Response 3 0.314 UDC Context 0 NA
Context 1 NA
Response 0 0.993
Response 1 0.952
Response 2 0.749 Response 3 0.184 Response 4 0.003

says he wanted food . <person> . he wanted the gold . how ' s he going to want the gold ? he couldn ' t even know we had it . <person> , i know . but it ' s not him , it ' s the only way he ' s got it all figured <person> , i know . but i have to tell you . these things are really stupid and you think i was wrong ? <person> , i ' m sure he did . <person> , i ' m not sure .
The netboot one is suppose to download packages from the net. like the ones to be installed? or the installed to be run? you don ' t need to install the whole system , just install the ubuntu installer you can install the ubuntu installer from the ubuntu menu I ' m not sure , I don ' t know . you can you a . 1 . . . . . . . . . . . . . . . . . . . . .

Context 0 NA
Response 0 0.991 Response 1 0.981 Response 2 0.615 Response 3 0.191 Response 4 0.002

DJones: update manager won't detect 12.04.1 as a new version if you are already running 12.04, because 12.04.1 = 12.04 + lots of package updates did you try a clean install of the latest version ? try installing the latest UNK and see if it works I ' m not sure you have a problem . . . try sudo apt-get remove the package that is not installed try the UNK . 1 . 1 . 1 . 1 . 1 . UNK . deb

Movie

Context 0 perhaps <person> had a word with the man upstairs .

HRED

i ' m sorry , <person> .

VHRED <person< ' t do it .

hredGAN w <person> , i ' m not gon na be okay . i just don ' t think it ' s a

good idea .

hredGAN u <person> , i cause it was all the way to you .

Context 1 a word ? i ' m sure by now he ' s engineered a hostile takeover .

HRED

i ' m sorry , <person> .

VHRED <person> ' t do it .

hredGAN w <person> , i know what you ' re saying , <person> , that ' s not

what i ' m saying .

hredGAN u <person> , i have to tell you i ' m not the same .

Context 0 <person> ' s .

HRED

i ' m sorry , <person> .

VHRED <person> ' t do it .

hredGAN w <person> , i ' m sure it ' s the only thing i ever imagined .

hredGAN u <person> , i ' ll be right there .

Context 1 can i ask you something about her ?

HRED

i don ' t know .

VHRED: you ' re not going to be here .

hredGAN w i don ' t know . i think i ' ve heard of it .

hredGAN u i ' m sorry , i can ' t .

Ubuntu

Context 0 this is Dacs i am in i used 'sudo statx and it let me in

HRED

what 's the problem ?

VHRED I don't know what you want to do . if you want to do it , you need to

do it to do it in the terminal ?

hredGAN w you don ' t have to do anything , just type in the terminal and it

should be to find the right device

hredGAN u you can have a look at the output of the command . . .

Context 1 good deal... cat /etc/X11/default-display-manager

HRED

what 's the problem ?

VHRED do you know what you want to do ?

hredGAN w I ' m trying to figure a command that I can find to find out the file

that I can find in the file"

hredGAN u I don ' t see the point , but I ' m not sure how to do that .

Context 2 /usr/sbin/lightdm http://paste.ubuntu.com/1286224/ <--- my

/etc/X11/xorg.conf

HRED

what 's the problem ?

VHRED is there a way to do that in the terminal ?

hredGAN w did you just type \" sudo mount -a \" ?

hredGAN u i have no idea , i just installed ubuntu and i have no idea how to do

that

capture the data distribution using single noise distribution. We hope to investigate this further in the future.
Discriminator Performance: Although only hredGAN uses a discriminator, the observed discriminator behavior is interesting. We observe that the discriminator score is generally reasonable with longer, more informative and more persona-related responses receiving higher scores as shown in Table 3. It worth to note that this behavior, although similar to the behavior of a human judge is learned without supervision. Moreover, the discriminator seems to have learned to assign average score to more frequent or generic responses such as "I don't know", "I'm not sure" and so on, and high score to rearer answers. That's why we sample a modified noise distribution during inference so that the generator can produce rearer utterances that will be scored high by the discriminator.

5 CONCLUSION AND FUTURE WORK
In this paper, we have introduced an adversarial learning approach that addresses response diversity and control of generator outputs, using an HRED-derived generator and discriminator. The proposed system outperforms existing state-of-the-art (V)HRED models for generating responses in multi-turn dialogue with respect to perplexity and automatic evaluation metrics. Our analysis also concludes that the word-level noise injection seems to perform better in general.
While this is a good starting point, we recognize the need to explore further improvements to the proposed adversarial framework: In the future, we hope to: explore which noise level works with which discrimination level; consider a multi-resolution discriminator with combined word- and utterancelevel discriminations; and explore further tuning of the generator and discriminator models.

8

Under review as a conference paper at ICLR 2019
REFERENCES
D. Bahdanau, K. Cho, and Y. Bengio. Neural machine translation by jointly learning to align and translate. In Proceedings of International Conference of Learning Representation (ICLR 2015), 2015.
R. E. Banchs. Movie-dic: A movie dialogue corpus for research and development. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pp. 203­207, 2012.
S. Banerjee and A. Lavie. Meteor: An automatic metric for mt evaluation with improved correlation with human judgments. In Proceedings of the ACL workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization, 2005.
E. Bruni and R. Fernndez. Adversarial evaluation for open-domain dialogue generation. In Proceedings of the 18th Annual SIGdial Meeting, 2018.
T. Che, Y. Li, R. Zhang, R. D. Hjelm, W. Li, Y. Song, and Y. Bengio. Maximum-likelihood augmented discrete generative adversarial networks. In arXiv preprint arXiv:1702.07983, 2017.
K. Cho, B. Merrienboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk, and Y. Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. In Proceedings of International Conference of Learning Representation (ICLR 2015), pp. 1724­ 1734, 2014.
X. Glorot and Y. Bengio. Understanding the difficulty of training deep feedforward neural networks. In International conference on artificial intelligence and statistics, 2010.
I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In Proceedings of Advances in Neural Information Processing Systems (NIPS 2014), 2014.
G. Hinton, L. Deng, D. Yu, G. Dahl, A. Mohamed, N. Jaitly, A. Senior, V. Vanhoucke, P. Nguyen, T. Sainath, and B. Kingsbury. Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. IEEE Signal Processing Magazine, 29(3):82­97, 2012.
P. Isola, J. Y. Zhu, T. Zhou, and A. A. Efros. Image-to-image translation with conditional adversarial networks. In Conference on Computer Vision and Pattern Recognition (CVPR, 2017), 2017.
S. Jean, K. Cho, R. Memisevic, and Y. Bengio. On using very large target vocabulary for neural machine translation. In arXiv preprint arXiv:1412.2007, 2015.
A. Kannan and O. Vinyals. Adversarial evaluation of dialogue models. In arXiv preprint arXiv:1701.08198v1, 2017.
A. Karpathy and L. Fei-Fei. Deep visual-semantic alignments for generating image descriptions. In Conference on Computer Vision and Pattern Recognition (CVPR 2015), 2015.
A. Lamb, A. Goyah, Y. Zhang, S. Zhang, A. Courville, and Y. Bengio. Professor forcing: A new algorithm for training recurrent networks. In Proceedings of Advances in Neural Information Processing Systems (NIPS 2016), 2016.
J. Li, M. Galley, C. Brockett, J. Gao, and B. Dolan. A diversity-promoting objective function for neural conversation models. In Proceedings of NAACL-HLT, 2016a.
J. Li, M. Galley, C. Brockett, G. Spithourakis, J. Gao, and B. Dolan. A persona-based neural conversation model. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pp. 994­1003, 2016b.
J. Li, W. Monroe, T. Shi, A. Ritter, and D. Jurafsky. Adversarial learning for neural dialogue generation. In arXiv preprint arXiv:1701.06547, 2017.
C. Y. Lin. Rouge: a package for automatic evaluation of summaries. In Proceedings of the Workshop on Text Summarization Branches Out, 2014.
9

Under review as a conference paper at ICLR 2019
C. Liu, R. Lowe, I. V. Serban, M. Noseworthy, L. Charlin, and J. Pineau. How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation. In Proceedings of EMNLP, pp. 2122­2132, 2016.
Y. Luan, Y. Ji, and M. Ostendorf. LSTM based conversation models. In arXiv preprint arXiv:1603.09457, 2016.
M. T. Luong, I. Sutskever, Q. V. Le, O. Vinyals, and W. Zaremba. Addressing the rare word problem in neural machine translation. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics, 2015.
T. Mikolov, M. Karafit, L. Burget, J. Cernocky, and S. Khudanpur. Recurrent neural network based language model. In Proceedings of the 11th Annual Conference of the International Speech Communication Association (INTERSPEECH 2010), 2010.
M. Mirza and S. Osindero. Conditional generative adversarial nets. In arXiv preprint arXiv:1411.1784, 2014, 2014.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. Bleu: A method for automatic evalution of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pp. 311­318, 2002.
S. Reed, Z. Akata, X. Yan, L. Logeswaran, B. Schiele, and H. Lee. Generative adversarial text to image synthesis. In Proceedings of the 33rd International Conference on Machine Learning (ICML 2016), 2016.
I. Serban, A. Sordoni, Y. Bengio, A. Courville, and J. Pineau. Building end-to-end dialogue systems using generative hierarchical neural network models. In Proceedings of The Thirtieth AAAI Conference on Artificial Intelligence (AAAI 2016), pp. 3776­3784, 2016.
I. V. Serban, T. Klinger, G. Tesauro, K. Talamadupula, B. Zhou, Y. Bengio, and A. Courville. Multiresolution recurrent neural networks: An application to dialogue response generation. In Proceedings of The Thirty-first AAAI Conference on Artificial Intelligence (AAAI 2017), 2017a.
I. V. Serban, A. Sordoni, R. Lowe, L. Charlin, J. Pineau, A. Courville, and Y. Bengio. A hierarchical latent variable encoder-decoder model for generating dialogue. In Proceedings of The Thirty-first AAAI Conference on Artificial Intelligence (AAAI 2017), 2017b.
L. Shang, Z. Lu, and H. Li. Neural responding machine for short-text conversation. In Proceedings of ACL-IJCNLP, pp. 1577­1586, 2015.
L. Shao, S. Gouws, D. Britz, A. Goldie, B. Strope, and R. Kurzweil. Generating long and diverse responses with neural conversational models. In Proceedings of International Conference of Learning Representation (ICLR), 2017.
A. Sordoni, M. Galley, M. Auli, C. Brockett, Y. Ji, M. Mitchell, J Nie, J. Gao, and B. Dolan. A neural network approach to context-sensitive generation of conversational responses. In Proceedings of NAACL-HLT, 2015.
I. Sutskever, O. Vinyals, and Q. Le. Sequence to sequence learning with neural networks. In Proceedings of Advances in Neural Information Processing Systems (NIPS), pp. 3104­3112, 2014.
O. Vinyals and Q. Le. A neural conversational model. In Proceedings of ICML Deep Learning Workshop, 2015.
R. J. Williams and D. Zipser. A learning algorithm for continually running fully recurrent neural networks. Neural computation, 1(2):270­280, 1989.
C. Xing, W. Wu, Y. Wu, M. Zhou, Y. Huang, and W. Ma. Hierarchical recurrent attention network for response generation. In arXiv preprint arXiv:1701.07149, 2017.
C. Xiong, V. Zhong, and R. Socher. Dynamic coattention networks for question answering. In Proceedings of International Conference of Learning Representation (ICLR 2017), 2017.
10

Under review as a conference paper at ICLR 2019 L. Yu, W. Zhang, J. Wang, and Y. Yu. Seqgan: sequence generative adversarial nets with policy
gradient. In Proceedings of The Thirty-first AAAI Conference on Artificial Intelligence (AAAI 2017), 2017. Y. Zhang, Z. Gan, K. Fan, Z. Chen, R. Henao, D. Shen, and L. Carin. Adversarial feature matching for text generation. In arXiv preprint arXiv:1706.03850, 2017. J. Y. Zhu, T. Park, P. Isola, and A. A. Efros. Image-to-image translation with conditional adversarial networks. In Conference on Computer Vision and Pattern Recognition (CVPR, 2017), 2017.
11

Under review as a conference paper at ICLR 2019
APPENDIX
6 RELATED WORK
Our work is related to end-to-end neural network­based open domain dialogue models. Most neural dialogue models use transduction frameworks adapted from neural machine translations (Sutskever et al., 2014; Bahdanau et al., 2015). These Seq2Seq networks are trained end-to-end with MLE criteria using large corpora of human-to-human conversation data. Others use GAN's discriminator as a reward function in a reinforcement learning framework (Yu et al., 2017) and in conjunction with MLE (Li et al., 2017; Che et al., 2017). Zhang et al. (2017) explored the idea of GAN with a feature matching criterion. Still, Seq2Seq models are limited in their ability to capture long temporal dependencies in multiturn conversation. Hence, the introduction of HRED models (Serban et al., 2016; 2017a;b; Xing et al., 2017) for modeling dialogue response in multi-turn conversation. However, these HRED models suffer from lack of diversity since they are trained with only MLE criteria. On other hand, adversarial system has been used for evaluating open domain dialogue models (Bruni & Fernndez, 2018; Kannan & Vinyals, 2017). Our work, hredGAN is closest to the combination of HRED generation models (Serban et al., 2016) and adversarial evaluation (Kannan & Vinyals, 2017).
7 ABLATION EXPERIMENTS
Before proposing the above adversarial learning framework for multi-turn dialogue, we carried out some experiments that are highlighted here.
7.1 GENERATOR:
First, we noted that by adding an additional attention memory to the HRED generator, we improved the perplexity score by more than 8 points on the Movie dataset and observed improved response quality. Hence, the decision for the modified HRED generator. However, with noise injected, training the generator using MLE objective only is very slow and the model ends up with high perplexity leading to generic responses during inference. Adversarial training, however, brings the perplexity between that of the noiseless system and the one with noise.
7.2 DISCRIMINATOR:
Before deciding on the word-level discrimination, we experimented with utterance-level discrimination. The utterance-level discriminator trains very quickly but it leads to mostly generic responses from the generator. We also note that utterance-level discriminator scores are mostly extreme (i.e., either low or high). Since we had used convolutional neural network discriminator (Yu et al., 2017) in our experiments, we hope to investigate this further with other architectures.
7.3 ADVERSARIAL TRAINING:
Lastly, we also tried a basic policy gradient approach (Li et al., 2017), where word-level discriminator score is used as a reward for each generated word token, but this leads to training instability. This is probably due to the instability of Monte Carlo sampling over large vocabulary size. We believe this might improve with other sampling methods such as importance sampling and hope to investigate further in the future.
12

Under review as a conference paper at ICLR 2019

8 OTHER GENERATED SAMPLES

Table 5: Additional sample responses of HRED, VHRED and hredGAN on Movie.

Movie
Context 0 HRED VHRED hredGAN w hredGAN u
Context 0 Context 1 HRED VHRED hredGAN w hredGAN u
Context 0 HRED VHRED hredGAN w hredGAN u
Context 0 Context 1 HRED VHRED hredGAN w hredGAN u
Context 0 Context 1 HRED VHRED hredGAN w hredGAN u
Context 0 Context 1 HRED VHRED: hredGAN w hredGAN u
Context 0 Context 1 HRED VHRED: hredGAN w hredGAN u
Context 0 Context 1 HRED VHRED: hredGAN w hredGAN u
Context 0 Context 1 HRED VHRED: hredGAN w hredGAN u
Context 0 Context 1 HRED VHRED: hredGAN w hredGAN u
Context 0 HRED VHRED: hredGAN w hredGAN u
Context 0 Context 1 HRED VHRED: hredGAN w hredGAN u
Context 0 Context 1 HRED VHRED: hredGAN w hredGAN u

<person> i ' ve raised my rate . i might even cut my sessions to forty minutes . i ' m sorry , <person> . <person>, <person>, <person>, <person> . <person> , i ' m sorry , but i ' m not sure if you ' re really a very good guy . i ' ll never see them again , <person> .
i ' m going to handle this exactly the way your father would have handled this . i ' ve got it solved . you ' ve got it solved ? where is she ? i don ' t know . <person>, , i ' m sorry. to the end of a beautiful woman who will be very happy . i ' m sorry , i just didn ' t know ­
of course not ! ¡person¿ ' s like a daughter to me . her father and i taught at university together . a good man , but he never listened . i ' m sorry , <person>. <person>, mr . <person> . <person> , i know it ' s been all six years since i told him about you . i ' m sure you didn ' t , but i would have done a little more .
of course not ! ¡person¿ ' s like a daughter to me . her father and i taught at university together . a good man , but he never listened . neither did i . i ' m sorry , <person>. <person> , you ' re a <unk> . <person>, i know you ' re think about it . think it ' ll be time , right ? i ' ll be the first one . if it did you , you ' ll be it .
come on , <person> , we could have a great week up in vermont . i see what you mean . but wednesday we ' ve got to be back in new york . <person> . <person> , i don ' t know what you ' re going to do . <person> , i know . i ' m kind of busy here . i ' m sorry , i can ' t .
isabel ? hi . that ' s what i ' m talking about . you ' re not going to be a <unk> , <person> . <person> ? what do you want to know ?
you understand mr . <person> is constantly barraged with nuisance litigation and irs audits . of course . that ' s right , <person> . <person> , you ' re going to be a <unk> of the <unk> . <person> , i ' m sure , but you ' re probably still in to the new <person> ' s house , huh ? you ' re gon na be a little boy , and i ' m not gon na get out !
<person> ' t go into my room , she ' s asleep . <person> , but the nanny , mrs . <person> , she wants to see her . i ' m sorry , <person> . <person> , mr . <person> . <person> , i know . but she ' s never seen me anyway . i ' m sorry i didn ' t know what to say .
what was that for ? i ' d forgotten how exciting it is working together . i ' m sorry , <person> . <person> , <person> . i don ' t know . i ' m sorry , <person> . so many people are so interested , but you ' re a very nice guy . i ' ve always been so sure to <person> .
a teacher ' s . oh my god . i ' m sorry , <person> . <person> , <person> ' t worry about it . i don ' t know what you ' re doing . i ' m sorry . i didn ' t mean to . i didn ' t mean to hurt you . i just wanted you <person> , i don ' t want to be your friend .
this is all we have . <person>, i ' m sorry . <person> , i don ' t know what you ' re doing . i don ' t know what i ' m going to do . i ' m sorry , sir , but i ' m a very good man . but you ' ve been in the apartment .
i took the initiative . you haven ' t been given an assignment in this case . <person> . <person> , <person> , <person> , <person> . i ' m not going to get out of the <unk> . i ' m not sure . <continued utterance> i ' m not gon na do you this shit anyway , <person> . <person> , i guess i didn ' t .
<person> , i was just gon na leave and see if i could pick up their trail . no , you wait right there for me . <person> be on the piedmont flight tomorrow at seven . meet me at the airport . i ' m sorry , <person> . what do you think i ' m saying ? i don ' t know what i ' m going to do . i don ' t know what i ' m going to do . i ' m not sure i don ' t . <continued utterance> do you want to go over to the station ? <person> , i don ' t know if i ' m not .

13

Under review as a conference paper at ICLR 2019

Table 6: Additional sample responses of HRED, VHRED and hredGAN on Ubuntu.

Ubuntu
Context 0 Context 1 HRED VHRED hredGAN w hredGAN u
Context 0 Context 1
HRED VHRED hredGAN w hredGAN u
Context 0 HRED VHRED hredGAN w hredGAN u
Context 0 Context 1 HRED VHRED hredGAN w hredGAN u
Context 0 HRED VHRED hredGAN w hredGAN u
Context 0 HRED VHRED hredGAN w hredGAN u
Context 0 Context 1
HRED VHRED hredGAN w hredGAN u
Context 0 Context 1
Context 2 HRED VHRED hredGAN w hredGAN u
Context 0 Context 1
Context 2 Context 3 HRED VHRED hredGAN w hredGAN u

what's the command you are running to chroot and the error message you get in return? i mountded the device sudo mount /dev/sda1 /mnt - that works - then sudo chroot /mnt ­ error is no such file or command what 's the problem ? is there a way to do that ? what do you mean ? I have no idea , I just did a sudo fdisk and it said it was mounted I ' m trying to get the latest version of ubuntu , but I ' m getting a lot of problems .
Hmm, have you checked that ICMP is being allowed all the way through and that the server responds to other ICMP requests? now i can ping it (i had to enable the lzo compression on client) i cannot reach the remote subnet adding a rule in the firewall forward the lan to vpn what 's the problem ? I don't know what you want to do I have no idea , I ' m just trying to get the ip address from the router to the router" I ' m not sure if that ' s the case , but I ' m not sure if it ' s a good idea to have a look at the output .
The netboot one is suppose to download packages from the net. I don't know what you want to do . how do I do that ? I ' m not sure of a command to do so I can just install the ubuntu . iso and burn a new iso you can ' t have a look at the man page . . .
The netboot one is suppose to download packages from the net. like the ones to be installed? or the installed to be run? I don't know what the problem is . is there a way to install the package manager ? you don ' t need to install the whole system , just install the ubuntu installer I ' m trying to install a UNK version of ubuntu , but I ' m trying to install it on my laptop .
You trying to mount it open with the password? I have to do that , but I have a problem with the same problem . is there a way to do ? yes , I ' m not sure if it ' s mounted or not I ' m trying to install the latest version of Ubuntu , but I ' m running on a UNK .
are you using lvm for your root partition? yes , but I have a problem with a new user , but I don't want to do that . what is the best way to do that ? what is that ? yes , I ' m on a live system , I ' m trying to use the partition to boot from windows I ' m not sure if it ' s a good idea to have a backup of the system . . .
are you using lvm for your root partition? i have the same config working on a 10.04 box. It appears in 12.04 lvm is on upstart and multipath is not. i do use lvm for my root folder nifty, is there any way to work around it? have you heard of anyone posting a bug about this to have it looked at? darn.... well i hope they can fix this eventually i hope they keep initrd around and move everything to upstart. Upstart is not easy to setup for programs that don't come packaged for upstart. I don't know what the problem is , but I don't know what the problem is . ? is there a way to do that ? or **unknown** ? you can also try the live cd and see if you can get it back up the live" I ' m trying to get my wireless working on my laptop , but I ' m getting to the point that I can be able to use the wireless card to get the wireless working .
are you using lvm for your root partition? i have the same config working on a 10.04 box. It appears in 12.04 lvm is on upstart and multipath is not. i do use lvm for my root folder nifty, is there any way to work around it? have you heard of anyone posting a bug about this to have it looked at? darn.... well i hope they can fix this eventually i hope they keep initrd around and move everything to upstart. Upstart is not easy to setup for programs that don't come packaged for upstart. yes, because i cant supply it at boot time, i want the truecrypt drive to come up by itself without manual intervention what is the problem ? what do you mean ? you can also mount a new one and put the mount command to the mount point" I ' m trying to get my sound working , but I ' m trying to get my sound working .
are you using lvm for your root partition? i have the same config working on a 10.04 box. It appears in 12.04 lvm is on upstart and multipath is not. i do use lvm for my root folder nifty, is there any way to work around it? have you heard of anyone posting a bug about this to have it looked at? darn.... well i hope they can fix this eventually i hope they keep initrd around and move everything to upstart. Upstart is not easy to setup for programs that don't come packaged for upstart. yes, because i cant supply it at boot time, i want the truecrypt drive to come up by itself without manual intervention Kinda defeats the use of it anyone could get in don't you think? what is the problem ? is there a way to mount the file ? if you want to do it ? I have no idea , I just want to get the data from the other computer I ' m trying to get the latest driver from the nvidia driver , but I ' m trying to get the nvidia driver working

14

