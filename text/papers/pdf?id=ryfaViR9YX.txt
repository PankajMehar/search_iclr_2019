Under review as a conference paper at ICLR 2019
VARIATION NETWORK: LEARNING HIGH-LEVEL ATTRIBUTES FOR CONTROLLED INPUT MANIPULATION
Anonymous authors Paper under double-blind review
ABSTRACT
This paper presents the Variation Network (VarNet), a generative model providing means to manipulate the high-level attributes of a given input. The originality of our approach is that VarNet is not only capable of handling pre-defined attributes but can also learn the relevant attributes of the dataset by itself. These two settings can be easily combined which makes VarNet applicable for a wide variety of tasks. Further, VarNet has a sound probabilistic interpretation which grants us with a novel way to navigate in the latent spaces as well as means to control how the attributes are learned. We demonstrate experimentally that this model is capable of performing interesting input manipulation and that the learned attributes are relevant and interpretable.
1 INTRODUCTION
We focus on the problem of generating variations of a given input in an intended way. This means that given some input element x, which can be considered as a template, we want to generate transformed versions of x with different high-level attributes. Such a mechanism is of great use in many domains such as image edition since it allows to edit images on a more abstract level and is of crucial importance for creative uses since it allows to generate new content.
More precisely, given a dataset D = {(x(1), m(1)), . . . , (x(N), m(N))} of N labeled elements (x, m)  X × M, where X stands for the input space and M for the metadata space, we would like to obtain a model capable of learning a relevant attribute space   Rd for some integer d > 0 and meaningful attribute functions  : X × M   that we can then use to control generation.
In a great majority of the recent proposed methods Lample et al. (2017); Upchurch et al. (2016), these attributes are assumed to be given. We identify two shortcomings: labeled data is not always available and this approach de facto excludes attributes that can be hard to formulate in an absolute way. The novelty of our approach is that these attributes can be either learned by the model (we name them free attributes) or imposed (fixed attributes). This problem is an ill-posed one on many aspects. Firstly, in the case of fixed attribute functions , there is no ground truth for variations since there is no x with two different attributes. Secondly, it can be hard to determine if a learned free attribute is relevant. However, we provide empirical evidence that our general approach is capable of learning such relevant attributes and that they can be used for generating meaningful variations.
In this paper, we introduce the Variation Network (VarNet), a probabilistic neural network which provides means to manipulate an input by changing its high-level attributes. Our model has a sound probabilistic interpretation which makes the variations obtained by changing the attributes statistically meaningful. As a consequence, this probabilistic framework provides us with a novel mechanism to "control" or "shape" the learned free attributes which then gives interpretable controls over the variations. This architecture is general and provides a wide range of choices for the design of the attribute function : we can combine both free and fixed attributes and the fixed attributes can be either continuous or discrete.
Our contributions are the following:
· A widely applicable encoder-decoder architecture which generalizes existing approaches Kingma & Welling (2013); Rubenstein et al. (2018); Lample et al. (2017)
1

Under review as a conference paper at ICLR 2019

Input: Noise: Output:

x  

NAF: Output

Input

  Meta   parameters

NN:

Identify function:

Concatenation:

u

z

z D

(x, m)

x m

Figure 1: VarNet architecture. The input x, x^ are in X , the input space and the metadata m is in M, the metadata space. The latent template code z lies in Z, the template space, while the latent variable z lies in Z the latent space. The variable u is sampled from a zero-mean unitvariance normal distribution. Finally, the features (x, m) are in , the attribute space. The Neural Autoregressive Flows (NAF) Huang et al. (2018) are represented using two arrows, one pointing to the center of the other one; this denotes the fact that the actual parameters of first neural network are obtained by feeding meta-parameters into a second neural network. The discriminator D acts on Z × .

· An easy-to-use framework: any encoder-decoder architecture can be easily transformed into a VarNet in order to provide it with controlled input manipulation capabilities,
· A novel and statistically sound approach to navigate in the latent space,
· Ways to control the behavior of the free learned attributes.
The plan of this paper is the following: Sect. 2 presents the VarNet architecture together with its training algorithm. For better clarity, we introduce separately all the components featured in our model and postpone the discussion about their interplay and the motivation behind our modeling choices in Sect. 3 and Sect. 4 discusses about the related works. In particular, we show that VarNet provides an interesting solution to many constrained generation problems already considered in the literature. Finally, we illustrate in Appendix A the possibilities offered by our proposed model and show that its faculty to generate variations in an intended way is of particular interest.
2 PROPOSED MODEL
We now introduce our novel encoder-decoder architecture which we name Variation Network. Our architecture borrows principles from the traditional Variational AutoEncoder (VAE) architecture Kingma & Welling (2013) and from the Wasserstein AutoEncoder (WAE) architecture Tolstikhin et al. (2017); Rubenstein et al. (2018). It uses an adversarially learned regularization Dumoulin et al. (2016); Lample et al. (2017), introduces a separate latent space for templates Adel et al. (2018) and decomposes the attributes on an adaptive basis Wang et al. (2018). It can be seen as a VAE with a particular decoder network or as a WAE with a particular encoder network. Our architecture is shown in Fig. 1 and our training algorithm is presented in Alg. 1.
We detail in the following sections the different parts involved in our model. In Sect. 2.1, we focus on the encoder-decoder part of VarNet and explain Eq. (3), (4) and (5). In Sect. 2.2, we introduce the adversarially-learned regularization whose aim is to disentangle attributes from templates (Eq. (1) and (6)). Section 2.3 discusses the special parametrization that we adopted for the attribute space .
2

Under review as a conference paper at ICLR 2019

Algorithm 1 Variation Network training procedure

Require: Dataset D = (x(i), m(i) i=1..N , reconstruction cost c, reproducing kernel k, batch size n

1: for Fixed number of iterations do

2: Sample x := (x1, . . . , xn) and m := (m1, . . . , mn) where (xi, mi) i.i.d. samples from D

3: 4:

Sample zi  q(·|xi) Compute z := {z1, . . .

,

zn}

where

zi

=

f(xi,mi)(zi)

5: Sample x^ := {x^1, . . . , x^n} where x^i  p(·|zi),

6: Sample random features {i}i=1..n from feature space  using  (see Sect. 2.3)

7: Let z~ := {z~1, . . . , z~n} where z~i  p(·)

8: Discriminator training phase

9: Compute

LDisc,n

:=

1 n

n

log D (zi, i) + log (1 - D(zi, (xi, mi)))

i=1

(1)

10: Gradient ascent step on the discriminator parameters using LDisc

11: Encoder-decoder training phase

12: Compute

LEncDec,n := REn + KLn + MMDk,n + RDisc,n

(2)

where

1n REn := n c(xi, x^i),
i=1

(3)

KLn

:=

1 n

n

log q(zi|xi) - log p(zi),

i=1

(4)

1 MMDk,n := n(n - 1)

1 k(zl, zj) + n(n - 1)

k(z~l,

z~j )

-

2 n2

k(zl, z~j),

l=k l=k l,j

(5)

RDisc,n

=

-1 n

n

log D(zi, (xi, mi)).

i=1

(6)

13: Gradient ascent step on all parameters except the discriminator parameters (encoder and decoder parameters, feature function parameters, features vectors and NAF f ) using LEncDec
14: end for

2.1 ENCODER-DECODER PART
Similar to the VAE architectures, we suppose that our data x  X depends on some latent variable z  Z through some decoder p(x|z) parametrized by a neural network. We introduce a prior p(z) over this latent space so that the joint probability distribution is expressed as p(x, z) = p(x|z)p(z). Since the posterior distribution p(z|x) is usually intractable, an approximate posterior distribution q(z|x) parametrized by a neural network is usually introduced.
The novelty of our approach is on how we write this encoder network. Firstly, we introduce an attribute space   Rd, where d is the dimension of the attribute space, on which we condition the encoder which we now denote as q(·|x,   ). More details about the attribute space  are given in Sect. 2.3. For the moment, we can consider it to be a subspace of Rd from which we can sample from. The objective in doing so is that decoding z  q(·|x, ) using p(x|z) will result in a sample x~ that is a variation of x but with features . Secondly, in order to correctly reconstruct x, introduce an attribute function  : X × M   computed from x and its metadata m with values in the attribute space . This attribute function is a deterministic neural network that will be learned during training and whose aim is to compute attributes of x.
For an input (x, m)  D, we want to decouple a template obtained from x from its attributes (x, m) computed from x and (possibly) from its metadata m. This is done by introducing another latent space Z that we term template space together with a approximated posterior distribution q(z|x)
3

Under review as a conference paper at ICLR 2019

parametrized by a neural network and a fixed prior p(z). The idea is then to compute z from z by applying a transformation parametrized only by the feature space . In practice, this is done by using a Neural Autoregressive Flow (NAF) Huang et al. (2018) f : Z  Z parametrized by   . Neural autoregressive flows are universal density estimation models which are capable of sampling any random variable Y by applying a learned transformation over a base random variable X (Thm. 1 in Huang et al. (2018)).

Given a reconstruction loss c on X , we have the following mean reconstruction loss: RE := E(x,m)DEx^p(·|z)Ezq(·|x,(x,m))c(x^, x).

(7)

We regularize the latent spaces Z and Z by adding the usual KL term appearing in the VAE Evidence Lower Bound (ELBO) on Z:

KL

:=

Ez  q  (.|x)

log

q(z|x) p(z)

(8)

and an MMD-based regularization on Z similar the one used in WAEs (see Alg. 2 in Tolstikhin et al. (2017)):

MMDk (q(·|x, (x, m)), p(·)) := k(z, ·)q(z|x, (x, m)) - k(z, ·)p(z) , (9)
Z Z Hk
where k : Z ×Z  R is an positive-definite reproducing kernel and Hk the associated Reproducing Kernel Hilbert Space (RKHS) Berlinet & Thomas-Agnan (2011).
The equations (3), (4) and (5) of Alg. 1 are estimators on a mini-batch of size n of equations (7), (8) and (9) respectively, (5) being the unbiased U-statistic estimator of (9) Gretton et al. (2012).

2.2 DISENTANGLING ATTRIBUTES FROM TEMPLATES
Our encoder q(z|x, ) thus depends exclusively on x and on the feature space . However, there is no reason, for a random attribute    = (x, m), that p(x|z) where z  q(z|x, ) generates variations of the original x with features . Indeed, all needed information for reconstructing x is potentially already contained in z.
We propose to add an adversarially-learned cost on the latent variable z to force the encoder q to discard information about the attributes of x: Specifically, we train a discriminator neural network D : Z×  [0, 1] whose role is to evaluate the probability D(z, ) that there exists a (x, m)  D such that  = (x, m) and z  q(·|x). In other words, the aim of the discriminator is to determine if the attributes  and the template code z originate from the same (x, m)  D or if the features  are randomly generated. We postpone the explanation on how we sample random features    in Sect. 2.3 and suppose for the moment that we have access to a distribution () over  from which we can sample. The encoder-decoder architecture presented in Sect. 2.1 is trained to fool the discriminator: this means that for a given (x, m)  D it tries to produce a template code z  q(·|x) which contains no information about the features (x, m).
In an optimal setting, i.e. when the discriminator is unable to match any z  Z with a particular feature   , the space of template codes and the space of attributes are decorrelated. All the missing information needed to reconstruct x given z  q(·|x) lies in the transformation f(x,m). Since these transformations between the template space Z and the latent space Z only depend on the feature space , they tend to be applicable over all template codes z and generalize well. During generation time, it is then possible to change the attributes of a sample without changing its template.
The discriminator is trained to maximize

LDisc := E(x,m)DEzq(·|x) E(·) log D(z, ) + log(1 - D(z, (x, m))) . while the encoder-decoder architecture is trained to minimize
RDisc := -E(x,m)DEzq(·|x) log D(zi, (x, m)).
Estimators of Eq. (10) and (11) are given by Eq. (1) and (6) respectively.

(10) (11)

4

Under review as a conference paper at ICLR 2019

2.3 PARAMETRIZATION OF THE ATTRIBUTE SPACE
We adopt a particular parametrization of our attribute function  : X × M so that we are able to sample fake attributes without the need to rely on an existing (x, m)  D pair. In the following, we make a distinction between two different cases: the case of continuous free attributes and the case of fixed continuous or discrete attributes.

2.3.1 FREE ATTRIBUTES

In order to handle free attributes, which denote attributes that are not specified a priori but learned.
For this, we introduce d attribute vectors vi of dimension d together with an attention module  : X × M  [0, 1]d , where d is the intrinsic dimension of the attribute space . By denoting i the coordinates of , we then write our attribute function  as

d
(x, m) = i(x, m)vi.
i=1

(12)

This approach is similar to the style tokens approach presented in Wang et al. (2018). The vi's are global and do not depend on a particular instance (x, m). By varying the values of the i's between [0, 1], we can then span a d-dimensional hypercube in Rd which stands for our attribute space . It is worth noting that the vi's are also learned and thus constitute an adaptive basis of the attribute space.

In order to define a probability distribution  over  (note that this subspace also varies during training), we are free to choose any distribution  over [0, 1]d . We then sample random attributes
from  by

d

     = ivi where i  .

(13)

i=1

2.3.2 FIXED ATTRIBUTES

We now suppose that the metadata variable m  M contains attributes that we want to vary at gen-
eration time. For simplicity, we can suppose that this metadata information can be either continuous with values in [0, 1]M (with a natural order on each dimension) or discrete with values in [|0, M |].

In the continuous case, we write our attribute function

M
(x, m) = mivi
i=1
while in the discrete case, we just consider

(14)

(x, m) = em,

(15)

where em is a d-dimensional embedding of the symbol m. It is important to note that even if the attributes are fixed, the vi's or the embeddings em are learned during training.
These two equations define a natural probability distribution  over :

     = (x, m) where (x, m)  D.

(16)

3 COMMENTS
We now detail our objective (2) and notably explain our particular choice concerning the regularizations on the latent spaces Z and Z. In Sect. 3.1, we will see that these insights suggest an additional way to "control" the influence of the learned free attributes. In Sect. 3.2, we further discuss about the multiple possibilities that we have concerning the implementation of the attribute function. We list, in Sect. 3.3, the different sampling schemes of VarNet. Finally, Sect. 3.4 is dedicated to implementation details.

5

Under review as a conference paper at ICLR 2019

3.1 CHOICE OF THE REGULARIZATIONS ON THE LATENT SPACES

We discuss our choice concerning the regularizations of the latent spaces and specifically why we chose a KL regularization on Z and an MMD loss on Z.

We found that using a MMD-based regularization on the template space Z resulted in approximated posterior distributions q(·|x) with very small variances (almost deterministic mappings).

One explanation of this behavior is that the MMD regularization tries to enforce that the aggre-

gated

posterior

1 N

N i=1

probability distributions

q(·|x(i)) matches the prior p: it does not act on the individual conditional q(·|x). This degenerate behavior is a side-effect of our adversarial regu-

larization since stochastic encoders have been successfully used in WAEs Rubenstein et al. (2018). When using the the Kullback-Leibler regularization on Z, this effect disappear which makes the

KL regularization that we considered more suited for VarNet since it helps to keep our model out

of a degenerate regime. For some applications, it can still be of interest to have a control over the variance of the conditional probability distributions q(·|x). Similar to the approach of Higgins et al.

(2016); Burgess et al. (2018), we propose to multiply the KL term by a scalar parameter  > 0. For

 = 1, we retrieve the original formulation. For  ]0, 1[, decreasing the value of  from one to zero decreases the variance of the q(·|x). We found no gain in considering values of  greater than

1. Examples where this tuning provides an interesting application are given in Sect. A.2.

We now consider the regularization over Z. This regularization is in fact superfluous and could be removed. However, we noticed that adding this MMD regularization helped obtaining better reconstruction losses.

3.2 FLEXIBILITY IN THE CHOICE OF THE ATTRIBUTE FUNCTION

In this section, we focus on the parametrization of the attribute function  : X × Z  Rd and propose some useful use cases. The formulation of Sect. 2.3 is in fact too restrictive and considered only one attribute function. It is in fact possible to mix different attributes functions by simply concatenating the resulting vectors. By doing so, we can then combine free and fixed attributes in a natural way but also consider different attention modules . We can indeed use neural networks with different properties similarly to what is done in Chen et al. (2016) but also consider different distributions over the attention vectors i.

It is important to note that the free attributes presented in Sect. 2.3.1 can only capture global attributes, which are attributes that are relevant for all elements of the dataset D. In the presence of discrete labels m, it can be interesting to consider label-dependent free attributes, which are attributes specific to a subset of the dataset. In this case, the attribute function  can be written as

d

(x, m) = i(x, m)em,i,

(17)

i=1

where em,i designates the ith attribute vector of the label m. With all these possibilities at hand, it is possible to devise numerous applications in which the notions of template and attribute of an input

x may have diverse interpretations.

Our choice of using a discriminator over  instead of, for instance, over the values of  themselves allow to encompass within the same framework discrete and continuous fixed attributes. This makes the combinations of such attributes functions natural.

3.3 SAMPLING SCHEMES

We quickly review the different sampling schemes of VarNet. We believe that this wide range of usages makes VarNet a promising model for a wide range of applications.

We can for instance:

· generate random samples x^ from the estimated dataset distribution: x^  p(·|z) with z = f(z) where z  p(·) and   (·),
· sample x^ with given attributes : x^  p(·|z) with z = f(z) where z  p(·),

(18) (19)

6

Under review as a conference paper at ICLR 2019

· generate a variations of an input x with attributes : x^  p(·|z) with z = f(z) where z  q(·|x),
· generate random variations of an input x: x^  p(·|z) with z = f(z) where z  q(·|x) and   (·).

(20) (21)

Note that for sampling generate random samples x^, we do that by sampling z  p(·) from the prior,   (·) from the distribution of the attributes and then decoding z = f(z) decoding it using the decoder p(·|z) instead of just decoding a z  p(·) sampled from the prior. This is due to the fact that, as already mentioned, this MMD regularization is not an essential element of the VarNet architecture: its role is more about fixing the "scale" of the Z space rather than enforcing that the aggregated posterior distribution exactly matches the prior.

In the case of continuous attributes of the form Eq. (12) or (14), VarNet also provides a new way to navigate in the latent space Z. Indeed, for a given template latent code z, it is possible to

move continuously in the latent space Z by simply changing continuously the values of the i and

then considering z = f(z) where  =

d i=1

ai

vi

.

The image by the above transformation in

the Z space of the d dimensional hypercube [0, 1]d constitutes the space of variations of the

template z. Since our feature space bears a measure , this space of variations has a probabilistic

interpretation. To the best of our knowledge, we think that it is the first time that a meaningful

probabilistic interpretation about the displacement in the latent space in terms of attributes is given:

We'll see in Appendix A.3 that two similar variations applied on different templates can induce

radically different displacements in the latent space Z. We hope that this new technique will be

useful in many applications and help go beyond the traditional (but unjustified) linear or spherical

interpolations White (2016).

3.4 IMPLEMENTATION DETAILS

Our architecture is general and any decoder and encoder networks can be used. We chose to use a NAF1 for our encoder network. This choice has the advantage of using a more expressive posterior
distribution compared to the often-used diagonal Gaussian posterior distributions.

Our priors p and p are zero-mean unit-variance Gaussian distributions. For the MMD regulariza-

tion, we used the parameters used in Tolstikhin et al. (2017) ( = 10 and k(x, y) = C/(C+

x-y

2 2

)

the inverse multiquadratics kernel with C = 2dim(Z)). For the scalar coefficient , we found that

a value of 10 worked well on all our experiments.

For the sampling of the  values in the free attributes case, we considered  to be a uniform distribution over [0, 1]d . In the fixed attribute case, we simply obtain a random sample {i}ni=1 by shuffling the already computed batches of {(xi, mi)}in=1 (lines 4 and 6 in Alg.1).

4 RELATED WORK

The Variation Network generalizes many existing models used for controlled input manipulation by providing a unified probabilistic framework for this task. We now review the related literature and discuss the connections with VarNet.
The problem of controlled input manipulation has been considered in the Fader networks paper Lample et al. (2017), where the authors are able to modify in a continuous manner the attributes of an input image. Similar to us, this approach uses an encoder-decoder architecture together with an adversarial loss used to decouple templates and attributes. The major difference with VarNet is that this model has a deterministic encoder which limits the sampling possibilities as discussed in Sect. A.2. Also, this approach can only deal with fixed attributes while VarNet is able to also learn meaningful free attributes. In fact, VAEs Kingma & Welling (2013), WAEs Tolstikhin et al. (2017); Rubenstein et al. (2018) and Fader networks can be seen as special cases of VarNet.
Recently, the Style Tokens paper Wang et al. (2018) proposed a solution to learn relevant free attributes in the context of text-to-speech. The similarities with our approach is that the authors condition an encoder model on an adaptive basis of style tokens (what we called attribute space in this
1We used the implementation of Huang et al. (2018) available at https://github.com/CW-Huang/NAF

7

Under review as a conference paper at ICLR 2019
work). VarNet borrows this idea but cast it in a probabilistic framework, where a distribution over the attribute space is imposed and where the encoder is stochastic. Our approach also allows to take into account fixed attributes, which we saw can help shaping the free attributes.
Traditional ways to explore the latent space of VAEs is by doing linear (or spherical White (2016)) interpolations between two points. However, there are two major caveats in this approach: the requirement of always needing two points in order to explore the latent space is cumbersome and the interpolation scheme is arbitrary and bears no probabilistic interpretation. Concerning the first point, a common approach is to find, a posteriori, directions in the latent space that accounts for a particular change of the (fixed) attributes Upchurch et al. (2016). These directions are then used to move in the latent space. Similarly, Hadjeres et al. (2017) proposes a model where these directions of interest are given a priori. Concerning the second point, Laine (2018) proposes to compute interpolation paths minimizing some energy functional which result in interpolation curves rather than interpolation straight lines. However, this interpolation scheme is computationally demanding since an optimization problem must be solved for each point of the interpolation path.
Another trend in controlled input manipulation is to make a posteriori analysis on a trained generative model Engel et al. (2017); Adel et al. (2018); Upchurch et al. (2016); Cao et al. (2018) using different means. One possible advantage of these methods compared to ours is that different attribute manipulations can be devised after the training of the generative model. But, these procedures are still costly and so provide any real-time applications where a user could provide on-the-fly the attributes they would like to modify. One of these approaches Cao et al. (2018) consists in using the trained decoder to obtained a mapping Z  X and then performing gradient descent on an objective which accounts for the constraints or change of the attributes. Another related approach proposed in Engel et al. (2017) consists in training a Generative Adversarial Network which learns to move in the vicinity of a given point in the latent space so that the decoded output enforces some constraints. The major difference of these two approaches with our work is that these movements are done in a unique latent space, while in our case we consider separate latent spaces. But more importantly, these approaches implicitly consider that the variation of interest lies in a neighborhood of the provided input. In Adel et al. (2018) the authors introduce an additional latent space called interpretable lens used to interpret the latent space of a generative model. This space shares similarity with our latent space Z and they also propose a joint optimization for their model, where the encoder-decoder architecture and the interpretable lens are learned jointly. The difference with our approach is that the authors optimize an "interpretability" loss which requires labels and still need to perform a posteriori analysis to find relevant directions in the latent space.
5 CONCLUSION AN FUTURE WORK
We presented the Variation Network, a generative model able to vary attributes of a given input. The novelty is that these attributes can be fixed or learned and have a sound probabilistic interpretation. Many sampling schemes have been presented together with a detailed discussion and examples. We hope that the flexibility in the design of the attribute function and the simplicity, from an implementation point of view, in transforming existing encoder-decoder architectures (it suffices to provide the encoder and decoder networks) will be of interest in many applications.
For future work, we would like to extend our approach in two different ways: being able to deal with partially-given fixed attributes and handling discrete free attributes. We also want to investigate the of use stochastic attribute functions . Indeed, it appeared to us that using deterministic attribute functions was crucial and we would like to go deeper in the understanding of the interplay between all VarNet components.
ACKNOWLEDGMENTS
Omitted for double blind review.
REFERENCES
Tameem Adel, Zoubin Ghahramani, and Adrian Weller. Discovering interpretable representations for both deep generative and discriminative models. In Jennifer Dy and Andreas Krause (eds.),
8

Under review as a conference paper at ICLR 2019
Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pp. 50­59, Stockholmsmssan, Stockholm Sweden, 10­15 Jul 2018. PMLR. URL http://proceedings.mlr.press/v80/adel18a.html.
Alain Berlinet and Christine Thomas-Agnan. Reproducing kernel Hilbert spaces in probability and statistics. Springer Science & Business Media, 2011.
C. P. Burgess, I. Higgins, A. Pal, L. Matthey, N. Watters, G. Desjardins, and A. Lerchner. Understanding disentangling in -VAE. ArXiv e-prints, April 2018.
C. Cao, D. Li, and I. Fair. Deep Learning-Based Decoding for Constrained Sequence Codes. ArXiv e-prints, September 2018.
Xi Chen, Diederik P. Kingma, Tim Salimans, Yan Duan, Prafulla Dhariwal, John Schulman, Ilya Sutskever, and Pieter Abbeel. Variational lossy autoencoder. CoRR, abs/1611.02731, 2016. URL http://arxiv.org/abs/1611.02731.
V. Dumoulin, I. Belghazi, B. Poole, O. Mastropietro, A. Lamb, M. Arjovsky, and A. Courville. Adversarially Learned Inference. ArXiv e-prints, June 2016.
Jesse Engel, Matthew Hoffman, and Adam Roberts. Latent constraints: Learning to generate conditionally from unconditional generative models. CoRR, abs/1711.05772, 2017. URL http://arxiv.org/abs/1711.05772.
Arthur Gretton, Karsten M Borgwardt, Malte J Rasch, Bernhard Scho¨lkopf, and Alexander Smola. A kernel two-sample test. Journal of Machine Learning Research, 13(Mar):723­773, 2012.
Gae¨tan Hadjeres, Frank Nielsen, and Franc¸ois Pachet. GLSR-VAE: geodesic latent space regularization for variational autoencoder architectures. CoRR, abs/1707.04588, 2017. URL http://arxiv.org/abs/1707.04588.
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. Beta-VAE: Learning basic visual concepts with a constrained variational framework. 2016.
Chin-Wei Huang, David Krueger, Alexandre Lacoste, and Aaron C. Courville. Neural autoregressive flows. CoRR, abs/1804.00779, 2018. URL http://arxiv.org/abs/1804.00779.
D. P Kingma and M. Welling. Auto-encoding variational Bayes. ArXiv e-prints, December 2013.
Samuli Laine. Feature-based metrics for exploring the latent space of generative models, 2018. URL https://openreview.net/forum?id=BJslDBkwG.
Guillaume Lample, Neil Zeghidour, Nicolas Usunier, Antoine Bordes, Ludovic Denoyer, and Marc'Aurelio Ranzato. Fader networks: Manipulating images by sliding attributes. CoRR, abs/1706.00409, 2017. URL http://arxiv.org/abs/1706.00409.
P. K. Rubenstein, B. Schoelkopf, and I. Tolstikhin. On the Latent Space of Wasserstein AutoEncoders. ArXiv e-prints, February 2018.
I. Tolstikhin, O. Bousquet, S. Gelly, and B. Schoelkopf. Wasserstein Auto-Encoders. ArXiv e-prints, November 2017.
Paul Upchurch, Jacob Gardner, Kavita Bala, Robert Pless, Noah Snavely, and Kilian Weinberger. Deep feature interpolation for image content changes. arXiv preprint arXiv:1611.05507, 2016.
Yuxuan Wang, Daisy Stanton, Yu Zhang, R. J. Skerry-Ryan, Eric Battenberg, Joel Shor, Ying Xiao, Fei Ren, Ye Jia, and Rif A. Saurous. Style tokens: Unsupervised style modeling, control and transfer in end-to-end speech synthesis. CoRR, abs/1803.09017, 2018. URL http://arxiv. org/abs/1803.09017.
Tom White. Sampling generative networks: Notes on a few effective techniques. arXiv preprint arXiv:1609.04468, 2016.
9

Under review as a conference paper at ICLR 2019
A EXPERIMENTS
We now apply VarNet on MNIST in order to illustrate the different sampling schemes presented in Sect. A. In all these experiments, we choose to use a simple MLP with one hidden layer of size 400 for the encoder and decoder networks. We present and comment results for different attribute functions and different sampling schemes. The different attribute functions we considered are
· 1Free: one-dimensional free attribute space (Eq. (12) with d = 1), · 2Free: two-dimensional free attribute space (Eq. (12) with d = 2), · 1Free+1FixedLabel: one-dimensional free attribute space (Eq. (12) with d = 1) concate-
nated with a fixed attribute which uses the labels of the digits (Eq. (15) with M = 10), · 1Free+1FreeLabel: one-dimensional free attribute space (Eq. (12) with d = 1) concate-
nated with a label-dependent free attribute of dimension 1 (Eq. (17) with M = 10 and d = 1).
A.1 UNCONSTRAINED AND CONSTRAINED SAMPLING SCHEMES
We display in Figure 2 samples obtained with the sampling procedures Eq. (18) and Eq. (19) when considering the 1Free+1FixedLabel attribute function. The results are in par with other probabilistic generative models on this task like VAEs, CVAEs or WAEs.

(a) (b)

(c)

Figure 2: Different sampling schemes. Fig. 2a: sampling from the dataset distribution using Eq. (18) using the 1Free+1FixedLabel attribute function. Fig. 2b: sampling elements with fixed attribute  using Eq. (19) with the 1Free+1FixedLabel attribute function. Fig. 2c: same as Fig. 2b but using the 1Free attribute function. In Fig 2c and 2b, two sets of samples (top and bottom) corresponding to two different values of  are shown.

(a) (b) Figure 3: Visualization of the spanned space of variations using two different inputs (shown in the last row). The attribute function 1Free+1FixedLabel is used. The values of i for the free attributes (see Eq. (12)) increase linearly from 0 to 1.
A.2 UNDERSTANDING FREE ATTRIBUTES From Fig. 2b, we see that the fixed label attribute have clearly been taken into account, but it can be hard to grasp which high-level attribute the free attribute function has captured. In order to visualize
10

Under review as a conference paper at ICLR 2019

Figure 4: Space of variations using the 1Free+1FreeLabel attribute function. The free label-dependent attribute varies along the y-axis while the free (global) attribute varies along the xaxis.

Figure 5: Sampling scheme Eq. (21) using the
1Free+1Label attribute function. Each row shows samples obtained by sampling z  q(.|x) for a fixed random feature . The original input is
shown on the last line.

this, we plot in Fig. 3 a visualization of the space of variations spanned by a given template latent code z. From these plots, it appears that the attribute vector encodes a notion of rotation meaningful for this digit dataset and it is interesting to note how different templates produce different "writing styles". Free attributes can thus be particularly interesting for capturing high-level features, such like rotation, that cannot be described in an absolute way or which are ill-defined.
By observing carefully Fig. 3, we note that the variations generated by varying the free attribute applies to all digit classes, irrespective of their label. In such a case, it is impossible to obtain different "writing conventions" for the same digit (like cursive/printscript style for the digit "2") by only modifying the attributes. We show in Fig. 4 that, by considering free label-dependent attributes, we are able to smoothly go from one "writing convention" to the other one.
We can gain further insight about the notion of template and attribute using the sampling scheme of Eq. (21). This sampling exploits the stochasticity of the encoder q(·|x) in order to generate variations of a given input x using a fixed attribute . An example of such variations is given in Fig. 5. The underlying idea is that, even for a given attribute , there are multiple ways to generate variations of x with attributes . We believe that this stochasticity is essential since, in many applications, there should not exist only one way to make variations.
The parametrization of the attribute function has a crucial effect on the high-level features that they will able to capture. For instance, if we do not provide any label information, the information present in the template and the information contained in the attribute function can differ drastically. Figure 6 show different space of variations where no label information is provided. The concepts captured in these cases are then related to thinness/roundness. Our intuition is that the free attributes capture the most general attributes of the dataset.
For some applications, variation spaces such as the one displayed in Fig. 6a, 6b or 6d are not desirable because they may tend to move too "far away" from the original input. As discussed in Sect. 3.1, it is possible to reduce how "spread" the spaces of variation are by modifying the  parameter multiplying the KL term in the objective Eq. (2). An example of such a variation space is displayed in Fig. 6c.
From all examples above, we see that our architecture is indeed capable of decoupling templates from learned attributes and that we have two ways of controlling the free attributes that are learned: by modifying the KL term in the objective Eq. (2) and by carefully devising the attribute function. Indeed, the learned free attributes can capture different high-level features depending on the other fixed attributes they are coupled with.
11

Under review as a conference paper at ICLR 2019
(a) (b) (c) (d) Figure 6: Figures 6a, 6b and 6c display the space of variations using the 2Free attribute function for two different input. Fig. 6d display the space of variations using the 1Free attribute function. Figure 6c was generated using a model trained with a low KL penalty ( = 0.1)
A.3 MOVING IN THE LATENT SPACE: BEYOND INTERPOLATIONS VarNet proposes a novel solution to explore the latent spaces. Usual techniques to navigate in the space of VAEs such as interpolations or the use of attribute vectors (distinct from what we called attribute vectors in this work) are mostly intrinsically-based on moving using straight lines. This assumes that the underlying geometry is euclidean, which is not the case, and forgets about the probabilistic framework. Also, computing attribute vectors requires data with binary labels which are not always available. On the contrary, our approach grants a sound probabilistic interpretation of the attributes and the variations they generate. Indeed, when the discriminator is fooled by the encoder-decoder architecture, the attributes are distributed according to  which has a simple interpretation (it is the push-forward of the  distribution which is considered to be a uniform distribution in all these examples). Also, thinking about variations as a subspace of smaller dimension than the whole latent space makes much sense for us.
Figure 7: Variation spaces (shown in Z) of a VarNet trained using the 1Free attribute function, for different z. We plotted {z = f(z)} for  = 1v1 where 1  [0.0, 0.05, . . . , 0.95, 1.0] and random z. Visualized using a 3D PCA in Z. Figure 7 shows a visualization in the latent space Z of the variation spaces spanned by moving with constant steps in the attribute space . Two key elements appear: constant steps in the attribute space do not induce constant steps in the Z space and variation spaces are extremely diverse (they are not translated versions of a unique variation space). For us, this advocates for the fact that displacements in the latent spaces using straight lines have a priori no meaningful interpretation: the same change of attributes for two different inputs can lead to radically different displacements in the latent space. More generally, our proposition of parametrizing attribute-related displacements in a latent space using flows conditioned on a simpler space is appealing from a conceptual point of view since we do not mix, in the same latent space, its probabilistic interpretation given by the prior and its ability to grant meaningful ways to vary attributes.
12

