Under review as a conference paper at ICLR 2019

THE EXPRESSIVE POWER OF GATED RECURRENT UNITS AS A CONTINUOUS DYNAMICAL SYSTEM
Anonymous authors Paper under double-blind review

ABSTRACT
Gated recurrent units (GRUs) were inspired by the common gated recurrent unit, long short-term memory (LSTM), as a means of capturing temporal structure with less complex memory unit architecture. Despite their incredible success in tasks such as natural and artificial language processing, speech, video, and polyphonic music, very little is understood about the specific dynamic features representable in a GRU network. As a result, it is difficult to know a priori how successful a GRURNN will perform on a given data set. In this paper, we develop a new theoretical framework to analyze one and two dimensional GRUs as a continuous dynamical system, and classify the dynamic features obtainable with such system. In addition, we show that a two dimensional GRU cannot mimic the dynamics of a ring attractor, or more generally, any line attractor without near zero constant curvature in phase space. These results were then experimentally verified by means of time series prediction.

1 INTRODUCTION

Recurrent neural networks (RNNs) have been widely used to capture and utilize sequential structure in natural and artificial languages, speech, video, and various other forms of time series. The recurrent information flow within RNN implies that the data seen in the past has influence on the current state of the RNN, forming a mechanism for having memory through (nonlinear) temporal traces. Unfortunately, training vanilla RNNs (which allow input data to directly interact with the hidden state) to capture long-range dependences within a sequence is challenging due to the vanishing gradient problem (Bengio et al., 1994). Several special RNN architectures have been proposed to mitigate this issue, notably the long short-term memory (LSTM; Hochreiter & Schmidhuber (1997)) which explicitly guards against unwanted corruption of the information stored in the hidden state until necessary. Recently, a simplification of LSTM called the gated recurrent unit (GRU; Cho et al. (2014)) has become wildly popular in the machine learning community thanks to its performance in machine translation (Britz et al., 2017), speech (Prabhavalkar et al., 2017), music (Choi et al., 2017), video (Dwibedi et al., 2018), and extracting nonlinear dynamics underlying neural data (Pandarinath et al., 2018). However, we lack systematic understanding of the internal time evolution of GRU's memory structure and its capability to represent nonlinear temporal dynamics.

In general, an RNN can be written as ht+1 = f (ht, xt) where xt is the current input in a sequence indexed by t, f is a point-wise nonlinear function, and ht represents the hidden memory state that carries all information responsible for future output. In the absence of input, the hidden state ht can evolve over time on its own:

ht+1 = f (ht)

(1)

where f (·) := f (·, 0) for notational simplicity. In other words, we can consider the temporal evolution of memory stored within RNN as a trajectory of a dynamical system defined by (1). Then we can use dynamical systems theory to investigate the fundamental limits in the expressive power of RNNs in terms of their temporal features. We develop a novel theoretical framework to study the dynamical features fundamentally attainable, in particular, given the particular form of GRU. We then validate the theory by training GRUs to predict time series with prescribed dynamics.

2 CONTINUOUS-TIME GATED RECURRENT UNIT

The GRU uses two internal gating variables: the update gate zt which protects the d-dimensional hidden state ht  Rd and the reset gate rt which allows overwriting of the hidden state and controls the interaction with the input xt  Rp.

zt =

(Wzxt +Uzht-1 + bz)

(update gate)

(2)

rt =

(Wrxt +Urht-1 + br)

(reset gate)

(3)

ht = zt tanh(Whxt+Uh(rt ht-1 + bh)) + (1 - zt) ht-1 (hidden state)

(4)

1

Under review as a conference paper at ICLR 2019

where Wz, Wr, Wh  Rd×p and Uz, Ur, Uh  Rd×d are the parameter matrices, bz, br, bh  Rd are bias vectors, represents the Hadamard product, and (z) = 1/(1 + e-z) is the element-wise logistic sigmoid function. Note that
the hidden state is asymptotically contained within [-1, 1]d due to the saturating nonlinearities.
Note that the update gate zt controls how fast each dimension at the hidden state decays, providing an adaptive time constant for memory. Specifically, as limzt0 ht = ht-1, GRUs can implement perfect memory of the past and ignore xt. Hence, a d-dimensional GRU is capable of keeping a near constant memory through the update gate--near constant since 0 < [zt]j < 1, where [·]j denotes j-th component of a vector. Moreover, the autoregressive weights (mainly Uh and Ur) can support time evolving memory (c.f., Laurent & Brecht (2016)) considered this a hindrance and proposed removing all complex dynamic behavior in a simplified GRU).
To investigate the memory structure further, let us consider the dynamics of hidden state in the absence of input, i.e. xt = 0, t, which is of the form (1). To utilize the rich descriptive language of continuous time dynamical system theory, we consider the following continuous time limit of the (autonomous) GRU time evolution:

z(t) = (Uzh(t) + bz) r(t) = (Urh(t) + br)
h = -z(t) (h(t) - tanh(Uh(r(t)

h(t)) + bh))

(continuous update gate) (continuous reset gate)
(continuous hidden state dynamics)

(5) (6)
(7)

where h



dh(t) dt

.

Since both (·) and tanh(·) are smooth, this continuous limit is justified.

The update gate z(t)

again plays the role of a state-dependent time constant for memory decay. Furthermore, since z(t) > 0, it does not

change the topological structure of the dynamics (only speed). For the following theoretical analysis sections (3 & 4),

we can safely ignore the effects of z(t). A derivation of the continuous-time GRU can be found in appendix A.

3 STABILITY ANALYSIS OF A ONE DIMENSIONAL GRU
For a single GRU (d = 1), (7) reduces to a one dimensional dynamical system where every variable is a scalar. The expressive power of a single GRU is quite limited, as only three stability structures (topologies) exist (see appendix B): (A) a single stable node, (B) a stable node and a half-stable node, and (C) two stable nodes separated by an unstable node (see Fig. 1). The corresponding temporal features are (A) decay to a fixed value, (B) decay to a fixed value, but from one direction halt at an intermediate value until perturbed, or (C) decay to one of two fixed values (bistability). The bistability can be used to capture a binary latent state in the sequence. It should be noted that a one dimensional continuous time autonomous system cannot exhibit oscillatory behavior, as is the case here (Hirsch et al., 2013).

AB
half-stable xed point stable xed point 00

C
unstable xed point 0

Figure 1: Three possible types of one dimensional flow for a single GRU. When h > 0, h(t) increases. This flow is indicated by a rightward arrow. Nodes ({h | h (h) = 0}) are represented as circles and classified by their stability
Hirsch et al. (2013).

The topology the GRU takes is determined by its parameters. If the GRU begins in a region of the parameter space corresponding to (A), we can smoothly vary the parameters to transverse (B) in the parameter space, and end up at (C). This is commonly known as a saddle-node bifurcation. Speaking generally, a bifurcation is the change in topology of a dynamical system, resulting from a smooth change in parameters. The point in the parameters space at which the bifurcation occurs is called the bifurcation point, and we will refer to the fixed point that changes its stability at the bifurcation point as the bifurcation fixed point. This corresponds to the parameters underlying (B) in our previous example. The codimension of a bifurcation is the number of parameters which must vary in order to achieve the bifurcation. In the case of our example, a saddle-node bifurcation is codimension-1 (Kuznetsov, 1998). Right before transitioning to (B), from (A), the flow near where the half-stable node would appear can exhibit arbitrarily slow flow. We will refer to these as slow points (Sussillo & Barak, 2012).
2

Under review as a conference paper at ICLR 2019

4 ANALYSIS OF A TWO DIMENSIONAL GRU

We will see that the addition of a second GRU opens up a substantial variety of possible topological structures when compared with the use of a single GRU. For notational simplicity, we denote the two dimensions of h as x and y. We visualize the flow fields defined by (7) in 2-dimension as phase portraits which reveal the topological structures of interest. For starters, the phase portrait of two independent bistable GRUs can be visualized as Figure 2A. It clearly shows 4 stable states as expected, with a total of 9 stable fixed points. This could be thought of as a continuoustime continuous-space implementation of a finite state machine with 4 states (Fig. 2B). The 3 types of observed fixed points--stable (sinks), unstable (sources), and saddle points--exhibit locally linear dynamics, however, the global geometry is nonlinear and their topological structures can vary depending on their arrangement.

A
example trajectories
1.5

nullcline

log speed -1

-1.5 1
-2

0.5 -2.5

-3 0
-3.5

-0.5 -4

-4.5 -1
-5

-1.5 -1.5 -1 -0.5 0 0.5 1 1.5

B (hidden) Markov Chain / Finite State Machine 01 11
00 10
sink (stable node point) saddle point source (unstable node point)

Figure 2: Illustrative example of two independent bistable GRUs. (A) Phase portrait. The flow field h = [x , y] is decomposed into direction (black arrows) and speed (color). Purple lines represent trajectories of the hidden state which converge to one of the four stable fixed points. Note the four quadrants coincide with the basin of attraction for each of the stable nodes. The fixed points appear when the x- and y-nullclines intersect. (B) The four stable nodes of this system can be interpreted as a continuous analogue of 4-discrete states with input-driven transitions.

We explored stability structures attainable by two GRUs. Due to the relatively large number of observed topologies, this section's main focus will be on demonstrating all possible local dynamical features obtainable by two GRUs. In addition, existence of two non-local dynamical features will be presented. A complete catalog of all observed topologies can be found in the appendix C, along with the parameters of every phase portrait depicted in this paper.
Before proceeding, let us take this time to describe all the local dynamical features observed. In addition to the previously mentioned three types of fixed points, two GRUs can exhibit a variety of bifurcation fixed points, resulting from regions of parameter space that separate all topologies restricted to simple fixed points (i.e stable, unstable, and saddle points). Behaviorally speaking, these fixed points act as hybrids between the previous three, resulting in a much richer set of obtainable dynamics. These bifurcation fixed points fall into two categories, separated by codimension. More specifically, two GRUs can feature both codimension-1 and codimension-2 bifurcation (fixed) points. Beginning with codimension-1, we have the saddle-node bifurcation fixed point, as expected from its existence in the single GRU case. We can further classify these points into two types. These can be thought of as both the fusion of a stable fixed point and a saddle point, and the fusion of an unstable fixed point and a saddle point. We will refer to these fixed points as saddle-node bifurcation fixed points of the first kind and second kind respectively.
One type of codimension-2 bifurcation fixed point that has been observed in the two GRU system acts as the fusion of all three simple fixed points. More specifically, these points arise from the fusion of a stable fixed point, unstable fixed point, and two saddle points. All of these local structures are depicted in figure 3.
While the existence of simple fixed points was already demonstrated (see Fig. 2A). Figure 3A demonstrates the maximum number of fixed points observed in a two GRU system, for a given set of parameters. A closer look at this system reveals its potential interpretation as a continuous analogue of 5-discrete states with input-driven transitions, similar to that depicted in figure 2, implying additional GRUs are needed for any Markov process modeled in this manner,

3

Under review as a conference paper at ICLR 2019

requiring more than five discrete states. We conjecture that the system depicted in figure 2A is the only eleven fixed point structure obtainable with two GRUs, as all observed structures containing the same number of fixed points are topologically equivalent to one another.
The addition of bifurcation fixed points opens the door to dynamically realize more sophisticated models. Take for example the four state system depicted in figure 3B. If the hidden state is set to initialize in the first quadrant of phase space, the trajectory will flow towards the codimension-2 bifurcation fixed point at the origin. Introducing noise through the input will stochastically cause the trajectory to approach the stable fixed point at (-1,-1) either directly, or by first flowing into one of the two saddle-node bifurcation fixed points of the first kind. Models of this sort can be used in a variety of applications, such as neural decision making (Wong & Wang (2006), Churchland & Cunningham (2014)).

A 1.5

B 0

C -1

0

y

1 -0.5 -1
0.5 -1.5
0 -2
-0.5 -2.5
-1 -3
-3.5 -1.5
-1.5 -1 -0.5 0 0.5 1 1.5 x

-2
-3
-4
-5
-6 -1.5 -1 -0.5 0 0.5 1 1.5
x

-1
-2
-3
-4
-5 -1.5 -1 -0.5 0 0.5 1 1.5
x

sink (stable xed point) saddle point source (unstable xed point) saddle-node bifurcation
xed point (sink-saddle collision) saddle-node bifurcation
xed point (source-saddle collision) co-dimension 2 bifurcation
xed point

Figure 3: Existence of all simple fixed points and bifurcation fixed points with two GRUs, depicted in phase space. Orange and pink lines represent the x and y nullclines respectively. Purple lines indicate various trajectories of the hidden state. Direction of the flow is determined by the black arrows, where the colormap underlaying the figure depicts the magnitude of the velocity of the flow in log scale.

We will begin our investigation into the non-local dynamics observed with two GRUs by showing the existence of homoclinic orbits. A trajectory initialized on a homoclinic orbit will approach the same fixed point in both forward and backward time. We observe that two GRUs can exhibit one or two bounded planar regions of homoclinic orbits for a given set of parameters, as shown in figure 4A and 4B respectively. Any trajectory initialized in one of these regions will flow into the codimension-2 bifurcation fixed point at the origin, regardless of which direction time flows in. This featured behavior enables the accurate depiction of various models, including neuron spiking (Izhikevich, 2007).
In regards to the second non-local dynamic feature, it can be shown that two GRUs can exhibit an Andronov-Hopf bifurcation, whereby a stable fixed point bifurcates into an unstable fixed point surrounded by a limit cycle. Behaviorally speaking, a limit cycle is a type of attractor, in the sense that there exists a defined basin of attraction. However, unlike a stable fixed point, where trajectories initialized in the basin of attraction flow towards a single point, a limit cycle pulls trajectories into a stable periodic orbit around the unstable fixed point at its center. To demonstrate this phenomenon, let (8) define the parameters of (7).

3 Uz, Ur, bz, br, bh = 0, Uh = 2

cos  sin 

- sin  cos 

(8)

where   R+.

If  = decrease

 3

,

,

the the

system system

has a single stable fixed point (stable spiral), as depicted in figure undergoes an Andronov-Hopf bifurcation approximately about  =

5A.

 3.8

.

If we As 

continuously continuously

decreases, the orbital period increases, and as the nullclines can be made arbitrarily close together, the length of this

orbital period can be set arbitrarily, up to machine accuracy. Figure 5B shows an example of a relatively short orbital

period, and figure 5C depicts the behavior seen for slower orbits.

With finite-fixed point topologies and global structures out of the way, the next logical question to ask is, can two GRUs exhibit an uncountable number of fixed points? Such behavior is often desirable in models that require stationary attraction to non-point structures, such as line attractors and ring attractors. The short answer to this question is no. In order to show this serious limitation of GRUs, we present the following lemma:

Lemma 1.  UZ , Ur, Uh  R2×2, bz, br, bh  R2, there can only exist finitely many fixed points.

4

Under review as a conference paper at ICLR 2019

y y
y y
y

A 1.5 single region of homoclinic orbit

1

0.5

0

-0.5

-1

-1.5

C

-1.5 -1 -0.5 0 x

0.5

1

1.5

1

0 B 1.5 double region of homoclinic orbit

-0.5 -1 1

-1.5 0.5 -2

-2.5 0

-3 -3.5 -0.5

-4 -1

-4.5

-1.5

D

-1.5 -1 -0.5 0 x

0.5

1

1.5

0.4

0 -0.5 -1 -1.5 -2 -2.5 -3 -3.5 -4 -4.5

0.5 0.2
x(t) 0 0 y(t) -0.2

-0.5 0

-0.4
50 100 150 200 250 0 t

50 100 150 200 250 t

Figure 4: Two GRUs exhibit bounded regions of homoclinic orbits. 4C and 4D represent the hidden state as a function of time, for a single initial condition within the homoclinic region(s) of the single and double homoclinic region cases respectively (denoted by solid black trajectories in each corresponding phase portrait).

A 1.5

0 B 1.5

0 C 1.5

0

1 -0.5 1 -0.5 1 -0.5 -1 -1 -1
0.5 -1.5 0.5 -1.5 0.5 -1.5

0 -2 0 -2 0 -2

-0.5

-2.5 -0.5

-2.5 -0.5

-2.5

-3 -3 -3

-1 -3.5 -1 -3.5 -1 -3.5

-1.5 -4 -1.5 -1 -0.5 0 0.5 1 1.5 x
2
1

-1.5 -4 -1.5 -1 -0.5 0 0.5 1 1.5 x
y(t) 0.5 x(t)

-1.5 -4 -1.5 -1 -0.5 0 0.5 1 1.5 x
1
0.5

0 00

-1 -0.5

-0.5 -2

-1

0 10 20 30 40 50

0 10 20 30 40 50 0

t

200 400 600 800

Figure

5:

Two

GRUs

exhibit

an

Andronov-Hopf

bifurcation,

where

the

parameters

are

defined

by

(8).

When



=

 3

the system exhibits a single stable fixed point at the origin (Fig. 5A). If  decreases continuously, a limit cycle emerges

around the fixed point, and the fixed point changes stability (Fig. 5B). Allowing  to decrease further increases the

size and orbital period of the limit cycle (Fig. 5C). The bottom row represents the hidden state as a function of time,

for a single trajectory (denoted by black trajectories in each corresponding phase portrait)

Proof. To achieve an uncountable number of fixed points, the hyperbolic tangent term in (7) must maintain a constant gradient of one on a connected curve in R2. To show this cannot be the case let (9) expand our previous notation. We
set all elements in Uz and bz to zero, as the update gate plays no part in the topology of (7) (shown in appendix B).

Uh =

Uh11 Uh21

Uh12 Uh22

, Ur =

Ur11 Ur21

Ur12 Ur22

, bh =

bh1 bh2

, br =

br1 br2

(9)

5

Under review as a conference paper at ICLR 2019

We can now rewrite (7) expanded in terms of the individual elements of Uh, Ur, bh, and br, as shown in (10) and (11).

x

=

-

1 2

[x

-

tanh(

1

+

Uh11x e-(Ur11 x+Ur12 y +br1 )

+

Uh12y 1 + e-(Ur21x+Ur22y+br2)

+ bh1)]

(10)

y

=

- 1 [y 2

-

tanh(

1

+

Uh21x e-(Ur11 x+Ur12 y +br1 )

+

Uh22y 1 + e-(Ur21x+Ur22y+br2)

+ bh2)]

We then take the derivative of the tanh term in (10), and set it equal to one, as depicted in (12).

(11)

sech2

Uh11x e-Ur11 x-Ur12 y -br1

+

1

+

Uh12y e-Ur21 x-Ur22 y -br2

+

1

+

bh1

=1



=

Uh11 Ur11 xe-Ur11 x-Ur12 y -br1 (e-Ur11x-Ur12y-br1 + 1)2

+

Uh11 e-Ur11 x-Ur12 y -br1

+1

+

Uh12 Ur21 y e-Ur21 x-Ur22 y -br2 (e-Ur21x-Ur22y-br2 + 1)2

(12) (13)

We must be able to equate the respective Taylor coefficients of the left and right hand side of (12), centered around an arbitrary point a  (-1, 1)2. Without loss of generality, if we expand the left hand side of (12) around (0, 0), we find
that this cannot be done, as the closest approximation, given by Uh12, Ur11, Ur12, Ur21, Ur22, bh1, br2 = 0, Uh11 = 1 + e-br1 , does not satisfy the requirement for arbitrarily ordered Taylor polynomials, thus completing the proof.

Despite this limitation, an approximation of a line attractor (infinitely many fixed points on a connected curve with sufficiently small (nearly zero) constant curvature) can be created using two GRUs. This approximation can be made arbitrarily close to an actual line attractor on a finite region in phase space, thereby satisfying computational needs on an arbitrary interval when scaled. We will refer to this phenomenon as a pseudo-line attractor. Figure 6 depicts an example of such an attractor.

A 1.5

B
0

0.2

0

y y

1 -1 0.15 -1

-2 0.1

-2

0.5 -3 0.05 -3 -4 -4
00 -5 -5

-0.5 -6 -0.05 -6

-7 -0.1

-7

-1 -8 -0.15 -8

-1.5 -9 -1.5 -1 -0.5 0 0.5 1 1.5 x

-0.2 -9

-0.2 -0.1

0

0.1 0.2

x

Figure 6: Two GRUs exhibit a pseudo-line attractor. Nullclines intersect at one point, but are close enough on a finite region to mimic an analytic line attractor in practice. 6A and 6B depict the phase portrait, on [-1.5, 1.5]2 and [-0.2, 0.2]2 respectively.

We conclude this section with a discussion of slow points in the two GRU system. As a logical extension to the single GRU system, slow points occur where the nullclines are sufficiently close together, but do not intersect, as demonstrated in figure 7. Given the previously discussed classes of dynamic behavior for two GRUs, slow points can only exist so long as the potential for a saddle-node bifurcation fixed point is possible in the location of the desired slow point, given an appropriate change in parameters, as they result from the collision and annihilation of two fixed points. This observation is consistent with the single GRU case, as slow points can only exist for a single fixed point. This would imply that given the one fixed point case, a maximum of five slow points are possible. However, this would imply that there must exist a six fixed point case by which five of the six fixed points exist at saddle-node bifurcation fixed points, which has not been observed (see appendix C). Despite this shortcoming, four simultaneous slow points are obtainable, as shown in figure 5C.
5 NUMERICAL EXPERIMENTS
As a means to put our theory to practice, in this section we explore several examples of time series prediction of continuous time planar dynamical systems using two GRUs. Results from the previous section indicate what dynamical features can be learned by this RNN, and suggest cases by which training will fail. All of the following computer experiments consist of an RNN, by which the hidden layer is made up of two GRUs, followed by a linear output layer.

6

Under review as a conference paper at ICLR 2019

A 1.5

0B1

y

1

-0.5 0.5

-1

0.5 -1.5 0 y(t)

0 -2

-0.5

-2.5 -0.5

x(t) passing through slow point

-3 -1 -1
-3.5

-1.5 -1.5 -1 -0.5 0 0.5 1 1.5 x

-1.5 0

5 10 15 20 25 t

Figure 7: An example of a slow point about the origin, obtainable with two GRUs. Initial conditions satisfying y < -x are attracted to the slow point at the origin before a secondary attraction to the sink. 7A depicts the phase portrait of the system, and 7B shows the dynamics of the hidden state for a single initial condition (denoted by a black trajectory on 7A).

The network is trained to make a 29-step prediction from a given initial observation, and no further input through prediction. As such, to produce accurate predictions, the RNN must rely solely on the hidden layer dynamics.

We train the network to minimize the following multi-step loss function:

L() = 1 Ntraj T T

w^ i(k; wi(0)) - wi(k)

2 2

i=1 k=1

(14)

where  are the parameters of the GRU and linear readout, T = 29 is the prediction horizon, wi(t) is the i-th time series generated by the true system, and w^ (k; w0) is k-step the prediction given w0.
The hidden states are initialized at zero for each trajectory. The RNN is then trained for 4000 epochs, using ADAM (Kingma & Ba, 2014) in whole batch mode to minimize the loss function, i.e., the mean square error between the predicted trajectory and the data. Ntraj = 667 time series were used for training. Figure 8 depicts the experimental results of the RNN's attempt at learning each dynamical system we describe below.

5.1 LIMIT CYCLE

To test if two GRUs can learn a limit cycle, we use a simple nonlinear oscillator called the FitzHugh-Nagumo Model. The FitzHugh-Nagumo model is defined by:

x

=

x

-

x3 3

-

y

+

Iext,

 y = x + a - by

(15)

where in this experiment we will chose  = 12.5, a = 0.7, b = 0.8, and Iext = N (0.7, 0.04). Under this choice of model parameters, the system will exhibit an unstable fixed point (unstable spiral) surrounded by a limit cycle (Fig. 8). As shown in section 4, two GRUs are capable of representing this topology. The results of this experiment verify this claim (Fig. 8), as two GRUs can capture topologically equivalent dynamics.

5.2 LINE ATTRACTOR

As discussed in section 4, two GRUs can exhibit a pseudo-line attractor, by which the system mimics an analytic line attractor. We will use the simplest representation of a planar line attractor:

x = -x, y = 0

(16)

This system will exhibit a line attractor along the y-axis, at x = 0 (Fig. 8). Trajectories will flow directly perpendicular towards the attractor. We added white Gaussian noise N (0, 0.1I) in the training data. While the hidden state dynamics of the trained network do not perfectly match that of an analytic line attractor, there exists a subset near each of the fixed points acting as a pseudo-line attractor (Fig. 8). As such, the added affine transformation (linear readout) allows for a sufficiently long subinterval by which the RNN can mimic the line attractor.

7

Under review as a conference paper at ICLR 2019

Target Analytical Dynamics y

Limit Cycle
3
2
1

1 0 -1

0 -2

-1
-2 -2 -1 0 1 2 x

-3 -4

1.5 1
1 0
0.5 -1
0 -2
-0.5 -3
-1 -4
-1.5 -1.5 -1 -0.5 0 0.5 1 1.5 x
1 x(t)

0 -1 y(t)

-2
0 10 20 30 40 50 t

Line Attractor

20
-1 1
-2

yy

0 -3

-4 -1
-5
-2 -6

-2 -1 0 1 2 x
1

0

0.5 -1 -2

0 -3

-4 -0.5 -5

-1 -1
1 0.5
0 -0.5
-1 0

-0.5 50 100

0 x
150 t

0.5 200

-6 1
250 300

yy

Ring Attractor
1.5

2

10
0.5 -2
0 -4
-0.5 -6
-1 -8
-1.5 -1.5 -1 -0.5 0 0.5 1 1.5 x
1.5 2

10
0.5 -2
0 -4
-0.5 -6
-1 -8
-1.5 -1.5 -1 -0.5 0 0.5 1 1.5 x
2

1

0

-1
0 50 100 150 200 250 300 t

Inferred GRU Dynamics y

Figure 8: Training 2-dim GRUs. (top row) Phase portraits of target dynamical systems. Red solid line represents 1-dimensional attractor. See main text for each system. (middle row) GRU dynamics learned from corresponding 29-step forecasting tasks. Note that the prediction is an affine transformation of the hidden state. (bottom row) An example time series generated through closed-loop prediction of the trained GRU (denoted by a black trajectory). Note that GRU fails to learn the ring attractor.

5.3 RING ATTRACTOR

For this experiment, a dynamical system representing a standard ring attractor of radius one is used:

x = -(x2 + y2 - 1)x, y = -(x2 + y2 - 1)y

(17)

This system exhibits an attracting ring, centered around an unstable fixed point. We added Gaussian noise N (0, 0.1I) to the training data.

Two GRUs will not be able to accurately capture the system's dynamics due to lemma 1, as the attractor defines a manifold with without near zero constant curvature in the phase space. The results of this experiment are demonstrated in figure 8. As expected, the RNN fails to capture the proper dynamical features of the ring attractor. Rather, the hidden state dynamics fall into an observed finite fixed point topology (see case xxix in appendix C).

6 CONCLUSION

Our analysis shows the rich but limited classes of dynamics the GRU can approximate in one and two dimensions. We developed a new theoretical framework to analyze GRUs as a continuous dynamical system, and showed that two GRUs can exhibit a variety of expressive dynamic features, such as limit cycles, homoclinic orbits, and a substantial catalog of stability structures and bifurcations. However, we also showed that two GRUs cannot accurately approximate a line attractor without near zero constant curvature in the phase space, such as a ring attractor. These claims were then experimentally verified. We believe these findings also unlock new avenues of research on the trainability of recurrent neural networks. Although we have analyzed GRUs only in 1- and 2- dimensions, we believe that the insights extends to higher-dimensions. We leave rigorous analysis of higher-dimensional GRUs as future work.

8

Under review as a conference paper at ICLR 2019
REFERENCES
Y. Bengio, P. Simard, and P. Frasconi. Learning long-term dependencies with gradient descent is difficult. IEEE transactions on neural networks, 5(2):157­166, 1994. ISSN 1045-9227. doi: 10.1109/72.279181.
Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc Le. Massive Exploration of Neural Machine Translation Architectures. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 1442­1451, Copenhagen, Denmark, 2017. Association for Computational Linguistics. doi: 10.18653/v1/D17-1151.
Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation. arXiv:1406.1078 [cs, stat], June 2014. arXiv: 1406.1078.
K. Choi, G. Fazekas, M. Sandler, and K. Cho. Convolutional recurrent neural networks for music classification. In 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 2392­2396, March 2017. doi: 10.1109/ICASSP.2017.7952585.
Mark M. Churchland and John P. Cunningham. A Dynamical Basis Set for Generating Reaches. Cold Spring Harbor Symposia on Quantitative Biology, 79:67­80, 2014. ISSN 1943-4456. doi: 10.1101/sqb.2014.79.024703.
Debidatta Dwibedi, Pierre Sermanet, and Jonathan Tompson. Temporal Reasoning in Videos Using Convolutional Gated Recurrent Units. pp. 1111­1116, 2018.
Morris W. Hirsch, Stephen Smale, and Robert L. Devaney. Differential Equations, Dynamical Systems, and an Introduction to Chaos. Elsevier Inc., 2013. ISBN 978-0-12-382010-5.
Sepp Hochreiter and Ju¨rgen Schmidhuber. Long Short-Term Memory. Neural Computation, 9(8):1735­1780, November 1997. ISSN 0899-7667. doi: 10.1162/neco.1997.9.8.1735.
Eugene M. Izhikevich. Dynamical systems in neuroscience. MIT press, 2007.
Diederik P. Kingma and Jimmy Ba. Adam: A Method for Stochastic Optimization. arXiv:1412.6980 [cs], December 2014. arXiv: 1412.6980.
Yuri A. Kuznetsov. Elements of Applied Bifurcation Theory (2Nd Ed.). Springer-Verlag, Berlin, Heidelberg, 1998. ISBN 978-0-387-98382-0.
Thomas Laurent and James von Brecht. A recurrent neural network without chaos. November 2016.
Chethan Pandarinath, Daniel J. O'Shea, Jasmine Collins, Rafal Jozefowicz, Sergey D. Stavisky, Jonathan C. Kao, Eric M. Trautmann, Matthew T. Kaufman, Stephen I. Ryu, Leigh R. Hochberg, Jaimie M. Henderson, Krishna V. Shenoy, L. F. Abbott, and David Sussillo. Inferring single-trial neural population dynamics using sequential autoencoders. Nature Methods, 15(10):805­815, October 2018. ISSN 1548-7105. doi: 10.1038/s41592-018-0109-9.
Rohit Prabhavalkar, Kanishka Rao, Tara N. Sainath, Bo Li, Leif Johnson, and Navdeep Jaitly. A Comparison of Sequence-to-Sequence Models for Speech Recognition. In Interspeech 2017, pp. 939­943. ISCA, August 2017. doi: 10.21437/Interspeech.2017-233.
David Sussillo and Omri Barak. Opening the Black Box: Low-Dimensional Dynamics in High-Dimensional Recurrent Neural Networks. Neural Computation, 25(3):626­649, December 2012. ISSN 0899-7667. doi: 10.1162/NECO a 00409.
Kong-Fatt Wong and Xiao-Jing Wang. A recurrent network mechanism of time integration in perceptual decisions. The Journal of Neuroscience: The Official Journal of the Society for Neuroscience, 26(4):1314­1328, January 2006. ISSN 1529-2401. doi: 10.1523/JNEUROSCI.3733-05.2006.
9

Under review as a conference paper at ICLR 2019

A CONTINUOUS TIME SYSTEM DERIVATION
We begin with the fully gated GRU as a discrete time system, where the input vector xt has been set equal to zero, as depicted in (18) - (20), where is the Hadamard product, and  is the sigmoid function.

zt = (Uzht-1 + bz)

(18)

rt = (Urht-1 + br)

(19)

ht = (1 - zt) ht-1 + zt tanh (Uh(rt ht-1 + bh) The following steps are a walk through of the derivation:
ht = ht-1 - zt ht-1 + zt tanh (Uh(rt ht-1) + bh)

(20) (21)

ht - ht-1 = -zt (ht-1 - tanh (Uh(rt ht-1) + bh)) Let t define an arbitrary time interval, and h(t)  ht-1. Then (22) becomes,

where,

h(t + t) - h(t) = -z(t) t

(h(t) - tanh Uh(r(t)

h(t)) + bh)

z(t) = (Uzh(t) + bz)

(22) (23) (24)

r(t) = (Urh(t) + br) If we take the limit as t  0, we get the analogous continuous time system to (18) - (20),

(25)

where

h



dh(t) dt

h = -z(t) (h(t) - tanh (Uh(r(t) h(t)) + bh))

B SINGLE GRU FIXED POINT PROOFS

(26)

The fixed points of our continuous time system (26) exist where the derivative h = 0. In the single GRU case, the Hadamard product reduces to standard scalar multiplication, yielding,

0 = -z(t)[h - tanh (Uhr(t)h + bh)] where z(t) and r(t) are defined by (24) and (25) respectively, and h  R represents a solution of (27).

(27)

We can divide out z(t), indicating that the update gate does not play a part in the stability of the system. For simplicity, lets expand r(t) in (27) by its definition (25).

0 = tanh (Uh(Urh + br)h + bh) - h where Uh, bh, Ur, br  R. Lemma 2. for all Uh, bh, Ur, br, there exists h such that (28) is satisfied.

(28)

Proof. The hyperbolic tangent function is continuous and bounded on (-1, 1). -h(t) is monotonic and achieves all values on R. Thus, their sum is unbounded and obtains every value on R at least once. By the intermediate value theorem, there is at least one point h such that (28) is satisfied, regardless of the choice of parameters Uh, bh, Ur, br.

10

Under review as a conference paper at ICLR 2019

Lemma 3. There exists a set of parameters Uh, bh, Ur, br such that there exists one, two, or three solutions to (28).
Proof. We will prove this lemma by showing the existence of each case. Let Ur = 80, br = 40, and Uh = -60. We then allow bh to vary. The existence of each of the three cases are shown in figure 1.
If bh = -1, there exists a single solution to (28). If bh decreases continuously, a second root appears and splits in two. Analogously, the system (26) goes through a saddle-node bifurcation, where a half-stable fixed point appears, and splits into a stable/unstable fixed point pair.
Theorem 1. For any choice of parameters Ur, br, Uh, bh, there can only exist one, two, or three solutions to (28), and all solutions exist on the interval (-1,1).

Proof. We begin with the argument of the hyperbolic tangent function in (28),

Uh(Urh + br)h + bh

(29)

Taking the derivative of (12) yields,

Uh(1 + e-Urh-br ) + UhUrhe-Urh-br (1 + e-Urh-br )2

(30)

Setting (30) to zero and simplifying will allow us to find the nontrivial critical points of (29), as shown in (31). Note that if Uh = 0, (29) is equal to bh h, yielding no critical points.

1 + e-Urh-br (1 + Urh) = 0

(31)

Let x  e-br and h^  Urh, and solve (31) for h^.

h^ = -W ( 1 ) - 1 xe

(32)

where W is the Lambert W function. Therefore, (29) has exactly one local maximum or minimum, so long as Uh = 0.

Now consider,

tanh (Uh(Urh + br)h + bh)

(33)

The hyperbolic tangent function preserves intervals of monotonic behavior in its argument. Therefore, (33) has at most one local maximum or minimum.

We take into account the fact that the hyperbolic tangent function bounds its argument on the interval (-1,1). If there

exists a subset S = [a, 1], for some a  [-1, 1) such that (33) is increasing, then there exists a k  S such that when

h = k (34) and (35) hold.

d dh

(tanh

(Uh  (Ur h

+

br )h

+

bh)

-

h)

=

0

(34)

d dh

(tanh

(Uh  (Ur h

+

br )h

+

bh)

-

h)

<

0,

h

>

k

(35)

This result in conjunction with the previous two lemmas completes the proof.

C ALL TOPOLOGICAL STABILITY STRUCTURES OBSERVED WITH TWO GRUS
Table 2 depicts all observed topologies of multiple-fixed point structures using two GRUs. Figure 9 displays an example of a phase portrait from a two GRU system for each case listed in 2. Note that all fixed points are denoted by a red dot, regardless of classification. Table 3 lists the parameters used for each of the observed cases. Note that all the update gate parameters are set to zero.

11

Under review as a conference paper at ICLR 2019

Table 1: Parameters Used for all Phase Portraits in Section 4

Figure Uh11 Uh12 Uh21 Uh22 Ur11 Ur12 Ur21 Ur22 bh1 bh2 br1 br2

2 3 0 0 3 0 0 0 0 0 00 0

3a 2 0 0 2 5 8 8 5 0 0 5 5

3b 2 0 0 2 -1 0 0 -1 0 0 0 0

3c 2

0

0

2

1 -2 3

1 -0.06 0 0.2 -0.85

4a 2 0 0 2 5 9 5 9 0 0 0 0

4b 2 0 0 2 5 9 9 5 0 0 0 0

5a 1.5 -2.598 2.598 1.5 0 0 0 0 0 0 0 0

5b 2.4271 -1.7634 1.7634 2.4271 0 0 0 0 0 0 0 0

5c 2.9665 -0.4471 0.4471 2.9665 0 0 0 0 0 0 0 0

6a 0.1 -0.1 -1 0 0 0 0 0 0 0 0 0

7a 2 2 2 2 100 100 100 100 0.01 0 0 0

Case
i ii iii iv v vi vii viii ix x xi xii xiii xiv xv xvi xvii xviii xix xx xxi xxii xxiii xxiv xxv xxvi xxvii xxviii xxix xxx xxxi xxxii xxxiii xxxiv xxxv xxxvi

Fixed Points
2 3 3 4 4 4 4 4 5 5 5 5 5 5 6 6 6 6 6 6 6 7 7 7 7 7 7 8 8 8 9 9 9 10 10 11

Table 2: Multiple Fixed Point Stability Structures Obtainable with two GRUs

Sinks
1 2 1 1 2 2 2 1 2 3 3 2 2 2 3 2 3 2 3 1 3 2 4 2 3 3 4 3 3 4 3 5 4 5 5

Sources
1 1 1 1 1 1 2 3 1 1 1 1 1 1

Saddle Points
1 1 1 1 2 2 1 1 1 1 2 2 2 2 2 1 3 3 2 2 2 3 3 2 4 3 4 4 4 5

Saddle Point and Stable Node Collisions
1 2 2 1 3 1 4 2 1 1 3 2 2 1 1 2 2 1 -

Saddle Point and Unstable Node Collisions
1 1 2 1 1 1 1 1 1 1 1 -

Codim. 2 Bifurcation
Point 1 1 1 -

Figure Reference
9i 9ii 9iii 9iv 9v 9vi 9vii 9viii 9ix 9x 9xi 9xii 9xiii 9xiv 9xv 9xvi 9xvii 9xviii 9xix 9xx 9xxi 9xxii 9xxiii 9xxiv 9xxv 9xxvi 9xxvii 9xxviii 9xxix 9xxx 9xxxi 9xxxii 9xxxiii 9xxxiv 9xxxv 9xxxvi

12

Under review as a conference paper at ICLR 2019

(i) (ii) (iii)

(iv) (v) (vi)

(vii)

(viii)

(ix)

(x) (xi) (xii)
Figure 9: Thirty six multiple fixed-point topologies obtainable with two GRUs, depicted in phase space. Orange and pink lines represent the x and y nullclines respectively. Red dots indicate fixed points. Each subfigure contains 64 purple lines, indicating trajectories in forward time, who's initial conditions were chosen to be evenly spaced on the vertices of a square grid on [-1.5, 1.5]2. Direction of the flow is determined by the black arrows, and the underlaying color map represents the magnitude of the velocity of the flow in log scale.
13

Under review as a conference paper at ICLR 2019

(xiii) (xiv) (xv)

(xvi)

(xvii)

(xviii)

(xix) (xx) (xxi)

(xxii)

(xxiii)

(xxiv)

Figure 9: Thirty six multiple fixed-point topologies obtainable with two GRUs, depicted in phase space. Orange and
pink lines represent the x and y nullclines respectively. Red dots indicate fixed points. Each subfigure contains 64
purple lines, indicating trajectories in forward time, who's initial conditions were chosen to be evenly spaced on the vertices of a square grid on [-1.5, 1.5]2. Direction of the flow is determined by the black arrows, and the underlaying
color map represents the magnitude of the velocity of the flow in log scale.

14

Under review as a conference paper at ICLR 2019

(xxv) (xxviii)

(xxvi) (xxix)

(xxvii) (xxx)

(xxxi)

(xxxii)

(xxxiii)

(xxxiv)

(xxxv)

(xxxvi)

Figure 9: Thirty six multiple fixed-point topologies obtainable with two GRUs, depicted in phase space. Orange and
pink lines represent the x and y nullclines respectively. Red dots indicate fixed points. Each subfigure contains 64
purple lines, indicating trajectories in forward time, who's initial conditions were chosen to be evenly spaced on the vertices of a square grid on [-1.5, 1.5]2. Direction of the flow is determined by the black arrows, and the underlaying
color map represents the magnitude of the velocity of the flow in log scale.

15

Under review as a conference paper at ICLR 2019

Case i ii iii iv v vi vii
viii ix x xi xii xiii xiv xv xvi xvii xviii xix xx xxi xxii xxiii0 xxiv xxv xxvi xxvii xxviii xxix xxx xxxi xxxii xxxiii xxxiv xxxv xxxvi

Uh11 2 2 1.2 2 2 2 2 1.2 3 6 6 2 2
2.9674 6 2 2 2 10 1.2
2.9763 6 3 1.5 2 3 7 6 2 3 3 2 3 1 3 2

Table 3: Parameters of each multiple fixed-point stability structure example

Uh12 2 2 0 0 0 0 0 0 3 0 0 0 0
-0.4409 0 0 0 0 0 0
-0.376 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0

Uh21 2 2 0 0 0 0 0 0 0 0 0 0 0
0.4409 0 0 0 0 0 0
0.376 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0

Uh22 2 2 2 2 2 2 4 2 3 6 6 2 4
2.9674 2 2 2 2 6 2
2.9763 6 3 2 3 3 3 10 3 3 3 2 3 1 3 2

Ur11 100
0 5 -1 1 1 1 5 0 0 0 1 1 0 -1 1 1 3 -3 -17 0 0 -3 -4 12.4 5.175 6 0 -10 5.26 0 5 6 5 6 5

Ur12 100 0 12 0 -1 -2 -2 20.5 0 -2 1 -2 -2 0 0 -2 -2 2 5 35 0 -2 -5 -7 11.6 9 3 0 -11.6 9 0 8 9 8 9 8

Ur21 100
0 8 0 1 3 3 8 0 0 0 3 3 0 0 3 3 2 -5 10 0 0 -5 8 -8 9 9 -5 8 9 0 8 9 8 9 8

Ur22 100 0 5 -1 1 1 1 5 0 0 0 1 1 0 0 1 1.1 3 3 -8 0 0 -3 5 -5 5.175 6 -8 5 5.26 0 5 6 5 6 5

bh1 0 0 0 0 0
-0.06 -0.06
0 0 0 0 -0.055 -0.06 0 0 -0.06 -0.06 0 0 0 0.0315 0 0 0 0 0.3 0.62 -0.08 0 0.25 0 0 0.3 0 0.24 0

bh2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.3
0.373 0 0
0.25 0 0 0.3 0
0.24 0

br1 0 0
-0.22 0 0 0.2
-0.3 -0.275
0 -1.695 -2.5 -0.1 -0.085
0 0 -0.08 0.2 0 -3 1.2 -0.015 0 -2 -0.4 1.8 3.95 4 0 4 3.95 0 4.4 3.75 4.4 3.95 5

br2 0 0 -0.5 0 0 -0.85 -0.42 -3.3 0 0 0 -0.02 -0.22 0 0 3 0 0 -3 -1.2 -0.015 0 -2 -1.2 7 3.95 3.4 -2 4.8 3.95 0 4.4 3.75 4.9 3.95 5

16

