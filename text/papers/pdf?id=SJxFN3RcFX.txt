Under review as a conference paper at ICLR 2019
FUNCTIONAL BAYESIAN NEURAL NETWORKS FOR MODEL UNCERTAINTY QUANTIFICATION
Anonymous authors Paper under double-blind review
ABSTRACT
In this paper, we extend the Bayesian neural network to functional Bayesian neural network with functional Monte Carlo methods that use the samples of functionals instead of samples of networks' parameters for inference to overcome the curse of dimensionality for uncertainty quantification. Based on the previous work on Riemannian Langevin dynamics, we propose the stochastic gradient functional Riemannian dynamics for training functional Bayesian neural network. We show the effectiveness and efficiency of our proposed approach with various experiments.
1 INTRODUCTION
Though deep neural networks have achieved tremendous success in various domains recently, there still exists some fundamental issues largely unclear and unsolved. One of them is that the training of neural networks usually ignores the uncertainty over the parameters since typically maximum a posteriori (MAP) is adopted for learning the parameters and only point estimates could be obtained. This problem can cause neural networks to make overconfident predictions, particularly in the region poorly covered by training data or far away from the underlying data manifold. Besides, the ignorance of model uncertainty also make neural networks vulnerable to adversarially perturbed data, so-called "adversarial examples" (Szegedy et al., 2013; Gal & Smith, 2018).
The Bayesian perspective provides a principled way of accounting for the uncertainty of model's prediction by integrating over the posterior distribution over parameters. In the scenario of neural networks, Bayesian neural networks (MacKay, 1992; Hinton & Van Camp, 1993; Neal, 1995) was proposed. However, for modern neural networks, the integral over posterior distribution is highly intractable due to the large network size and complex multi-modality.
There are mainly two groups of approaches for handling the intractability of the complex highdimensional distribution. The first one is to employ various Markov Chain Monte Carlo (MCMC) (Neal (1993); Max & Whye (2011); Chen et al. (2014); Shang et al. (2015); Ye et al. (2017)) to obtain the samples from the distribution; and then the Monte Carlo approximation can be used. However, the high dimensionality and a large number of modes in Bayesian neural networks prohibit the scaling of current MCMC methods, i.e. the mixing is extremely time-consuming. The other method is variational inference, typically approximating the original complex posterior distribution with independent Gaussian distributions over each weight in networks (Graves (2011); Herna´ndez-Lobato & Adams (2015); Blundell et al. (2015); Gal & Ghahramani (2016)). The limitation of this strategy is that the introduced approximation might underestimate the posterior when optimizing the variational lower bound.
In this paper, we extend the Bayesian neural network to functional Bayesian neural network for MCMC methods. Instead of sampling a single parameter each step, we propose to sample a function which can represents the posterior distribution each step. Based on the previous work for functional Hamiltonian method, we extend a previous work on Riemannian Langevin dynamics and propose its functional extension with mean-field Gaussian approximation.
2 FUNCTIONAL BAYESIAN NEURAL NETWORK
In this section, we will first explain the preliminary of Bayesian neural network and then extend it into the functional space.
1

Under review as a conference paper at ICLR 2019

Neural networks are most commonly trained in a maximum a posteriori (MAP) setting, where only point estimates of the network parameters can be obtained. This ignores any uncertainty about the parameters that often result in overconfident predictions, especially in regimes that are weakly covered by training data or far away from the data manifold. Bayesian neural networks Neal (1995) incorporates neural networks into the Bayesian framework for accounting for the parameter uncertainty through modeling the posterior distribution.

Firstly, one need to provide a prior distribution over the weights, p0() = N (0, 02I), where 02 is the variance magnitude. Assuming the likelihood function has the form,

p(yi|xi, ) = N yi|u(xi; ), 2I ,

(1)

where u(x; ) represents the output of the neural network. Then the posterior of the weights  is

p(|D) 

N i=1

p(yi

|xi,

)p0().

The uncertainty of the model, typically formulated as the expectation of a specific statistics g(; x, y). could be computed based on the posterior distribution of the weights,

µg = E[g(; x, y)] = g(; x, y)p(|D)d.

(2)

Due to the analytic intractability of the integral, the expectation of g(; x, y) is estimated using

Monte Carlo integration

µg



1 T

T

g(i; x, y),

i=1

(3)

where {i}iM=1 is drawn from the posterior p(|D).

To derive the functional Bayesian neural networks, we first define a functional f :   [0, 1] which

maps a parameter setting  to a probability, or more formally, we define a separable Hilbert space

H with inner product and norm operation and the functional f :   [0, 1] is in H. Note that f is a

probability distribution of weights . Similar to Bayesian neural networks, suppose we get posterior

distribution of functionals given the data: p(f |D) 

N i=1

p(yi|xi,

f

)p0(f ),

where

p0(f )

is

the

prior distribution of f , the uncertainty of the model can be formulated as the expectation of a specific

statistics g(; x, y):

µg = E[g(f ; x, y)] = g(f ; x, y)p(f |D)df,

(4)

where g(f ; x, y) = g(; x, y)f ()d is the expectation of the g(; x, y) given the distribution functional f . Due to the analytic intractability of the integral, similarly, the expectation of g(; x, y) can be estimated using a two-loop Monte Carlo integration,

µg



1 T

T

M
g(ij; x, y), Sample ij from fi,

i=1 j=1

(5)

where we sample M parameters from each posterior fi and T posteriors is used for computing the expectation. Through this formulation, we can perform inference with functional Bayesian neural networks. Note that with the same number of iterations T , the functional Bayesian neural network can have M times more samples than Bayesian neural networks. We provide a functional sampling example in section 5.1 for illustration.

In the next parts, we will propose the stochastic gradient functional Riemannian Langevin dynamics (SGFuncRLD) for training functional Bayesian neural network.

3 FUNCTIONAL RIEMANNIAN LANGEVIN DYNAMICS
Beskos et al. (2011) first introduced the concept of functional Monte Carlo method on Hilbert space with (second-order) Langevin dynamics. Beskos et al. proved that if the target distribution U () can be represented by the sum of weighted sequence of functionals f with the coefficients of functionals

2

Under review as a conference paper at ICLR 2019

decreasing faster than a polynomial rate, along with other necessary assumptions, sampling the functionals can be equivalent to sampling the posterior U () directly. However, the HMC method cannot adapt to the local geometry and need to tune parameters carefully and in real practice , tuning hyper-parameter can be costly. We want the training algorithm to be scalable and robust to different hyper-parameter settings, we thus extend the Riemannian Langevin dynamics to functional space to make the functional MCMC method more robust.

Similar to Beskos et al. (2011), we represent the posterior U () with its finite approximation

UD() =

D i

iui.

We

denote

the

parameter

of

UD ()

to

be





RD

thus

given





RD ,

we

have

a mapping from  to UD(). Note that this mapping is continuous and bounded. Then by sampling

, we sample a functional f equivalently. The Riemannian Langevin dynamics on the functional

space can thus be written as:

d = b()dt + 2G()dW

(6)

where dW represents the standard Brownian motion, and the drift force b(, ) has the following

form,

b() = -G() U () - () 

(7)

i()

=

-

d j=1

 j

Gij (),

(8)

where Gij is the Riemannian information metric. Similar to its counterpart defined in real number space, we have the following theorem,

Theorem 1. p()  exp (-U ()) is a stationary distribution of the dynamics of Eq. (6), if G() is

a positive semidefinite matrix.

Proof. The Fokker-Planck equation of the dynamics in Eq. (6),



 2

t(, t) = -

i

 i j

bj(, )(, t) + i,j ij 2Gij(, t)

(9)

We

insert

b()

=

-G()

U () 

-

()

into

the

above

equation,

the

Fockker-Planck

equation

can

be simplified as,



t(, t) =

i

 i 

j

{Gij

U () j

-

Gij j

}(,

t)

+

i,j

2 ij 2Gij(, t)

(10)

When (, t) = p(), the stationary distribution will be reached (t(, t) = 0). Then we observe that right hand side of the Fokker Planck equation vanishes. Thus, when p(, t)  exp(-U ()),
t(, t) = 0.

To simulate Functional Riemannian Langevin dynamics for neural networks, we use the following approximate computation for stochastic functional Riemannian Langevin dynamics (SGFuncRLD) for neural networks.

4 APPROXIMATE COMPUTATION

4.1 FINITE FUNCTIONAL APPROXIMATION

We use the mean-field Gaussian approximation to approximate U (). Mean-field Gaussian approximation has been widely used for neural networks and shows good performance for Bayesian inference for neural networks, such as in variational inference (Blei et al. (2017)). We use this approximation and thus U () is represented in a simple one-line form,

N
p(|D)  p(f ) = p(i|D)
i=1

(11)

3

Under review as a conference paper at ICLR 2019

where p(i|D) = N (µi, i|D) and N (µi, i) is a normal distribution with mean µi and standard deviation i. Note that unlike variational inference, we do not have the problem of zero forcing or zero avoiding (Murphy (2013)).

4.2 STOCHASTIC COMPUTATION APPROXIMATION

We use the Fisher information metric as the Riemman information metric (RIM) as in the previous work (Li et al., 2016):

U () U () T G() = E  

(12)

We only use the diagonal part of the RIM and set the remaining part to be zero for computationally purpose,

Gii() = E

U () 2 i

(13)

We approximate the gradients on the dataset with the smoothed gradients on mini-batches for scalable computation. Besides, as we only need to approximate form of RIM, we do not consider () for scalable computation on big data.

We use the gradient computed on the k-th mini-batch {xk1 , . . . , xkm } to approximate the gradient,

U~ () = - N m

m

log p(xkj |) - log p0().

j=1

(14)

However, previous work in optimization literature shows that the smoothed and bias-corrected form

of gradient shows more stable performance than this unbiased stochastic approximation when scaled

to large datasets (Kingma & Ba (2014)), we then approximate the gradient with smoothed and

bias-corrected version,

mt = 1mt-1 + (1 - 1)U~ (t)

(15)

mt = mt/(1 - 1t )

(16)

where mt is the smoothed gradient at step t, 1 is the smoothing coefficient. We also apply the same technique for computing the RIM.

Gt() = 2Gt-1() + (1 - 2)(U~ (t))2 Gt() = Gt()/(1 - 2t ) where Gt is the smoothed gradient at step t, 2 is the smoothing coefficient.

(17) (18)

4.3 STOCHASTIC GRADIENT FUNCTIONAL RIEMANNIAN DYNAMICS
With these approximations, we have the algorithm in Algorithm 1. After we derive samples of the coefficients i for the mean-field Gaussian distribution, we can use Eq. 5 for inference.

5 EXPERIMENTS
In this section, we will first illustrate how functional MCMC method works with functional Hamiltonian dynamics and Hamiltonian dynamics on a double-well potential function. Then we will compare our proposed method with other methods including stochastic gradient Langevin dynamics (Max & Whye, 2011) (SGLD), stochastic gradient Hamiltonian Monte Carlo (Max & Whye, 2011)(SGHMC), preconditioned stochastic gradient Langevin dynamics (Li et al., 2016) (pSGLD) in various examples with neural networks. In the following experiments for neural networks, we set the number of (functional) samples T to be 5, and for functional Bayesian neural network, we set the number of samples from each functional M to be 5. For SGFuncRLD, we set 1 to be 0.9 and 2 to be 0.999. We implement the experiments with Tensorflow and Tensorflow-probability.

4

Under review as a conference paper at ICLR 2019

Algorithm 1: SGFuncRLD for training Bayesian neural networks
1: Input: 1, 2, . 2: Initialize 0, m0, G0. 3: for t = 1, 2, . . . do 4: Randomly sample a minibatch of the dataset to obtain U~ (ft ): 5: Sample t  N (0, I) from the standard Gaussian distribution ; 6: Compute the smoothed gradient mt;
mt = 1mt-1 + (1 - 1)U~ (t), mt = mt/(1 - 1t )

7: Compute the smoothed RIM Gt(); Gt() = 2Gt-1() + (1 - 2)(U~ (t))2,

Gt() = Gt()/(1 - 2t )

8: Update the parameter;

t

=

t-1

-

Gt

()-

1 2

mt

+

9: end for

2Gt()-1 t

5.1 ILLUSTRATION OF FUNCTIONAL MCMC
To illustrate how functional MCMC methods work, we show an example of sampling double-well potential function. Double-well potential function is widely used for evaluating MCMC methods, the target distribution function used is: U () = -22 + 0.24, similar to the one used in Chen et al. (2014). Note that the sampling iteration is set to be 10 instead of 80000 × 50 in the original example (Chen et al. (2014)) to test the methods' ability to efficiently sample the parameter space in a limited amount of time. For Functional MCMC, we set the initialization functional to be a standard normal distribution. We use the Hamiltonian dynamics for the Functional MCMC method-FuncHMC, which is the functional extension of the widely-used Hamiltonian Monte Carlo (HMC). For fair comparison, we use the same parameter for FuncHMC and HMC (learning rate is 0.2, momentum is 0.5). We show the sampled functional from FuncHMC at each step and HMC's samples in Figure 1 (Left). From Figure 1 (Left), we can observe that different from HMC that can only generate one single sample of parameter at each time, FuncHMC generates one sample of distribution function at each time. Even with very few iterations, FuncHMC is able to sample the multi-modal distribution while HMC's samples are concentrated near  = 1. This property can help overcome the curse of dimensionality when sampling for high dimension distributions especially for Bayesian neural networks.
To compare quality of samples generated by FuncHMC or HMC, we use the KLIEP 1 to estimate the ratio distribution of benchmark samples to FuncHMC samples or HMC samples. We use HMC with a learning rate of 0.02 and a momentum of 0.5 and run it for 106 iterations and sample every 100 iterations which gives a total of 1e4 samples as the benchmark samples.
From Figure 1, we can observe that ratio distribution of FuncHMC varies close to the line of y = 1. Though HMC achieves good approximation close to  = 1, HMC fails to correlate well with the benchmark samples within a broader range. For FuncHMC, we generate 100 samples from each posterior functional sampled and this gives us 1000 samples in total from 10 iterations. The plot of the ratio distribution is shown in Figure 1 (Right). From Figure 1 (Right), we can observe that ratio distribution of FuncHMC varies closely to the black horizontal line y = 1. Besides, HMC can achieve good approximation close to  = 1, but it fails to correlate well with the benchmark samples across the distribution range in a limited amount of steps.
Next, we will compare our proposed method SGFuncRLD with other popular SG-MCMC methods for Bayesian neural networks on uncertainty estimation.
5

Under review as a conference paper at ICLR 2019

Probability density function

init

Step1

4 3

Step2 10

Step3

Step4

Step5 Step6

8

Step7

FuncHMC HMC

Step8

Step9 6

2

Step10 HMC

4

1
2

0

2.0

1.5

1.0

0.5 0.0

0.5

1.0

1.5

2.0

0 -2

-1

0

1

2

Figure 1: Left: Sampled functionals by FuncHMC and samples generated by HMC. Right: Ratio distribution of benchmark to FuncHMC or HMC (The closer to the black line y = 1 the better).
1.0

Empirical cumulative distribution

0.8

0.6

0.4

0.2
0.0 0.0

0.5 1.0 1.5 Predictive entropy

SGFuncRLD pSGLD SGHMC SGLD Deterministic
2.0

Figure 2: Empirical cumulative distribution function of predictive entropy (The lower the better).

5.2 UNCERTAINTY ESTIMATION ON OUT-OF-DISTRIBUTION DATA
Accurate uncertainty estimation on unseen data is key to many safety-critical applications, such as autonomous driving and disease diagnosis. To measure the networks' ability on uncertainty estimation for out-of-distribution data, we use a similar experiment setting as in Ritter et al. (2018). We train Bayesian neural networks and the functional Bayesian neural network on the MNIST dataset and use the trained models to predict on the unseen NoMNIST dataset2 that consists of images of letters from "A" to "J" with various fonts. We compare the entropy of predictions on the NoMNIST dataset. The minimum value of the predictive entropy is 0 and the maximum value of the predictive entropy is log(10)  2.30. We use the neural network architecture of conv (6 filters with a kernel size of 5)-pool-conv (16 filters with a kernel size of 5)-pool-conv (120 filters with a kernel siz of 5)-fully connected (84)-fully connected (10), which is the same as in the Tensorflow probability example 3. We train the network for 5000 iterations and use a batch size of 128, which is the same as in the official example. In the training phase, we set the learning rate of SGFuncRLD, pSGLD and Adam(Deterministic method) to be 0.001, SGLD and SGHMC to be 0.1, and the momentum for
1Sugiyama et al. (2008) http://www.ms.k.u-tokyo.ac.jp/software.html 2https://www.kaggle.com/lubaroli/notmnist 3https://github.com/tensorflow/probability/blob/r0.3/tensorflow probability/examples/bayesian neural network.py
6

Under review as a conference paper at ICLR 2019

SGHMC to be 0.1. In the test phase, we draw five samples (functionals) for MCMC methods such as SGFuncRLD, pSGLD, SGHMC and SGLD; For SGFuncRLD, we further draw five samples for each functional; For deterministic training method, one sample is used. We average the predicted probability from samples as the final predicted probability. The empirical cumulative distribution function of predictive entropy on NoMNIST dataset is shown in Figure 2. From Figure 2, we can observe that all MCMC methods can achieve better uncertainty estimation performance than the deterministic method which indicates that Bayesian neural network is necessary for safety-critical applications requiring accurate uncertainty estimation. SGFuncRLD achieves the best performance by predicting the unseen examples with high entropy.
6 UNCERTAINTY ESTIMATION ON ADVERSARIAL ATTACK DATA
Though neural networks have achieved great success in many applications, they are found to be vulnerable to maliciously manipulated perturbation over the original data (Szegedy et al., 2013). To test the neural networks' uncertainty estimates to adversarial attack, we generate the adversarial examples from one instance of each Bayesian neural network trained by different MCMC methods and compute the predictive entropy of the adversarial attack examples from other instances to quantify the uncertainty of the neural network's predictions. We use the same architecture and configuration as the previous experiment but test with MNIST data instead. We use the fast gradient sign method (FGSM) to generate the adversarial data with different attack strength-epsilon. We plot the predictive entropy and accuracy on the attacked data in Figure 3. From Figure 3, we can observe that with the increase of attack strength epsilon, the predictive entropy of SGFuncRLD increases quickly while the accuracy decreases smoothly. When the FGSM attack epsilon is below 0.05, the accuracy remains close to 98% . When the FGSM attack epsilon is above 0.05, the predictive entropy increases quickly while the accuracy decreases smoothly. Note that for other methods, when the attack epsilon is larger than 0.2, the predictive entropy does not increase, which might be dangerous in real practice as the strongly-perturbed data still have high confidence for Bayesian neural network. This indicates that SGFuncRLD trained Functional Bayesian neural network can achieve the best performance on uncertainty estimation on adversarial attack data. We speculate that this is because sampling in the high dimensional space is hard for common MCMC method and the proposed SGFuncRLD can explore the parameter space much more efficiently to capture the multi-modality.
1.0 1.0

Accuracy Predictive entropy

0.8
0.6 SGFuncRLD pSGLD SGHMC
0.4 SGLD

0.8 0.6 0.4

0.2 0.2

0.0 0.00 0.05 0F.1G0SM at0ta.1c5k epsil0o.2n0 0.25 0.30 0.0
Figure 3: Uncertainty estimation on adversarial data. Next, we will test our proposed method's generalization abilities on a practical application.
6.1 TRAFFIC SIGN RECOGNITION To test methods' generalization abilities, we use the German traffic sign recognition benchmarks (GTSRB) dataset. The GTSRB dataset consists of 39209 training images and 12630 test images. We
7

Under review as a conference paper at ICLR 2019

Training error Validation error

further split the training images into two part-34799 images for training, 4410 images for validation. Then We use a neural network with similar architecture as LeNet Lecun et al. (1998). We use the gray version of the traffic sign images and do the image local normalization and normalize the images for pre-processing the data. The code is adapted from the repository 4. The network architecture is conv (6 filters with a kernel size of 5)-pool-conv (16 filters with a kernel size of 5)-pool-fully connected (128)-fully connected (43). We do a grid search to determine the best parameter for each method. The best parameter setting for each method is: SGFuncRLD(learning rate is 0.001), pSGLD(learning rate is 0.0001), SGHMC(learning rate is 0.1, momentum is 0.6), SGLD(learning rate is 0.1). The training and validation curves are shown in Figure 4. From Figure 4, we can observe that the SGLD converges faster among all methods with SGFuncRLD only slower than SGLD. However, different from all other methods, the training and validation curves are more smooth for SGFuncRLD. All methods can achieve similar results after mixing. We speculate that this is because the landscape of loss function in functional space is smoother than the loss function in parameter space because of the mean-field Gaussian approximation. We test the trained models on the test dataset. As we observe that there is some small numerical difference for each run, we run the experiment five times and get the mean and the standard deviation of test accuracy as shown in Table 1. From Table 1, we can observe that the SGFuncRLD can achieve the best generalization performance on the large test dataset.

0.200 SGFuncRLD 0.200 SGFuncRLD

0.175

pSGLD

0.175

pSGLD

SGHMC

SGHMC

0.150 SGLD 0.150 SGLD

0.125 0.125

0.100 0.100

0.075 0.075

0.050 0.050

0.025 0.025

0.000 5 10 E1p5och 20 25 30 0.000 5 10 E1p5och 20 25 30

Figure 4: Left: Training curve. Right: Validation curve.

Method SGFuncRLD pSGLD SGHMC SGLD

Test accuracy 91.67% ± 0.28% 90.17% ± 0.39% 88.35% ± 0.20% 91.10% ± 0.11%

Table 1: Test accuracy of CNN on traffic sign recognition.

7 CONCLUSION
In this work, we extend the Bayesian neural networks to functional Bayesian neural networks for model uncertainty quantification. We propose a novel stochastic functional Riemannian dynamics for training functional Bayesian neural networks. We show the superiority of functional Bayesian neural networks over various examples.
REFERENCES
A. Beskos, F.J. Pinski, J.M. Sanz-Serna, and A.M. Stuart. Hybrid monte carlo on hilbert spaces. Stochastic Processes and their Applications, 121(10):2201 ­ 2230, 2011. ISSN 0304-4149. doi: https://doi.org/10.1016/j.spa.2011.06.003. URL http://www.sciencedirect.com/science/article/pii/ S0304414911001396. 4https://github.com/ColinShaw/python-tensorflow-traffic-sign-recognition-project
8

Under review as a conference paper at ICLR 2019
David M. Blei, Alp Kucukelbir, and Jon D. McAuliffe. Variational inference: A review for statisticians. Journal of the American Statistical Association, 112(518):859­877, 2017. doi: 10.1080/01621459. 2017.1285773. URL https://doi.org/10.1080/01621459.2017.1285773.
Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty in neural network. In International Conference on Machine Learning, pp. 1613­1622, 2015.
T. Chen, E. B. Fox, and C. Guestrin. Stochastic gradient Hamiltonian Monte Carlo. In Proceedings of the 31st International Conference on Machine Learning, pp. 1683­1691, 2014.
Y. Gal and L. Smith. Sufficient Conditions for Idealised Models to Have No Adversarial Examples: a Theoretical and Empirical Study with Bayesian Neural Networks. ArXiv e-prints, June 2018.
Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model uncertainty in deep learning. In International conference on machine learning, pp. 1050­1059, 2016.
Alex Graves. Practical variational inference for neural networks. In Advances in neural information processing systems, pp. 2348­2356, 2011.
Jose´ Miguel Herna´ndez-Lobato and Ryan Adams. Probabilistic backpropagation for scalable learning of bayesian neural networks. In International Conference on Machine Learning, pp. 1861­1869, 2015.
Geoffrey E Hinton and Drew Van Camp. Keeping the neural networks simple by minimizing the description length of the weights. In Proceedings of the sixth annual conference on Computational learning theory, pp. 5­13. ACM, 1993.
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. CoRR, abs/1412.6980, 2014. URL http://dblp.uni-trier.de/db/journals/corr/corr1412.html#KingmaB14.
Yann Lecun, Lon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. In Proceedings of the IEEE, pp. 2278­2324, 1998.
Chunyuan Li, Changyou Chen, David Carlson, and Lawrence Carin. Preconditioned stochastic gradient langevin dynamics for deep neural networks. In AAAI, 2016.
David JC MacKay. A practical Bayesian framework for backpropagation networks. Neural computation, 4(3):448­472, 1992.
Welling Max and Teh Yee Whye. Bayesian learning via stochastic gradient langevin dynamics. In ICML, 2011.
Kevin P. Murphy. Machine learning : a probabilistic perspective. MIT Press, 1 edition, August 2013. ISBN 0262018020. URL http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path= ASIN/0262018020.
Radford M Neal. Bayesian learning via stochastic dynamics. In Advances in neural information processing systems, pp. 475­482, 1993.
Radford M. Neal. Bayesian Learning for Neural Networks. PhD thesis, Toronto, Ont., Canada, Canada, 1995. AAINN02676.
Hippolyt Ritter, Aleksandar Botev, and David Barber. A scalable laplace approximation for neural networks. In International Conference on Learning Representations, 2018. URL https://openreview. net/forum?id=Skdvd2xAZ.
X. Shang, Z. Zhu, B. Leimkuhler, and A. J. Storkey. Covariance-controlled adaptive langevin thermostat for large-scale bayesian sampling. In NIPS, 2015.
Masashi Sugiyama, Shinichi Nakajima, Hisashi Kashima, Paul V. Buenau, and Motoaki Kawanabe. Direct importance estimation with model selection and its application to covariate shift adaptation. In J. C. Platt, D. Koller, Y. Singer, and S. T. Roweis (eds.), Advances in Neural Information Processing Systems 20, pp. 1433­1440. Curran Associates, Inc., 2008.
9

Under review as a conference paper at ICLR 2019 Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian J. Goodfellow,
and Rob Fergus. Intriguing properties of neural networks. CoRR, abs/1312.6199, 2013. URL http://arxiv.org/abs/1312.6199. Nanyang Ye, Zhanxing Zhu, and Rafal Mantiuk. Langevin dynamics with continuous tempering for training deep neural networks. In Advances in Neural Information Processing Systems, pp. 618­626, 2017.
10

