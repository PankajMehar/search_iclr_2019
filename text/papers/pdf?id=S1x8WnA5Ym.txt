Under review as a conference paper at ICLR 2019
LEARNING DIVERSE GENERATIONS USING DETERMINANTAL POINT PROCESSES
Anonymous authors Paper under double-blind review
ABSTRACT
Generative models have proven to be an outstanding tool for representing highdimensional probability distributions and generating realistic looking images. A fundamental characteristic of generative models is their ability to produce multimodal outputs. However while training, they are often susceptible to mode collapse, which means that the model is limited in mapping the input noise to only a few modes of the true data distribution. In this paper, we draw inspiration from Determinantal Point Process (DPP) to devise a generative model that alleviates mode collapse problem while producing higher quality samples. DPP is an elegant probabilistic measure used to model negative correlations within a subset, and hence quantify its diversity. We propose a generation penalty term that encourages the generator to behave as a Determinantal Point Process sampler and hence learns to generates diverse data. In contrast to previous state-of-the-art generative models that tend to use additional trainable parameters or complex training paradigms, our method does not change the original training scheme. Embedded in an adversarial strategy, our Generative DPP approach shows a consistent resistance to mode-collapse on a wide-variety of synthetic data and natural image datasets including MNIST and CIFAR10, while outperforming state-of-the-art methods for data-efficiency, convergence-time, and generation quality. Our code will be made publicly available.
1 INTRODUCTION
Deep generative models have gained enormous research interest in the recent years as a powerful framework to learn high dimensional data in unsupervised fashion. Generative Adversarial Networks (GANs) (Goodfellow et al., 2014) are among the most dominant generative approaches, and consist of training two networks: a generator and a discriminator. The generator attempts to map random noise to fake data points that simulate the probability distribution of real data. In adversary, the discriminator aims to distinguish real data from fake data. The constant competition between the networks results in improved performance of both of them. GANs are typically attributed with high quality and sharp images. Nevertheless, in the process of learning such multi-modal complex distribution, the system may converge to a trivial solution where the generator only learns to produce few modes exclusively, as referred as the mode collapse problem.
To address this, we propose to model the generator as a Determinantal Point Process (DPP) sampler hence it learns to generates diverse examples. DPP is a probabilistic model that has been mainly adopted to solve subset selection problems with diversity constraints (Kulesza & Taskar, 2011), such as video and document summarization. In these application, DPPs maximizes the diversity selected subset to be diverse. From generation perspective, we instead start with generator G suffers from mode collapse and we aim at teaching it to generate a subset or all possible generations with diversity constraints. The key idea is to design a diversity loss function that encourages the generator to behave as a DPP sampler with a simple and tractable approach. By attempting to force the generator on producing samples of similar diversity distribution to the true-data distribution, the generator learns to explicitly cover significantly more modes of the real distributions alleviating the mode collapse problem, see Fig. 1.
Recent approaches tackled the mode-collapse problem in one of two different ways: (1) improving the learning of the system to reach a better convergence point(e.g. Metz et al. (2017); Arjovsky &
1

Under review as a conference paper at ICLR 2019

pdata(x)

p1 p2

p3

p1 p2

p3

v22ffaakkee

v1f ake 1f ake

v2real 1real 2 real

v 1 real

p0(z)

p(z) with DPP

p1 p2

p3

(a) Avoiding mode collapse by enforcing a diverse set of data sampling modeled by a DPP P (Y = {p1, p3}) > P (Y = {p1, p2}).

(b) Our diversity criterion inspired from DPP learns a matrix via an extra output branch in the discriminator. The fake eigenvalues and eigenvectors are enforced to be close to the real ones.

Figure 1: Intuition behind our approach: As we aim to generate samples from a distribution as close as possible to the true data distribution (a, top) and avoid mode collapse (a, middle), we add an extra criterion to the generator, we denote as Generative Determinantal Point Process (GDPP) loss. The loss aims at encouraging our generator G to behave as a DPP and hence generate diverse examples. For example, we aim to encourage sampling p1 and p3 than sampling p1 and p2. (b) In our model, the diversity of the learned distribution is enforced to be close to the diversity of real data.

Bottou (2017)); or (2) explicitly enforcing the models to capture diverse modes or map back to the true-data distribution (e.g. Srivastava et al. (2017); Che et al. (2017)). Here we focus on a relaxed version of the former, where we use the same learning paradigm of the standard GANs and only change the objective function. The advantage of such an approach is to avoid adding any extra trainable parameters to the trained system while maintaining the same back-propagation steps as the standard GANs. Thus, our model converges faster to a fair equilibrium point where the generator captures the diversity of the true-data distribution while preserving the quality of the generations.
Contribution. We introduce a new loss function, we denote as Generative Determinantal Point Processes (GDPP) loss. Our loss only assumes an access to a Generator G, a feature extraction function (·), and sampler from true data distribution pd. The loss encourages the generator G to behave as a DPP sampler producing diverse examples. This criterion can be considered as a complement to the original adversarial loss which attempts to learn an indistinguishable distribution from the true-data distribution without being specific to diverse modes. We assess the performance of GDPP on three different synthetic data environments, while also verifying the superiority on two real-world images datasets. We compared our approach with state-of-the-art approaches of more complex architectures and learning paradigms and our experiments show that outperforms all the competing methods in terms of alleviating mode-collapse, and the generator quality.
2 RELATED WORK
Among the tremendous amount of work that tackle the training challenges of Generative Adversarial Networks (GANs), a few methods stood out as significant contributions towards addressing the problem of mode collapse.
Methods that map the data back to noise. (Donahue et al., 2017; Dumoulin et al., 2017) are one of the earliest methods that proposed learning a reconstruction network besides learning the deep generative network. Adding this extra network to the system aims at reversing the action of the generator by mapping from data to noise. Likelihood-free variational inference (LFVI) (Tran et al., 2017), merge this concept with learning implicit densities using hierarchical Bayesian modeling. Ultimately, VEEGAN (Srivastava et al., 2017) used the same concept, but the authors did not base their reconstruction loss on the discriminator. This has the advantage of isolating the generation process from the discriminator's sensitivity to any of the modes. Che et al. (2017) proposed several ways of regularizing the objective of adversarial learning including geometric metric regularizer, mode regularizer and manifold-diffusion training. Mode regularization, specifically has shown a potential into addressing the mode collapse problem and stabilizing the GANs training in general.
2

Under review as a conference paper at ICLR 2019

Methods that provide a surrogate objective function. Chen et al. (2016) on the other hand propose with InfoGAN an information-theoretic extension of GANs that obtains disentangled representation of data by latent-code reconstitution through a penalty term in its objective function. InfoGAN includes an autoencoder over the latent codes; however it was shown to have stability problems similar to the standard GAN and requires stabilization tricks. Ghosh et al. (2018) base the ModeGAN method on the assumption of the availability of sufficient samples of every mode on the training data. In particular, if a sample from the true data distribution belongs to a particular mode, then the generated fake sample is likely to belong to the same mode. The Unrolled-GAN of Metz et al. (2017) propose a novel objective to update the generator with respect to the unrolled optimization of the discriminator. This allows training to be adjusted between using the optimal discriminator in the generator's objective. It has been shown to improve the generator training process which in turn helps to reduce the mode collapse problem. Generalized LS-GAN of Edraki & Qi (2018) define a pullback operator to map generated samples to the data manifold. There is however no specific enforcement of diversity of samples. Spectral normalization strategies have been recently proposed in the works of Miyato et al. (2018) and SAGAN (Zhang et al., 2018) to further stabilize the training. We note that these strategies are orthogonal to our contribution and could be implemented in conjunction with ours to further improve the training stability of generator models. Finally, improving the Wasserstein GANs of Arjovsky et al. (2017), WGAN-GP (Gulrajani et al., 2017) introduce a gradient penalization employed in state-of-the-art systems (Karras et al., 2018).
Methods that use multiple generators. One of the popular methods to reduce mode collapse is using multiple generator networks to provide a better coverage of the true data distribution. Liu & Tuzel (2016) propose using two generators with shared parameters to learn the joint distribution of the data. The two generators are trained independently on two domains to ensure diverse generation. However, sharing the parameters guide both the generators to a similar subspace. Also, Durugkar et al. (2017) propose a similar idea of multiple discriminators that are being ensemble, which was shown to produce better quality samples. Recently, Ghosh et al. (2018) proposed MAD-GAN which is a multi-agent GAN architecture incorporating multiple generators and one discriminator. Along with distinguishing real from fake samples, the discriminator also learns to identify the generator that generated the fake sample. The learning of such system implies forcing different generators to learn unique modes, which helps in a better coverage of data modes. In contrast to these approaches, our DPP-GAN does not require the training of extra networks.

3 BACKGROUND

3.1 DETERMINANTAL POINT PROCESS (DPP)

DPP is a probabilistic measure that was introduced in quantum physics( Macchi (1975)) and have been studied extensively in random matrix theory( Hough et al. (2006)). It provides a tractable and efficient means to capture negative correlation with respect to a similarity measure, that in turn can be used to quantify the diversity within a subset. A key characteristic in DPP that the model is agnostic about the order of items as pointed out by Gong et al. (2014), and therefore can be used to model data that is randomly sampled from a certain distribution.
A point process P on a ground set V is a probability measure on the power set of V (i.e., 2N ), where N = |V| is the size of the ground set. A point process P is called determinantal if, given a random subset Y drawn according to P, we have for every S  Y ,

P(S  Y )  det(LS)

(1)

for some symmetric similarity kernel L  RN×N . L must be real, positive semidefinite matrix L I (all the eigenvalues of L is between 0 and 1); since it represents a probabilistic measure and all of its principal minors must be non-negative.

L is often referred to as the marginal kernel because it contains all the information needed to compute
the probability of any subset S being selected in V. LS denotes the sub-matrix of L indexed by S. Hence, the marginal probability of including one element ei is p(ei  Y ) = Lii, and two elements ei and ej is LiiLjj - 2Li2j = p(ei  Y )p(ej  Y ) - Li2j. A large value of Lij reduces the likelihood of both elements to appear together. The kernel L is indexed by the elements of S, where
LS  [Lij]; i, j  S. Kulesza & Taskar (2010) proposed decomposing the kernel L as a Gram

3

Under review as a conference paper at ICLR 2019

matrix:

P(S  Y )  det((S) (S)) q2(ei),

(2)

ei Y

Here q(ei)  0 may be seen as a quality score of an item ei in the ground set V, while i  RD; D  N and ||i||2 = 1 is used as an 2 normalized feature vector of an item. In this manner,
i j  [-1, 1] is evaluated as a "normalized similarity" between items ei and ej of V, and the kernel L is guaranteed to be real positive semidefinite matrix.

Geometric interpretation. det((S) (S)) = i i, where i is the ith eigen value of the matrix (S) (S). Hence, we may visualize that DPP models diverse representations of data because the determinant of (S) (S) corresponds to the volume in n-D represented by the multiplication of the variances of the data (i.e., the eigen values).
DPP in literature: DPP has proven to be a tremendously valuable tool when addressing the problem of diversity enforcing such as document summarization (e.g., Kulesza & Taskar (2011); Hong & Nenkova (2014)), pose estimation (e.g., Gupta (2015)) and video summarization (e.g., Gong et al. (2014); Mahasseni et al. (2017)). For instance, Zhang et al. (2016) proposed to learn the two parameters q,  in Eq. 2 to quantify the diversity of the kernel LS Recently. Hsiao & Grauman (2018) proposed to use DPP to automatically create capsule wardrobes, i.e. assemble a minimal set of items that provides maximal mix-and-match outfits given an inventory of candidate garments.

3.2 GENERATIVE ADVERSARIAL NETWORKS (GANS)

GANs (Goodfellow et al., 2014) learn to sample from a distribution by training two networks, a generator G and a discriminator D to compete with each other.

min G

max D

V

(D,

G)

=

Expdata [log

D(x)]

+

Ezpz [log(1 - D(G(z)))],

(3)

where x is a real image from the data distribution pdata, z is a noise vector sampled from distribution pz (e.g., uniform or Gaussian distribution). In practice, the generator G and the discriminator D, are trained by sampling two batches from real images and fake images. By optimizing D and
G alternatively, GAN is trained to generate images that emulate the training distribution pdata. However, as described in the literature, a generator with a good capability to sample a few images
of the real data would minimize Eq. 3, making standard GANs suffer from mode-collapse problem.

4 GENERATIVE DETERMINANTAL POINT PROCESSES

We now introduce our Generative Determinantal Point Processes (GDPP) loss, which encourages learning to sample data that match the diversity of the true distribution. The key idea is to quantify the negative correlation within a discrete data distribution. For that, we utilize DPP to construct a diversity kernel for the true data distribution as well as for the fake data distribution. Then we encourage the generator to synthesize samples with a diversity similar to the diversity of real data.

During training, we have access to a generator G that produces a batch of samples SB = {e1, e2, · · · eB}, where B is the batch size. In order to have a set of diverse generations, we aim
at producing SB that is probabilistically sampled with a DPP

P(SB  Y )  det(LSB ),

(4)

such that Y is a random variable that represents a subset drawn with a generative point process P,
and LSB is the kernel matrix of the subset indices by S, as detailed in Sec. 3.1. Connecting DPP to the data generation, we assume that G is the point process sampler that generates the subset SB according to P. Let (SB)  Rd×B be a feature representation of the generated subset SB, where (·) is some feature extraction function.

LSB = (SB) (SB); SB = G(zB)

(5)

where zB  Rdz×B is noise vector that corresponds to the generated subset SB.

Formally speaking, we aim at matching P(SB  Y )  [det(LSB ) = i fi ake] to P(DB  pd)  [det(LDB ) = i ri eal], where DB is a batch sampled from the real data distribution pd, ri eal and

4

Under review as a conference paper at ICLR 2019

fi ake are the ith eigenvalues of LDB and LSB respectively. Hence, the problem is reduced to learn a fake diversity kernel LSB close to the real diversity kernel LDB . As demonstrated in Figure 1b, we choose to solve the learning problem by optimizing the eigenvalues and eigenvectors of the fake
kernel to match their corresponding ones of the real kernel.

Our GDPP loss is composed of two components: diversity magnitude loss Lm, and diversity structure loss Ls as follows:

LgDP P = Lm + Ls =

ri eal - fi ake 2 -

^ri eal cos(vrieal, vfi ake)

ii

(6)

where vfi ake and vrieal are the ith eigenvectors of LDB and LSB respectively. ^ireal are the min-max normalized version of its corresponding eigenvalues ri eal. We note that   0 for both fake and real data, since both LSB and LDB are guranteed to be positive semidefinite matrices.

Scaling the structure loss aims to induce noise invariance within the eigenvectors similarity learning.
This can be seen as alleviating the effect of outlier structures that intrinsically exist within the real data on learning the diversity kernel of fake data. We note that all the eigenvalues of LSB and LSD will be real non-negatives since both of the kernels are symmetric semi-positive definite. Therefore,
the kernels represent a probability measure since none of the principal minors will be negative.

Integrating GDPP loss with GANs. We choose to integrate our GDPP loss with GANs. Since
we aim to avoid adding any extra trainable parameters, we utilize features that are extracted by the
discriminator. We choose to use the hidden activations before the last layer as our feature extraction function (.). We apply 2 normalization on the obtained features that guarantees constructing a positive semi-definite matrix according to eq. 2. We finally integrate LDg P P into the GAN objective by only modifying the generator loss as follows:

Lg = Ezpz [log(1 - D(G(z)))] + LDg P P .

(7)

5 EXPERIMENTS

In our experiments, we target evaluating the generation based on two criteria: mode collapse and generated samples quality. Due to the intractability of log-likelihood estimation, this problem tends to be non-trivial in real data. Therefore, we start by analyzing our method on synthetic data where we can accurately evaluate the performance. Then, we demonstrate the effectiveness of our method on real data using standard evaluation metrics. We note that the same architecture is used for all the methods on the same data; one for synthetic data and one for the real datasets (See appendix A for details).

5.1 SYNTHETIC DATA EXPERIMENTS
Mode collapse and the quality of generations can be explicitly evaluated on synthetic data since the true distribution is well-defined. In this section, we evaluate the performance of the methods on

GAN

ALI Unrolled-GAN VEE-GAN WGAN-GP GDPP-GAN

Figure 2: Scatter plots of the true data(green dots) and generated data(blue dots) from different GAN methods trained on mixtures of Gaussians arranged in a ring (top) or a grid (bottom).
5

Under review as a conference paper at ICLR 2019

GAN ALI Unrolled GAN VEE-GAN WGAN-GP GDPP-GAN

2D Ring

Modes % High Quality

(Max 8)

Samples

1 99.3

2.8 0.13

7.6 35.6

8.0 52.9

6.8 59.6

8.0 71.7

2D Grid

Modes % High Quality

(Max 25)

Samples

3.3 0.5

15.8 1.6

23.6 16.0

24.6 40.0

24.2 28.7

24.8 68.5

1200D Synthetic

Modes % High Quality

(Max 10)

Samples

1.6 2.0

3 5.4

0 0.0

5.5 28.3

6.4 29.5

7.4 48.3

Table 1: Sample quality and degree of mode collapse on mixtures of Gaussians. GDPP-GAN consistently captures the highest number of modes and produces better samples.

mixtures of Gaussian of known mode locations and distribution (See appendix B for details). We use the same architecture for all the models, which is the same one used by Metz et al. (2017) and Srivastava et al. (2017). Fig. 2 displays the effect of each method on the 2D Ring and Grid data. As shown by the vanilla-GAN in the 2D Ring example (Fig. 2a), it can generate the highest quality samples however it only captures a single mode. On the other extreme, the WGAN-GP on the 2D grid (Fig. 2k) captures almost all the modes in the true distribution, but this is simply because it generates highly scattered samples that do not precisely depict the true distribution. GDPP-GAN (Fig. 2f,l) creates a precise representation of the true data distribution reflecting that the method learned an accurate structure manifold.
Performance Evaluation: In every iteration of our experiments, we sample fake points from the generator and real points from the given distribution. The mode collapse is quantified by the number of real modes recovered in fake data, and the generation quality is quantified by the % of High Quality Samples. A generated sample is counted as high-quality if it was sampled within three standard deviations in the case of the 2D Ring or 2D Grid, and ten standard deviations in the case of the 1200D data. We train all the models for 25K iterations, except for VEEGAN which is trained for 100K iterations. At inference time, we generate 2500 samples from each of the trained models and measure both metrics. We report the numbers averaged over five runs with different random initialization in Table 1. GDPP-GAN clearly outperforms all other methods, for instance on the most challenging 1200D dataset that was designed to mimic a natural data distribution, bringing a 63% relative improvement in high quality samples and 15% in mode detection over its best competitor WGAN-GP.
Ablation Study: We run a study on the 2D Ring and Grid data to show the individual effects of each component in our loss. As shown in Table 2, learning only the structure is prone to being affected by outlier structures introduced by the noise in the data and in the learning process. However, when scaling the structure loss by the true-data eigenvalues seems to better isolate the model from the noise that exist within the true-data features and only focus on learning the dominant structure.
Data-Efficiency: We evaluate the amount of training data needed by each method to reach the same local optima as evaluated by our two metrics on both the 2D Ring and Grid data. Since we are sampling the true-data from a mixture of Gaussians, we can generate an infinite size of training data. Therefore, we can quantify the amount of the training data by using the batch-size while fixing the number of back-propagation steps. In this experiment (Fig. 3a), we run all the methods for the same number of iterations (25,000) and vary the batch size. However, WGAN-GP tends to capture higher quality samples with less data. In the case of the 2D Grid data, GDPP-GAN performs on par with other methods for small amounts of data, yet it tends to significantly outperform other methods on the quality of generated samples once trained on enough data.

Only diversity magnitude Only diversity structure GDPP-loss unnormalized diversity structure GDPP-loss

Lm Ls Lm + Lus Lm + Ls

2D Ring

Modes % High Quality

(Max 8)

Samples

8 67.0

8 65.2

7.2 81.2

8 71.7

2D Grid

Modes % High Quality

(Max 25)

Samples

20.4 15.9

18.2 35.2

20.6 68.8

24.8 68.5

Table 2: GDPP loss Ablation study. Lus is the same as Ls without min-max eigen value normalization

6

Under review as a conference paper at ICLR 2019

# Modes

2D Ring
8 7 6 5
4 GDPP-GAN 3 Unrolled-GAN 2 VEE-GAN 1 WGAN-GP
32 128 Batc5h12Size 1024 2048
2D Grid
25

20

15

GDPP-GAN 10 Unrolled-GAN

5

VEE-GAN WGAN-GP

32 128 Batc5h12Size 1024 2048

High quality samples

High quality samples

2D Ring

80 70 60

GDPP-GAN Unrolled-GAN VEE-GAN

50 WGAN-GP

40

30

20

10

0
32 128 Batc5h12Size 1024

2D Grid
80 GDPP-GAN 70 Unrolled-GAN 60 VEE-GAN 50 WGAN-GP
40 30 20 10 0
32 128 Batc5h12Size 1024

2048 2048

#Modes

#Modes

2D Ring
8

7

6
GDPP-GAN 5 Unrolled-GAN
VEE-GAN 4 WGAN-GP
5Numbe10r of ite1r5ations (2x01000)25
2D Grid

24

22

20

18

GDPP-GAN Unrolled-GAN

16

VEE-GAN WGAN-GP

14

5Numbe10r of ite1r5ations (2x01000)25

High quality samples

High quality samples

2D Ring

70 GDPP-GAN

60 Unrolled-GAN

50 40

VEE-GAN WGAN-GP

30

20

10

0
5Numbe10r of ite1r5ations (2x01000)25

2D Grid
70 GDPP-GAN 60 Unrolled-GAN 50 VEE-GAN 40 WGAN-GP

30

20

10

0
5Numbe10r of ite1r5ations (2x01000)25

# Modes

(a) Examining the effect of training batch size B given the same number of training iterations.

(b) Monitoring convergence at different iterations given the same training data size.

Figure 3: Evaluating the models on the 2D Ring and Grid datasets in terms of (a) data-efficiency and (b) time-efficiency. GDPP-GAN tends to converge faster and require the least amount of training data.

Time-Efficiency: Another metric of interest is which method converges faster given the same amount of training data. In this experiment, we fix the batch size on 512 and run the models for variable number of iterations(Fig. 3b). For the 2D Ring, VEE-GAN captures higher number of modes before GDPP-GAN, however they are of much lower quality than the ones generated by GDPP-GAN. In the 2D Grid data, GDPP-GAN performs on par with unrolled-GAN for the first 5,000 iterations, however it outperforms all the methods significantly afterwards on both of the number of captured modes and the quality of generated samples.
5.2 IMAGE GENERATION EXPERIMENTS
We use the architecture described in (Gulrajani et al., 2017) for evaluating all the models on the Stacked MNIST (Metz et al., 2017) and CIFAR10 datasets. In the evaluation, we mainly focus on comparing to methods that adopt a change in the original adversarial loss. Nevertheless, many of them can be deemed orthogonal to our contribution and can enhance the generation if embedded with our approach. Since our method is cost-free, we observe that the training of GDPP-GAN has an indistinguishable running time than the DCGAN, which are the fastest models to finish training.
Stacked-MNIST A variant of MNIST (LeCun, 1998) designed to increase the number of discrete modes in the data. The data is synthesized by stacking three randomly sampled MNIST digits along the color channel resulting in a 28x28x3 image. In this case, Stacked MNIST has 1000 discrete modes corresponding to the number of possible triplets of digits. Following (Gulrajani et al., 2017), we generate 50,000 images that are later used to train the networks. We train all the models for 15,000 iterations, except for DCGAN and unrolled-GAN that need 30,000 iterations to converge to a reasonable local-optima. We follow (Srivastava et al., 2017) to evaluate the methods on the number of recovered modes and the divergence between the true and fake distributions. We sample 26000 fake images for all the models. We identify the mode of each generated image by using the classifier mentioned in (Che et al., 2017) that is trained on standard MNIST dataset to classify each channel of the fake sample. The quality of samples is evaluated by computing the KL-divergence between the generated label distribution and the training labels distribution.
CIFAR-10 Finally, we evaluate the methods on CIFAR-10 after training all the models for 100K iterations. Unlike Stacked-MNIST, the modes are intractable in this dataset. To assess the performance on real-world images, we use two metrics: Inception Score for the generation quality and Inference-via-Optimization for diversity. As shown in the Quantitative results on CIFAR and Stacked MNIST (Table 3), GDPP-GAN consistently outperforms all other methods in both mode collapse and developing higher quality samples.
Inference-via-optimization (Metz et al., 2017) has been used to assess the severity of mode collapse in any generator by providing a way to compare real images with the nearest generated image. In the case of mode collapse, there are some real images for which this distance is large. We sample a real
7

Under review as a conference paper at ICLR 2019

DCGAN (Radford et al., 2016) Unrolled-GAN (Metz et al., 2017) RegGAN (Che et al., 2017) WGAN (Arjovsky et al., 2017) WGAN-GP (Gulrajani et al. (2017)) GDPP-GAN (Ours)

Stacked-MNIST

#Modes (Max 1000) KL div.

427 3.163

817 1.430

955 0.925

961 0.140

995 0.148

1000

0.135

CIFAR-10
Inception score IvO 5.26 ± 0.13 0.0911 5.43 ± 0.21 0.0898 5.91 ± 0.08 0.0903 5.44 ± 0.06 0.0891 6.27 ± 0.13 0.0891 6.58 ± 0.10 0.0883

Table 3: Performance of various methods on real datasets. Stacked-MNIST is evaluated using the number of captured modes (Mode Collapse) and KL-divergence between the generated class distribution and true class distribution (Quality of generations). CIFAR-10 is evaluated by Inference-via-Optimization (Mode-Collapse) and Inception-Score (Quality of generations).

Figure 4: Real images and their nearest generation from Figure 5: Evolution of the generations quality

CIFAR-10.

throughout the training as measured by the in-

ception score on CIFAR-10.

image x from the test set of real data. Then we optimize the 2 loss between x and generated image G(z) by modifying the noise vector z. If a method attains low MSE, then it can be assumed that this method captures more modes than ones that attain a higher MSE. As demonstrated by (Srivastava et al., 2017), this metric can be fooled by producing blurry images out of the optimization. That is why inception score is necessary in this evaluation. Inception score (Salimans et al., 2016) is widely used as a metric for assessing the quality of images. It bases its validity from the premise that every realistic image should be recognizable, which means that the score distribution for it must be, meaning that it is ideally dominated by one class. Randomly generated sample images can be seen in the appendix, and Fig. 9 presents some test images with their nearest generations. We also assess the stability of the training, by calculating the inception score at different while training on CIFAR-10 (Fig. 5). Evidently, DCGAN has the most unstable training, while GDPP-GAN tends to generate high-quality images the earliest on training with a stable increase.
6 CONCLUSION
In this work, we introduce a novel criterion to train generative networks on capturing a similar diversity to the one of the true data by utilizing Determinantal Point Process(DPP) . We apply our criterion to Generative Adversarial training by learning a kernel via features extracted from the discriminator. We train the generator on optimizing a loss between the fake and real eigenvalues and eigenvectors of this kernel to simulate the diversity of the real data. Our GDPP framework accumulates many desirable properties: it does not require any extra trainable parameters, it works in an unsupervised setting, and outperforms state-of-the-art on synthetic data and real image datasets for both generation quality and invariance to mode collapse. Furthermore, GDPP-GANs exhibit a stabilized training as compared to other paradigms, and has been shown to be time and data efficient as compared to stateof-the-art approaches. Moreover, the GDPP criterion is architecture and model invariant. Therefore, we aim on future work to explore incorporating the GDPP criterion with orthogonal methods such as adversarial feature learning, conditional GANs, and other generative models as well as deeper architectures.
8

Under review as a conference paper at ICLR 2019
REFERENCES
Martin Arjovsky and Le´on Bottou. Towards principled methods for training generative adversarial networks. stat, 1050:17, 2017.
Martin Arjovsky, Soumith Chintala, and Le´on Bottou. Wasserstein gan. stat, 1050:26, 2017.
Tong Che, Yanran Li, Athul Paul Jacob, Yoshua Bengio, and Wenjie Li. Mode regularized generative adversarial networks. ICLR, 2017.
Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. Infogan: Interpretable representation learning by information maximizing generative adversarial nets. In NIPS, 2016.
Jeff Donahue, Philipp Kra¨henbu¨hl, and Trevor Darrell. Adversarial feature learning. ICLR, 2017.
Vincent Dumoulin, Ishmael Belghazi, Ben Poole, Olivier Mastropietro, Alex Lamb, Martin Arjovsky, and Aaron Courville. Adversarially learned inference. ICLR, 2017.
Ishan Durugkar, Ian Gemp, and Sridhar Mahadevan. Generative multi-adversarial networks. ICLR, 2017.
Marzieh Edraki and Guo-Jun Qi. Generalized loss-sensitive adversarial learning with manifold margins. In ECCV, 2018.
Arnab Ghosh, Viveka Kulharia, Vinay Namboodiri, Philip HS Torr, and Puneet K Dokania. Multiagent diverse generative adversarial networks. CVPR, 2018.
Boqing Gong, Wei-Lun Chao, Kristen Grauman, and Fei Sha. Diverse sequential subset selection for supervised video summarization. In NIPS, 2014.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In NIPS, 2014.
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville. Improved training of Wasserstein GANs. In NIPS. 2017.
Swati Gupta. Determinantal point processes. Lecture notes, 2015.
Kai Hong and Ani Nenkova. Improving the estimation of word importance for news multi-document summarization. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pp. 712­721, 2014.
J Ben Hough, Manjunath Krishnapur, Yuval Peres, Ba´lint Vira´g, et al. Determinantal processes and independence. Probability surveys, 3:206­229, 2006.
Wei-Lin Hsiao and Kristen Grauman. Creating capsule wardrobes from fashion images. In CVPR, 2018.
Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of GANs for improved quality, stability, and variation. ICLR, 2018.
Alex Kulesza and Ben Taskar. Structured determinantal point processes. In NIPS, 2010.
Alex Kulesza and Ben Taskar. Learning determinantal point processes. arXiv:1202.3738, 2011.
Yann LeCun. The MNIST database of handwritten digits. http://yann. lecun. com/exdb/mnist/, 1998.
Ming-Yu Liu and Oncel Tuzel. Coupled generative adversarial networks. In NIPS, 2016.
Odile Macchi. The coincidence approach to stochastic point processes. Advances in Applied Probability, 7(1):83­122, 1975.
Behrooz Mahasseni, Michael Lam, and Sinisa Todorovic. Unsupervised video summarization with adversarial lstm networks. In CVPR, 2017.
9

Under review as a conference paper at ICLR 2019
Luke Metz, Ben Poole, David Pfau, and Jascha Sohl-Dickstein. Unrolled generative adversarial networks. ICLR, 2017.
Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization for generative adversarial networks. ICLR, 2018.
Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. ICLR, 2016.
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. In NIPS, 2016.
Akash Srivastava, Lazar Valkoz, Chris Russell, Michael U Gutmann, and Charles Sutton. Veegan: Reducing mode collapse in GANs using implicit variational learning. In NIPS, 2017.
Dustin Tran, Rajesh Ranganath, and David M Blei. Deep and hierarchical implicit models. CoRR, abs/1702.08896, 2017.
Han Zhang, Ian Goodfellow, Dimitris Metaxas, and Augustus Odena. Self-attention generative adversarial networks. arxiv 1805.08318, 2018.
Ke Zhang, Wei-Lun Chao, Fei Sha, and Kristen Grauman. Video summarization with long shortterm memory. In ECCV, 2016.
10

Under review as a conference paper at ICLR 2019

SUPPLEMENTARY MATERIAL
A NETWORK ARCHITECTURES
The architectures of the generator and discriminator networks employed in our experiments are given in Figure 6.

Z
Generator
FC-128 Tan h
FC-128 Tan h FC-2
linear

Discriminator

(x,y)

FC-128

Tanh

FC-128

Tanh


FC-1 Sigmoid

Z Generator
FC-4096 BatchNorm
Relu Reshape Deconv2d-128 BatchNorm
Relu Deconv2d-64 BatchNorm
Relu Deconv2d-28*28*3
Sigmoid

Discriminator

Image

Conv2D-64

BatchNorm

L-Relu

Conv2D-128

BatchNorm

L-Relu

Conv2D-256

BatchNorm

L-Relu

Reshape


FC-1 Sigmoid

(true, false)

(true, false)

(a) (b)
Figure 6: (a) Architectures employed in the synthetic experiments. (b) Architectures employed in our image generation experiments.

11

Under review as a conference paper at ICLR 2019
A.1 HYPERPARAMETERS In all of our experiments, we use Adam Optimizer with 1 = 0.5 and = 1 × 10-8. For the synthetic data experiments, we follow the configurations used by VEEGAN and unrolled-GAN. We use 1 × 10-4 for the discriminator learning rate, and 1 × 10-3 for the generator learning rate. For the Stacked MNIST and CIFAR-10 dataset, we use 2 × 10-4 as the learning rate for both of the generator and the discriminator. To stabilize the training of DCGAN, we follow the protocol in WGAN-GP to train it by applying a learning rate scheduler. The decay is to happen with a ratio of 1/(#max - iters) at every iteration.
B SYNTHETIC DATA COLLECTIONS
The first data collection is introduced in (Metz et al., 2017) as a mixture of eight 2D Gaussian distributions arranged in a ring. This distribution is the easiest to mimic since it only requires the generated data to have an equal repulsion from the center of the distribution, even if it is not targeted to the modes. The second and third collections were introduced by (Srivastava et al., 2017). In the second collection, there is a mixture of twenty-five 2D Gaussian distributions arranged in a grid. Unlike the first collection, this one requires a more structured knowledge of the true data modes' locations. The last collection is a mixture of ten 700 dimensional Gaussian distributions embedded in a 1200 dimensional space. This mixture arrangement mimics the higher dimensional manifolds of natural images, and demonstrates the effectiveness of each method on manipulating sparse patterns.
C ADDITIONAL RESULTS
Figure 7: GDPP-GAN with different random initializations. GDPP-GAN respects the structure of the true data distribution even with poor initializations. On the other extreme, WGAN-GP tends to map the generated data to a disperse distribution covering all the modes with lower quality samples.
12

Under review as a conference paper at ICLR 2019
Figure 8: Random Samples generated by GDPP-GAN on Stacked-MNIST after 15K iterations.
Figure 9: Random Samples generated by GDPP-GAN after 100K iterations.
Figure 10: Fixed noise qualitative samples progression for different models. 13

