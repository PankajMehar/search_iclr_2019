Under review as a conference paper at ICLR 2019
LEARNING INFORMATION PROPAGATION IN THE DYNAMICAL SYSTEMS VIA INFORMATION BOTTLENECK HIERARCHY
Anonymous authors Paper under double-blind review
ABSTRACT
Extracting relevant information, causally inferring and predicting the future states with high accuracy is a crucial task for modeling complex systems. On one hand, the aforementioned challenges require a rigorous mathematical analysis capable of dealing with high-dimensional heterogeneous data streams. On the other hand, this rigorous mathematical framework allows us to learn precise, compact information and be able to coherently propagate measures of uncertainty across spatiotemporal states. To efficiently and rigorously process high-dimensional data coming from complex systems, we advocate for an information theory inspired approach that incorporates stochastic calculus and seeks to determine a trade-off between the predictive accuracy and compactness of the mathematical representation. Mathematically, such a model construction is cast as an optimization problem that maximizes the compression such that the predictive ability and correlation (relatedness) constraints between the original data and compact model are closely bounded. To learn this compact representation of a time-varying complex system and solve the above-mentioned optimization problem we use variational calculus and derive its general solution expressions. Moreover, we provide theoretical guarantees concerning the convergence of the proposed algorithm. To further test the proposed framework, we consider a high-dimensional Gaussian case study and describe an iterative scheme for updating the new model parameters. Using numerical experiments, we demonstrate the benefits on compression and prediction accuracy for a class of dynamical systems. Finally, we apply the proposed algorithm to the real-world dataset of multimodal sentiment intensity and show improvements in prediction with reduced dimensions.
1 INTRODUCTION
The ever-growing use of machine learning dominates plenty of areas. Although it achieves some impressive results for many applications, modeling time-varying complex systems from highdimensional data is still a challenging task and appealing for more investigation. In fact, determining the relevant information, causally inferring and predicting the future states with accuracy is the key for modeling complex systems. Most of the times limited information is available about the true dimensionality and interdependence among components. More precisely, the extraction of relevant features from a set of variables, carefully, to better predict another variable is an important problem. The causal inference of complex systems is made even more challenging by high-dimensionality, which begs for a compact representation. Although there exist a plethora of approaches for complex systems modeling (e.g., multi-input multi-output state space identification (Stoica & Jansson, 2000), expectation maximization (EM) (Martens, 2010), regularization (Chiuso, 2016), graphical models (Meinshausen & Buhlmann, 2006), combined regularization and Bayesian learning (Fox et al., 2008; 2011; Bonettini et al., 2015), kernel-based regularization (Pillonetto & Chiuso, 2015)), the above mentioned problem has not been addressed.
Extracting relevant information to predict another variable has been studied in (Tishby et al., 2000). The authors have introduced the information bottleneck (IB) principle which upon performing soft clustering of the input variable can predict the considered output variable, provided the joint probability distribution. The IB has been successfully applied to speech recognition (Hecht & Tishby,
1

Under review as a conference paper at ICLR 2019

2005), document classification (Slonim & Tishby, 2000), gene expression (Friedman et al., 2001) and deep learning (Tishby & Zaslavsky, 2015), etc, and it has shown good performance.
In the dynamical systems, during progress, several unknown factors add to the observed activity. The identification of information flow which is an inherent property of the system is a critical task for making better future predictions, and representing a given system. We aim to understand the fundamental information flow process by developing an alternate representation of the dynamical process through Information bottleneck hierarchy (IBH).

1.1 MAIN CONTRIBUTIONS
We aim to learn the hierarchical information flow across the given dynamical system. The main contributions of this paper are as follows.
· We propose an alternate compact dynamical system of the given process, with emphasis on the prediction accuracies.
· We formulate a novel optimization setup, compact perception problem, and derive general solution to the information theoretic problem.
· We quantify how most relevant information about future gets transformed at each hop in the alternatively designed dynamical system.
A brief mention of the mathematical notations is provided in the next part.

1.2 DEFINITIONS AND NOTATIONS

In this manuscript, we use capital letters to denote random variables (RVs), and lowercase letters
are used for the realizations. The bold letters are used for multi-variate RVs. For a RV X, with
little abuse of notation, we denote the probability mass function pX (x) as p(X), unless specified otherwise. The expectation operator is denoted as E[.]. A Gaussian distributed multi-variate RV is denoted as X  N (µX, X), where µX and X are the mean vector and covariance matrix, respectively. Next, we present a few information theoretic definitions relevant to this work.

Definition 1. The Kullback-Leibler (KL) divergence (Cover & Thomas, 1991) between two probability mass functions p(·) and q(·) is written as

DKL(p||q) =

p(x) p(x) log .
q(x)

x

(1)

The KL divergence is in general not symmetric, and DKL  0 with DKL(p||q) = 0 if and only if p = q. Using (1), the mutual information between two RVs X and Y is defined as I(X; Y ) = DKL(p(X, Y )||p(X)p(Y )). Next, we state the problem statement addressed in this work.

2 PROBLEM FORMULATION
Many complex systems consist of a large number of interacting dynamic components. In various situations, due to technological limitations or unknown dynamical and structural information about the complex system, we only have partial observations with unknown interdependence among the variables. Consequently, the challenge is how to analyze the given limited (partial) information with high-dimensionality input, and extract only the relevant information from such complex data streams. Under stationary assumptions, (Tishby et al., 2000) proposed the IB as an unsupervised approach to process information. For the sake of completeness, we provide a brief overview of the IB principle.

2.1 INFORMATION BOTTLENECK APPROACH
The IB compresses a variable X into a new stochastic variable B, while maintaining as much information as possible about another variable of interest Y . The variable B operates to minimize the information compression task and to maximize the relevant information. Provided that the relevance

2

Under review as a conference paper at ICLR 2019

of one RV to another is measurable by an information-theoretic metric (i.e., mutual information), the trade-off can be written as the following variational problem

min I(X; B) - I(B; Y ),
p(B |X )

(2)

where  controls the trade-off between the tasks mentioned above. Hence, the variable B, solving the minimization problem (2), encodes the most informative part from the input X about output Y .

Inspired from the IB concept and its internal predictive coding, we propose a causal inference framework for partially observable discrete-time stochastic dynamical systems. More precisely, we label two consecutive dynamic states Xk and Xk+1 to be the input and the output of the bottleneck Bk, respectively. Hence, Bk carries the most informative part (relevant information) from the past about the future. Next, we formalize this idea to create a sequence of bottlenecks to efficiently predict the future of the dynamical system.

2.2 LEARNING INFORMATION PROPAGATION: SETUP

We consider a stochastic dynamical system, involving large number n of random processes X = [X1, X2, ....Xn], evolving in time. A fundamental problem for decision making or prediction is to learn a compressed representation of the system dynamics from high-dimensional data (i.e., system identification). However, the high-dimensionality makes this task challenging, and it needs sophisticated techniques to extract the meaningful information for an appropriate application. In this paper, we propose a framework that focuses only on the dynamics of the relevant information, by learning an alternate representation of the given process.

Xk-1

Xk

Xk+1

time

Bk Bk+1

Figure 1: The IBH across the kth hop of a stochastic dynamical system. Given three consecutive states Xk-1, Xk and Xk+1 of the input process, the stochastic variables Bk, Bk+1 represent dynamics of the alternatively designed process to capture the relevant information.

Adopting an information theoretic representation, we aim to determine Bk and Bk+1 jointly, since they provide compressed predictive information about the system dynamics. Figure 1 summarizes
our objectives, i.e., determine the stochastic variable Bk that not only compresses Xk-1 as much as possible while preserving the relevant information about Xk, but also delivers this information to Bk+1. The variable Bk+1 quantifies the meaningful information about the state of the system at time k + 1, building upon the compressed information received via Bk, thus forming a dynamics of the relevant information.

By construction, the new mapping Bk is designed from Xk-1 to preserve the consistent information about Xk, therefore, given Xk-1, Bk and Xk are independent. Similarly, the mapping Bk+1 is independent of Xk+1 given Bk. Since, Bk+1 carries information from Bk which is compressed representation of Xk-1, then given Bk, Xk-1 and Bk+1 are also independent. With this framework, the following Markov chains are considered: Xk­Xk-1­Bk, Xk+1­Bk­Bk+1, Xk-1­Bk­Bk+1 and Bk­Xk-1­Xk+1.

The trade-off between the compression and preservation of relevant information is defined as the minimum achievable rate I(Xk-1; Bk) subject to constraints on the information processing. This can be termed as a compact perception problem which determines a trade-off between compression representation and predictive characteristics. Formally, this can be written as the following optimization.

min
p(Bk |Xk-1 ),p(Bk+1 |Bk )
subject to

I(Xk-1; Bk)
I(Xk-1; Xk) - I(Bk; Xk) I(Bk; Bk+1) - I(Xk-1; Xk) I(Xk-1; Xk+1) - I(Xk+1; Bk+1)

1 2 3

(3)

3

Under review as a conference paper at ICLR 2019

where the constraints characterize the bounds on the desired prediction at each step. For example, 1 bounds the accuracy of the prediction of Xk by Bk-1. The information flow across alternate dynamical process is controlled by 2. Lastly, 3 defines closeness of prediction of Xk+1 by Bk+1. We show in the Section 3.1, and results in Section 4, that such trade-off can be alternatively studied
by choice of the Lagrange parameters.

3 LEARNING INFORMATION PROCESSING FOR DYNAMICAL SYSTEMS

This section provides the main results concerning solving the compact perception optimization problem in equation (3) under the most general case. Next, this general result is used to study a highdimensional continuous Gaussian distribution. Lastly, we describe an iterative method to update the corresponding parameters.

3.1 LEARNING INFORMATION PROPAGATION: SOLUTION

Finding the alternate dynamical representation, or Bk and Bk+1, as stated in (3) requires to solve a variational problem. To solve this problem, we introduce the Lagrange multipliers ,  and  for the information processing constraints. Hence, the alternative representation (or IBH) can be found by minimizing the following functional:

F = I(Xk-1; Bk) - I(Bk; Xk) +  (I(Bk; Bk+1) - I(Xk+1; Bk+1)) .

(4)

The solution to the functional in (4) can be obtained using the following result.
Theorem 1. The solution that minimizes functional F in equation 4 is given by the following selfconsistent equations:

p(Bk |Xk-1 )

=

p(Bk ) Z1

×

exp

{-DKL

(p(Xk |Xk-1 )||p(Xk |Bk ))

- DKL (p(Bk+1|Bk)||p(Bk+1))

- EBk+1|Bk [DKL (p(Xk+1|Xk-1)||p(Xk+1|Bk+1))] ,

p(Bk+1 |Bk )

=

p(Bk+1) Z2

exp

{-DKL

(p(Xk+1 |Bk )||p(Xk+1 |Bk+1 ))}

,

where Z1 and Z2 are normalizing partition functions.

(5) (6)

Proof. For the sake of simplicity and due to space limitation, a sketch of the proof is given for discrete variables. The Lagrangian associated with the minimization problem is the following

L=F-

1(Xk-1)p(Bk|Xk-1) -

2 (Bk )p(Bk+1 |Bk ),

Bk ,Xk-1

Bk ,Bk+1

(7)

where 1(Xk-1) and 2(Bk) are Lagrange multipliers for the normalization of the distributions p(Bk|Xk-1) and p(Bk+1|Bk), respectively. Taking the derivative of each term of the Lagrangian L with respect to p(Bk|Xk-1), we have

I(Xk-1; Bk)  p(Bk |Xk-1 )

=

p(Xk-1)

log

p(Bk |Xk-1 ) p(Bk )

,

I(Xk; Bk)  p(Bk |Xk-1 )

=

p(Xk-1)

Xk

p(Xk|Xk-1) log

p(Xk|Bk) , p(Xk )

I(Bk; Bk+1)  p(Bk |Xk-1 )

=

p(Xk-1 )DK L (p(Bk+1 |Bk )||p(Bk+1 )),

I(Xk+1; Bk+1)  p(Bk |Xk-1 )

=

-p(Xk-1)

p(Bk+1 |Bk )DK L (p(Xk+1 |Xk-1 )||p(Xk+1 |Bk+1 ))

Bk+1

+ p(Xk-1)DKL(p(Xk+1|Xk-1)||p(Xk+1)).

(8)

Setting the derivative of the Lagrangian equal to zero and arranging the terms we obtain the self consistent equation (5). Note that all the constant terms in the derivative independent of Bk will be

4

Under review as a conference paper at ICLR 2019

captured by the Lagrange multiplier 1(Xk-1). The derivative of the Lagrangian L with respect to p(Bk+1|Bk) involves only the two last terms from the functional F and the term that ensures the
normalization condition. Then, we have

I(Bk; Bk+1)  p(Bk+1 |Bk )

=

p(Bk )

log

p(Bk+1 |Bk ) p(Bk+1)

,

I(Xk+1; Bk+1)  p(Bk+1 |Bk )

=

p(Bk )

Xk+1

p(Xk+1 |Bk )

log

p(Xk+1|Bk+1) . p(Xk+1)

(9) (10)

Thus, the variational condition is written as follows

p(Bk)

log

p(Bk+1 |Bk ) p(Bk+1)

+

DKL

(p(Xk+1 |Bk )||p(Xk+1 |Bk+1 ))

-

2 (Bk )

= 0,

(11)

where 2(Bk) is the summation of the Lagrange multiplier 2(Bk) and the terms independent of Bk+1, and hence the equation (6) follows.

The functional F in (4) may not be convex in the product space of the associated probability simplexes. However, an iterative approach (detailed in the Appendix) similar to the Blahut-Arimoto algorithm (Arimoto, 1972; Blahut, 1972), also observed in (Tishby et al., 2000) can be obtained from the self-consistent equations in Theorem 1. The convergence of the iterations is established through the following result.
Lemma 1. The iterative procedure using the self-consistent equations in Theorem 1 to minimize the functional F in (4) is convergent.
Corollary 1. The IBH solution in Theorem 1 reduces to IB in (2) upon setting Xk-1 = Xk, and   . Proof. With Xk-1 = Xk, the functional of IBH in equation (4) can be written as
F = (1 - )I(Xk-1; Bk) +  (I(Bk; Bk+1) - I(Xk+1; Bk+1)) .
The functional F minimization in the limit of    has one solution of p(Bk|Xk-1) = 1Bk=Xk-1 (such that I(Xk-1; Bk) > 0), and the problem reduces to minimize the following
F^ = I(Xk-1; Bk+1) - I(Xk+1; Bk+1),
where  can be dropped, as   0.
An advantage of using the optimization framework in (3) is that, it can be generalized to any length of the given input dynamical process by properly repeating the second and third constraint. In this work, we have studied the case of length three of the input process. However, the same principles can be used to write the solution for any length of the dynamical system, as will be presented in the future work.

3.2 MEASURING INFORMATION FLOW FOR LINEAR DYNAMICS
Many applications in machine learning involve time series with multi-dimensional observations where each one is assumed to be correlated to the state of observations that evolves in time. Assuming that these observations are corrupted by Gaussian noise, then a linear dynamical system is a promising model for analyzing the provided time series data. Thus, the system dynamics can be modeled similarly as the evolution of a stochastic time-invariant linear system. Assuming that the system is affected by Gaussian noise and the initial state is normally distributed, then the state dynamics is a Gaussian random vector for any time instant. In this case, our framework learns the IBH through Gaussian random vectors.
Recall that the states Xk of the dynamical system under study are jointly Gaussian and without loss of generality we assume that they are centered. As explained previously, our aim is to design Bk and Bk+1 to define an alternate representation which captures dynamics of the relevant information. As proved by prior work (Globerson & Tishby, 2003; Chechik et al., 2005), the optimum solution obtained by a stochastic transformation that is jointly Gaussian with bottleneck's input. Consequently, Bk is jointly Gaussian with Xk-1 and Bk+1. Accordingly, Bk can be represented as a linear transformation of Xk-1, similarly Bk+1 is a linear transformation of Bk. Formally, we write
Bk = Xk-1 + k,

5

Under review as a conference paper at ICLR 2019

12 200 250

one BN

IBH 10

one BN

one BN IBH

IBH 200

150

8

150

6 100

100 4

50 2 50

0 00

0 0.1 0.2 0.3 0.4 0.5

0

2

4

6

80

2

4

6

8

Figure 2: A comparison among single IB (designed locally) and IBH for various size tuples of (Xk-1, Xk, Xk+1), respectively. The horizontal axis denotes required level of information transfer, while vertical is inversely proportional to compression levels.

Bk+1 = Bk + k+1,

(12)

where k and k+1 are centered Gaussian random vectors independent of Xk-1 and Bk, respectively. Given the aforementioned settings, the solution of the minimization problem in equation (3)
is determined by finding the matrices  and , and the covariance matrices k and k+1 . An iterative procedure using Theorem 1 to update the concerned parameters in (12) is presented as the
following result.

Theorem 2. Given the parameters ,  and , the Gaussian bottlenecks Bk = Xk-1 + k and Bk+1 = Bk + k+1 are obtained by performing the following iterations over the parameters

(tk+1) =



B-1k

(t) |Xk

-

(

-

1)

-B1k (t)

+

 T

(t) B-1k+(t1) (t)

-1
,

(t+1) = (tk+1)



-B1k

(t) |Xk

(t)

(I

-

Xk-1

|Xk

-1
Xk-1

)

(tk++11) = (t+1) =

+

T

     (t) -1 (t)

(t) (t) -1

-1

Bk+1 |Xk+1

Xk+1 Xk+1Xk-1 Xk-1

,

-1 (t)
Bk+1 |Xk+1

-

(

-

1)-B1k+(t1)

-1
,

I

-



- 

1

(t)
Bk+1 |Xk+1

B-1k+(t1)

-1
(t)

I

-

(t+1)
Bk |Xk+1

B-1k

(t+1)

,

(13)

where t is the iteration index.

The detailed proof of the Theorem 2 is provided in the Appendix. In the next section, we show some numerical results generated using synthetic data.

4 SIMULATION EXPERIMENTS
We numerically evaluate the results of Theorem 1 and Theorem 2 using synthetically generated Gaussian distribution. Specifically, the covariance matrices for the input dynamical process Xk-1­Xk­Xk+1 are generated numerically for a given size tuple, and we compute the parameters of (12) using (13). The quantities of interest are I(Bk+1; Xk+1) and I(Bk+1; Xk-1) which are indicators of prediction information and inverse of compression, respectively. We compare the prediction/compression behavior of the proposed approach of alternate design of the dynamical system vs designing local IB's between each hop. We show the distinction upon varying the dimensions of the input process (Xk-1, Xk, Xk+1) in Figure 2. It is observed that the gap between prediction (for a fixed level of compression) grows with increase in the input dimensions. The IBH by design takes into account the entire input dynamical system, and construct an alternate representation which provides better prediction at each step, by appropriate choice of the Lagrange parameters , , .
The Lagrange parameters (, , ) control the trade-off between compression and prediction at each step of the alternatively designed dynamical process. In the optimization problem (3),  corresponds

6

Under review as a conference paper at ICLR 2019
(a) (b) (c) Figure 3: Variations of rank() with Lagrange parameters ,  and , when dimension of input dynamics (Xk-1, Xk, Xk+1) is (40, 30, 20). The rank variation is presented by fixing one parameter in each scenario: ( = 100, , ) in (3a), (,  = 10, ) in (3b), and (, ,  = 0.01) in (3c).
to the first constraint, and hence plays a deciding role in prediction accuracy of Bk. The  corresponds to the second constraint, and will control the flow of relevant information across Bk. Finally,  and  together tune the accuracy of prediction using Bk+1. For example, in (12), the information tapping behavior can be visualized by inspecting the ranks of  and  matrices upon varying (, , ). In Figure 3a, the rank() increases upon increasing  for each choice of . Since  appears in front of both prediction and compression expression in (4), it has little effect on the rank() for a fixed  and . Next, in Figure 3b, we observe dynamical effects of the information flow. By fixing , we limit the information acceptance of Bk+1, hence the parameter  can only increase the rank() up to a certain limit by allowing maximum information through Bk. We witness in Figure 3b, that with higher , the parameter  quickly increase the rank(). Now, for a fixed , both  and  intertwine with each other to decide rank(). By fixing , we limit the input information through Bk to Bk+1, or availability, and hence  can only increase the rank() up to certain extent. Similarly, fixing  limits the maximum information that Bk+1 can process, and therefore  can do best narrowly up to some extent. We witness this hyperbolic behavior in Figure 3c.
5 REAL-WORLD DATA: MULTIMODAL SENTIMENT INTENSITY
In this section, we apply the ideas of IBH to extract the features from the challenging multimodal datasets available in the form of time-series. We will be using the CMU Multimodal Sentiment Analysis (CMU-MOSI) dataset (Zadeh et al., 2016) which consists of a total of 2198 videos. Each video comprises of one speaker expressing their opinion in front of the camera. The available modalities are text, visual and audio, and the corresponding features are extracted using GloVe word embeddings (Pennington et al., 2014), Facet (iMotions, 2017) and COVAREP (Degottex et al., 2014), respectively. The extracted feature size are 300 for text, 74 for audio, and 46 for visual component. The extracted features in the form of time-series are aligned across modalities as shown in Figure 4. Specifically, multiple features of visual and audio modality (due to high frame/sampling rate) are time averaged with boundaries corresponding to the text component. For each speaker, we have a total of 20 words with three modalities and the corresponding sentiment intensity being a real number ranging from -3 to 3, with negative values representing negative sentiments and vice-versa. The IBH is applied to various modalities to capture the information flow patterns across them, and in the compressed fashion. We have taken three modalities to be in the following Markov Chain, text­audio­visual. The intuitive reason behind this assumption is that text is the most informative modality for sentiment and hence the first state, while audio and visual follows text in the Markov chain assuming the speaker is being honest in speaking and making visual expressions for a particular sentiment. The data is mean centered and the covariances of three modalities are estimated for each speaker in training as well as testing dataset. However, we have only 20 words and hence 20 samples to estimate the covariance matrix of much larger dimensions. To remedy this less samples problem, we have resorted to something called pooling of the covariance matrix as follows. The covariance matrix of any modality for the ith speaker is written as i = ^ i + (1 - )pool, where ^ i is the estimated covariance from 20 samples, and pool is called pooled covariance matrix
7

Under review as a conference paper at ICLR 2019

I thought they were

average

Figure 4: The alignment of three modalities (text, visual and audio) with averaging of visual and audio features corresponding to the time boundaries obtained from text.

Feature Selection
Early Fusion MFM (Tsai et al., 2018) IBH

# features
8400 8400 1150

binary
51.9% 77.3% 77.4%

7-class
19.1% 35.4% 39.4%

MAE
1.382 0.961 0.922

Table 1: Comparison of sentiment prediction with three different methods of evaluations for early fusion of features vs features extraction by IBH for CMU-MOSI.

which is estimated by taking all of the training data. The parameter  is used to make trade-off between these two matrices and is usually chosen close to 1. The covariance matrices are fed to the algorithm in Theorem 2 to estimate  and  matrices. We use  matrix as feature to predict the sentiment intensity, as this matrix is central to information propagation from text, through audio, to visual component. The low rank of  will be key in reducing the number of features. The values of parameters (, , ) are chosen such that maximum information flow to first bottleneck, by setting high value for , and  close to 1, and low values for  for better compression.
The results are reported for various evaluation methods, namely binary (with positive and negative sentiment) and 7- class classification, and Mean Average Error (MAE) for regression. We compare our performance with naive early fusion of features in raw format, most recent results in the multimodal neural networks (Tsai et al., 2018) vs features processed by IBH, and the numerical results are presented in Table 1. Support Vector Machines (SVM) is used in the cases of early fusion and IBH. The processing of features by IBH has two fold advantage: First, due to compression the dimensionality of the input can be reduced from 8400 to 1150. Second, the performance with respect to various metrics are better.
6 CONCLUSION
In this paper, we have introduced a novel information-theoretic inspired approach to learn the compact dynamics of a time-varying complex system. The trade-off between the predictive accuracy and the compactness of the mathematical representation is formulated as a multi-hop compact perception optimization problem. A key ingredient to solve the aforementioned problem is to exploit variational calculus in order to derive the general solution expressions. Additionally, we have investigated the guaranteed convergence of the proposed iterative algorithm. Moreover, considering a specific class of distributions (Gaussian), we have provided closed-form expressions for the model parameters' update in our algorithm. Interestingly, the proposed compact perception shows improvements in prediction with reduced dimension on challenging real-world problems.
The quantification of information flow across a dynamical system can have an enormous impact on understanding and improving the current state-of-the-art in neural networks as realized in (Tishby & Zaslavsky, 2015). Moreover, modeling with dynamical systems is a standard approach, and by using the proposed framework, we can make a better compact representation of the system. The driving force of a dynamical system can enforce different behaviors of information flow, as realized in defining dynamical entropy by (Sinai, 1959). Therefore, measuring the information flow can help in estimating/differentiating the actual driving component behind the observed activities. Such concepts are useful in predicting brain imagined tasks from observed electroencephalogram activities.

8

Under review as a conference paper at ICLR 2019
REFERENCES
S. Arimoto. An algorithm for computing the capacity of arbitrary discrete memoryless channels. IEEE Transactions on Information Theory, 18(1):14­20, January 1972.
R. Blahut. Computation of channel capacity and rate-distortion functions. IEEE Transactions on Information Theory, 18(4):460­473, July 1972.
S. Bonettini, A. Chiuso, and M. Prato. A scaled gradient projection method for bayesian learning in dynamical systems. SIAM J. Sci. Comput., 37(3):A1297A1318, 2015.
Gal Chechik, Amir Globerson, Naftali Tishby, and Yair Weiss. Information bottleneck for gaussian variables. Journal of machine learning research, 6(Jan):165­188, 2005.
A. Chiuso. Regularization and bayesian learning in dynamical systems: Past, present and future. Annual Reviews in Control - in press, 2016.
T. M. Cover and J. A. Thomas. Elements of Information Theory. New York: Wiley, 1991.
G. Degottex, J. Kane, T. Drugman, T. Raitio, and S. Scherer. COVAREP; a collaborative voice analysis repository for speech technologies. In 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 960­964, May 2014.
Gal Elidan and Nir Friedman. The information bottleneck EM algorithm. CoRR, arxiv:1212.2460, 2012.
E. Fox, E.B. Sudderth, M.I. Jordan, and A.S. Willsky. Bayesian nonparametric inference of switching dynamic linear models. Trans. Sig. Proc., 59(4):1569­1585, April 2011.
Emily B. Fox, Erik B. Sudderth, Michael I. Jordan, and Alan S. Willsky. Nonparametric bayesian learning of switching linear dynamical systems. In Proceedings of the 21st International Conference on Neural Information Processing Systems, NIPS'08, pp. 457­464, 2008.
Nir Friedman, Ori Mosenzon, Noam Slonim, and Naftali Tishby. Multivariate information bottleneck. In Proceedings of the Seventeenth conference on Uncertainty in artificial intelligence, pp. 152­161. Morgan Kaufmann Publishers Inc., 2001.
Amir Globerson and Naftali Tishby. Sufficient dimensionality reduction. Journal of Machine Learning Research, 3(Mar):1307­1331, 2003.
Gene H. Golub and Charles F. Van Loan. Matrix Computations (3rd Ed.). Johns Hopkins University Press, Baltimore, MD, USA, 1996.
Ron M Hecht and Naftali Tishby. Extraction of relevant speech features using the information bottleneck method. In Ninth European Conference on Speech Communication and Technology, 2005.
iMotions. Facial expression analysis, 2017.
James Martens. Learning the linear dynamical system with asos. In Proceedings of the 27th International Conference on International Conference on Machine Learning, ICML'10, pp. 743­750, 2010.
N. Meinshausen and P. Buhlmann. High-dimensional graphs and variable selection with the lasso. The Annals of Statistics, 34(3):1436­1462, 2006.
Jeffrey Pennington, Richard Socher, and Christopher D. Manning. Glove: Global vectors for word representation. In In EMNLP, 2014.
Gianluigi Pillonetto and Alessandro Chiuso. Tuning complexity in regularized kernel-based regression and linear system identification. Automatica, 58(C):106­117, August 2015.
Ya.G. Sinai. On the notion of entropy of a dynamical system. Doklady of Russian Academy of Sciences, 124:768­771, 1959.
9

Under review as a conference paper at ICLR 2019
Noam Slonim and Naftali Tishby. Document clustering using word clusters via the information bottleneck method. In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pp. 208­215. ACM, 2000.
P. Stoica and M. Jansson. Mimo system identification: state-space and subspace approximations versus transfer function and instrumental variables. IEEE Transactions on Signal Processing, 48 (11):3087­3099, Nov 2000.
Naftali Tishby and Noga Zaslavsky. Deep learning and the information bottleneck principle. In Information Theory Workshop (ITW), 2015 IEEE, pp. 1­5. IEEE, 2015.
Naftali Tishby, Fernando C Pereira, and William Bialek. The information bottleneck method. arXiv preprint physics/0004057, 2000.
Yao-Hung Hubert Tsai, Paul Pu Liang, Amir Zadeh, Louis-Philippe Morency, and Ruslan Salakhutdinov. Learning factorized multimodal representations, 2018. arXiv:1806.06176.
A. Zadeh, R. Zellers, E. Pincus, and L. P. Morency. Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages. IEEE Intelligent Systems, 31(6):82­88, Nov 2016.
10

Under review as a conference paper at ICLR 2019

The appendix is arranged as follows: In the Section A, we provide the iterative procedure to minimize the functional in (4). Next, in Section B, we present the detailed proof of the Lemma 1, and finally, in Section C, a detailed proof of Theorem 2 is presented.

A ITERATIVE SOLUTION FOR THEOREM 1

The self-consistent equations derived in Theorem 1 to minimize the functional F in (4) can be used to write the following set of iterative equations.

p(t+1) (Bk |Xk-1 )

=

p(t) (Bk ) Z1(t+1)(, , , Xk-1)

× exp

-DKL

- DKL p(t)(Bk+1|Bk)||p(t)(Bk+1)

p(Xk |Xk-1 )||p(t) (Xk |Bk )

-



(t)
EBk+1

|Bk

DKL

p(Xk+1|Xk-1)||p(t)(Xk+1|Bk+1)

,

(14)

p(t+1)(Bk) =

p(t+1)(Bk|Xk-1) p(Xk-1),

Xk-1

(15)

p(t+1)(Xk|Bk) =

p(Xk|Xk-1) p(t+1)(Xk-1|Bk),

(16)

Xk-1

p(t+1)(Xk+1|Bk) = p(Xk+1|Xk) p(t+1)(Xk|Bk),

(17)

Xk

p(t+1) (Bk+1 |Bk )

=

p(t)(Bk+1) Z2(t+1)(, Bk)

exp

-DKL

p(t+1)(Xk+1|Bk)||p(t)(Xk+1|Bk+1) , (18)

p(t+1)(Bk+1) = p(t+1)(Bk+1|Bk) p(t+1)(Bk),

Bk

p(t+1)(Bk+1|Xk+1) =

p(t+1)(Bk+1|Bk) p(t+1)(Bk|Xk-1) p(Xk-1|Xk+1),

Bk ,Xk-1

(19) (20)

where in equations (15)-(17), (19) and (20) we have used the Markov assumption as stated in Section 2.2.

B PROOF OF LEMMA 1

Proof. The proof of the Lemma 1 can be divided into two parts. First, we show that the F in (4) is lower-bounded. Next, we show that each iteration using the equations (14)-(20) monotonically decrease the functional.

Lower bound: Let us consider the following alternate functional.

F~ = I(Xk-1; Bk) + EXk-1,Bk DKL(p(Xk|Xk-1)||p(Xk|Bk)) +  I(Bk; Bk+1)

 EXk-1,Bk EBk+1|Bk DKL(p(Xk+1|Xk-1)||p(Xk+1|Bk+1)).

(21)

It can be readily verified that the functional F~  0 for given non-negative constants ,  and . Also, the F~ in (21) can be expanded as

F~

=

I(Xk-1; Bk) + EXk-1,Bk

Xk

p(Xk

|Xk-1)log

p(Xk |Xk-1 ) p(Xk |Bk )

+



I (Bk ;

Bk+1)

+



EXk-1 ,Bk

Bk+1 ,Xk+1

p(Xk+1|Xk-1)log

p(Xk+1|Xk-1) p(Xk+1|Bk+1)

= I(Xk-1; Bk) + (I(Xk-1; Xk) - I(Xk; Bk)) +  I(Bk; Bk+1)

+ (I(Xk-1; Xk+1) - I(Xk+1; Bk+1)).

(22)

11

Under review as a conference paper at ICLR 2019

Since the functional F~ in the equation (22) differs from the functional F in (4) only in constants, therefore, F is lower bounded as well.
Monotonicity: For proving monotonic decrement of the functional F, we will use the formulation similar to (Arimoto, 1972). First, let us consider the following observation made in (Tishby et al., 2000).

For a given joint distribution p(X, Y ), we can write the following.

p(Y ) = arg min EX DKL(p(Y |X)||(Y )),
(Y )

(23)

where the minimization is performed over the probability simplex of (Y ) such that the joint distribution is p(X, Y ). The functional F~ in (22) can be written in its most general form as

F~(p1,

p2,

1,

2)

=

EXk-1

,Bk

|Xk-1

p1

log

p1 p(Bk

)

+ EXk-1,Bk|Xk-1p1 DKL(p(Xk|Xk-1)||1)

+



EXk-1 ,Bk |Xk-1 p1

EBk+1 |Bk p2

log

p2 p(Bk )

+  EXk-1,Bk|Xk-1p1 EBk+1|Bkp2 DKL(p(Xk+1|Xk-1)||2),

(24)

where p1 = p(Bk|Xk-1), p2 = p(Bk+1|Bk), 1 = 1(Xk|Bk) and 2 = 2(Xk+1|Bk+1), therefore, F~ reduces to the form in (22) upon setting 1 = p(Xk|Bk) and 2 = p(Xk+1|Bk+1). With the objective of minimizing the functional F~, we can write its value at iteration t as F~(t) =
F^(p1(t), p2(t), 1(t), (2t)). The iterations to minimize F~ will involve the successive choice of tuple (p1, p2, 1, 2). At iteration t, let us assume that we have chosen p(1t) and p(2t), and we define the following

G(t, t)

=

min
1 ,2

F~(p1(t),

p(2t),

1,

2)

= F~(p1(t), p(2t), 1(t), (2t)).

(25)

Using equation (23), it easily follows that (1t) = p(t)(Xk|Bk) and (2t) = p(t)(Xk+1|Bk+1), and hence G(t, t) = F~(t). Now, for fixed p2(t), 1(t), (2t), it can be easily realized that the F~ is convex in p1, therefore, minimizing F~ with respect to (w.r.t.) p1 will involve writing Lagrangian, and then
differentiation, and setting to zero. This step is similar to the Theorem 1, and we can write that

p(1t+1) = arg min F~(p1, p(2t), 1(t), 2(t)),
p1

(26)

where the resulting solution is (5), and hence p(1t+1) will have the expression as in (14). Similarly, for fixed p(1t+1), (1t), (2t), the F~ is convex in p2, and the same steps follow to obtain p(2t+1) as written in (18). It should be noted that the choice to perform minimization w.r.t. p1 before p2 is arbitrary,
and the reverse can also be performed. This will change the order of iteration index in equations
(14)-(20) accordingly. Using equations (25) and (26), we can conclude that

F~(t+1) = G(t + 1, t + 1)  G(t + 1, t)  G(t, t) = F~(t),

and therefore, iterating equations (14)-(20) written using the self-consistent equations of Theorem 1 minimizes F~(t) monotonically. Since F~ and F differs only in constant, it reduces F as well mono-
tonically from above.

C PROOF OF THEOREM 2

Proof. For a multivariate random variable X, X  Rn with Gaussian distribution, i.e. X  N (µ, ), the entropy can be written as

1 H(X) = log det() + c,
2

(27)

12

Under review as a conference paper at ICLR 2019

where c is constant for a given dimension n. Using equation (27), the KL-divergence between two Gaussian distributed random variables, X1  N (µ1, 1) and X2  N (µ2, 2) of the same dimensions, is written as

DKL(p(X1)||p(X2))

=

1 log det(2) 2 det(1)

+

1 2

tr(2-1

1)

+

1 2 (µ2

- µ1)T 2-1(µ2

- µ1).

(28)

We have assumed that the given data is centered, hence all considered random variables will have zero mean, i.e., for characterizing each random variable, we only need the corresponding covariance matrix. Let us revisit the linear transformation model for the IBH.

Bk = Xk-1 + k, Bk+1 = Bk + k+1.

Now, to completely specifying the model, we have to determine the constant matrices ,  and the covariances of k, k+1. Since entropy is well defined for Gaussian distribution, as in (27), due to their nice tail distribution, we can use Theorem 1 and equation (28) to write the self-consistent transition probabilities. First, expressions of the necessary KL-divergence terms are expanded as follows.

DK L (p(Xk |Xk-1 )||p(Xk |Bk ))

=

c

+

1 2 (E

Xk |Xk-1

-

E Xk|Bk)T X-1k|Bk

(E Xk|Xk-1 - E Xk|Bk),

(29)

DK L (p(Bk+1 |Bk )||p(Bk+1 ))

=

c

+

1 2 (E

Bk+1

|Bk

)T

-1
Bk+1

E

Bk+1 |Bk ,

(30)

DKL(p(Xk+1|Xk-1)||p(Xk+1|Bk+1))

=

c

+

1 2 (E

Xk+1|Xk-1

-

E

Xk+1|Bk+1)T

-1
Xk+1 |Bk+1

(E Xk+1|Xk-1 - E Xk+1|Bk+1),

(31)

where c are different constants at each step and,

E Xk|Bk = XkBk B-1k Bk = kBk, Xk|Bk = Xk - XkBk B-1k BkXk
= Xk - XkXk-1 T -B1k Xk-1Xk , E Bk+1|Bk = Bk,

Bk+1|Bk = k+1 ,

E Xk+1|Bk+1

=

Xk+1

Xk-1

T

T

-1
Bk+1

Bk+1

=

k+1Bk+1,

Xk+1 |Bk+1

=

Xk+1

-

Xk+1

Xk-1

T

T

-1
Bk+1

Xk-1

Xk+1

.

Also, using (31), we can write that

EBk+1|Bk DKL (p(Xk+1|Xk-1)||p(Xk+1|Bk+1)) = c

-

EBk+1 |Bk

BkT+1

Tk+1

-1
Xk+1

|Bk+1

E

Xk+1|Xk-1

+

1 2 EBk+1|Bk

BkT+1

kT+1

-1
Xk+1

|Bk+1

k+1

Bk+1

=c

-

BTk

T

 T -1
k+1 Xk+1|Bk+1

E

Xk+1|Xk-1.

(32)

Upon substituting the equations (29)-(31) and (32) in Theorem 1, we obtain the following selfconsistent equations.

log p(Bk|Xk-1)

=

c

-

1 2

BkT

-B1k

Bk

-

 2

BkT

kT

X-1k

|Bk

k

Bk

-

 2

BTk

T

-1
Bk+1

Bk

+

BkT

kT

X-1k|Bk E Xk|Xk-1

+

BkT

T

 T -1
k+1 Xk+1|Bk+1

E

Xk+1|Xk-1.

(33)

13

Under review as a conference paper at ICLR 2019

Now, Bk|Xk-1  N (Xk-1, k ), therefore upon comparing terms, we obtain the following self-consistent equations.

-k1

=

-B1k

+



kT -X1k|Bk k

+



T

-1
Bk+1

,



=

k

(

kT

-X1k |Bk

Xk Xk-1

-1
Xk-1

+

T

 T -1
k+1 Xk+1|Bk+1

Xk+1 Xk-1

-1
Xk-1

).

(34)

Setting up the iterations, similar to Blahut-Arimoto equations, we obtain the following iterative procedure with t as iteration index.

(tk+1) =

B-1k (t)

+



kT

(t)

X-1k

(t) |Bk

(kt)

+



T

(t) -B1k+(t1) (t)

-1

(=a)



-B1k

(t) |Xk

-

(

-

1)

B-1k (t)

+

 T

(t) B-1k+(t1) (t)

-1
,

(t+1)

=

(tk+1)(

kT

(t)

-X1k

(t) |Bk

Xk

Xk-1

-1
Xk-1

+

T

    )(t) T (t) -1 (t)

-1

k+1 Xk+1|Bk+1 Xk+1Xk-1 Xk-1

(=b)

(tk+1)(

-B1k

(t) |Xk

(t)

(I

-

Xk-1

|Xk

-1
Xk-1

)

+

T

(t)

-1 (t)
Bk+1 |Xk+1

(t)

(t)

-1
Xk+1

Xk+1

Xk-1

-1
Xk-1

),

(35)

where in (a) and (b) we have used the expansion of k, k+1, matrix inversion lemma (Golub & Van Loan, 1996), and the identity X|Y XY -Y 1 = -X1XY Y-1|X , where X, Y and Z are Normal distributed random variables. We can also write the transition probability of the bottleneck variables, Bk+1|Bk using Theorem 1 and the following useful expansion of the required KL-divergence term.

DK L (p(Xk+1 |Bk )||p(Xk+1 |Bk+1 ))

=

c

+

1 2 (E

Xk+1|Bk

-

E

Xk+1

|Bk+1

)T

-1
Xk+1

|Bk+1

(E Xk+1|Bk - E Xk+1|Bk+1),

(36)

where,

E Xk+1|Bk = Xk+1Xk-1 T -B1k Bk = kBk, Xk+1|Bk = Xk+1 - Xk+1Xk-1 T B-1k Xk-1Xk+1 .
After substituting equation (36) in (6) of Theorem 1, we obtain

log p(Bk+1|Bk)

=

c

-

1 2

BTk+1

-1
Bk+1

Bk+1

-

 2

BkT+1

kT+1

-1
Xk+1

|Bk+1

k+1

Bk+1

+



BkT+1

Tk+1

-1
Xk+1

|Bk+1

k Bk .

(37)

Again, since Bk+1|Bk  N (Bk, k+1 ), after comparing the terms on both sides of the equation (37), we obtain

-1
k+1

=

-1
Bk+1

+



Tk+1

-1
Xk+1

|Bk+1

k+1

,



=



k+1

Tk+1

-1
Xk+1

|Bk+1

k

.

(38)

After setting up the iterations like we did for equation (34), and using the (18)-(20) we first write that

(t)
Bk+1

=

(t)B(t+k 1)(t)

+

(t)
k+1

,

(t)
Bk+1 |Xk+1

=

(t)

(t+1)
Bk |Xk+1

(t)

+

(t)
k+1

,

(t)
Bk+1 Xk+1

=

(t)

(t+1)
Bk Xk+1

.

(39)

Using (38) and (39), we obtain the following.

(tk++11) =

-1 (t)
Bk+1 |Xk+1

-

(

-

1)B-1k+(t1)

-1
,

14

Under review as a conference paper at ICLR 2019

(t+1)

=

      (t+1) -1 (t)

(t)

-1

T (t) -1 (t+1)

k+1 Bk+1|Xk+1 Bk+1Xk+1 Xk+1 Xk+1Xk-1

Bk

(=a)

I

-



- 

1 (t) -1 (t)  Bk+1|Xk+1 Bk+1

-1
(t)

I

-

(t+1)
Bk |Xk+1

B-1k

(t+1)

,

(40)

where (a) is written using the previously used identity X|Y XY -Y 1 = -X1XY -Y 1|X , and matrix inversion lemma is used at each step.

15

