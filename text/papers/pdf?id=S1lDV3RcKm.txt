Under review as a conference paper at ICLR 2019
LEARNING FROM INCOMPLETE DATA WITH GENERATIVE ADVERSARIAL NETWORKS
Anonymous authors Paper under double-blind review
ABSTRACT
Generative adversarial networks (GANs) have been shown to provide an effective way to model complex distributions and have obtained impressive results on various challenging tasks. However, typical GANs require fully-observed data during training. In this paper, we present a modular approach to learning GANs from incomplete observations that can be combined with different generator and discriminator networks and is amenable for use with complex, high-dimensional inputs. The proposed framework learns a complete data generator along with a mask generator that models the missingness. We further demonstrate how to impute missing data by equipping our framework with an adversarially trained imputer. We evaluate the proposed framework using a series of experiments with several types of missing completely at random missing data processes.
1 INTRODUCTION
Generative adversarial networks (GANs) (Goodfellow et al., 2014) provide a powerful modeling framework for learning complex high-dimensional distributions. Unlike likelihood-based methods, GANs are referred to as implicit probabilistic models (Mohamed & Lakshminarayanan, 2016). They represent a probability distribution through a generator that learns to directly produce samples from the desired distribution. The generator is trained adversarially by optimizing a minimax objective together with a discriminator. In practice, GANs have been shown to be very successful in a range of applications including generating photorealistic images (Karras et al., 2018). Other than generating samples, many downstream tasks require a good generative model, such as image inpainting (Pathak et al., 2016; Yeh et al., 2017).
Training GANs normally requires access to a large collection of fully-observed data. However, it is not always possible to obtain a large amount of fully-observed data. Missing data is well-known to be prevalent in many real-world application domains where different data cases might have different missing patterns. This arbitrary missingness can poses a significant challenge when learning certain kinds of models, including essentially all discriminative models.
Following Little & Rubin (2014), the generative process for incompletely observed data can be described below where x  Rn is a complete data vector and m  {0, 1}n is a binary mask1 that determines which entries in x to reveal:
x  p(x), m  p(m|x). Let xobs denotes the observed elements of x and xmis the missing elements according to the mask m. In addition, let  denote the unknown parameters of the data distribution, and  denote the unknown parameters for the mask distribution, which are usually assumed to be independent of . In the standard maximum likelihood setting, the unknown parameters are estimated by maximizing the following marginal likelihood, integrating over the unknown missing data values:
p(xobs, m) = p(xobs, xmis)p(m|xobs, xmis)dxmis.
Little & Rubin (2014) characterize the missing data mechanism p(m|xobs, xmis) in terms of independence relations between complete data and the masks:
1 The complement m¯ is usually referred to as the missing data indicator in the literature.
1

Under review as a conference paper at ICLR 2019

· Missing completely at random (MCAR): p(m|x) = p(m), · Missing at random (MAR): p(m|x) = p(m|xobs), · Not missing at random (NMAR): m depends on xmis in addition to xobs.

Most work on incomplete data assumes MCAR or MAR because under these assumptions p(xobs, m) can be factorized into p(xobs)p(m|xobs). With such decoupling, the missing data mechanism can be ignored when learning the data generating model while yielding correct estimates for . When
p(x) does not admit efficient marginalization over xmis, estimation of  is usually performed by maximizing a variational lower bound, as shown below, using the EM algorithm or a more general
approach (Little & Rubin, 2014; Ghahramani & Jordan, 1994):

log p(xobs)  Eq(xmis|xobs) [log p(xobs, xmis) - log q(xmis|xobs)] .

(1)

The primary contribution of this paper is the development of a a framework called MisGAN for learning the distribution from high-dimensional data in the presence of incomplete observations. Our framework augments a standard GAN with an auxiliary generator and discriminator to learn the mask distribution for modeling the missingness. The framework learns to generate both complete data examples (as in a standard GAN), and the masks that indicate which entries to be observed. The generated masks are used to "mask" the generated complete data example by filling elements indicated as missing with a constant value. The learning criterion is based on matching the distribution of masked generated data examples to an empirical distribution of the masked data examples, obtained by similarly filling in the missing values in the incompletely observed real data examples with the same constant value. Further, the learning criterion requires that the distribution of the masks match the empirical distribution of the masks associated with the incomplete data.

Our framework builds on the ideas of AmbientGAN (Bora et al., 2018). AmbientGAN modifies the discriminator of a GAN to distinguish corrupted real samples from corrupted generated samples under a range of corruption processes (or measurement processes). For images, examples of the measurement processes include random dropout, blur, block-patch, and so on. Missing data can be seen as a special type of corruption, except that we have access to the missing pattern in addition to the corrupted measurements. Moreover, AmbientGAN assumes the measurement process is known or parameterized only by a few parameters, which is not the case in general missing data problems.

We provide empirical evidence that the proposed framework is able to effectively learn complex, high-dimensional data distributions from highly incomplete data when the structure of the GAN generator provides sufficiently strong constraints over the data generation process. We further show how the architecture can be used to generate high-quality imputations.

2 MISGAN: GAN FOR MISSING DATA

In the missing data problem, we know exactly which entries in each data examples are missing.
Therefore, we can represent an incomplete data case as a pair of a partially-observed data vector x  Rn and a corresponding mask m  {0, 1}n that indicates which entries in x are observed:
xd is observed if md = 1 otherwise xd is missing and might contain an arbitrary value that we should ignore. With this representation, an incomplete dataset is denoted D = {(xi, mi)}i=1,...,N , assumed i.i.d. We choose this representation instead of xobs because it leads to a cleaner description of MisGAN. It also suggests how MisGAN can be implemented efficiently in practice as both x and
m are fixed-length vectors.

We begin by defining a masking operator f that fills in missing entries with a constant value  , where m¯ denotes the complement of m and denotes element-wise multiplication:

f (x, m) = x m +  m¯ .

(2)

Two key ideas underlie the MisGAN framework. First, since the masks in the incomplete dataset are fully observed, we can estimate their distribution using any generative model applicable to fully-observed data. Second, we use two generators, one for generating complete data vectors and the other for generating masks. We combine the output of the two generators with the GAN training framework using f to match the distribution of the masked incompletely observed real data (masked with the same f ) and the masked complete generated data.

2

Under review as a conference paper at ICLR 2019

Specifically, we use two generator/discriminator pairs (Gm, Dm) and (Gx, Dx) for the mask and the data respectively. In this paper, we focus on the case of missing completely at random, where the two
generators are independent of each other and have their own noise distributions pz and p. We define the following two loss functions, one for the masks and the other for the data:

Lm(Dm, Gm) = E(x,m)pD [Dm(m)] - Ep [Dm(Gm())] ,

(3)

Lx(Dx, Gx, Gm) = E(x,m)pD [Dx(f (x, m))] - Ep,zpz [Dx (f (Gx(z), Gm()))] . (4)

The losses above follow the Wasserstein GAN formulation (Arjovsky et al., 2017), although the proposed framework is compatible with many GAN variations (Goodfellow et al., 2014; Berthelot et al., 2017; Gulrajani et al., 2017). We optimize the generators and the discriminators according to the following objectives:

min max Lx(Dx, Gx, Gm),
Gx DxFx
min max Lm(Dm, Gm) + Lx(Dx, Gx, Gm),
Gm DmFm

(5) (6)

where Fx, Fm are defined such that Dx, Dm are both 1-Lipschitz as in Wasserstein GANs (Arjovsky et al., 2017). Practically, we follow the common practice that alternates between a few steps of
optimizing the discriminators and one step of optimizing the generators (Goodfellow et al., 2014; Arjovsky et al., 2017; Gulrajani et al., 2017). The coefficient  is introduced when optimizing the mask generator Gm to aim at minimizing both Lm and Lx. Although in theory we could choose  = 0 to train Gm and Dm using only masks without the data x, we find that choosing a small value such as  = 0.2 gives better performance. This encourages the generated masks not only match
the distribution of the real masks, but under which the masked generated complete samples also
attempt to match the masked real data. The overall structure of MisGAN is illustrated in Figure 8 in
Appendix C.

Note that the data discriminator Dx takes as input the masked samples as if the data are fullyobserved. This allows us to use any existing architecture designed for complete data to construct the data discriminator. There is no need to develop customized neural network modules for dealing with missing data. For example, Dx can be a standard convolutional network for image applications.
Note that the masks are binary-valued. Since discrete data generating processes have zero gradient almost everywhere, to carry out gradient-based training for GANs, we relax the output of the mask generator Gm from {0, 1}n to [0, 1]n. We employ a sigmoid activation (x) = 1/(1 + exp(-x/)) with a low temperature 0 <  < 1 to encourage saturation and makes the output closer to zero or one.

Finally, we note that as result of these modeling choices, the discriminator Dx in MisGAN is unaware of which entries are missing in the masked input samples, and does not even need to know which value  is used for masking. In the next section, we present a theoretical analysis providing support for the idea that this type of masking process does not necessarily make it more difficult to recover the complete data distribution. The experiments provide compelling empirical evidence of the effectiveness of the proposed framework.

3 THEORETICAL RESULTS
In Section 2 we mentioned that the discriminator Dx in MisGAN takes as input the masked samples using (2) without knowing what value  is used and which entries in the input vector are missing. In this section, we are going to discuss the following two important questions: i) How should we choose the filled-in value  ? ii) Does ignoring the information about the location of missing values complicate the problem in terms of the chance of recovering the data distribution?
We address these questions in a simplified scenario where each feature in the data vector takes values from a finite set P. For n-dimensional data, let M = {0, 1}n be the set of masks and I = Pn be the set of all possible data vectors. Also let DM and DI be the set of probability distributions on M and I respectively, so all the elements in them are non-negative and sum to one. We first discuss the case where the filled-in value   P as it is the more convenient case in practice.
Given   P and q  DM, we can construct a left transition matrix Tq,  RI×I defined below where the (t, s)-th entry specifies the transition probability from a data vector s  I to an outcome

3

Under review as a conference paper at ICLR 2019

t  I masked by f , which involves all possible masks under which s is converted into t by filling in with  :

Tq, (t, s) =

q(m).

mM:f (s,m)=t

Let px  DI data specified

be the by q,

unknown true data distribution we want to estimate. In the presence of the masked samples then follow the distribution py = Tq, px. Without

missing making

use of any prior knowledge about the underlying application, MisGAN with  = 0 in (6) can be

viewed as a method for solving the linear system py = Tq, px, where px  DI is the unknown

data distribution to solve for. Here we consider that py and Tq, are given, as those can be estimated

separately from a collection of fully-observed masks and masked samples.

Note that a transition matrix preserves the sum of the vectors it is applied to since 1 Tq, = 1 . For px to be a valid distribution vector, we only need the non-negativity constraint because any solution px automatically sums to one. That is, estimating the data generating process in the presence of missing data based on the masking scheme as in MisGAN is equivalent to solving the linear problem

Tq, px = py subject to px 0.

(7)

We first state a key property of the transition matrix Tq, that leads to the answer to our questions. Theorem 1. Given q  DM, the transition matrices Tq, have the same null space for all   P.

The proof is deferred to Appendix A. Theorem 1 implies that if the solution to the constrained linear

system (7) is not unique for a given Tq,0 px = Tq,0 px , then we must

h0avePT,qt,h aptxis=, thTeqre,epxxisftsorsoamllenonP-n.egInatiovteheprxw=orpdxs,

such that whether

the true data distribution is uniquely recoverable is independent of the choice of the filled-in value 

and therefore we can arbitrarily choose any value for   P.

Here we only discuss the case when the probability of observing all features q(1) is zero; otherwise

the linear system is uniquely solvable as the transition matrix Tq,0 has full rank. With the non-

negativity constraint, it is possible that the solution for the linear system (7) is unique when the true

data and

distribution px is v(s2) < 0 for all

sparse. In particular, if there exists two v  Null(Tq, ) \ {0} and also px(s1)

indices s1, s2  I such that v(s1) > 0 = px(s2) = 0, then the solution to (7)

is unique, where v(s) denotes the (scalar) entry in v indexed by s. Roughly speaking, when the

missing rate is high, that is, if the masks in M that have many zeros are more probable, the null

space of Tq, will be larger and therefore it is more likely that the non-negative solution is not unique.

The sparsity of the data distribution is a reasonable assumption in many situations. For example,

natural images are typically considered to lie on a low dimensional manifold, which means most of

the instances in I should have almost zero probability. Bruckstein et al. (2008) proposed a sufficient

condition on the sparsity of the non-negative solutions to a general underdetermined linear system

that guarantees unique optimality.

In the case of   P, an entry  in some masked sample t  I might have the original entry being  or it might be masked into  due to the missingness in that entry. One might wonder if this prevents an algorithm from recovering the true distribution if that is possible. In other words, if we take the location of the missing values into account, would that make the missing data problem less ill-posed? Theorem 1 suggests that those concerns are not the case with following:
Corollary 1. If the linear system Tq, px = Tq, px does not have a unique non-negative solution, then for this missing data problem we cannot uniquely recover the true data distribution even if we take the location of the missing values into account.

Corollary 1 is justified in Appendix B, in which we discuss the case for  / P. Note that the analysis above characterizes how difficult the missing data problem is, which is independent of the choice of the algorithm that solves it. In practice, it is common to incorporate prior knowledge into the model to regularize the problem when it is ill-posed. For example, for modeling natural images, convolutional networks are commonly used to exploit the local structure of the data. In addition, decoder-based deep generative models such as GANs implicitly enforce some (soft) sparsity constraints due to the use of low dimensional latent code for the generator, which also helps to regularize the problem.

4

Under review as a conference paper at ICLR 2019

4 MISSING DATA IMPUTATION

Missing data imputation is an important technique when dealing with incomplete data. In this section, we show how to impute missing data according to p(xmis|xobs) by equipping MisGAN with an imputer Gi accompanied by a corresponding discriminator Di. The imputer is a function of the incomplete example (x, m) and a random vector  drawn from a noise distribution p. It outputs the completed sample with the observed part in x kept intact.

To train the imputer-equipped MisGAN, we define the loss for the imputer in addition to (3) and (4):

Li(Di, Gi, Gx) = Ezpz [Di(Gx(z))] - E(x,m)pD,p [Di(Gi(x, m, ))] . We jointly learn the data generating process and the imputer according to the following objectives:

min max Li(Di, Gi, Gx),
Gi DiFi
min max Lx(Dx, Gx, Gm) + Li(Di, Gi, Gx),
Gx DxFx
min max Lm(Dm, Gm) + Lx(Dx, Gx, Gm),
Gm DmFm

(8) (9) (10)

where we use  = 0.1 in the experiments when optimizing Gx for encouraging the generated complete data to match the distribution of the imputed real data in addition to having the masked generated data to match the masked real data. The overall structure of MisGAN is illustrated in Figure 9 in Appendix C.

We can also train a stand-alone imputer using only (8) with a pre-trained data generator Gx as the architecture shown in Figure 9 without the shaded part. Moreover, it is also possible to train the
imputer targeting a different missing distribution pm with a pre-trained data generator Gx alone without access to the original (incomplete) training data:

min
Gi

max
Di Fi

Ezpz

[Di(Gx(z))]

-

Empm,zpz ,p

[Di(Gi(Gx(z),

m,

))]

.

(11)

We construct the imputer Gi(x, m, ) as follows:

Gi(x, m, ) = x m + fIMP(x m +  m¯ ) m¯ ,

where fIMP generates the imputed result with the same dimensionality as its input, x m +  m¯ , which could be implemented by a deep neural network. The masking outside of fIMP ensures that the observed part of x stays the same in the output of the imputer Gi. The similar masking on the input of fIMP, x m +  m¯ , ensures that the amount of noise injected to fIMP is complementary to the size of the observed features. This is intuitive in the sense that when a data case is almost fully-observed, we expect less variety in p(xmis|xobs) and vice versa. Note that the noise  needs to have the same dimensionality as x.

5 EXPERIMENTS
In this section, we first assess various properties of MisGAN on the MNIST dataset: we demonstrate qualitatively how MisGAN behaves under different missing patterns and different architectures. We then conduct an ablation study to justify the construction of MisGAN. At the end, we compare MisGAN with various baseline methods on the missing data imputation task over three datasets under a series of missingness settings.
Data We evaluate MisGAN on three datasets: MNIST, CIFAR-10 and CelebA. MNIST is a dataset of handwritten digits images of size 28×28 (LeCun et al., 1998). We use the provided 60,000 training examples for the experiments. CIFAR-10 is a dataset of 32×32 color images from 10 classes (Krizhevsky, 2009). Similarly, we use 50,000 training examples for the experiments. CelebA is a large-scale face attributes dataset (Liu et al., 2015) that contains 202,599 face images, where we use the provided aligned and cropped images and resize them to 64×64. For all three datasets, the range of pixel values of each image is rescaled to [0, 1].
Missing data distributions We consider three types of missing data distribution: i) Square observation: all pixels are missing except for a square occurring at a random location on the image.

5

Under review as a conference paper at ICLR 2019
ii) Dropout: each pixel is independently missing according to a Bernoulli distribution. iii) Variable­ size rectangular observation: all pixels are missing except for a rectangular observed region. The width and height of the rectangle are independently drawn from 25% to 75% of the image length uniformly at random, which results in a 75% missing rate on average. As opposed to the previous two missing distributions that have a constant missing rate, in this missing distribution each example may have different number of missing pixels. In the extreme case, the missing rate can go up to 93.75%.
Evaluation metric We use the Fréchet Inception Distance (FID) (Heusel et al., 2017) to evaluate the quality of the learned generative model. Instead of the Inception network trained on ImageNet (Salimans et al., 2016), we use a basic LeNet implementation2 trained on the complete MNIST training set. We take the 50-dimensional output from the second-to-last fully-connected layer as the features and compute the FID for MNIST. For CIFAR-10 and CelebA, we follow the procedure described in Heusel et al. (2017) to compute the FID using the pretrained Inception-v3 model. When evaluating the generative model using the FID, we use the same number of samples generated by the model as the size of the training set.
5.1 EMPIRICAL STUDY OF MISGAN ON MNIST
In this section, we study various properties of MisGAN perform on the MNIST dataset.
Architectures We consider two kinds of architecture for MisGAN: convolutional networks and fully connected networks. We follow the DCGAN architecture (Radford et al., 2015) for (de)convolutional generators and discriminators to exploit the local structures of images. We call this model ConvMisGAN.
To demonstrate the performance of MisGAN in the absence of the implicit structural regularization provided by the use of a convolutional network, we construct another MisGAN with only fullyconnected layers for both the generators and the discriminators, which we call FC-MisGAN.
In the experiments, both Conv-MisGAN and FC-MisGAN are trained using the improved procedure for the Wasserstein GAN with gradient penalty (Gulrajani et al., 2017). Throughout we use  = 0 for the masking operator the temperature  = 0.66 for the mask activation (x) as described in Section 2.
Baseline We compare MisGAN to a strong baseline model for learning from large-scale incomplete data: generative convolutional arithmetic circuit (ConvAC) models (Sharir et al., 2016). ConvAC is an expressive mixture model similar to sum-product networks (Poon & Domingos, 2011) with a compositional structure similar to deep convolutional networks. Moreover, ConvAC admits tractable marginalization due to the product form of the base distributions for the mixtures, which makes it readily capable for learning with missing data.
Results Figures 1 and 2 show the generated data samples as well as the learned mask samples produced by Conv-MisGAN and FC-MisGAN under the square observation and independent dropout missing mechanisms. From these results, we can see that Conv-MisGANs produces visually better samples than FC-MisGANs. On the other hand, under the same missing rate, independent dropout leads to worse samples than square observations. Samples generated by ConvAC are shown in Figure 16 in Appendix G.
We quantitatively evaluate Conv-MisGAN, FC-MisGAN and ConvAC under two missing patterns with missing rates from 10% to 90% with a step of 10%. Figure 3 shows that MisGAN in general outperforms ConvAC as ConvAC tends to generate samples with aliasing artifacts as shown in Figure 16. It also shows that in the square observation case, Conv-MisGAN and FC-MisGAN have similar performance in terms of FIDs. However, under independent dropout, the performance of FC-MisGAN degrades significantly as the missing rate increases compared to Conv-MisGAN. This is because independent dropout with high missing rate makes the problem more challenging as it induces less overlapping co-occurrence among pixels, which degrades the signal for understanding the overall structure. This is illustrated in Figure 4 where the observed pattern comes from one of four equally probable 14×14 square quadrants with no overlap. Clearly this missing data problem is ill-posed and we could never uniquely determine the correlation between pixels across different quadrants. The samples generated by the FC-MisGAN produce obvious discontinuity across the
2https://github.com/pytorch/examples/tree/master/mnist
6

Under review as a conference paper at ICLR 2019

(a) 9×9 (90% missing) (b) 13×13 (80% missing) (c) 90% dropout

(d) 80% dropout

Figure 1: Conv-MisGAN results under different missing data processes. Top: training samples where
gray pixels indicate missing data. Middle: data samples generated by Gx. Bottom: mask samples generated by Gm.

(a) 9×9 (90% missing) (b) 13×13 (80% missing) (c) 90% dropout

(d) 80% dropout

Figure 2: Data samples generated by FC-MisGAN.

boundary of the quadrants as it does not rely on any prior knowledge about how pixels are correlated. On the contrary, the discontinuity artifact is less severe with Conv-MisGAN as the convolutional layers encourage local smoothness. This shows the importance of incorporating prior knowledge into the model when the problem is highly ill-posed.
Ablation study We point out that the mask discriminator in MisGAN is important for learning the correct distribution robustly. Figure 5 shows two common failure scenarios that frequently happen with an AmbientGAN, which is essentially equivalent to a MisGAN without the mask discriminator. Figure 5 (left) shows a case where AmbientGAN produces perfectly consistent masked outputs, but the learned mask distribution is completely wrong. This is a coincidence as both the mask and pixel values are in the same range [0, 1] in our experiments. Since we use f=0(x, m) = x m, it makes the role of x and m interchangeable. To avoid this situation, we rescale the range of pixel values from [0, 1] to [-1, 1], but AmbientGAN still fails often. Figure 5 (right) shows another frequently occurring failure case of AmbientGAN. In contrast, MisGAN avoids learning such degenerate solutions due to explicitly modeling the mask distribution.

square observation Conv-MisGAN FC-MisGAN ConvAC 6
4
2
0 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 missing rate

independent dropout Conv-MisGAN FC-MisGAN ConvAC 15
10
5
0 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 missing rate

Figure 3: Left & Middle: Missing rate versus FID (The lower the better) with different missing data processes. Right: Data samples (top) and mask samples (bottom) generated by Conv-MisGAN learned with variable-size observations.

7

FID FID

Under review as a conference paper at ICLR 2019
(a) incomplete training data (b) FC-MisGAN (FID: 20.6) (c) Conv-MisGAN (FID: 10.8) Figure 4: Data samples generated by MisGAN when trained on missing data distributions with non-overlapping samples (square quadrants).
Figure 5: Two failure cases of AmbientGAN. In each pair, data samples produced by Gx are on the left, mask samples from Gm are on the right. In the right panels, the range of pixel values is rescaled to [-1, 1] so gray pixels correspond to  = 0. It learns the masks with all ones.
Missing data imputation We construct the imputer network fIMP using a a three-layer fullyconnected network with 500 hidden units in all the middle layers. Figure 6 (left) shows the imputation results on different examples applying novel masks randomly drawn according to the same distribution. Figure 6 (right) shows the imputation results where each row corresponds to the same incomplete input. It demonstrates that the imputer can produce a variety of different imputed results due to the random noise input to the imputer. We also note that if we modify (11) to train the imputer together with the data generator from scratch without the mask generator/discriminator, it fails most of the time for a similar reason to why AmbientGAN fails. The learning problem is highly ill-posed without the constraints on the mask distribution. 5.2 QUANTITATIVE EVALUATION In this section, we quantitatively evaluate the performance of MisGAN on three datasets: MNIST, CIFAR-10, and CelebA. We first note that we found ConvAC, which we compare MisGAN with in Section 5.1, fails to learn the distribution of CIFAR-10 and CelebA as it overfits severely when it applies to color images as pointed out in Sharir et al. (2016) even with suggested regularization; see Appendix G for more details. Therefore, we focus on evaluating MisGAN on the missing data imputation task as it is widely studied and many baseline methods are available. Baselines We compare MisGAN imputer to a range of baseline methods including the basic zero/mean imputation, matrix factorization, and the recently proposed Generative Adversarial Imputation Network (GAIN) (Yoon et al., 2018). GAIN is an imputation model that employs an imputer
Figure 6: Inside of each red box are the observed pixels; the pixels outside of the box are generated by the imputer. Right: each row corresponds to the same incomplete input, marked by the red box.
8

Under review as a conference paper at ICLR 2019

FID FID FID FID FID FID

MNIST: square observation

60

zero imputation mean imputation

40

matrix factorization GAIN

20 MisGAN

0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 missing rate

MNIST: independent dropout

100

50

0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 missing rate

CIFAR-10: square observation 150 100 50
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 missing rate CIFAR-10: independent dropout
200
100
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 missing rate

CelebA: square observation 200
100
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 missing rate CelebA: independent dropout
300 200 100
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 missing rate

Figure 7: Comparison of FID across different missing rates.

network to complete the missing data. It is trained adversarially with a discriminator that determines which entries in the completed data were actually observed and which were imputed. It has shown to outperforms many state-of-the-art imputation methods.
Evaluation of imputation We impute all of the incomplete examples in the training set and use the FID between the imputed data and the original fully-observed data as the evaluation metric.
Architecture We use convolutional generators and discriminators for MisGAN for all experiments in this section. For MNIST, we use the same fully-connected imputer network as described in the previous section; for CIFAR-10 and CelebA, we use a five-layer U-Net architecture (Ronneberger et al., 2015) for the imputer network fIMP in MisGAN.
Results We compare all of the methods under two missing patterns, namely square observation and independent dropout, with missing rates from 10% to 90%. Figure 7 that MisGAN consistently outperforms other methods in all of the cases especially under high missing rate. In our experiments, we found GAIN training is quite unstable for the block observation missingness. There is a sweet spot for the number of training epochs for training GAIN. If trained longer, the imputation behavior will gradually become similar to constant imputation; see Appendix H for more details. On the other hand, training MisGAN is more stable than GAIN across all scenarios in the experiments. The imputation results of MisGAN and GAIN are shown in Appendix E, F, and H.
6 DISCUSSION AND FUTURE WORK
This work presents and evaluates a highly flexible framework for learning standard GAN data generators in the presence of missing data. Although we only focus on the MCAR case in this work, MisGAN can be easily extended to cases where the output of the data generator is provided to the mask generator. These modifications can capture both MAR and NMAR mechanisms. The question of learnability requires further investigation and the analysis in Section 3 no longer holds due to the dependence between the transition matrix and the data distribution. However, we have tried this modified architecture in our experiments and it showed similar results as to the original MisGAN. This suggests that the extra dependencies do not adversely affect learnability. We leave the formal evaluation of this modified framework for future work.
REFERENCES
Martin Arjovsky, Soumith Chintala, and Léon Bottou. Wasserstein generative adversarial networks. In International Conference on Machine Learning, pp. 214­223, 2017.
9

Under review as a conference paper at ICLR 2019
David Berthelot, Tom Schumm, and Luke Metz. Began: Boundary equilibrium generative adversarial networks. arXiv preprint arXiv:1703.10717, 2017.
Ashish Bora, Eric Price, and Alexandros G Dimakis. AmbientGAN: Generative models from lossy measurements. In International Conference on Learning Representations (ICLR), 2018.
Alfred M Bruckstein, Michael Elad, and Michael Zibulevsky. On the uniqueness of nonnegative sparse solutions to underdetermined systems of equations. IEEE Transactions on Information Theory, 54(11):4813­4820, 2008.
Zoubin Ghahramani and Michael I Jordan. Supervised learning from incomplete data via an em approach. In Advances in neural information processing systems, 1994.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing systems, 2014.
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville. Improved training of wasserstein gans. In Advances in Neural Information Processing Systems, pp. 5769­5779, 2017.
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilibrium. In Advances in Neural Information Processing Systems, pp. 6629­6640, 2017.
Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. In International Conference on Learning Representations (ICLR), 2018.
Alex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, Citeseer, 2009.
Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278­2324, 1998.
Roderick JA Little and Donald B Rubin. Statistical analysis with missing data, volume 333. John Wiley & Sons, 2014.
Guilin Liu, Fitsum A Reda, Kevin J Shih, Ting-Chun Wang, Andrew Tao, and Bryan Catanzaro. Image inpainting for irregular holes using partial convolutions. arXiv preprint arXiv:1804.07723, 2018.
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In Proceedings of International Conference on Computer Vision (ICCV), 2015.
Shakir Mohamed and Balaji Lakshminarayanan. Learning in implicit generative models. arXiv preprint arXiv:1610.03483, 2016.
Deepak Pathak, Philipp Krähenbühl, Jeff Donahue, Trevor Darrell, and Alexei Efros. Context encoders: Feature learning by inpainting. In CVPR, 2016.
Hoifung Poon and Pedro Domingos. Sum-Product Networks: a new deep architecture. In Uncertainty in Artificail Intelligence (UAI), 2011.
Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.
Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computerassisted intervention, pp. 234­241. Springer, 2015.
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. In Advances in Neural Information Processing Systems, pp. 2234­2242, 2016.
10

Under review as a conference paper at ICLR 2019 Or Sharir, Ronen Tamari, Nadav Cohen, and Amnon Shashua. Tractable generative convolutional
arithmetic circuits. arXiv preprint arXiv:1610.04167, 2016. Raymond A Yeh, Chen Chen, Teck Yian Lim, Alexander G Schwing, Mark Hasegawa-Johnson, and
Minh N Do. Semantic image inpainting with deep generative models. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5485­5493, 2017. Jinsung Yoon, James Jordon, and Mihaela van der Schaar. GAIN: Missing data imputation using generative adversarial nets. In International Conference on Machine Learning, 2018.
11

Under review as a conference paper at ICLR 2019

A PROOF OF THEOREM 1

Let P be the finite set of feature values. For the n-dimensional case, let M = {0, 1}n be the set of masks and I = Pn be the set of all possible feature vectors. Also let DM be the set of probability
distributions on M, which implies m 0 and vI m(v) = 1 for all m  M, where m(v) denotes the entry of m indexed by v.

Given   P and q  DM, define the transformation
Tq, : RI  RI x  y = Tq, x

by where

y(v) = Tq, x(v) =

q(m)x(u)1{u m +  m¯ = v}, for all v  I

mM uI

is the entry-wise multiplication and 1{·} is the indicator function.

(12)

Given m  M, define an equivalent relation m on I by v m u iff v m = u m, and denote by [v]m the equivalence class containing v.

Given q  DM, let Sq  M be the support of q, that is,

Sq = {m  M : q(m) > 0}.

Given   P and v  I, let M,v denote the set of masks consistent with v in the sense that q(m) > 0 and v m¯ =  m¯ , that is,
M,v = {m  Sq : v m¯ =  m¯ }.
Proposition 1. For any q  DM and x  RI, the collection of marginals {x([v]m) : v  I, m  Sq} determines Tq, x for all   P where x([v]m) := u[v]m x(u).

Proof. This is clear from the following equation

Tq, x(v) =

q(m)x([v]m),

mM,v

which can be obtained from (12) as follows,

Tq, x(v) =

q(m)x(u)1{u m = v m}1{ m¯ = v

mSq uI

= q(m)1{ m¯ = v m¯ } x(u)1{u m = v

mSq

uI

= q(m)1{ m¯ = v m¯ }x([v]m)
mSq

= q(m)x([v]m).
mM,v

m¯ } m}

(13)

Proposition 2. For any   P, q  DM and x  RI, the vector Tq, x determines the collection of marginals {x([v]m) : v  I, m  Sq}.
Proof. Fix   P, q  DM and x  RI. Since v m +  m¯  [v]m, it suffices to show that we can solve for x([v]m) in terms of Tq, x for m  M,v = . We use induction on the size of M,v. First consider the base case |M,v| = 1. Consider v0  I with M,v0 = {m0}. By (13),
Tq, x(v0) = q(m0)x([v0]m0 ). Hence x([v0]m0 ) = Tq, x(v0)/q(m0), which proves the base case.
12

Under review as a conference paper at ICLR 2019

Now assume we can solve for x([v]m) in terms of Tq, x for m  Sq and v  I with |M,v|  k.
Consider v0  I with |M,v0 | = k + 1; if no such v0 exists, the conclusion holds trivially. Let M,v0 = {m0, m1, . . . , mk}. We need to show that Tq, x determines x([v0]m ) for = 0, 1, . . . , k.
By (13) again,

k

Tq, x(v0) = q(m )x([v0]m ).

(14)

=0

Let m =

k =0

m

,

which

may

or

may

not

belong

to

Sq.

Note

that

x([v0]m) =

x([v]m ) = x([v0]m ) +

x([v]m ),

v[v0 ]mm¯

v[v0]mm¯ \{v0}

and hence

x([v0]m ) = x([v0]m) -

x([v]m ).

v[v0]mm¯ \{v0}

Plugging (15) into (14) yields

(15)

x([v0]m) =



1k

k =0 q(m

Tq, x(v0) + )

q(m )

x([v]m ) .

=0 v[v0]mm¯ \{v0}

(16)

Note that M,v  M,v0 \ {m } for v  [v0]mm¯ \ {v0}, so |M,v|  k. By the induction hypothesis, x([v]m ) is determined by Tq, x. It follows from (16) and (15) that x([v0]m) and
x([v0]m ) are also determined by Tq, x. This completes the induction step.

Theorem 1 is a direct consequence of Proposition 1 and Proposition 2 as the collection of marginals {x([v]m) : v  I, m  Sq} is independent of  . Therefore, if x1, x2  RI satisfy Tq,0 x1 = Tq,0 x2 for some 0  P, then Tq, x1 = Tq, x2 for all   P. Theorem 1 is a special case when x1 = 0.
Moreover, Proposition 2 also shows that MisGAN attempts to match the distribution of p(xobs, m) of the data as x([v]m) nicely connects p(xobs|m) with the distribution of f (x, m) that is seen by the data discriminator.

B JUSTIFICATION OF COROLLARY 1
Corollary 1 can be explained by augmenting the set of feature values by P = P  {} with a novel symbol  / P. If we choose  =  for the masking operator, whenever we spot a  in a masked sample, we know that it corresponds to a missing entry. We can also construct the corresponding transition matrix Tq,  RI ×I where I = (P )n given the mask distribution q  DM before. In this setting, the generative model for missing data is equivalent to solving the linear system Tq,px = Tq,px so that px  RI is non-negative and px(s) = 0 for all s  I \ I, where the true distribution px is given by px (s) = px(s) for all s  I and zeros elsewhere. Theorem 1 implies that if the solution to original problem (7) is not unique, the non-negative solution to the augmented linear system with the extra constraint on I \ I with  =  is not unique either.

C ARCHITECTURE OF MISGAN AND IMPUTER
Figure 8 and Figure 9 illustrate the architecture of MisGAN and the MisGAN imputer.

D ARCHITECTURAL DETAILS AND HYPERPARAMETERS
All of the generators and discriminators in Conv-MisGAN follow the architecture used by the DCGAN model (Radford et al., 2015) with 128-dimensional latent code. As for FC-MisGAN, the architecture of the generators is
FC(128, 256)­FC(256, 512)­FC(512, 784)

13

Under review as a conference paper at ICLR 2019
Figure 8: Architecture of MisGAN
Figure 9: Architecture of MisGAN with imputer with ReLUs in between. The discriminators are of the structure
FC(784, 512)­FC(512, 256)­FC(256, 128)­FC(128, 1) also with ReLUs in between. For the imputer network for MisGAN trained on CIFAR-10 and CelebA, we follow the U-Net implementation of the CycleGAN and pix2pix work3. In the experiments, we use 5-layer U-Nets for both CIFAR-10 and CelebA. For training Wasserstein GAN with gradient penalty, We use all the default hyperparameters reported in Gulrajani et al. (2017). For all the datasets, MisGAN is trained for 300 epochs. We train MisGAN imputer for 1000 epochs for MNIST and CIFAR-10 as the networks are smaller and 600 epochs for CelebA. For ConvAC, we use the same architecture described in Sharir et al. (2016). We train ConvAC for 1000 epochs using Adam optimizer with learning rate 10-4.
3 https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix 14

Under review as a conference paper at ICLR 2019

training samples

Gx samples (a) 10×10 block (90% missing)

Gm samples

training samples

Gx samples (b) 14×14 block (80% missing)

Gm samples

training samples

Gx samples (c) 30×30 block (10% missing)

Gm samples

Figure 10: MisGAN on CIFAR-10 with block observation missingness

E MISGAN ON CIFAR-10
Figure 10, 11 and 12 show the results of MisGAN trained on CIFAR-10 for the two extreme missing rates, namely 90% and 80%, as well as the case of 10% that is close to full observation.
F MISGAN ON CELEBA
Figure 13, 14 and 15 show the results of MisGAN trained on CelebA for the two extreme missing rates, namely 90% and 80%, as well as the case of 10% that is close to full observation.
G RESULTS OF CONVAC
Figure 16 shows the samples generated by ConvAC trained with the square observation missing pattern. However, we find that when training ConvAC on CIFAR-10, the generated samples have severe aliasing artifacts and fail to capture the details in the training images as shown in Figure 17. On the other hand, ConvAC is hard to scale up to data like CelebA. For CelebA, if we use 256 channels for the first layer, it requires 50,331,648 parameters for the input image of size 64×64.
H MISSING DATA IMPUTATION WITH GAIN
Figure 18 shows the imputation results of GAIN on different epochs during training with the 20×20 square observation missingnss. We found that this is a common phenomenon for the square observation missing pattern. To obtain better results for GAIN, we analysis the FIDs during the course of training and use the model that achieves the best FID to favorably compare with MisGAN for the square observation case. For CIFAR-10, we use the results from the 500th epoch; for CelebA,

15

Under review as a conference paper at ICLR 2019

training samples

Gx samples (a) 90% missing

Gm samples

training samples

Gx samples (b) 80% missing

Gm samples

training samples

Gx samples (c) 10% missing

Gm samples

Figure 11: MisGAN on CIFAR-10 with independent dropout missingness

10×10 (90% missing)

14×14 (80% missing) (a) square observation missingness

30×30 (10% missing)

90% missing

80% missing (b) independent dropout missingness

10% missing

Figure 12: MisGAN imputation on CIFAR-10

16

Under review as a conference paper at ICLR 2019

training samples

Gx samples (a) 20×20 block (90% missing)

Gm samples

training samples

Gx samples (b) 29×29 block (80% missing)

Gm samples

training samples

Gx samples (c) 61×61 block (10% missing)

Gm samples

training samples

Gx samples

(d) Variable-size block (75% missing on average)

Gm samples

Figure 13: MisGAN on CelebA with block observation missingness

17

Under review as a conference paper at ICLR 2019

training samples

Gx samples (a) 90% missing

Gm samples

training samples

Gx samples (b) 80% missing

Gm samples

training samples

Gx samples (c) 10% missing

Gm samples

Figure 14: MisGAN on CelebA with independent dropout missingness

20×20 (90% missing)

29×29 (80% missing) (a) square observation missingness

61×61 (10% missing)

90% missing

80% missing (b) independent dropout missingness
Figure 15: MisGAN imputation on CelebA

10% missing

18

Under review as a conference paper at ICLR 2019

(a) ConvAC: 9×9 (90%)

(b) ConvAC: 13×13 (80%)

Figure 16: Results of ConvAC trained with square observations of different sizes on MNIST.

10×10 (90% missing)

30×30 (10% missing)

(a) square observation missingness

90% missing

10% missing

(b) independent dropout missingness

Figure 17: Samples generated by ConvAC trained on CIFAR-10.

19

Under review as a conference paper at ICLR 2019

30th epoch

60th epoch

90th epoch

120th epoch

150th epoch

180th epoch

210th epoch

240th epoch

270th epoch

Figure 18: Imputation results of GAIN on different epochs during training under 20×20 square observation missingness. If over-trained, the imputation behavior of GAIN will gradually become similar to constant imputation.

we use the results from the 50th epoch. Otherwise, we train GAIN for 1000 epochs for CIFAR-10 and 300 epochs for CelebA. Our implementation is adapted from the code released by the authors of GAIN.4
Figure 19 shows the imputation results of GAIN for both CIFAR-10 and CelebA.
I RELATIONSHIP BETWEEN IMPUTATION AND IMAGE INPAINTING
Different from most of the image inpainting work that aims at completing an incomplete image and producing a single visually convincing result, the goal of missing data imputation is to model the conditional distribution p(xmis|xobs). In addition, most of the state-of-the-art image inpainting work are required to train with complete image datasets (Pathak et al., 2016; Yeh et al., 2017; Liu et al., 2018).
We also note that although we demonstrate a simple construction of the imputer Gi in the MisGAN imputation framework as described in Section 4, it is compatible with many specialized architectures that suit the application of interest. When it comes to image inpainting, we could use the architectures of other image inpainting work (Pathak et al., 2016; Yeh et al., 2017; Liu et al., 2018) as the imputer network within our framework.

4 https://github.com/jsyoon0823/GAIN 20

Under review as a conference paper at ICLR 2019

10×10 (90% missing)

14×14 (80% missing)

30×30 (10% missing)

(a) CIFAR-10 with square observation missingness

90% missing

80% missing

10% missing

(b) CIFAR-10 with independent dropout missingness

20×20 (90% missing)

29×29 (80% missing)

61×61 (10% missing)

(c) CelebA with square observation missingness

90% missing

80% missing (d) CelebA with independent dropout missingness
Figure 19: GAIN imputation

10% missing

21

