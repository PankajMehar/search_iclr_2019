Under review as a conference paper at ICLR 2019

DEEP RECURRENT GAUSSIAN PROCESS WITH VARIATIONAL SPARSE SPECTRUM APPROXIMATION
Anonymous authors Paper under double-blind review

ABSTRACT
Modeling sequential data has become more and more important in practice. Some applications are autonomous driving, virtual sensors and weather forecasting. To model such systems so called recurrent models are frequently used. In this paper we introduce several new Deep Recurrent Gaussian Process (DRGP) models based on the Sparse Spectrum Gaussian Process (SSGP) and the improved version called Variational Sparse Spectrum Gaussian Process (VSSGP). We follow the recurrent structure given by an existing DRGP based on a specific variational sparse Nystro¨m approximation, the recurrent Gaussian Process (RGP). Therefore, we also variationally integrate out the input-space and hence can propagate uncertainty through the GP layers. Further, we combine the (V)SS approximations with a well known inducing-input regularization framework. This case naturally collapses to a tractable expression by calculating the integrals. For the simple extension of the (V)SS approximation an optimal variational distribution exists. Training is realized through optimizing the variational lower bounds. We improve over current state of the art methods in prediction accuracy for experimental data-sets used for their evaluation and introduce a new data-set for engine control, named Emission.

1 INTRODUCTION

Modeling sequential data for simulation tasks in the context of machine learning is hard for several reasons. Its internal structure poses the problem of modeling short term behavior and long term behavior together for different types of data variables, where the data variables itself might differ in the information gain in the chosen time frequency. Recurrent models (Hochreiter & Schmidhuber, 1997; Nelles, 2013; Pascanu et al., 2013) have proven to perform well on these tasks. They consist of output-data and input-data structured sequentially for shifted discrete time steps. The general form of a recurrent model is given by

hi = (hi-1, . . . , hi-Hh , xi-1, . . . , xi-Hx ) + ih,

yi = (hi, . . . , hi-Hh ) +

y i

,

(1) (2)

where xi is an external input, yi is an output observation, hi is a latent hidden representation or state

(details on dimensions and ranges will be specified in upcoming sections) at time i = Hx+1, . . . , N ,

where N  N is the number of data samples, Hx, Hh  N are the chosen time horizons, ,  are

non-linear functions modeling transition and observation and

ih,

y i

are

transition

and

observation

noise, which are adjusted for the specific problem.

In control and dynamical system identification previous work on Bayesian recurrent approaches for

modeling sequential data usually make use of (non-)linear auto-regressive with exogenous inputs

models ((N)ARX) and state-space models (SSM), for both see Nelles (2013). The general recurrent

model given by the Equations (1), (2) represents both cases. This can be recognized by its gen-

eral recurrent and hierarchical structure. This work deals with deep learning in a recurrent fashion

for modeling sequential data in a Bayesian non-parametric approach by using Gaussian Processes

(GP). To make a connection to the general recurrent model, the deep structure arises by defining 

in Equation (1) in a deep manner (Pascanu et al., 2013, Section 3).

This paper proposes deep recurrent GP models based on (variational) Sparse Spectrum approxi-

mations, denoted by DRGP-(V)SS. For reproducibility of the experimental results, we provide the

1

Under review as a conference paper at ICLR 2019

code online1. Therefore, we follow the same deep recurrent structure as introduced in Mattos et al. (2016). To summarize the contributions of this paper:
· Extension of the sparse GP based on the SS approximation introduced by La´zaro-Gredilla et al. (2010) and the improved VSS approximation by Gal & Turner (2015) to DRGPs;
· Improving regularization properties of the variational bounds through the combination of the (V)SS approximation with the inducing-point (IP) regularization of Titsias & Lawrence (2010);
· Propagation of uncertainty through the hidden layers of our DGPs by variationally integrating out the input-space;
· The existence of an optimal variational distribution in the sense of a functional local optimum of the variational bounds of our DRGPs models is established.
The DRGP of Mattos et al. (2016) is limited to a small class of deterministic covariance functions, because the covariance functions variational expectation has to be analytically tractable. Using the (V)SS approximation instead, we can derive a valid approximation for every stationary covariance function, because the basis functions expectation is always tractable. We show that this approach improves over state of the art approaches in prediction accuracy on several cases of the experimental data-sets used in Mattos et al. (2016); Svensson et al. (2016); Al-Shedivat et al. (2017); Salimbeni & Deisenroth (2017); Do¨rr et al. (2018) in a simulation setting. For scalability, Distributed Variational Inference (DVI) (Gal et al., 2014) is recommended and can lower the complexity per core from O(N M 2QmaxL) down to O(M 3), for N  M , M the sparsity parameter, L the amount of GPs and Qmax is the maximum over all input dimensions used in our defined deep structure for  and .

2 RELATED WORK TO GAUSSIAN PROCESSES WITH SSM AND DGPS

An SSM with GPs (GP-SSM) for transition and observation functions is used by Wang et al. (2005), where the uncertainty in the latent states is not accounted for, which can lead to overconfidence. Turner et al. (2010) solved this problem, but they have complicated approximate training and inference stages and the model is hard to scale. Frigola et al. (2014) used a GP for transition, while the observation is parametric. Svensson et al. (2016) used an approximation of the spectral representation by Bochner's theorem in a particular form and with a reduced rank structure for the transition function. They realize inference in a fully Bayesian approach over the amplitudes and the noise parameters. Do¨rr et al. (2018) introduced a GP-SSM with scalable training based on doubly stochastic variational inference for robust training. Our models extend the GP-SSM framework by defining the transition as a DRGP based on our newly derived (V)SS approximations in Sections 3.3, 3.4 where the latent (non-observed) output-data is learned as a hidden state. We refer to the report Fo¨ll et al. (2017)2 for a detailed but preliminary formulation of our models and experiments. Following Damianou & Lawrence (2013), a Deep Gaussian Process (DGP) is a model assuming

yi = f(L+1)(f(L)(f(L-1)(. . . (f(1)(xi) +

h(1) i

)

.

.

.

)

+

) +h(L-1)
i

h(L) i

)

+

y i

,

where the index i = 1, . . . , N is not necessarily the time and where we define h(i1) d=ef f(1)(xi) +

,h(1)
i

hi(l+1)

d=ef

f(l)(hi(l)) +

,h(l)
i

for

l

=

2...,L

-

1,

where

L



N

is

the

number

of

hidden

layers. The noise

,h(l)
i

y i

is

assumed

Gaussian

and

the

functions

f (l)

are

modeled

with

GPs

for

l = 1, . . . , L + 1. To obtain computational tractability, in most cases variational approximation and

inference is used. Damianou & Lawrence (2013) introduced these kind of DGPs based on the sparse

variational approximation following Titsias & Lawrence (2010). Based on this Dai et al. (2016) in-

troduced a DGP with a variationally auto-encoded inference mechanism and which scales on larger

data-sets. Cutajar et al. (2016) introduced a DGP for the so called Random Fourier Features (RFF)

approach, where the variational weights for each GPs are optimized along with the hyperparameters.

This approach does not variationally integrate out the latent inputs to carry through the uncertainty

and no existence of an optimal distribution for the variational weights is proven, to reduce the amount

of parameters to optimize in training. Further, Salimbeni & Deisenroth (2017) introduced a approx-

imation framework for DGPs which is similar to the single GP of Hensman & Lawrence (2014) but

1DRGP-(V)SS code available from http://github.com/RomanFoell/DRGP-VSS. 2Available on the website https://arxiv.org/.

2

Under review as a conference paper at ICLR 2019

does not force independence between the GP layers and which scales to billions of data. Two state of the art approaches for DRGPs have been introduced by Mattos et al. (2016), the RGP, which we call DRGP-Nystro¨m, based on the variational sparse Nystro¨m/inducing-point approximation introduced by Titsias (2009); Titsias & Lawrence (2010), as well as Al-Shedivat et al. (2017), which we call GP-LSTM, based on deep kernels via a Long-short term memory (LSTM) network, a special type of Recurrent Neural Network (RNN). DRGP-Nystro¨m uses a recurrent construction, where the auto-regressive structure is not realized directly with the observed output-data, but with the GPs latent output-data and uses a Variational Inference (VI) framework named Recurrent Variational Bayes (REVARB). The structure acts like a standard RNN, where every parametric layer is a GP. So additionally uncertainty information can be carried through the hidden layers. GP-LSTM is a combination of GPs and LSTMs. LSTMs have proven to perform well on modeling sequential data. LSTMs try to overcome vanishing gradients by placing a memory cell into each hidden unit. GP-LSTM uses special update rules for the hidden representations and the hyper parameters through a semi-stochastic optimization scheme. It combines a GP with the advantages of LSTMs by defining structured recurrent deep covariance functions, also called deep kernels, which reduces the time and memory complexities of the linear algebraic operations (Wilson et al., 2016).

3 GAUSSIAN PROCESS AND VARIATIONAL SPARSE SPECTRUM GP

Loosely speaking, a GP can be seen as a Gaussian distribution over functions. We will first introduce GPs and GP regression and then recall the SSGP by (La´zaro-Gredilla et al., 2010) and its improved version VSSGP by (Gal & Turner, 2015). Based on these we derive new variational approximations.

3.1 GAUSSIAN PROCESS

A stochastic process f is a GP if and only if any finite collection of random variables fX d=ef [fx1 , . . . , fxN ]T forms a Gaussian random vector (Rasmussen, 2006). A GP is completely defined by its mean function m : RQ  R, x  m(x) and covariance function k : RQ × RQ  R, (x, x ) 
k(x, x ) (Kallenberg, 2006, Lemma 11.1), where

m(x) d=ef E [f (x)] , k(x, x ) d=ef cov(f (x), f (x )) = E [(f (x) - m(x))(f (x ) - m(x ))] ,

and the GP will be written as f  GP(m, k).

Let y d=ef [y1, . . . , yN ]T

 RN and we assume yi = f(xi) +

y i

,

where

y i



N (0, 2noise), for

i = 1, . . . , N , and our aim is to model any set of function values f = [f(x1), . . . , f(xN )]T  RN

at X d=ef [x1, . . . , xN ]T  RN×Q as samples from a random vector fX. Therefore, we assume the prior fX|X  N (0, KNN ), meaning that any set of function values f given X are jointly Gaussian

distributed with mean 0  RN and a covariance matrix KNN d=ef (k(xi, xj))iN,j=1  RN×N .

The predictive distribution pfx |x,X,y for a test point x  RQ, where KN d=ef (k(xi, x))Ni=1  RN , K, KN analogously, can be derived through the joint probability model and conditioning as

fx |x, X, y  N (KN (KNN + n2oiseIN )-1y, K - KN (KNN + 2noiseIN )-1KN).

In preview of our experiments in Section 5 and the following sections we choose a specific covariance function, the spectral mixture (SM) covariance function (Wilson & Adams, 2013)

k(x, x ) = p2ower

Q
exp
q=1

-

1 2

l-q 2

(xq

-

xq )2

cos 2

Q q=1

pq-1(xq

-

xq )

,

(3)

with length scales lq, pq  R, q = 1, . . . , Q. As pq  , this corresponds to the squared exponential (SE) covariance function in the limit (Gal & Turner, 2015).

3.2 VARIATIONAL SPARSE SPECTRUM GP
We introduce the SSGP following Gal & Turner (2015). For a stationary covariance function k on RQ × RQ there exists a function  : RQ  R,   ( ), such that k(x, x ) = (x - x ) for x, x  RQ. Bochner's theorem states that any stationary covariance function k can be represented as the Fourier transform of a positive finite measure µ (Stein, 2012). Then ( ), using  = x - x ,

3

Under review as a conference paper at ICLR 2019

can be expressed via Monte Carlo Approximation (MCA) following Gal & Turner (2015) Section 2

as ( ) =

e2izT  dµ(z)

(4)

RQ
 2power M

M m=1

2

cos(2zmT

(x

-

um

)

+

bm

)

cos(2zTm

(x

- um) + bm) d=ef

k~(x, x )

We refer to zm as the spectral points, bm as the spectral phases and um as the pseudo-input/inducing

points for m = 1, . . . , M . Choosing the probability density like in Gal & Turner (2015) Proposition

2, we approximate the SM covariance function with a scaling matrix L d=ef diag([2lq]qQ=1) 

RQ×Q, a scaling vector p d=ef [p1-1, . . . , p-Q1]T  RQ and Z = [z1, . . . , zM ]T  RQ×M via

(x, Z) d=ef

2p2owerM -1 cos(2(L-1z1 + p)T (x - u1) + b1), . . . , cos(2(L-1zM + p)T (x - uM ) + bM ) T  RM .

(5)

Here we sample b  Unif [0, 2], z  N (0, IQ) and we set K~N(SNM) d=ef T with  d=ef [(x1, Z), . . . , (xN , Z)]T  RN×M . In Gal & Turner (2015) the SSGP was improved to VSSGP by variationally integrating out the
spectral points and instead of optimizing the spectral points additionally optimizing the variational
parameters. We follow the scheme of Gal & Turner (2015) Section 4 for the 1-dimensional output case y  RN×1. By replacing the covariance function with the sparse covariance function k~(SM) and setting the priors pzm , pa to

zm  N (0, IQ), a  N (0, IM ),

(6)

for m = 1, . . . , M , where we have y|a, Z, U , X  N (a, 2noiseIN ) with U = [u1, . . . , uM ]T  RQ×M (we do not define priors on p, L-1, b = [b1, . . . , bM ]T  RM ), we can expand the marginal likelihood (ML) with Bishop (2006) Equations 2.113 - 2.115 to

p(y|X) = p(y|a, Z, U, X)p(a)p(Z)dadZ.

(7)

Now, to improve the SSGP to VSSGP, variational distributions qzm , qa are introduced in terms of
zm  N (m, m), a  N (m, s),
with m  RQ×Q diagonal, for m = 1, . . . , M , and s  RM×M diagonal. From here on we use variational mean-field approximation to derive the approximate models with different lower bounds to the log ML introduced by Gal & Turner (2015):

log(p(y|X))  E[log(p(Y|a, Z, U, X))]qaqZ - KL(qa||pa) - KL(qZ ||pZ )).

(8)

As usual, KL defines the Kullback-Leibler (KL) divergence. By proving the existence of an optimal distribution qaopt for a Gal & Turner (2015) Proposition 3 in the sense of a functional local optimum of the right hand side of 8, where a  N (A-11T y, n2oiseA-1), with A = 2 + n2oiseIM , 1 = E []qZ  RN×M , 2 = E T  qZ  RM×M , we can derive the optimal bound case.

3.3 (V)SSGP WITH REGULARIZATION PROPERTIES VIA INDUCING POINTS (IP)

As a first contribution of this paper we combine two approximation schemes to two new methods (V)SSGP-IP. We want to point out that the (V)SSGP has not the same regularization properties as the GP of Titsias & Lawrence (2010) when optimizing the parameters U because the prior 6 of the weights a are defined generic via Bishop (2006) Equations 2.113 - 2.115. We now define them as
a|U  N (0, KMM ), y|a, Z, U , X  N (KM-1M a, KNN - KNM KM-1M KMN ), (9)
where KNN , KNM , KMM are defined through the given covariance function in Equation (3). Consequently, the resulting bound in 10 has an extra regularization property compared to the right hand side of 8, which is reflected in the different form of A = 2 + n2oiseKMM , which involves KMM , the choosen covariance matrix filled in with the pseudo-input points U and three extra terms
2-1 log(|KMM |), (22noise)-1tr(KNN ), (22noise)-1tr(KM-1M KMN KNM ).

4

Under review as a conference paper at ICLR 2019

The optimal variational distribution for a, which collapses by reversing Jensen's inequality, is similar to Titsias & Lawrence (2010) Section 3.1 and the resulting bounds (SSGP-IP without KL(qZ||pZ) and 1 = , 2 = T ) can be calculated in the same way as Titsias & Lawrence (2010) Equation 14 in closed form by simply calculating the integral in Equation 7:

log(p(y|X))  - (N

- 2

M

)

log(n2oise)

-

N 2

log(2) -

yT y 2n2oise

+

log(|KMM | 2

A-1

)

+

yT 1A-11T y 22noise

-

tr(KNN )

+

tr(KM-1M KMN KNM ) 22noise

-

KL(qZ ||pZ ).

(10)

3.4 VARIATIONAL APPROXIMATION OF THE INPUT-SPACE FOR (V)SSGP(-IP)

As a second contribution of this paper, in this section we marginalize also the input-space. This is not straightforward as it is not clear whether for the (V)SS sparse covariance function these expressions even exist. To prevent misunderstanding, we will write from now on H = [h1, . . . , hN ]T  RN×Q instead of X, to highlight H is now a set of latent variables (later on the hidden states of the DGP). Therefore, we introduce priors and variational distributions

pH d=ef

N
i=1 phi , where hi  N (0, IQ),

qH d=ef

N
i=1 qhi , where hi  N (µi, i),

i  RQ×Q diagonal, for i = 1, . . . , N . As a consequence, for VSSGP-IP we overall derive statistics 0 = tr (E[KNN ]qH ) = N 2power, 1 = E []qZqH  RN×M , 2 = E T  qZqH  RM×M and reg = E [KMN KNM ]qH as defined in the Appendix 6.3. The SSGP-IP model derives by being not variational over the spectral points.
This extra step will makes it possible to propagate uncertainty between the hidden layers of a DGP,
as we gain an extra variance parameter for the inputs. For the IP case we get the lower bound:

log(p(y|H))  - (N

- M) 2

log(2noise) -

N 2

log(2) -

yT y 2n2oise

+

log(|KMM | 2

A-1

)

+

yT 1A-11T y 22noise

-

0

+

tr(KM-1M reg) 2n2oise

- KL(qZ ||pZ ) -

KL(qH ||pH ).

(11)

For the extension of the SSGP and VSSGP in the optimal bound case in 8 (we only focus on this case

in

the

following),

we

again

have

A

=

2

+ n2oiseIM

and

eliminate

log(|KM 2

M

|)

,

.0+tr(KM-1M reg )
2n2oise

4 DRGP WITH VARIATIONAL SPARSE SPECTRUM APPROXIMATION

In this section we want to combine our newly derived (V)SSGP-(IP) approximations in 11, overall four cases SSGP, VSSGP, SSGP-IP, VSSG-IP, with the framework introduced in Mattos et al. (2016), to derive our models DRGP-SSGP, -VSSGP, -SSGP-IP, -VSSG-IP.

4.1 DRGP-(V)SS(-IP) MODEL DEFINITION

Choosing the same recurrent structure as in Mattos et al. (2016), where now i represents the time, yHx+1: = [yHx+1, . . . , yN ]T  RN^ (to simplify notation, we write hH(Lx++11): d=ef yHx+1:), we have

:

h(il) = f(l)(h^i(l)) +

,h(l)
i

:

yi = f(l)(h^i(l)) +

y i

,

with prior with prior

f (l)
H^ (l)

|H^

(l)



N (0,

KN(^l)N^ ),

f (l)
H^ (l)

|H^

(l)



N (0,

KN(^l)N^ ),

l = 1, . . . , L l = L+1

with ,  in Equation (1) and (2),

h(l) i



N (0, ((nlo)ise)2),

y i

 N (0, ((nLoi+se1))2) and N^

=

N - Hx,

for i = Hx + 1, . . . , N . The matrix KN(^l)N^ represents a covariance matrix coming from our chosen

k~ from Equation 4 and 5. A set of input-data H^ (l) = [h^H(l)x+1, . . . , h^(Nl)]T is specified as

5

Under review as a conference paper at ICLR 2019


      h^(il) d=ef 
      

hi(-1)1, xi-1 T d=ef hi(-l)1, hi(l-1) T d=ef
hi(L)d=ef

hi(-1)1, . . . , h(i-1)Hh

T
, [xi-1, . . . , xi-Hx ] ,

hi(-l)1, . . . , h(i-l)Hh , h(il-1), . . . , h(i-l-H1h) +1

h(iL), . . . , h(i-L)Hh+1

T
,

T
,

l = 1 (12) l = 2, . . . , L l = L + 1,

where h^i(1)  RHh+HxQ, h^(il)  R2Hh for l = 2, . . . , L, h^i(L+1)  RHh , for i = Hx + 1, . . . , N . For simplification we set H d=ef Hx = Hh in our experiments.
Now we use the new approximations in 11 to derive the new joint probability density

p [ ] =yHx+1:

a(l),Z(l),h(l),U (l)

L+1 |X
l=1

L+1
p p p p ,l=1 hH(l)x+1:|a(l),Z(l),H^ (l),U (l) a(l) Z(l) h~ (l)

with ph~ (L+1) = 1, h(L+1) = {} and h~(l) = [h1(l+) Hx-Hh , . . . , h(Hl)h ]T  R2Hh-Hx . Here the priors pa(l) , pzm(l) , ph~ (l) are

a(l)  N (0, IM ), zm(l)  N (0, IQ), h~ (l)  N (0, I2Hh-Hx ),

the product of them is defined as P ,REVARB and the variational distributions qa(l) , qzm(l) , qhi(l) are

a(l)  N (m(l), s(l)), zm(l)  N ((ml), (ml)), hi(l)  N (µi(l), i(l)),

the product of them is defined as Q ,REVARB and where (ml)  RQ×Q is diagonal, for i = 1 + Hx -

Hh, . . . , N , m = 1 . . . , M , l = 1, . . . , L + 1. For the setting (V)SSGP-IP, see Section 3.3, we

choose no variational distribution for the weights a(l) but for l = 1, . . . , L + 1 the prior assumptions

a(l)|U (l)  N (0, KM(l)M ), hH(l)x+1:|a(l), Z(l), H^ (l), U (l)  N ((KM(l)M )-1a(l), KN(l)N - KN(l)M (KM(l)M )-1KM(l)N ). This defines our models for the cases DRGP-VSS, DRGP-VSS-IP. In the case where we are not variational over the spectral-points we derive the simplified versions DRGP-SS, DRGP-SS-IP.

4.2 DRGP-(V)SS(-IP) VARIATIONAL EVIDENCE LOWER BOUND

Using standard variational approximation techniques (Blei et al., 2017), the Recurrent Variational Bayes lower bound for the (V)SS(-IP) approximations, denoted as REVARB-(V)SS(-IP), is given by

log(p(yHx+1:|X)) 

E[

L+1 l=1

log(p(hH(l)x+1:|a(l), Z(l), H^ (l), U(l)))]QREVARB

-

KL(QREVARB ||PREVARB )

d=ef

L .REVARB (V)SS(-IP)

(13)

Additionally,

for

the

simple

(V)SSGP

approximations

the

optimal

bound

LREVARB (V)SS-opt

can

be

obtained

immediately analogous to Gal & Turner (2015) Proposition 3 and the fact, that the bound decom-

poses into a sum of independent terms for a(l). Maximizing the lower bounds is equivalent to

minimizing the KL-divergence of QREVARB and the true posterior, therefore this is a way to optimize the approximated model parameter distribution with respect to the intractable, true model param-

eter posterior.

Calculating

LREVARB (V)SS-opt/IP

requires O(N M 2QmaxL), where Qmax

=

maxl=1...,L+1 Q(l),

Q(l) d=ef dim(h^i(l)) and h^(il) from Equation (12). DVI can reduce the complexity to O(M 3) if the number of cores scales suitable with the number of training-data. A detailed derivation of the

REVARB-(V)SS(-IP) lower bound can be found in the Appendix 6.3.4.

4.3 MODEL PREDICTIONS
After model optimization based on the lower bounds in Equation 13, model predictions for new h^(l) in the REVARB-(V)SS(-IP) framework can be obtained based on the approximate, variational posterior distribution Q .REVARB They are performed iteratively with approximate uncertainty propagation between each GP layer. We derive qh(l) from previous time-steps and it is per definition Gaussian with mean and variance derived from previous predictions for l = 1, . . . , L. These kind of models propagate the uncertainty of the hidden GP layers' outputs, not of the observed output-data and are relevant for good model predictions. The detailed expressions for the mean and variance of the predictive distribution involved during the predictions can be found in the Appendix 6.3.5.

6

Under review as a conference paper at ICLR 2019

4

32
2 11
00 -1
-2 -1 -3

32
1 2
0
1 -1

-4 -2

0 -2

100

200 250

0

100

200 250

0

100

200 250

0

100 200 250

4

42

2

2 2

0000

-2 -2 -2 -2
-4 -4

0

200

400 512

0

200

400 512

0

200

400 512

0

200 400 512

Figure 1: Simulation results visualized for the data-sets Drive (first row) and Actuator (second row) for the method DRGP-VSS. First column represents the initial hidden states, blue: first layer, and red: second layer. The second column represents the learned hidden states. The third column shows the simulation results, blue: real data, black: simulation, grey: ±2 times Standard Deviation (SD) and the fourth column the predicted hidden states.

5 EXPERIMENTS
In this section we want to compare our methods DRGP-SS, DRGP-VSS (optimal bound case) and DRGP-SS-IP, DRGP-VSS-IP, against other well known sparse GPs and the full GP with NARX structure, the GP-SSM of Svensson et al. (2016), the DRGP-Nystro¨m of Mattos et al. (2016), the DGP-DS of Salimbeni & Deisenroth (2017) with NARX structure, the GP-LSTM of Al-Shedivat et al. (2017) and PR-SSM Do¨rr et al. (2018). The full GP is named GP-full, the FITC approximation of Snelson & Ghahramani (2006) is named GP-FITC, the DTC approximation of Williams & Seeger (2000) is named GP-DTC, the SSGP of La´zaro-Gredilla et al. (2010) is named GP-SS, the VSSGP of Gal & Turner (2015) is named GP-VSS. The setting in this system identification task is simulation. This means that no past measured output observations (but perhaps predicted output observations) are used to predict next output observations. To enable a fair comparison, all methods are given access to a predefined amount of data. Details about the methods, their configuration, as well as the benchmark data-sets can be found in the Appendix 6.1 and 6.2.
5.1 IMPLEMENTATION
Our methods DRGP-(V)SS(-IP) were implemented in Python, using the library Theano and Matlab R2016b. For the optimization/training we used Python, Theano. Theano allows us to take full advantage of the automatic differentiation to calculate the gradients. For simulation and visualization we used Matlab R2016b. We further implemented in Matlab R2016b the methods DRGP-Nystro¨m, GP-SS, GP-DTC, GPFITC, GP-full and used these implementations for the experiments. For GP-VSS, GP-LSTM and DGP-DS we used the published code345. For GP-SSM the published code is only applicable for small range of state dimension and a small time horizon, so we just show the results from their paper. For PRR-SSM we also show the results from their paper.
5.2 BENCHMARK DATA-SETS MODEL LEARNING AND COMPARISON
In Figure 1 we show a comparison of the latent model states before and after training, the simulation results, as well as the simulated latent states for the data-sets Drive and Actuator for the model DRGP-VSS. The test RMSE results for all methods are summarized in Table 1. The results show that on most data-sets DRGP-(V)SS(-IP) improve slightly in comparison to other methods. In order
3GP-VSS code available from https://github.com/yaringal/VSSGP. 4GP-LSTM code available from https://github.com/alshedivat/keras-gp. 5DGP-GP code available from https://github.com/ICL-SML/Doubly-Stochastic-DGP.

7

Under review as a conference paper at ICLR 2019

RMSE RMSE RMSE

Drive 0.8

Damper 15

Actuator 0.7

0.6 10

0.6 0.5

0.4 0.4

5

0.2 0.3

1234

1234

1234

layers L

layers L

layers L

DRGP-Nyström DRGP-SS DRGP-VSS DRGP-SS-IP DRGP-VSS-IP

Figure 2: RMSE values for different number of layers L for the data-sets Drive, Damper, Actuator.

Table 1: Summary of RMSE values for the free simulation results on test data. Best values per data-set are bold. All values are calculated on the original data, unless the data-set Power Load, where the RMSE is shown for the normalized data. Here we have full recurrence for our methods and DRGP-Nystro¨m and with auto-regressive part for standard sparse GPs and full GP. For non-rec we turned off the auto-regressive part in the first layer for our methods and DRGP-Nystro¨m and also turned off the auto-regressive part for standard sparse GPs, full GP and DGP-DS.

methods-data
DRGP-VSS DRGP-VSS-IP
DRGP-SS DRGP-SS-IP DRGP-Nystro¨ m
DGP-DS GP-LSTM
PR-SSM GP-SSM GP-VSS
GP-SS GP-DTC GP-FITC
GP-full

Emission
0.104 0.119 0.108 0.118 0.109 0.106 0.096
N/A N/A 0.130 0.128 0.137 0.126 0.122

non-rec
0.062 0.064 0.062 0.065 0.059 0.062
N/A N/A N/A 0.058 0.060 0.061 0.057 0.066

Power Load
0.457 0.544 0.497 0.631 0.493 0.543 0.529
N/A N/A 0.514 0.539 0.566 0.536 0.696

Damper
5.825 6.112 5.277 5.129 6.344 6.267 9.083
N/A 8.170 6.554 6.730 7.474 6.754 9.890

Actuator
0.357 0.441 0.329 0.534 0.368 0.590 0.430 0.502
N/A 0.449 0.439 0.458 0.433 0.449

non-rec
0.388 0.546 0.563 0.547 0.415 0.576
N/A N/A N/A 0.767 0.777 0.864 0.860 1.037

Ballbeam
0.084 0.071 0.081 0.076 0.082 0.066 0.062 0.073
N/A 0.120 0.077 0.122 0.084 0.128

Dryer
0.109 0.107 0.108 0.107 0.109 0.085 0.108 0.140
N/A 0.112 0.106 0.105 0.108 0.106

Drive
0.229 0.302 0.226 0.297 0.249 0.422 0.320 0.492
N/A 0.401 0.358 0.408 0.403 0.444

non-rec
0.268 0.293 0.253 0.261 0.289 0.571
N/A N/A N/A 0.549 0.556 0.540 0.539 0.542

to evaluate the reproducing quality of our results, we provide a robustness test for our methods and DRGP-Nystro¨m on the data-sets Drive and Damper. We run the optimization for different time horizons. For every method we visualized a boxplots with whiskers from minimum to maximum in Figure 4. For our models we derive good results compared with DRGP-Nystro¨m on these data-sets, in particular for the setting of time horizons of Table 1 with H = 10. In Figure 2 the RMSE results for different layers L on the data-sets Drive, Damper and Actuator are shown. We can observe that different layers L are favored.
5.3 CONCLUSION
In this paper we introduced four new DRGPs based on the SS approximation introduced by La´zaroGredilla et al. (2010) and the improved VSS approximation by Gal & Turner (2015). We combined the (V)SS approximations with the variational inducing-point approximation from Titsias & Lawrence (2010), also integrated variationally over the input-space and established the existence of an optimal variational distribution of the weights a(l) in the sense of a functional local optimum of the variational bounds for DRGP-(V)SS. We could show that our methods slightly improve on the data-sets used in this paper compared to the RGP from Mattos et al. (2016) and other state-of-the-art methods. Our sparse approximations are also practical for dimensionality reduction as shown in Titsias & Lawrence (2010) and can be further expanded to a deep version in this application (Damianou & Lawrence, 2013).

ACKNOWLEDGMENTS We would like to acknowledge support for this project from the ETAS GmbH.
8

Under review as a conference paper at ICLR 2019

RMSE RMSE

H=6
0.6 0.5 0.4 0.3 0.2

H=10

H=12

H=2
15 10
5

H=6 H=10

DRGP-Nyström DRGP-VSS DRGP-VSS-IP DRGP-SS DRGP-SS-IP DRGP-Nyström DRGP-VSS DRGP-VSS-IP DRGP-SS DRGP-SS-IP DRGP-Nyström DRGP-VSS DRGP-VSS-IP DRGP-SS DRGP-SS-IP DRGP-Nyström DRGP-VSS DRGP-VSS-IP DRGP-SS DRGP-SS-IP DRGP-Nyström DRGP-VSS DRGP-VSS-IP DRGP-SS DRGP-SS-IP DRGP-Nyström DRGP-VSS DRGP-VSS-IP DRGP-SS DRGP-SS-IP

Figure 3: Data-set Drive, Boxplot, 10 runs. Figure 4: Data-set Damper, Boxplot, 10 runs.
REFERENCES
Maruan Al-Shedivat, Andrew Gordon Wilson, Yunus Saatchi, Zhiting Hu, and Eric P Xing. Learning scalable deep kernels with recurrent structure. The Journal of Machine Learning Research, 18(1): 2850­2886, 2017.
Christopher M Bishop. Pattern recognition. Machine Learning, 128:1­58, 2006.
David M Blei, Alp Kucukelbir, and Jon D McAuliffe. Variational inference: A review for statisticians. Journal of the American Statistical Association, 112(518):859­877, 2017.
Kurt Cutajar, Edwin V Bonilla, Pietro Michiardi, and Maurizio Filippone. Practical Learning of Deep Gaussian Processes via Random Fourier Features. stat, 1050:14, 2016.
Zhenwen Dai, Andreas Damianou, Javier Gonza´lez, and Neil D Lawrence. Variational Autoencoded Deep Gaussian processes. International Conference on Learning Representations, 2016.
Andreas C Damianou and Neil D Lawrence. Deep Gaussian Processes. In Artificial Intelligence and Statistics, pp. 207­215, 2013.
Andreas Do¨rr, Christian Daniel, Schiegg Martin, Duy Nguyen-Tuong, Stefan Schaal, Marc Toussaint, and Sebastian Trimpe. Probabilistic Recurrent State-Space Models. arXiv preprint arXiv: 1801.10395, 2018.
Roman Fo¨ll, Bernard Haasdonk, Markus Hanselmann, and Holger Ulmer. Deep Recurrent Gaussian Process with Variational Sparse Spectrum Approximation. arXiv preprint arXiv:1711.00799v2, 2017.
Roger Frigola, Yutian Chen, and Carl Edward Rasmussen. Variational Gaussian process state-space models. In Advances in Neural Information Processing Systems, pp. 3680­3688, 2014.
Yarin Gal and Richard Turner. Improving the Gaussian Process Sparse Spectrum Approximation by Representing Uncertainty in Frequency Inputs. In International Conference on Machine Learning, pp. 655­664, 2015.
Yarin Gal, Mark van der Wilk, and Carl Edward Rasmussen. Distributed variational inference in sparse Gaussian process regression and latent variable models. In Advances in Neural Information Processing Systems, pp. 3257­3265, 2014.
James Hensman and Neil D Lawrence. Nested Variational Compression in Deep Gaussian Processes. stat, 1050:3, 2014.
Sepp Hochreiter and Ju¨rgen Schmidhuber. Long short-term memory. Neural computation, 9(8): 1735­1780, 1997.
Olav Kallenberg. Foundations of modern probability. Springer Science & Business Media, 2006.
9

Under review as a conference paper at ICLR 2019
Miguel La´zaro-Gredilla, Joaquin Quin~onero-Candela, Carl Edward Rasmussen, and An´ibal R. Figueiras-Vidal. Sparse spectrum Gaussian process regression. Journal of Machine Learning Research, 11(Jun):1865­1881, 2010.
Ce´sar Lincoln C Mattos, Zhenwen Dai, Andreas Damianou, Jeremy Forth, Guilherme A Barreto, and Neil D Lawrence. Recurrent Gaussian processes. International Conference on Learning Representations, 2016.
Oliver Nelles. Nonlinear system identification: from classical approaches to neural networks and fuzzy models. Springer Science & Business Media, 2013.
Razvan Pascanu, Caglar Gulcehre, Kyunghyun Cho, and Yoshua Bengio. How to construct deep recurrent neural networks. arXiv preprint arXiv:1312.6026, 2013.
Carl Edward Rasmussen. Gaussian processes for machine learning. 2006.
Hugh Salimbeni and Marc Deisenroth. Doubly stochastic variational inference for deep gaussian processes. In Advances in Neural Information Processing Systems, pp. 4588­4599, 2017.
Jonas Sjo¨berg, Qinghua Zhang, Lennart Ljung, Albert Benveniste, Bernard Delyon, Pierre-Yves Glorennec, Ha°kan Hjalmarsson, and Anatoli Juditsky. Nonlinear black-box modeling in system identification: a unified overview. Automatica, 31(12):1691­1724, 1995.
Edward Snelson and Zoubin Ghahramani. Sparse Gaussian processes using pseudo-inputs. Advances in neural information processing systems, 18:1257, 2006.
Michael L Stein. Interpolation of spatial data: some theory for kriging. Springer Science & Business Media, 2012.
Andreas Svensson, Arno Solin, Simo Sa¨rkka¨, and Thomas Scho¨n. Computationally efficient Bayesian learning of Gaussian process state space models. In Artificial Intelligence and Statistics, pp. 213­221, 2016.
Michalis K Titsias. Variational Learning of Inducing Variables in Sparse Gaussian Processes. In Artificial Intelligence and Statistics, volume 5, pp. 567­574, 2009.
Michalis K Titsias and Neil D Lawrence. Bayesian Gaussian Process Latent Variable Model. In Artificial Intelligence and Statistics, volume 9, pp. 844­851, 2010.
Ryan D Turner, Marc Peter Deisenroth, and Carl Edward Rasmussen. State-Space Inference and Learning with Gaussian Processes. In Artificial Intelligence and Statistics, pp. 868­875, 2010.
Jack M Wang, David J Fleet, and Aaron Hertzmann. Gaussian process dynamical models. In Neural Information Processing Systems, volume 18, pp. 3, 2005.
Jiandong Wang, Akira Sano, Tongwen Chen, and Biao Huang. Identification of Hammerstein systems without explicit parameterisation of non-linearity. International Journal of Control, 82(5): 937­952, 2009.
Torbjo¨rn Wigren. Input-output data sets for development and benchmarking in nonlinear identification. Technical Reports from the department of Information Technology, 20:2010­020, 2010.
Christopher KI Williams and Matthias Seeger. Using the Nystro¨m method to speed up kernel machines. In Proceedings of the 13th International Conference on Neural Information Processing Systems, pp. 661­667. MIT press, 2000.
Andrew Wilson and Ryan Adams. Gaussian process kernels for pattern discovery and extrapolation. In International Conference on Machine Learning, pp. 1067­1075, 2013.
Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, and Eric P Xing. Deep kernel learning. In Artificial Intelligence and Statistics, pp. 370­378, 2016.
10

Under review as a conference paper at ICLR 2019

6 APPENDIX
This additional material provides details about the derivations and configuration of the proposed DRGP-(V)SS(-IP) in the Sections 3-4. and elaborates on the methods and the employed data-sets in the experiments in Section 5.

6.1 DATA-SET DESCRIPTION

Table 2: Summary of the data-sets for the system identification tasks

parameters \
data-sets
Drive Dryer Ballbeam Actuator Damper Power Load Emission

N
500 1000 1000 1024 3499 9518 12500

Ntrain
250 500 500 512 2000 7139 10000

Ntest
250 500 500 512 1499 2379 2500

input dimension
1 1 1 2 1 11 6

output dimension
1 1 1 1 1 1 1

In this section we introduce the data-sets we used in our experiments. We chose a large number of data-sets in training size going from 250 to 12500 data-points in order to show the performance for a wide range. We will begin with the smallest, the Drive data-set, which was first introduced by Wigren (2010). It is based on a system which has two electric motors that drive a pulley using a flexible belt. The input is the sum of voltages applied to the motors and the output is the speed of the belt. The data-set Dryer6 describes a system, where air is fanned through a tube and heated at an inlet. The input is the voltage over the heating device (a mesh of resistor wires). The output is the air temperature measured by a thermocouple. The third data-set Ballbeam67 describes a system, where the input is the angle of a beam and the output the position of a ball. Actuator is the name of the fourth data-set, which was described by Sjo¨berg et al. (1995) and which stems from an hydraulic actuator that controls a robot arm, where the input is the size of the actuator's valve opening and the output is its oil pressure. The Damper data-set, introduced by Wang et al. (2009), poses the problem of modeling the input­output behavior of a magneto-rheological fluid damper and is also used as a case study in the System Identification Toolbox of Mathworks Matlab. The data-set Power Load8, used in Al-Shedivat et al. (2017), consists of data, where the power load should be predicted from the historical temperature data. This data-set was used for 1-step ahead prediction, where past measured output observations are used to predict current or next output observations, but we will use it here for free simulation. We down-sampled by starting with the first sample and choosing every 4th data-point, because the original data-set with a size of 38064 samples and a chosen time-horizon of 48 is too large for our implementation, which is not parallelized so far. The newly provided dataset Emission9 contains an emission-level of nitrogen oxide from a driving car as output and as inputs the indicated torque, boost pressure, EGR (exhaust gas recirculation) rate, injection, rail pressure and speed. The numerical characteristics of all data-sets are summarized in Table 2. The separation of the data-sets Drive, Dryer, Ballbeam, Actuator, Damper, Power Load in training- and test-data was given by the papers we use for comparison. The separation of the Emission data-set was chosen by ourself.

6Received from http://homes.esat.kuleuven.be/~tokka/daisydata.html. 7Description can be found under http://forums.ni.com/t5/NI-myRIO/ myBall-Beam-Classic-Control-Experiment/ta-p/3498079. 8Originally received from Global Energy Forecasting Kaggle competitions organized in 2012. 9Available from http://github.com/RomanFoell/DRGP-VSS.
11

Under review as a conference paper at ICLR 2019

6.2 NONLINEAR SYSTEM IDENTIFICATION

Table 3: Summary of the methods for the system identification tasks

method DRGP-VSS DRGP-VSS-IP
DRGP-SS DRGP-SS-IP DRGP-Nystro¨ m
DGP-DS GP-LSTM
PR-SSM GP-SSM GP-VSS
GP-SS GP-DTC GP-FITC
GP-full

references this one this one this one this one
(Mattos et al., 2016) (Salimbeni & Deisenroth, 2017)
(Al-Shedivat et al., 2017) (Do¨rr et al., 2018)
(Svensson et al., 2016) (Gal & Turner, 2015)
(La´zaro-Gredilla et al., 2010) (Williams & Seeger, 2000)
(Snelson & Ghahramani, 2006) (Rasmussen, 2006)

The methods for the system identification tasks and their references are summarized in Table 2. For the data-sets Drive and Actuator we chose for our methods DRGP-(V)SS(-IP) the setting L = 2 hidden layers, M = 100 spectral-points and time-horizon Hh = Hx = 10, which was also used in Mattos et al. (2016), Al-Shedivat et al. (2017) and Do¨rr et al. (2018) for free simulation (using M pseudo-input points instead of spectral-points). For these two data-sets we filled the results from Mattos et al. (2016); Al-Shedivat et al. (2017) into Table 1. Further, for our methods DRGP(V)SS(-IP) and DRGP-Nystro¨m we chose on the data-sets Ballbeam and Dryer L = 1, M = 100 and Hh = Hx = 10. For the data-set Damper we chose L = 2, M = 125 and Hh = Hx = 10. For the data-set Power Load we chose L = 1, M = 125 and Hh = Hx = 12. For the data-set Emission we chose L = 1, M = 125 and Hh = Hx = 10. The other sparse GP, the full GP and DGP-DS were trained with NARX structure Hx = Hy with the same time horizon as for our DRGPs and with the same amount of pseudo-input points or spectral points. For GP-LSTM we chose the same setting for the amount of hidden layers, pseudo-input points and time horizon as for our DRGPs. We used Adam optimizer with a learning rate of 0.01. As activation function we chose tanh and as setting free simulation. We tested with 8, 16, 32, 64, 128 hidden units (every hidden layer of a RNN is specified by a hidden unit parameter) for all training data-sets. For the data-sets with training size smaller or equal to 2000 we chose the version GP-LSTM in AlShedivat et al. (2017) and for the ones larger than 2000 the scalable version MSGP-LSTM. We did not pre-train the weights. For DGP-DS we tested for L = 1, . . . , 3 number of GPs. We used natural gradients for the last GP with gamma 0.1 and Adam optimizer for the others with a learning rate of 0.01. The batch size was chosen to be the training data-size. All GPs which use the Nystro¨m approximation were initialized for the pseudo-inputs points with a random subset of size M from the input-data and trained with SE covariance function. For the ones which use the (V)SS approximations, which includes our methods, we trained with a spectral-point initialization sampled from N (0, IQ), an initialization for the pseudo-input points with a random subset of size M from the input-data (or setting them all to zero; not in the IP case). For our methods DRGP-(V)SS(-IP) and GP-VSS we fixed the length scales p(ql) = , for all q, l. So all GPs with (V)SS approximations were also initialized as SE covariance function, see Equation 5. For all methods we used automatic relevance determination, so each input dimension has its own length scale. For our methods DRGP-(V)SS(-IP) and DRGP-Nystro¨m, the noise parameters and the hyperparameters were initialized by n(lo)ise = 0.1, p(lo)wer = 1 and the length scales by either
lq(l) = max(H^ (ql)) - min(H^ (ql)) or lq(l) = max(H^ (ql)) - min(H^ (ql)), for all q, l, where H^ q(l) is the
data-vector containing the q-th input-dimension values of every input-data point h^i(l), for all i. Furthermore, we initialized the latent hidden GP states with the output-observation data y. The other standard GPs were also initialized with noise = 0.1, power = 1 and the same initialization for length scales with respect to the NARX structure input data as before. For GP-LSTM we used the initialization for the weights provided by Keras, a Deep Learning library

12

Under review as a conference paper at ICLR 2019

for Theano and TensorFlow and noise = 0.1, power = 1 and for the length scale initialization we chose lq = 1 for all input-dimensions.

For DGP-DS we used the initialization (nlo)ise = 0.1 and (plo)wer = 1 and for the length scale initialization we chose l(ql) = 1 for all l, q.

For all our implementations, see Section 5.1, we used the positive transformation x = log(1 +

exp(x))2 for the calculation of the gradients in order for the parameters constrained to be positive

and with L-BFGS optimizer, either from Matlab R2016b with fmincon, or Python 2.7.12 with scipy

optimize.

All

methods

were

trained

on

the

normalized

data

···-µ 2

(for

every

dimension

independently),

several

times (same amount per data-set: the initializations are still not deterministic, e.g. for pseudo-inputs

points and spectral points) with about 50 to 100 iterations and the best results in RMSE value on the

test-data are shown in Table 1. For our methods DRGP-(V)SS(-IP) and DRGP-Nystro¨m we fixed n(lo)ise, (plo)wer for all l (optional the spectral points/pseudo-input points for DRGP-(V)SS; for the IP case we never excluded the

pseudo-input points because we would fall back to the DRGP-(V)SS case; for DRGP-Nystro¨m we

always included the pseudo-input points) during the first iterations to independently train the latent

states. For all other GPs we also tested with fixed and not fixed noise = 0.1, except GP-LSTM and DGP-DS. For DRGP-VSS(-IP) we fixed m(l) for all m, l to small value around 0.001, as well as the spectral phases bm for all m, l sampling from Unif [0, 2] (this seems to work better in practice).
The limitations for (ml) also holds for GP-VSS as well. We want to signify at this point that setting um = 0 for all m = 1, . . . , M worked sometimes better

than choosing a subset from the input-data (not in the IP case). This seems to be different to Gal &

Turner (2015), who pointed out: 'These are necessary to the approximation. Without these points

(or equivalently, setting these to 0), the features would decay quickly for data points far from the

origin (the fixed point 0).'

For GP-SSM we show the result of the data-set Damper from their paper in Table 1.

For PR-SSM we show the results from their paper in Table 1.

We show additional results for the data-sets Drive, Actuator and Emission with missing auto-

regressive part for the first layer for our methods DRGP-(V)SS(-IP) and DRGP-Nystro¨m in Table 1,

named non-rec. For the sparse GP, the full GP and DGP-DS and the data-sets Drive, Actuator and

Emission we show the results with missing auto-regressive part in Table 1, just modeling the data

with exogenous inputs. Here we want to examine the effect of the auto-regressive part of the first

layer for the DRGP models on the RMSE. GP-LSTM, GP-SSM and PR-SSM are not listed for

this setting of recurrence (we used the original code for GP-LSTM, which is not adaptable for this

recurrence setting).

6.3 VARIATIONAL APPROXIMATION AND INFERENCE FOR DRGP-(V)SS(-IP)

In the Sections 6.3.1-6.3.3 we derive the statistics 0, 1, 2 and reg for the four model cases DRGP-(V)SS(-IP). In Section 6.3.4 we derive the resulting variational lower bounds. In Section 6.3.5 we show the mean and variance expressions of the predictive distributions of our DRGP models.
In the following we use the abbreviations and formulas

· B.1, (Gal & Turner, 2015, see Section 4.1),

· B.2, (Rasmussen, 2006, see A.7.),

·

1 2

(cos(a

-

b

+

x

-

y)

+

cos(a

+

b

+

x

+

y))

=

cos(x

+

a)

cos(y

+

b).

· JI, for Jensen's inequality.

6.3.1 DRGP-VSS(-IP), THE STATISTICS 1, 2

For the versions DRGP-VSS(-IP) the statistics are

(1)nm = E [nm]qzm qhn

B=.1 E

2p2ower(M )-1e-

1 2

h¯ Tnm m h¯ nm

cos(^ mT (hn

-

um)

+

bm)

qhn

B=.2

1mZnme-

1 2

^ TmCnm^ m

cos(^ mT (cnm

-

um)

+

bm),

13

Under review as a conference paper at ICLR 2019

for m, = 1, . . . , M , n = 1, . . . , N with

h¯nm = 2L-1(hn - um),

^ m = 2(L-1m + p),

cnm = Cnm(m(2)2L-2um + -n 1µn),

Cnm = (m(2)2L-2 + -n 1)-1,

vnm = um - µn,

Vnm = (2)-2L2-m1 + n,

Znm =

1 e ,-

1 2

vnTm

Vn-m1

vnm

|Vnm|

1m = 2p2ower

Q l2q (M )-1, q=1 mq

and

2 = nN=1(2)n, where

(2)mn m

= E Tnmnm qzm qzm qhn

B=.1 E

22power

(M

)-1

e-

1 2

(h¯ nTm

m

h¯ nm

+h¯ nTm

m

h¯ nm

)

cos(^ Tm(hn - um) + bm) cos(^ mT (hn - um ) + bm )
qhn

B=.2 m2 m Zmn m

e-

1 2

¯ mT m

Dnmm

¯ mm

cos(¯ Tmm dmn m

- ¯mm

+ b¯mm )

+e-

1 2

+T
mm

Dnmm

+
mm

+T
cos(mm

dmn m

-

+
mm

+
+ bmm )

.

for m, m = 1, . . . , M , m = m , with

bmm = bm - bm ,

+
bmm = bm + bm ,

¯mm = ^ mT um - ^ mT um ,

+
mm

= ^ mT um + ^ Tm um ,

¯ mm = ^ m - ^ m ,

+
mm

= ^ m + ^ m ,

bmm = Bmm (2)2L-2(mum + m um ),
mm = m + m ,
Bmm = (2)-2L2-m1m , dmn m = Dmn m (Bm-1m bmm + n-1µn), Dmn m = (B-m1m + -n 1)-1, wmn m = bmm - µn, Wmn m = Bmm + n,
umm = um - um ,

Umm = (2)-2L2(m-1 + -m1),

Zmn m =

1 e ,-

1 2

(wmn m

T Wmn m

-1wmn m

+umT m

U-1
mm

umm

)

|Wmn m | |Umm |

m2 m = 2power

Q q=1

l2q mq m q

(M )-1,

14

Under review as a conference paper at ICLR 2019

and

(2)mn m = E Tnmnm qzm qhn

B=.1 E

2p2ower

(M

)-1(

1 2

+

1 e-2h¯Tnmmh¯nm 2

cos(2(^ mT (hn

-

um)

+

bm))

qhn

B=.2 2power(M )-1 1 + ~ 2mZ~nme-2^ TmC~ nm^ m cos(2(^ mT (c~nm - um) + bm)) ,

for m, m = 1, . . . , M , m = m , with

~ m2 =

Q lq2 2-Q. q=1 mq

6.3.2 DRGP-SS(-IP), THE STATISTICS 1, 2

For the versions DRGP-SS(-IP) the statistics are

(1)nm = E [nm]qhn

= E 22power(M )-1 cos(z^mT (hn - um) + bm)
qhn

B=.2

2p2ower(M )-1e-

1 2

z^mT

n

z^m

cos(z^mT (µn

-

um)

+

bm),

for m = 1, . . . , M , n = 1, . . . , N with z^m = 2(L-1zm + p),
and

2 = nN=1(2)n, where

(2)nmm = E Tnmnm qhn

B=.1 E 2p2ower(M )-1 cos(z^Tm(hn - um) + bm) cos(z^Tm (hn - um ) + bm ) qhn

= p2ower(M )-1

e-

1 2

z¯Tmm

n z¯mm

cos(z¯mT m µn - ¯mm

+ b¯mm )

+e-

1 2

+z mT m

n +z mm

cos(+zmT m µn - +mm

+
+ bmm ))

,

for m, m = 1, . . . , M with

¯mm = z^Tmum - z^mT um ,

+
mm

= z^Tmum + z^Tm um ,

z¯mm = z^m - z^m ,

+zmm = z^m + z^m ,

for the other variables, see the defined variables in the DRGP-VSS case.

6.3.3 DRGP-(V)SS-IP, THE STATISTICS reg AND 0
For reg = E [KMN KNM ]qH see 2 in 6.3.1 but setting bm = 0, m = 0 and m = 1 for all m = 1, . . . , M .
0 naturally is given by 0 = tr (E[KNN ]qH ) = N p2ower because of the chosen SE covariance function.

15

Under review as a conference paper at ICLR 2019

6.3.4 DRGP-(V)SS(-IP), LOWER BOUNDS

In this section we derive the different variational lower bounds for our models DRGP-(V)SS(-IP).

We

first

show

the

bound

LREVARB (V)SS

without

optimal

variational

distribution

for

a(l).

Then

the

bounds

LREVARB (V)SS-opt

with

optimal

variational

distribution

for

a(l)

follows,

as

well

as

the

LREVARB (V)SS-IP

case.

We use the simplified notation dAdZdH = da(1) . . . da(L+1)dZ(1) . . . dZ(L+1)dh(1) . . . dh(L).

log(p(yHx+1:|X))

= log

L+1
p yHx+1:, a(l), Z(l), h(l), U (l) l=1 |X

dAdZdH

= log

Q pREVARB QREVARB

 JI p  QREVARB log 

yHx+1:, a(L+1), Z(L+1), U (L+1),
yHx+1:, a(L+1), Z(L+1), U (L+1), QREVARB

L

a(l), Z(l), h(l), U (l)

|X

l=1

a(l), Z(l), h(l), U (l)

L l=1

|X

dAdZdH   dAdZdH

L+1
=
l=1

q(a(l))q(Z(l))q(h(l))p(hH(l)x+1:|a(l), Z(l), H^ (l), U (l))da(l)dZ(l)dh(l)



-

L

 N^ 

-

N

log(2i(l)) +

Hh

log(2) +

2 2

2

l=1 i=1+Hx-Hh

i=1+Hx -Hh

(il) + µi(l) 2 2


  

L+1

- KL(qa(l) ||pa(l) ) - KL(qZ(l) ||pZ(l) )

l=1

=

- N^ 2

L+1
log(2(n(lo)ise)2) -
l=1

yHT x+1:yHx+1: 2 n(Lo+is1e) 2

+

yHT x+1:1(L+1)m(L+1)
2

-

tr

n(Lo+is1e)

2(L+1)(s(L+1) + m(L+1)(m(L+1))T ) 2 n(Lo+is1e) 2


L
+ - 
l=1 2

1 (nlo)ise

2

N
(il)
i=L+1

+ (µ(l))THx+1:µH(l)x+1:

+

(µ(Hl)x+1:)T 1(l)m(l) (nlo)ise 2

tr -

(2l)(s(l) + m(l)(m(l))T ) 2 n(lo)ise 2

- N^ + N log(2i(l)) - Hh log(2) -

22

2

i=1+Hx -Hh

i=1+Hx -Hh

i(l) + µ(il) 2 2


  

L+1
- KL(qa(l) ||pa(l) ) - KL(qZ(l) ||pZ(l) )
l=1
= L ,def REVARB VSS

where

we

derive

LREVARB SS

by

being

not

variational

over

Z (l) .

Using

the

optimal

distribution

for

a(l)



N ((A(l))-1((1l))T µH(l)x+1:, ((nlo)ise)2(A(l))-1), with A(l) = (2l) + ((nlo)ise)2IM , respective yHx+1:

16

Under review as a conference paper at ICLR 2019

for L + 1 we obtain



- N^

-

M

L+1
log

2

l=1

(nlo)ise 2

-

yHT x+1:yHx+1:
2

2 n(Lo+is1e)

+

yHT x+1:(1L+1)(A(L+1))-1((1L+1))T yHx+1: 2 (nLo+is1e) 2

+

log(|(A(L+1))-1|) 2


L
+ - 
l=1 2

1 (nlo)ise

2

N
(il)
i=L+1

+ (µH(l)x+1:)T µH(l)x+1:

+

(µH(l)x

+1:

)T

(1l)(A(l))-1 2 n(lo)ise

(1(l)
2

)T

µH(l)x

+1:

+

log(|(A(l))-1|) 2

- N^ + N log(2(il)) - Hh log(2) -

22

2

i=1+Hx -Hh

i=1+Hx -Hh

(il) + µi(l) 2 2


  

-

(L + 1)N^ 2

L+1
log(2) - KL(qZ(l) ||pZ(l) )

l=1

= L ,def

REVARB VSS-opt

where

we

derive

LREVARB SS-opt

by

being

not

variational

over

Z (l) .

The IP regularization case with A(l) = 2(l) + (n(lo)ise)2KM(l)M is given by:

N^ - M L+1  - log
2
l=1

n(lo)ise 2

-

yHT x+1:yHx+1:
2
2 (nLo+is1e)

+

log(|KM(LM+1)|) 2

+

yHT x+1:1(L+1)(A(L+1))-1((1L+1))T yHx+1:
2
2 n(Lo+is1e)

+

log(|(A(L+1))-1|) 2

-

(0L+1)

+

tr((KM(LM+1))-1(rLeg+1)) 2n(Lo+is1e)



L
- - 
l=1 2

1 (nlo)ise

2

N
i(l)
i=L+1

+ (µH(l)x+1:)T µ(Hl)x+1:

+ log(|KM(l)M |) 2

+

(µ(Hl)x

+1:

)T

(1l)(A(l))-1 2 (nlo)ise

((1l)
2

)T

µH(l)x

+1:

+

log(|(A(l))-1|) 2

-

(0l)

+

tr((KM(l)M 2(nlo)ise

)-1 r(le)g )

-

N^ 2

N
+
i=1+Hx -Hh

log(2(il)) 2

Hh log(2) --
2
i=1+Hx -Hh

i(l) + µi(l) 2 2



  

-

(L

+ 1)N^ 2

log(2)

-

L+1
KL(qZ(l) ||pZ(l) )

l=1

= L ,def

REVARB VSS-IP

where

again

we

derive

LREVARB SS-IP

by

being

not

variational

over

Z (l) .

17

Under review as a conference paper at ICLR 2019

6.3.5 PREDICTIONS

Predictions for each layer l and new h^(l) are performed in the simple DRGP-(V)SS case with

E f (l) qf(l) = 1(l)m(l),

V f (l)

T
= m(l)

q
f

(l)

2(l) -

(1l) T 1(l)

m(l) + tr s(l)(2l) ,

where for the optimal distribution case for a(l) we have with A(l) = (2l) + ((nlo)ise)2IM

m(l) o=pt

-1
A(l)

1(l) T µ(Hl)x+1:,

s(l) o=pt (n(lo)ise)2

-1
A(l) ,

for 1, . . . , L, and fully analog for l = L + 1 by replacing µH(l)x+1: with yHx+1:. In the DRGP-(V)SS-IP case we make predictions for each layer l and new h^(l) through

E

f (l)

q
f

(l)

= 1(l)(l),

V f (l)

T
= (l)

q
f

(l)

(2l) - 1(l) T 1(l)

(l)

+ 0 - tr (KM(l)M )-1(rle)g - ((nlo)ise)2 A(l) -1 2(l)

,

where A(l) = (2l) + ((nlo)ise)2KM(l)M and

(l) o=pt

-1
A(l)

1(l) T µ(Hl)x+1:,

for 1, . . . , L, and fully analog for l = L + 1 by replacing µ(Hl)x+1: with yHx+1:.

18

