Under review as a conference paper at ICLR 2019
A DIFFERENTIABLE SELF-DISAMBIGUATED SENSE EMBEDDING MODEL VIA SCALED GUMBEL SOFTMAX
Anonymous authors Paper under double-blind review
ABSTRACT
We present a differentiable multi-prototype word representation model that disentangles senses of polysemous words and produces meaningful sense-specific embeddings without external resources. It jointly learns how to disambiguate senses given local context and how to represent senses using hard attention. Unlike previous multi-prototype models, our model approximates discrete sense selection in a differentiable manner via a modified Gumbel softmax. We also propose a novel human evaluation task that quantitatively measures (1) how meaningful the learned sense groups are to humans and (2) how well the model is able to disambiguate senses given a context sentence. Our model outperforms competing approaches on both human evaluations and multiple word similarity tasks.
1 SENSE-SPECIFIC EMBEDDING
Machine learning models for natural language processing applications often represent words with embeddings that are real-valued vectors. Popular word embedding models such as Word2Vec (Mikolov et al., 2013a;b) and GloVe (Pennington et al., 2014) have been instrumental in achieving state-ofthe-art results on NLP tasks such as sentiment analysis (Kim, 2014; Tai et al., 2015) and textual entailment (Chen et al., 2017).
However, for polysemous words (those with multiple senses), learning a single vector for each word type conflates different meanings (e.g., "A hydrogen bond exists between water molecules." vs. "Do you want to buy this bond?"). This is not a new problem--Schu¨tze (1998) demonstrates the deficiency of assigning just one vector per word--but it is more pernicious in modern models, as conflated senses can pull semantically unrelated words toward each other in the embedding space (Neelakantan et al., 2014; Pilehvar & Collier, 2016; Camacho-Collados & Pilehvar, 2018). To disentangle distinct senses in word embeddings and learn finer-grained semantic clusters, multi-prototype word embedding models learn multiple sense-specific embeddings for a single word (Section 7).
But what makes a good multisense word embedding? While word similarity is the most common evaluation, it has many detractors (Faruqui et al., 2016; Gladkova & Drozd, 2016): similarity is subjective and is hard to be differentiate from word relatedness. Moreover, word similarity tasks-- with the exception of Stanford Contextual Word Similarity (Huang et al., 2012, SCWS)--ignore polysemous cases or are tied to specific sense inventories (Boyd-Graber et al., 2006).
Moreover, these evaluations ignore a key component of learning sense inventories: do they make sense to a human? Previous multisense embedding papers present nearest neighbors to claim their representations are interpretable and useful. Like topic models, these claims need to be rigorously verified. In Section 6, we adapt techniqes for evaluating topic models (Chang et al., 2009) to measure whether learned sense groups are internally coherent and whether humans can consistently match a learned sense vector to a word in context. Just like topic models, word embedding models that win conventional evaluations do not always make sense to humans.
We present a simple, differentiable word sense embedding model that is interpretable (measured by human evaluations) while scoring well on traditional word similarity evaluations. Our model extends the Skip-Gram Word2Vec model and simultaneously learns (1) automatic sense induction given local context and (2) sense-specific embeddings. To learn disentangled sense representations (i.e., avoid sense mixing), we approximate hard attention and preserve differentiability via a scaled variant of the Gumbel Softmax function (Section 3.2). Both qualitative and quantitative analysis show that the
1

Under review as a conference paper at ICLR 2019

G Gumbel softmax M Marginalization

P (ski |wi, c~i)

sense attention

...

P (cji |wi) predict contexts
M

c¯i
c1i

...

cmi

G

...

s1i chemical si2 007
siK financial

context embeddings lookup

C

Ssense embeddings lookup

context words c~i

center word wi

+ You only live twice, Mr. Bond

Figure 1: Network struture with an example of our GASI model which learns a set of global context embeddings C and a set of sense embeddings S

proposed variant ­ Scaled Gumbel Softmax ­ is critical to disambiguate senses. Figure 1 gives an overview of the structure of our model.
We compare our proposed Gumbel-Attention Sense Induction (GASI) model with previous stateof-the-art sense-specific embedding models on both word similarity tasks (Section 5) and our new crowdsourcing evaluations (Section 6). Our model performs the best on both human tasks and multiple word similarity tasks, including the SCWS task which is tailored for polysemous cases. It is also comparable to previous state-of-the-art results on other similarity tasks.

2 FOUNDATIONS: SKIP-GRAM AND GUMBEL SOFTMAX

Our model extends Skip-Gram Word2Vec Mikolov et al. (2013a;b). The Skip-Gram Word2Vec jointly learns word embeddings W  R|V |×d and context embeddings C  R|V |×d, where V is the vocabulary and d is the embedding dimension, by maximizing the likelihood of the context words cij that surrounds a given center word wi in a context window c~i,

J(W, C) 

log P (cji | wi; W, C).

wiV cij c~i

(1)

Where P (cij | wi) is estimated by a softmax over all possible context words, i.e, the whole vocabulary,

P (cij | wi; W, C) =

exp cji wi cV exp (c wi) .

In practice, log P (cji | wi) is approximated by negative sampling to reduce computational cost.

(2)

2.1 GUMBEL SOFTMAX

The Gumbel softmax Jang et al. (2016); Maddison et al. (2016) approximates the sampling of discrete
random variables. Given a discrete random variable X with P (X = k)  k, k  (0, ), the Gumbel-max Gumbel & Lieblein (1954); Maddison et al. (2014) refactors the sampling of X into

X = arg max(log k + gk),
k

(3)

where the Gumbel noise gk = - log(- log(uk)) and uk are i.i.d samples drawn from Uniform(0, 1).

The Gumbel softmax approximates the sampling results one hot(arg maxk(log k + gk)) by,

yk = softmax((log k + gk)/ ).

(4)

3 GUMBEL-ATTENTION SENSE INDUCTION (GASI)

Building on these foundations, we now introduce our model (GASI, and along the way introduce a soft-attention stepping-stone, SASI); afterward, we will compare the model on both traditional

2

Under review as a conference paper at ICLR 2019

GASI- (0.4)

GASI- (0.5)

GASI- (0.7)

GASI (no scaling)

Probability

0.8  = 0.5
0.6
0.4 0.2 0.0
sense0 sense1 sense2

 = 0.5

 = 0.5

sense0 sense1 sense2 sense0 sense1 sense2

 = 0.1  = 0.5  = 1.0
sense0 sense1 sense2

Figure 2: As the scale factor  increases, the sense selection distribution for "bond" given examples from SemCor3.0 for synset "bond.n.02" becomes flatter, indicating less disambiguated sense vectors.

evaluation metrics and interpretability. The critical component of our model is that we model the sense selection probability, which can be interpreted as sense attention over contexts, into the SkipGram model while preserving the original objective through marginalization (Figure 1). By using Gumbel Softmax, our model both approximates discrete sense selection and is differentiable. Previous models are either non-differentiable or otherwise complicate inference through hard attention with reinforcement learning methods (Lee & Chen, 2017).

3.1 ATTENTIONAL SENSE INDUCTION FRAMEWORK

Embedding Parameters We learn a context embedding matrix C  R|V |×d and a sense embedding tensor S  R|V |×K×d. Unlike previous work (Neelakantan et al., 2014; Lee & Chen, 2017), no extra
embeddings are kept for sense induction.

Number of Senses For simplicity and consistency with most of previous work, we present our model with a fixed number of senses K.1 We can prune duplicate senses by a model-specific pruning
threshold  estimated from learned embeddings,



=

1 2

(mean(Ddup)

+

mean(Dnn)),

(5)

where Ddup is a set of cosine distances between duplicate senses (senses of the same word that are

nearest neighbors of each other) of sampled words and Dnn is a set of cosine distances between different nearest-neighbor words.2

Sense Attention in Objective Function Assuming a center word wi has senses {si1, s2i , . . . , siK }, the original Skip-Gram likelihood given local context c~i can be written as marginal distribution over all senses of wi with the sense induction probability P (sik | wi, c~i).

K
P (cji | wi, c~i) = P (cji | ski ) P (ski | wi, c~i),

(6)

k=1 attention

Replacing P (cji | wi) in Equation 1 with Equation 6 gives our objective function,

J(S, C) 

K
log P (cji | ski )P (sik | wi, c~i).

wiV cij c~i

k=1

(7)

Lower Bound the Objective for Negative Sampling Like the Skip-Gram objective (Equation 2), we model the likelihood of a context word given the center sense P (cji | ski ) using softmax,

P (cij | sik) =

exp cij sik

|V | j=1

exp

cj ski

,

(8)

where the bold symbol sik looks up the embedding of sense skj from S, and cj looks up the context embedding of word cj from C.

Computing the softmax over the vocabulary is time-consuming. We want to adopt negative sampling to approximate log P (cji | ski ), which does not exist explicitly in our objective function (Equation 7).3

1We can set different number of senses based on word frequency in the training, details in Appendix B.3. 2We elaborate the details and discuss our choices in Appendix B. 3Deriving the negative sampling requires the logarithm of a softmax Goldberg & Levy (2014).

3

Under review as a conference paper at ICLR 2019

uk  U(0, 1)
c¯i ski
gk : Gumbel noise

Figure 3: Our hard attention mechanism is approximated with Gumbel softmax on the context-sense dot product c¯i sik (Equation 14), whose mean and std plotted here as a function of iteration. The shadowed area shows that it has a smaller scale than the gumbel noise gk, such that gk, rather than the embeddings, dominates the sense attention.

However, given the concavity of the logarithm function, we can apply Jensen's inequality,

KK

log P (cij | sik)P (sik | wi, c~i)  P (sik | wi, c~i) log P (cij | ski ),

k=1

k=1

(9)

and create a lower bound of the objective. Maximizing this lower bound gives us a tractable objective,

K

J(S, C) 

P (ski | wi, c~i) log P (cij | sik),

wiV cij c~i k=1

(10)

where log P (cij | ski ) is estimated by negative sampling Mikolov et al. (2013b),
n
log (cji sik) + EcjPn(c)[log (-cj sjk))],
j=1

(11)

Modeling Sense Attention We can model the attention term, contextual sense induction distribu-

tion, with soft attention; we call the resulting model soft-attention sense induction (SASI); although it

is a stepping stone to our final model, we compare against it in our experiments as it helps isolate the

contributions of hard attention. In SASI, the sense attention is conditioned on the entire local context

c~i with softmax:

P (sik | wi, c~i) =

exp c¯i ski

K k=1

exp

c¯i sik

,

(12)

where c¯i is the mean of the context vectors in c~i.

3.2 SCALED GUMBEL SOFTMAX FOR SENSE DISAMBIGUATION
To reduce separate senses and learn distinguishable sense representations, we implement hard attention in our full model, GASI. To preserve differentiability and circumvent the difficulties in training reinforcement learning (Sutton & Barto, 1998), we apply the reparameterization trick with Gumbel softmax (Section 2.1) to our sense attention function (Equation 12) and make a continuous relaxation.

Vanilla Gumbel Attention The discrete sense sampling from Equation 12 can be refactored by

zi = one hot(arg max(c¯i ski + gk)),
k

(13)

and the hard attention is approximated with

yki = softmax((c¯i sik + gk)/ ).

(14)

Scaled Gumbel Softmax for Sense Disambiguation Gumbel softmax learns a flat distribution over senses even with low temperatures (Figure 2): the dot product c¯i ski is too small compared to the Gumbel noise gk (Figure 3).4 Thus we use a scaling factor  to reduce the randomness,5 and tune
4Float32 precision, the saturation of log((·)) and gradient vanishing result in a small range of c¯i ski . 5Normalizing c¯i sik or directly using log P (ski | wi, c~i) results in a similar outcome.

4

Under review as a conference paper at ICLR 2019

top neighbors of bond_0

blofeld_0

thunderball_1 octopussy_0 octopussy_1

moonraker_2 goldfinger_2

007_1

bond_1 bond_2 bond_0

MUSE

top neighbors of bond_1 top neighbors of bond_2

bond_0
securities_1 mortgage-backed_2
repo_1 repurchase_2 coupon_2

transition_0 bond_1
hydrogen_1 atoms_0 bonding_0
covalent_1

GASI-0

octopussy_2 moonraker_1

goldeneye_0goldfinger_0 007_2 bond_2
Figure 4: t-SNE projections of nearest neighbors for "bond" by hard-attention models: 1) previous SOTA model MUSE (RL-based); 2) our proposed GASI-. Trained on same dataset and vocabulary, both models learn three vectors per word. Here, word i represent the i-th vector for word. Our GASI (right) learns three distinct senses of "bond" while MUSE (left) learns overlapping senses.

it as a hyperparameter.6

ki = softmax((c¯i sik + gk)/ ),

(15)

We use GASI- to identify the GASI model with scaling factor. This modification is critical for learning distinguishable senses (Figure 2, Table 1, and Table 4).

Final Objective Function The objective function of our GASI- model is

K

J(S, C) 

softmax((c¯i sik + gk)/ ) log P (wc | ski ).

wiV wcci k=1

(16)

4 TRAINING SETTINGS

For fair comparisons, we try to remain consistent with previous work (Huang et al., 2012; Neelakantan et al., 2014; Lee & Chen, 2017) in all aspects of training. In particular, we train GASI on the same April 2010 Wikipedia snapshot (Shaoul C., 2010) with 1B tokens the same vocabulary released by Neelakantan et al. (2014); set the number of senses K = 3 and dimension d = 300 for each word unless otherwise specified. More details are in Appendix A. We fix the temperature  = 0.5,7 and tune the scaling factor  from {0.1, 0.2, ...,0.9} on the AvgSimC measure for the contextual word similarity task (Section 5). The optimal scaling factor  is 0.4.
If not reprinted, the numbers in this paper for competing models are either computed with pre-trained embeddings released by authors or trained on released code.8

5 WORD SIMILARITY EVALUATION
We first compare our GASI and GASI- model with previous work on standard word similarity tasks before turning to interpretability experiments. Each task has word pairs with a similarity/relatedness score. For evaluation, we measure Spearman's rank correlation  (Spearman, 1904) between word embedding similarity and the gold similarity judgements: higher scores imply the model captures semantic similarities consistent with the trusted similarity scores.
6Learning  instead of fixing it as a hyperparameter does not successfully disambiguate senses. 7This is similar to the experiment settings for Gumbel softmax in Maddison et al. (2016) 8We adopt the numbers for Li & Jurafsky (2015) from Lee & Chen (2017) and tune the PFTGM (Athiwaratkun et al., 2018) model on the same 1B corpus and vocabulary as previous works using https://github.com/benathi/multisense-prob-fasttext with suggested hyperparameters and select the best results.

5

Under review as a conference paper at ICLR 2019

Model

MaxSimC AvgSimC

Huang et al. (2012)-50d MSSG-6K MSSG-30K
Tian et al. (2014) Li & Jurafsky (2015)
Qiu et al. (2016) Bartunov et al. (2016)
MUSE Boltzmann
SASI
GASI(w/o scaling) GASI-

26.1 57.3 59.3 63.6 66.6 64.9 53.8 67.9
55.1 68.2 66.4

65.7 69.3 69.2 65.4 66.8 66.1 61.2 68.7
67.8 68.3 69.5

Table 1: Spearman's correlation 100 on SCWS. All models are trained on the 1B token data and learn 300d embeddings except for Huang et al.

Contextual Word Similarity Tailored for sense embedding evaluation, Stanford Contextual Word Similarities (Huang et al., 2012, SCWS) has 2003 word pairs and similarity scores with sentential context. Moreover, the word pairs and their contexts reflect homonymous and polysemous words. Therefore, we use this dataset to tune our hyperparameters.

To compute the word similarity with senses we use two metrics Reisinger & Mooney (2010) that take context and sense disambiguation into account: MaxSimC computes the cosine similarity cos(s1, s2) between the two most probable senses s1 and s2 that maximizes P (ski | wi, c~i). AvgSimC weights average similarity over the combinations of all senses,

KK
P (s1i | w1, c~1)P (sj2 | w2, c~2) cos(si1sj2).
i=1 i=j

(17)

We first compare variants of our model with multi-prototype sense embedding models (Table 1), including two previous state-of-the-art models: the clustering-based Multi-Sense Skip-Gram model (Neelakantan et al., 2014, MSSG) on AvgSimC metric and the RL-based Modularizing Unsupervised Sense Embeddings (Lee & Chen, 2017, MUSE) on MaxSimC. All three are better than the baseline Skip-Gram model (65.2 using the word embedding).
GASI better captures similarity than SASI, corroborating that hard attention aids word sense selection. Moreover, GASI with scaling () has better MaxSimC than all other models; however, it learns a flat sense distribution (Figure 2). GASI- has the best AvgSimC and a competitive MaxSimC. While MUSE has a higher MaxSimC than GASI-, it fails to distinguish senses as well (Figure 4, Section 6).
The Probabilistic FastText Gaussian Mixture (Athiwaratkun et al., 2018, PFT-GM) achieves state-ofthe-art results on multiple non-contextual word similarity tasks (Table 2). Since it does not estimate the sense induction distribution based on local context, we compute the correlation score (66.4) for PFT-GM with MaxSim (Equation 18). Our GASI- is comparable to it on MaxSim with the same 66.4, and has better correlation on AvgSimC (69.5).

Non-Contextual Word Similarity We also evaluate our model on the non-contextual word sim-

ilarity datasets: RG-65 (Rubenstein & Goodenough, 1965); SimLex-999 (Hill et al., 2015); WS-

353 (Finkelstein et al., 2002); MEN-3k (Bruni et al., 2014); MC-30 (Miller & Charles, 1991);

YP-130 (Yang & Powers, 2006); MTurk-287 (Radinsky et al., 2011); MTurk-771 (Halawi et al.,

2012); RW-2k (Luong et al., 2013). Similar to Lee & Chen (2017) and Athiwaratkun et al. (2018),

we compute the word similarity based on senses by MaxSim (Reisinger & Mooney, 2010), which

maximizes the cosine similarity over the combination of all sense pairs and does not require local

contexts,

MaxSim(w1,

w2)

=

max
0iK,0jK

cos(s1i ,

sj2).

(18)

This metric evaluates the quality of each specific sense embedding, rather than the average embeddings. GASI- has better correlation on three datasets and is competitive on the rest (Table 2) and remains

6

Under review as a conference paper at ICLR 2019

Dataset MSSG-30K MSSG-6K MUSE Boltzmann GASI GASI- PFT-GM

SimLex-999 WS-353 MEN-3k MC-30 RG-65 YP-130 MT-287 MT-771 RW-2k

31.80 65.69 65.99 67.79 73.90 40.69 65.47 61.26 42.87

28.65 67.42 67.10 76.02 64.97 42.68 64.04 58.83 39.24

39.61 68.41 74.06 81.80 81.11 43.56 67.22 64.00 48.46

40.14 68.49 73.13 82.47 77.19 49.82 67.37 66.65 47.22

41.68 69.36 72.32 85.27 79.77 56.34 66.13 66.70 47.69

40.19 68.6 77.40 74.63 79.75 59.39 69.66 68.91 45.69

Table 2: Spearman's correlation 100 on non-contextual word similarity measured by MaxSim. GASI- outperforms the other models on three datasets are competitive on the others. Note that
PFT-GM are trained with two components/senses while other models learn three senses.

competitive without scaling. GASI performs better than MUSE, the other hard-attention multiprototype model, on six datasets and worse on three. Taken as a whole, our results on these non-contextual word similarity tasks indicate that we have not lowered the quality of our word representations in the process of introducing sense-specific mechanisms.
6 CROWDSOURCING EVALUATION
GASI can capture word similarity (Section 5), but do the learned representations make sense? Could a human use them to help build a dictionary? If you show a human the senses, can they understand why a model would assign a sense to that context? In this section we evaluate whether the representations make sense to human consumers of multisense models. Qualitive analysis Previous papers use nearest neighbors of a few examples to qualitatively argue that their models have captured meaningful senses of words. We also give an example in Figure 4, which provides an intuitive view on how the learned senses are clustered by visualizing the nearest neighbors of word "bond" using t-SNE projection (Maaten & Hinton, 2008). Our proposed model (right) disentangles the three sense of "bond" clearly and learns three distinct sense vectors.
However, the examples can be cherry-picked and lack standards. This problem also bedeveled topic modeling until the introduction of rigorous human evaluation (Chang et al., 2009). We adapt both aspects Chang et al's evaluations: word intrusion (Schnabel et al., 2015) to evaluate whether individual senses are coherent and topic intrusion--rather sense intrusion in this case--to evaluate whether humans agree with models' sense assignments in context. Both crowdsourcing tasks collect human inputs on Figure-Eight.
We compare our models with the two previous state-of-the-art multi-prototype sense embeddings models that disambiguate senses given local context, i.e., MSSG (Neelakantan et al., 2014) and MUSE (Lee & Chen, 2017).9
6.1 WORD INTRUSION FOR SENSE COHERENCE
Schnabel et al. (2015) suggests a "good" word embedding should have coherent neighbors and evaluate coherence by word intrusion they present Turkers a group of four words, three of which are close neighbors while one of which is an "intruder", and ask the Turkers to find the intrusion word. If the original sense/topic/embedding makes sense, contributors will easily spot the word that "does not belong".
Similarly, we examine the coherency of the ten nearest neighbors used in the contextual word sense selection task (Section 6.2) by randomly replace one neighbor with an "intruder", and ask the contributor to find the intrusion word Figure 5. We generate three questions with different intruders for each sense and collect three judgements per question. We consider the "intruder" to be corretly selected if at least two judgements are correct.
9MSSG has two settings, we run human evaluation with MSSG-30K which achieves higher correlation score with MaxSimC on SCWS, indicating better quality of each sense vector given local context.
7

Under review as a conference paper at ICLR 2019

Model

Sense-level Accuracy

Judgement-level Accuracy

Aggrement

MUSE
MSSG-30K GASI-

67.33 69.33 71.33

62.89 66.67 67.33

0.73 0.76 0.77

Figure 5: Word intrusion task prompt Table 3: Word intrusion evalutations on top ten nearest neighbors of sense embeddings.

Generate Intruder Like Chang et al. (2009), we want the "intruder" to not be too different in

terms of frequency to we randomly select a

the target set but not too similar semantically. word from the neighbors of another sense sin

For sense smi of wi but with

of word type wi, a low threshold,

i.e., any words that has cosine similarity larger than 0.0 can be viewed as a neighbor. We discuss

further refinement of intruder selection in the discussion section.

Result and Analysis All three models have comparable model accuracy. GASI- learns senses that have the highest coherency among top ten nearest neighbors while MUSE learns more sense mixtures.

Agreement We use the aggregated confidence score provided by Figure-Figure to estimate the level of agreement between multiple contributors.10 The agreements are adequately high for all models and
our GASI- achieves the highest agreement, indicates that the senses represented by nearest neighbors learned by GASI- are easier to interpret for human.

6.2 CONTEXTUAL WORD SENSE SELECTION
The previous task measures whether individual senses are coherent. In this task, we measure whether the learned senses by sense embedding models make sense human and evaluate the models' ability in disambiguate senses in context.

Task Description Given a target word in context, we ask a contributor to select which sense group
learned by a model that best fits the sentence. Each sense group is described by its top ten distinct nearest neighbors (Figure 6).11

Question (required)
Vandiver mentions the $100 million highway bond issue approved earlier in the
* Choose one sense group that the target (underlined) word fits best.
007, octopussy, moneypenny, goldfinger, thunderball, moonraker, goldeneye atom, transition, bonding, covalent, hydrogen, molecule, substituent, carbons mortgage-backed, securities, coupon, debenture, repurchase, refinance, surety,

Figure 6: An example (target: bond) of the contextual word sense selection task; each option contains top ten nearest neighbors of a sense embedding learned by the model; senses in this example are from our GASI- (1. 007; 2. chemical; 3. financial).

Data Collection We select fifty nouns with five sentences from SemCor 3.0 (Miller et al., 1994). We first filter all word senses in the dataset that have fewer than ten sentences, then select the top fifty nouns among the remaining via the number of synsets in WordNet (Miller & Fellbaum, 1998). For each noun, we randomly select five sentences, each as one question in this task.
Metrics For each model, we collect three judgements for each question. For each question, if at least two contributors select the same sense as the model does, we consider the model's selection is consistent with that of humans. We also compute the sense induction probability P assigned to the human choices by the model, indicating the model's confidence in sense selection. P = 1/3 indicates the model learns flat sense induction distribution is unable to disambiguate senses.
Sense disambiguation and interpretability If a user can consistently pick the same sense as the model, it means that three things are true. 1) human is able to interpret each group of nearest neighbor words (as measured by the previous experiment); 2) the senses are distinguishable enough from each other for the human to make one selection; 3) the human's selection is consistent with the model's.
10https://success.figure-eight.com/hc/en-us/articles/201855939-How-to-Calculate-a-Confidence-Score 11We shuffle the choices for questions with the same target word.

8

Under review as a conference paper at ICLR 2019

Model

Accuracy P Agreement

MUSE

28.0 0.33

MSSG-30K

44.5 0.37

GASI (w/o scaling) 33.8 0.33

GASI-

50.0 0.48

0.68 0.73 0.68 0.75

Table 4: Human-model consistency on contextual word sense selection, where P is the average probability assigned by the model to the human choices. GASI- is more consistent with human than
baseline models.

Results and Analysis GASI- selects senses that are most consistent with humans; it has the highest accuracy and assigns the largest probability assigned to the human choices (Table 4, left). Thus, GASI- produces sense embeddings that are both more interpretable and distinguishable, and has stronger ability in disambiguating sense.12 The canonical GASI model without scaling factor, however, has low consistency and flat sense distribution. Therefore, our proposed modification to Gumbel Softmax is critical in learning sense disambiguation.
Agreement We use the confidence score computed by Figure-Eight to estimate the rater's agreement for this task as well. Our GASI- achieves the hight agreement while both MUSE and GASI without scaling have the lowest.
6.3 WORD SIMILARITY VS. SENSE DISAMBIGUATION
The evaluation results on word similarity tasks (Section 5) and human evaluations (Section 6) are inconsistent for several models. Among all the models that learn sense-specific embedding and support sense disambiguation given local context, our GASI, GASI- model and the MUSE model are equally competitive in overall word similarity evaluations and achieve at least close to state-ofthe-art results (Table 1 and Table 2). However, both GASI and MUSE perform poorly in the human evaluation task while GASI- performs the best (Table 4). Both canonical GASI model and MUSE fail to learn distinguishable sense embeddings and cannot actually disambiguate senses given local context. Therefore, achieving high word similarity evaluation performance does not necessarily indicate "good" sense embeddings quality. Our proposed human evaluation task ­ contextual word sense selection ­ provides complementary evaluation.
7 RELATED WORK
Schu¨tze (1998) introduces context-group discrimination for senses and uses the centroid of context vectors as a sense representation. Other work induces senses by context clustering (Purandare & Pedersen, 2004) or probabilistic mixture models (Brody & Lapata, 2009). Reisinger & Mooney (2010) first introduce multiple sense-specific vectors for each word, inspiring other multi-prototype sense embedding models.
Generally, to address polysemy in word embeddings, some previous work trained on annotated sense corpora (Iacobacci et al., 2015) or external sense inventories (Labutov & Lipson, 2013; Chen et al., 2014; Jauhar et al., 2015; Chen et al., 2015; Wu & Giles, 2015; Pelevina et al., 2016); Rothe & Schu¨tze (2015; 2017) extend word embeddings to lexical resources without training; others induce senses via multilingual parallel corpora (Guo et al., 2014; S uster et al., 2016; Ettinger et al., 2016).
We mainly contrast our GASI to unsupervised monolingual multi-prototype models along two dimensions: sense induction methodology and differentiability. On the first dimension, Huang et al. (2012) and Neelakantan et al. (2014) induce senses by context clustering; Tian et al. (2014) model a corpuslevel sense distribution; Li & Jurafsky (2015) model the sense assignment as a Chinese Restaurant Process; Qiu et al. (2016) induce senses by minimizing an energy function on a context-depend network; Bartunov et al. (2016) model the sense assignment as a steak-breaking process; Nguyen et al. (2017) model the sense embeddings as a weighted combination of topic vectors with pre-computed
12Workers tends to select the first choice when the choices are duplicated, which explains why MUSE achieves lower accuracy than random choice.
9

Under review as a conference paper at ICLR 2019
weights by topic models; Athiwaratkun & Wilson (2017) and Athiwaratkun et al. (2018) model word representations as Gaussian Mixture embeddings where each Gaussian component captures different senses; Lee & Chen (2017) computes sense distribution by a separate set of sense induction vectors; while our GASI introduces sense attention by marginalizing the likelihood of contexts over senses and induces senses by local context vectors; the most similar structure actually is a bilingual model (S uster et al., 2016) except it does not introduce lower bound for negative sampling. On the second dimension, for models that learn sense disambiguation given local context, most of which are non-differentiable and discretely select senses. The two exceptions are: S uster et al. (2016) use weighted vectors over senses; Lee & Chen (2017) implement hard attention with reinforcement learning to mitigate the non-differentiability. In contrast, GASI keeps full differentiability by reparameterization and approximates discrete sense sampling with scaled Gumbel softmax.
8 CONCLUSION
We present a differentiable Gumbel Attention Sense Induction (GASI) model that learns both distinguishable and meaningful sense representations for words. It applies hard attention to simultaneously induce and embed word senses from unlabeled monolingual corpora, and approximates the discrete sense sampling with Scaled Gumbel Softmax. The proposed scaling factor is critical for our hardattention model to disambiguate senses given local context. Due to the lack of standard intrinsic evaluation for sense-specific embeddings, we propose a novel crowdsourcing contextual word sense selection task to quantitatively evaluate the semantic meaningfulness of sense embeddings. It measures how consistent the model's sense selections are to that of humans given context sentence. We further evaluate the coherency of the learned senses represented each by its nearest neighbors through the word intrusion human evaluation task. The scaled version GASI- of our sense embedding model achieves higher accuracy on both consistent and coherent human evaluations than competing approaches while maintaining sate-of-the-art results on multiple traditional word similarity tasks, including the SCWS task which is tailored for polysemous cases. It is also comparable to previous state-of-the-art results on other similarity tasks. On the other hand, the inconsistent performance of several sense embedding models on human evaluation tasks and word similarity tasks indicate our proposed contextual word sense selection is complementary to traditional word similarity evaluations.
We believe that evaluating the interpretability of sense representations is important not only for building better models but for improving our understanding of language. Creating intruder words and tasks that better align with real-world tasks of lexicographers or linguists would help better ground word sense embedding evaluations.
REFERENCES
Ben Athiwaratkun and Andrew Wilson. Multimodal word distributions. In Proceedings of the Association for Computational Linguistics, 2017.
Ben Athiwaratkun, Andrew Wilson, and Anima Anandkumar. Probabilistic fasttext for multi-sense word embeddings. In Proceedings of Empirical Methods in Natural Language Processing, 2018.
Sergey Bartunov, Dmitry Kondrashkin, Anton Osokin, and Dmitry Vetrov. Breaking sticks and ambiguities with adaptive skip-gram. In Proceedings of Artificial Intelligence and Statistics, 2016.
Jordan L. Boyd-Graber, Sonya S. Nikolova, Karyn A. Moffatt, Kenrick C. Kin, Joshua Y. Lee, Lester W. Mackey, Marilyn M. Tremaine, and Maria M. Klawe. Participatory design with proxies: Developing a desktop-PDA system to support people with aphasia. In International Conference on Human Factors in Computing Systems, 2006.
Samuel Brody and Mirella Lapata. Bayesian word sense induction. In Proceedings of the European Chapter of the Association for Computational Linguistics, 2009.
Elia Bruni, Nam-Khanh Tran, and Marco Baroni. Multimodal distributional semantics. Journal of Artificial Intelligence Research, 49, 2014.
Jose Camacho-Collados and Taher Pilehvar. From word to sense embeddings: A survey on vector representations of meaning. arXiv preprint arXiv:1805.04032, 2018.
10

Under review as a conference paper at ICLR 2019
Jonathan Chang, Sean Gerrish, Chong Wang, Jordan L Boyd-Graber, and David M Blei. Reading tea leaves: How humans interpret topic models. In Proceedings of Advances in Neural Information Processing Systems, 2009.
Qian Chen, Xiaodan Zhu, Zhenhua Ling, Si Wei, Hui Jiang, and Diana Inkpen. Enhanced lstm for natural language inference. In Proceedings of the Association for Computational Linguistics, 2017.
Tao Chen, Ruifeng Xu, Yulan He, and Xuan Wang. Improving distributed representation of word sense via wordnet gloss composition and context clustering. In Proceedings of the Association for Computational Linguistics, pp. 15­20. Association for Computational Linguistics, 2015.
Xinxiong Chen, Zhiyuan Liu, and Maosong Sun. A unified model for word sense representation and disambiguation. In Proceedings of Empirical Methods in Natural Language Processing. Citeseer, 2014.
Allyson Ettinger, Philip Resnik, and Marine Carpuat. Retrofitting sense-specific word vectors using parallel text. In Conference of the North American Chapter of the Association for Computational Linguistics, 2016.
Manaal Faruqui, Yulia Tsvetkov, Pushpendre Rastogi, and Chris Dyer. Problems with evaluation of word embeddings using word similarity tasks. In Proceedings of the Association for Computational Linguistics, 2016.
Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias, Ehud Rivlin, Zach Solan, Gadi Wolfman, and Eytan Ruppin. Placing search in context: The concept revisited. ACM Transactions on Information Systems, 20(1), 2002.
Joseph L Fleiss. Measuring nominal scale agreement among many raters. Psychological bulletin, 76 (5), 1971.
Anna Gladkova and Aleksandr Drozd. Intrinsic evaluations of word embeddings: What can we do better? In RepEval@ACL, 2016.
Yoav Goldberg and Omer Levy. word2vec explained: Deriving mikolov et al.'s negative-sampling word-embedding method. arXiv preprint arXiv:1402.3722, 2014.
Emil Julius Gumbel and Julius Lieblein. Statistical theory of extreme values and some practical applications: a series of lectures. 1954.
Jiang Guo, Wanxiang Che, Haifeng Wang, and Ting Liu. Learning sense-specific word embeddings by exploiting bilingual resources. In Proceedings of International Conference on Computational Linguistics, 2014.
Guy Halawi, Gideon Dror, Evgeniy Gabrilovich, and Yehuda Koren. Large-scale learning of word relatedness with constraints. In Knowledge Discovery and Data Mining, 2012.
Felix Hill, Roi Reichart, and Anna Korhonen. Simlex-999: Evaluating semantic models with (genuine) similarity estimation. Computational Linguistics, 41(4), 2015.
Eric H Huang, Richard Socher, Christopher D Manning, and Andrew Y Ng. Improving word representations via global context and multiple word prototypes. In Proceedings of the Association for Computational Linguistics, 2012.
Ignacio Iacobacci, Taher Mohammad Pilehvar, and Roberto Navigli. Sensembed: Learning sense embeddings for word and relational similarity. In Proceedings of the Association for Computational Linguistics, pp. 95­105. Association for Computational Linguistics, 2015.
Eric Jang, Shixiang Gu, and Ben Poole. Categorical reparameterization with gumbel-softmax. arXiv preprint arXiv:1611.01144, 2016.
Sujay Kumar Jauhar, Chris Dyer, and Eduard Hovy. Ontologically grounded multi-sense representation learning for semantic vector space models. In Conference of the North American Chapter of the Association for Computational Linguistics, 2015.
11

Under review as a conference paper at ICLR 2019
Yoon Kim. Convolutional neural networks for sentence classification. In Proceedings of Empirical Methods in Natural Language Processing, 2014.
Igor Labutov and Hod Lipson. Re-embedding words. In Proceedings of the Association for Computational Linguistics, 2013.
Guang-He Lee and Yun-Nung Chen. Muse: Modularizing unsupervised sense embeddings. In Proceedings of Empirical Methods in Natural Language Processing, 2017.
Jiwei Li and Dan Jurafsky. Do multi-sense embeddings improve natural language understanding? arXiv preprint arXiv:1506.01070, 2015.
Thang Luong, Richard Socher, and Christopher Manning. Better word representations with recursive neural networks for morphology. In Conference on Computational Natural Language Learning, 2013.
Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of Machine Learning Research, 9(Nov), 2008.
Chris J Maddison, Daniel Tarlow, and Tom Minka. A* sampling. In Proceedings of Advances in Neural Information Processing Systems, 2014.
Chris J Maddison, Andriy Mnih, and Yee Whye Teh. The concrete distribution: A continuous relaxation of discrete random variables. arXiv preprint arXiv:1611.00712, 2016.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781, 2013a.
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. Distributed representations of words and phrases and their compositionality. In Proceedings of Advances in Neural Information Processing Systems, 2013b.
George Miller and Christiane Fellbaum. Wordnet: An electronic lexical database. MIT Press Cambridge, 1998.
George A Miller and Walter G Charles. Contextual correlates of semantic similarity. Language and cognitive processes, 6, 1991.
George A Miller, Martin Chodorow, Shari Landes, Claudia Leacock, and Robert G Thomas. Using a semantic concordance for sense identification. In Proceedings of the workshop on Human Language Technology, 1994.
Arvind Neelakantan, Jeevan Shankar, Alexandre Passos, and Andrew McCallum. Efficient nonparametric estimation of multiple embeddings per word in vector space. In Proceedings of Empirical Methods in Natural Language Processing, 2014.
Dai Quoc Nguyen, Dat Quoc Nguyen, Ashutosh Modi, Stefan Thater, and Manfred Pinkal. A mixture model for learning multi-sense word embeddings. In Proceedings of the 6th Joint Conference on Lexical and Computational Semantics, 2017.
Maria Pelevina, Nikolay Arefiev, Chris Biemann, and Alexander Panchenko. Making sense of word embeddings. In Proceedings of the 1st Workshop on Representation Learning for NLP, 2016.
Jeffrey Pennington, Richard Socher, and Christopher D Manning. Glove: Global vectors for word representation. In Proceedings of Empirical Methods in Natural Language Processing, 2014.
Mohammad Taher Pilehvar and Nigel Collier. De-conflated semantic representations. In Proceedings of Empirical Methods in Natural Language Processing, 2016.
Amruta Purandare and Ted Pedersen. Word sense discrimination by clustering contexts in vector and similarity spaces. In Conference on Computational Natural Language Learning, 2004.
12

Under review as a conference paper at ICLR 2019
Lin Qiu, Kewei Tu, and Yong Yu. Context-dependent sense embedding. In Proceedings of Empirical Methods in Natural Language Processing, 2016.
Kira Radinsky, Eugene Agichtein, Evgeniy Gabrilovich, and Shaul Markovitch. A word at a time: computing word relatedness using temporal semantic analysis. In Proceedings of the World Wide Web Conference, 2011.
Joseph Reisinger and Raymond J. Mooney. Multi-prototype vector-space models of word meaning. In Conference of the North American Chapter of the Association for Computational Linguistics, 2010.
Sascha Rothe and Hinrich Schu¨tze. Autoextend: Extending word embeddings to embeddings for synsets and lexemes. In Proceedings of the Association for Computational Linguistics, 2015.
Sascha Rothe and Hinrich Schu¨tze. Autoextend: Combining word embeddings with semantic resources. Computational Linguistics, 43(3), 2017.
Herbert Rubenstein and John B Goodenough. Contextual correlates of synonymy. Communications of the ACM, 8(10), 1965.
Tobias Schnabel, Igor Labutov, David Mimno, and Thorsten Joachims. Evaluation methods for unsupervised word embeddings. In Proceedings of Empirical Methods in Natural Language Processing, pp. 298­307, 2015.
Hinrich Schu¨tze. Automatic word sense discrimination. Computational linguistics, 24(1), 1998. Westbury C Shaoul C. The Westbury Lab Wikipedia Corpusa. 2010. Charles Spearman. The proof and measurement of association between two things. The American
journal of psychology, 15, 1904. Simon S uster, Ivan Titov, and Gertjan van Noord. Bilingual learning of multi-sense embeddings
with discrete autoencoders. In Conference of the North American Chapter of the Association for Computational Linguistics, 2016. Richard S Sutton and Andrew G Barto. Reinforcement learning: An introduction, volume 1. MIT press Cambridge, 1998. Kai Sheng Tai, Richard Socher, and Christopher D. Manning. Improved semantic representations from tree-structured long short-term memory networks. In Proceedings of the Association for Computational Linguistics, 2015. Fei Tian, Hanjun Dai, Jiang Bian, Bin Gao, Rui Zhang, Enhong Chen, and Tie-Yan Liu. A probabilistic model for learning multi-prototype word embeddings. In Proceedings of International Conference on Computational Linguistics, 2014. Zhaohui Wu and C Lee Giles. Sense-aaware semantic analysis: A multi-prototype word representation model using wikipedia. In Association for the Advancement of Artificial Intelligence, pp. 2188­ 2194. Citeseer, 2015. Dongqiang Yang and David Martin Powers. Verb similarity on the taxonomy of WordNet. Masaryk University, 2006.
13

Under review as a conference paper at ICLR 2019

# of senses left

2.75

2.50

GASI-0.4, K=5 GASI-0.4, K=3

2.25

2.00

1.75

1.50

1.25

1.00 rank by freq (high to low)

Figure 7: Histogram of number of senses left after post-training pruning for two models: GASI-0.4 initialized with three senses and GASI-0.4 initialized with five senses. We rank the number of senses of words by their frequency from high to low.

A TRAINING DETAILS
During training, we fix the window size to five and the dimensionality of the embedding space to 300 for comparison to previous work. We initialize both sense and context embeddings randomly within U(-0.5/dim, 0.5/dim) as in Word2Vec. We set the initial learning rate to 0.01; it is decreased linearly until training concludes after 5 epochs. The batch size is 512, and we use five negative samples per center word-context pair as suggested by Mikolov et al. (2013a). We train our model on the GeForce GTX 1080 Ti, and our implementation (using pytorch 3.0) takes  6 hours to train one epoch on the April 2010 Wikipedia snapshot Shaoul C. (2010) with 100k vocabulary. For comparison, our implementation of Skip-Gram on the same framework takes  2 hours each epoch.

B NUMBER OF SENSES
For simplicity and consistency with most of previous work, we present our model with a fixed number of senses K.

B.1 POST-TRAINING PRUNING

For words that do not have multiple senses or have most senses appear very low-frequently in corpus,

our model (as well as many previous models) learns duplicate senses. We can easily remove such

duplicates by pruning the learned sense embeddings with a threshold . Specifically, for each word

wi, if them

ttohebceodsuinpelidciastteasn.cAe bfteetrwdeiesncoavneyrionfgitaslslednuspeleicmabteedpdaiinrsg,sw(semist,asrint )prisunsminagllweritthhatnhes, ewnesecosnkistihdeart

has the most duplications and keep pruning with the same strategy until no more duplicates remain.

Model-specific pruning We estimate a model-specific threshold  from the learned embeddings instead of deciding it arbitrary. Therefore, this pruning methods is also applicable to other sense
embedding models. We first sample 100 words from the negative sampling distribution over the
vocabulary. Then, we retrieve the five nearest neighbors (from all senses of all words) to each sense
of each sampled word. If one of a word's own senses appears as a nearest neighbor, we append the distance between them to a sense duplication list Ddup. For other nearest neighbors, we append their distances to the word neighbor list Dnn. After populating the two lists, we want to choose a threshold that would prune away all of the sense duplicates while differentiating sense duplications with other
distinct neighbor words. Thus, we compute



=

1 2

(mean(Ddup)

+

mean(Dnn)).

(19)

14

Under review as a conference paper at ICLR 2019

Model

MaxSimC AvgSimC

GASI-0.4 GASI-0.4-30K GASI-0.4-post-pruning

66.4 64.3 64.6

69.6 69.3 68.9

Table 5: Spearman's ranking correlation 100 ×  on SCWS. GASI-0.4-30K means top 30,000 words are initialized with three senses while the others have one sense.

Table 1 compares the sense embeddings after pruning with the original mode on the Stanford Contextual Word Similarities (SCWS) task Huang et al. (2012). Both AvgSimC and MaxSimC with post-pruning embeddings decrease only a few compare to that from GASI-0.4.
B.2 NUMBER OF SENSES VS. WORD FREQUENCY
It is a common assumption that more frequent words have more senses. Figure 1 shows a histogram of the number of senses left for words ranked by their frequency, and the results agree with the assumption. Generally, the model learns more sense for high frequent words, except for the most frequent ones. The most frequent words are usually considered stopwords, such as "the", "a" and "our', which have only one common meaning. Moreover, we compare our model initialized with three senses (GASI-0.4, K = 3) against the one that has five (GASI-0.4, K = 5). Initializing with a larger number of senses, the model is able to uncover more senses for most words.
B.3 INITIALZING K BASED ON WORD FREQUENCY
Despite our model has a fixed number of senses. It is easy to implement our model with different number of senses with a mask matrix. And we can define different number of senses for each word based on their frequency. In Table 1, we show the results from a model that only top 30,000 word are initialized with three senses while others have one. The same choice is applied by Neelakantan et al. (2014).

15

