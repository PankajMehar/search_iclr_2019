Under review as a conference paper at ICLR 2019
ACCELERATING NONCONVEX LEARNING VIA REPLICA EXCHANGE LANGEVIN DIFFUSION
Anonymous authors Paper under double-blind review
ABSTRACT
Langevin diffusion is a powerful method for nonconvex optimization, which enables the escape from local minima by injecting noise into the gradient. In particular, the temperature parameter controlling the noise level gives rise to a tradeoff between "global exploration" and "local exploitation", which correspond to high and low temperatures. To attain the advantages of both regimes, we propose to use replica exchange, which swaps between two Langevin diffusions with different temperatures. We theoretically analyze the acceleration effect of replica exchange from two perspectives: (i) the convergence in 2-divergence, and (ii) the large deviation principle. Such an acceleration effect allows us to faster approach the global minima. Furthermore, by discretizing the replica exchange Langevin diffusion, we obtain a discrete-time algorithm. For such an algorithm, we quantify its discretization error in theory and demonstrate its acceleration effect in practice.
1 INTRODUCTION
We consider the problem of minimizing a nonconvex objective function, which arises from numerous machine learning problems such as training neural networks. However, due to the existence of spurious local minima, nonconvex optimization remains challenging in both theory and practice. To overcome this difficulty, one idea is to construct a diffusion process whose invariant distribution concentrates around the global minima (Chiang et al., 1987). If we run such a diffusion process for a sufficiently long time, we expect to draw from its invariant distribution a point that is close to a global minimum with high probability.
One commonly used diffusion process is the Langevin diffusion, which is closely related to firstorder optimization (Gidas, 1985). In specific, the Langevin diffusion can be viewed as gradient flow with injected noise, where the noise is scaled by a temperature parameter. Such a temperature parameter gives rise to a tradeoff between two opposite effects, namely "global exploration" and "local exploitation". More specifically, a higher temperature results in a larger injected noise, which increases the probability of escaping from spurious local minima and facilitates the global exploration of the whole domain. On the other hand, with a lower temperature, the Langevin diffusion behaves more like the gradient flow, which focuses more on exploiting the local geometry to decrease the objective value, yielding a more concentrated invariant distribution.
In this paper, we aim to bridge the gap between "global exploration" and "local exploitation" in nonconvex optimization with replica exchange, which originates from parallel tempering Markov chain Monte Carlo methods for sampling from a multimodal distribution (Earl & Deem, 2005). In contrast to the standard Langevin diffusion driven by a single temperature, the replica exchange Langevin diffusion consists of two Langevin diffusions with low and high temperatures, which locally exploits the geometry and globally explores the domain, respectively. In particular, the two Langevin diffusions exchange their positions following a specific swapping scheme, which ensures that the invariant distribution concentrates around the global minima. See Figures 1.(a)-(b) for an illustration of swapping. Compared with the standard Langevin diffusion, replica exchange accelerates the rate of convergence to the invariant distribution. As a result, with replica exchange we
1

Under review as a conference paper at ICLR 2019

U (x)

swap

2(µt ) acceleration



swap x
(a) (b)

t space of measures
(c) (d)

Figure 1: An illustration of the replica exchange Langevin diffusion. In (a) we illustrate the diffusion process driven by the low temperature, which locally exploits the geometry. The orange dashed lines characterize the evolution of the standard Langevin diffusion, while the blue dashed line denotes the swap, which drives the diffusion process into the neighborhood of another local minimum. In (b) we illustrate the trajectories of a pair of diffusion processes driven by two temperatures. The orange and yellow lines correspond to the low and high temperatures, respectively. The black lines are the contours of the objective function. Note that the lines of the same colors are disjoint due to the swap, which is denoted by the red dashed line. In (c) we illustrate the evolution of the 2-divergence. The upper and lower blue curves correspond to diffusion processes with zero and positive swapping intensities, respectively. The two solid red arrows denote the derivatives of the 2-divergence, and the angle between them characterizes the acceleration effect. In (d) we illustrate the concentration of the empirical measures. The horizontal plane denotes the space of measures, whose center is , that is, the stationary distribution of the replica exchange Langevin diffusion. The yellow and blue surfaces that center at  characterize the probability densities of the empirical measures, corresponding to zero and positive swapping intensities, respectively. Compared with the blue surface, the yellow one is more concentrated around , which also characterizes the acceleration effect of swapping.

obtain a more accurate solution to the nonconvex optimization problem within a shorter time. It is worth mentioning that, although in this paper we focuses on the case of swapping two Langevin diffusions, our theory and method naturally extend to multiple Langevin diffusions.
Our theory quantifies the acceleration effect of replica exchange from two perspectives. First, we use the theory of Markov semigroup, particularly the Dirichlet form, to characterize the evolution of the 2-divergence between the distribution at time t and the invariant distribution. In specific, we show that, compared with the standard Langevin diffusion, replica exchange boosts the Dirichlet form with a nonnegative term, which results in a faster decay of the 2-divergence. Further combined with the Poincare´ inequality, we establish the exponential rate of convergence of the 2-divergence to zero, where the acceleration effect of replica exchange is characterized by the Poincare´ constant. We illustrate such an acceleration effect in Figure 1.(c). Second, we use the large deviation principle (LDP) to characterize the exponential decay of the probability that the empirical measure of the sample path deviates from the invariant distribution. In particular, we show that replica exchange boosts the LDP rate function, which implies a faster exponential decay rate. See Figure 1.(d) for an illustration. Both perspectives are built on the infinitesimal generator of the replica exchange Langevin diffusion. We show that essentially the acceleration effects are the consequences of an additional term in the infinitesimal generator, which is introduced by replica exchange. In addition to quantifying the acceleration effect of replica exchange, we use the Euler scheme to discretize the replica exchange Langevin diffusion and propose a discrete-time algorithm. We establish an upper bound of the discretization error via Gro¨nwall's inequality. We also discuss several issues related to the parameters of the replica exchange Langevin diffusion, especially the swapping intensity and temperatures. We defer these discussions to §A of the appendix.
Related Work: The idea of nonconvex optimization via diffusion process dates back to simulated annealing (C erny`, 1985) and is systematically studied in Chiang et al. (1987). For the application of the Langevin diffusion in nonconvex optimization, see, for example, Gidas (1985) and Geman & Hwang (1986) and the followup works. More recently, Dalalyan & Tsybakov (2009); Bubeck et al. (2015); Dalalyan (2017) analyze the nonasymptotic rate of convergence of the Langevin diffusion for strongly convex objective functions. Moreover, Durmus et al. (2017); Zhang et al. (2017); Raginsky et al. (2017) further extend the analysis to handle nonconvexity and

2

Under review as a conference paper at ICLR 2019

stochastic gradient. See also, for example, Belloni et al. (2015); Ge et al. (2015); Hazan et al. (2016); Cheng et al. (2017) for related works on the extensions of the Langevin diffusion and other diffusions. However, all these works focus on the setting with a single temperature. In comparison, we study the acceleration effect of replica exchange, which utilizes more than one temperature. Hence, our work is orthogonal to these existing works and can potentially be applied to accelerate other diffusion processes.
In a parallel line of works, the idea of replica exchange is studied in the context of parallel tempering Markov chain Monte Carlo for sampling from a multimodal distribution. See, for example, Earl & Deem (2005); Sindhikara et al. (2008) and the references therein. More recently, Woodard et al. (2009) study the mixing time of parallel tempering, while Dupuis et al. (2012) extend the swapping rate of replica exchange to infinity and establish the corresponding LDP. In addition, another well-studied method is simulated tempering, a technique similar to replica exchange, which also aims at accelerating the convergence of diffusion processes (Marinari & Parisi, 1992; Geyer & Thompson, 1995). The main difference between replica exchange and simulated tempering is that the former tracks multiple diffusion processes driven by various temperatures and accelerates the convergence by swapping, while the latter tracks only one diffusion process but treats the temperature as a stochastic process. See, for example, Zheng (2003) and the references therein for a detailed discussion on the difference. More recently, Ge et al. (2017) study the convergence of simulating tempering for nonconvex objective functions from the perspective of mixing time, which is also orthogonal to our work. The LDP techniques in our work may potentially be applied to the analysis of simulated tempering as well.
Main Contribution: Despite the broad application in sampling, to the best of our knowledge, this paper is the first attempt to apply the replica exchange Langevin diffusion in the context of nonconvex optimization. In summary, our contribution is twofold: (i) We quantify the acceleration effect of the replica exchange Langevin diffusion from two perspectives, that is, the convergence of the 2-divergence and the LDP for empirical measures. (ii) We propose a nonconvex optimization algorithm based on the discretization of the replica exchange Langevin diffusion and establish an upper bound for the discretization error.

2 BASIC IDEA

We consider the following unconstrained optimization problem,

minimize U (x).
xRd

(2.1)

When U (x) is nonconvex, it is difficult to obtain its global minima. A commonly used algorithm is

the Langevin diffusion, which is defined by the stochastic differential equation 
dXt = -U (Xt)dt + 2 dWt.

(2.2)

Here {Wt}t0 is a standard d-dimensional Brownian motion and  > 0 is the temperature parameter. Under mild regularity conditions, the Langevin diffusion {Xt}t0 has a unique invariant distribution that is absolutely continuous with respect to the Lebesgue measure with density

 (x)

=

 e-U(x)/ Rd e-U (x)/

dx

.

(2.3)

Here


Rd

e-U(x)/ dx

is

the

normalization

constant.

In particular, 

is the limiting distribution

of {Xt}t0, which means that with any initialization X0, the distribution of Xt converges to 

(Bakry et al., 2013). We observe from (2.3) that with   0 the probability measure  concentrates

around the global minima of U (x) (Hwang, 1980). In other words, if we choose a sufficiently small

temperature parameter  and run the Langevin diffusion in (2.2) for a sufficiently long time, we

expect to obtain a solution that falls into the neighborhood of a global minimum of U (x) with high

probability.

3

Under review as a conference paper at ICLR 2019

Here the temperature parameter  plays a crucial role. In practice, we can only run the Langevin diffusion for a finite time, giving rise to a tradeoff between "global exploration" and "local exploitation", which correspond to high and low temperatures. In specific, when the temperature parameter  is small, the convergence of Xt is slow and the particle can be trapped by a local minimum for a long time without globally exploring the whole domain. Consequently, within a finite time, we can only obtain a sample from a distribution that is far away from the invariant distribution  . In contrast, when the temperature parameter  is large, the convergence is accelerated due to better global exploration. The distribution of Xt converges faster to the invariant distribution  globally, but locally  is less concentrated around the global minima of U (x).

To bridge the gap between high and low temperatures, in this paper we study an adaptive algorithm

called replica exchange Langevin diffusion. In detail, we consider a pair of particles driven by two

Langevin diffusions as defined in (2.2) with temperatures 1 < 2, respectively. We use Zt =

(Zt(1), Zt(2)) to denote the positions of the two particles at time t. In other words, we have

dZt(1)

=

-U (Zt(1))dt

+

 21

dWt(1),

dZt(2)

=

-U

(Zt(2)

) dt

+

22dWt(2).

(2.4)

According to (2.3), the invariant distribution of {Zt}t0 is absolutely continuous with respect to the

Lebesgue measure on R2d and its density is proportional to

() µ(x1, x2) = exp -U (x1)/1 - U (x2)/2 .

(2.5)

The marginal invariant distribution of the low-temperature particle concentrates around the global

minima of U (x). Hence, the low-temperature particle is of particular interest for the purpose of

nonconvex optimization. The key idea of replica exchange is to enable the low-temperature particle

to achieve better global exploration by swapping its position with the high-temperature particle. In

specific, at time t and positions (x1, x2), the two particles swap with rate

()

a · s(x1, x2) = a ·

1  µ(x2, x1) µ(x1, x2)

,

(2.6)

which means

()

P(Zt+dt

=

(x2, x1) |

Zt

=

(x1,

x2

) )

=

a

·

s(x1,

x2)dt,

P Zt+dt = (x1, x2) | Zt = (x1, x2) = 1 - a · s(x1, x2)dt.

(2.7)

Here a  0 is a constant called swapping intensity. As is shown in Lemma 3.2, the specific form of
s(x1, x2) in (2.6) ensures that for any a, the invariant distribution of the replica exchange Langevin diffusion {Zt}t0 is the same as (2.5), that is, as if the two particles are independent. Corresponding to the continuous-time process in (2.4)-(2.6), in §3.4 of the appendix we consider the replica exchange stochastic gradient descent algorithm, which corresponds to the discretization of {Zt}t0 using Euler scheme.

To better understand the intuition behind replica exchange, note that we use two particles driven

by low and high temperatures to achieve "local exploitation" and "global exploration", respectively.

For the purpose of optimization, we only need to track the trajectory of the first particle. By plugging

(2.5) in (2.6), we obtain ( ( ))
a · s(x1, x2) = a · exp 0  (1/1 - 1/2) · U (x1) - U (x2) .

(2.8)

Since 1 < 2, the rate a · s(x1, x2) is monotone increasing with respect to the difference between the objective values at x1 and x2, which denote the positions of the two particles. Hence, the two particles are more likely to swap when the first one has a larger objective value. In other words,
swapping tends to move the first particle, which we are interested in, to a position corresponding to
a lower objective value. An extreme case of the replica exchange Langevin diffusion is 1 = 0 and 2 = . In this case, the first equation in (2.4) reduces to an ordinary differential equation charactering the deterministic gradient descent, while the second one in (2.4) corresponds to an approximated uniform exploration of the whole domain Rd. According to (2.8), the particles never swap if the

4

Under review as a conference paper at ICLR 2019

objective value of the first particle is smaller than the second. Hence, roughly speaking, the replica exchange Langevin diffusion reduces to the deterministic gradient descent with uniformly randomized restarts. In contrast to this extreme case, for 0 < 1 < 2 < , the second particle globally explores the whole domain more adaptively with not only noise but also gradient information. In particular, its stationary distribution has a larger density around the local minima, which leads to better restarts that adapt to the global geometry for the first particle.

3 THEORETICAL ANALYSIS

In this section, we lay out the theoretical analysis of replica exchange Langevin diffusion introduced in §2, which demonstrates the acceleration effect of swapping. Due to space constraint, we defer the necessary background and detailed proofs to §B and §C of the appendix, respectively. Throughout the following analysis, we assume that the objective function U (·) satisfies the following assumption.
Assumption 3.1 (Smoothness and Dissipativity). The function U (·) is L-smooth, that is, there exists a positive constant L such that for all x, y  Rd

U (x) - U (y)  Lx - y.

(3.1)

The function U (·) is also (, )-dissipative, that is, there exist positive constants  and  such that

for all x  Rd

 x,

U

 (x)



x2

-

.

(3.2)

The assumption on smoothness in (3.1) characterizes the Lipschitz continuity of the gradient of objective function, which is commonly used in the optimization literature (Nesterov, 2013). The assumption on dissipativity in (3.2), roughly speaking, characterizes the approximate quadratic growth of the objective function at infinity, which is commonly used in the control and dynamic system literature (Hale, 2010). This condition is also used in Raginsky et al. (2017). It is worth noting that our theory does not require the convexity assumption.

3.1 INVARIANCE AND REVERSIBILITY

In this section, we show that the invariant distribution of the replica exchange Langevin diffusion
{Zt}t0 has the form in (2.5) rigorously, whose first component preserves the concentration. We also show the reversibility of {Zt}t0, which is a nice property necessary for the subsequent convergence analysis. We consider the replica exchange Langevin diffusion {Zt}t0 defined by (2.4)(2.6), where Zt = (Zt(1), Zt(2)) denotes the positions of the two particles at time t, and a  0 is the swapping intensity that controls the frequency of swapping. The following auxiliary lemma
characterizes the invariant distribution of {Zt}t0 and its reversibility. Restricted to the space, we provide a detailed proof in §C.1 of the appendix.

Lemma 3.2. The infinitesimal generator of {Zt}t0 with swapping intensity a, which is defined in

(2.4)-(2.6), takes the form

L

a(f

(x1,

) x2)

=

 - x1

f

(x1,

x2),

x1

U

 (x1)

+

1x1

f

(x1,

x2)

(3.3)





L1a(f

(x1

,

x2

) )

(

)

- x2 f (x1, x2), x2 U (x2) + 2x2 f (x1, x2) + a · s(x1, x2) · f (x2, x1) - f (x1, x2) .

L2a(f

(x1

,

x2

) )

Lsa

( f

(x1,

) x2)

Moreover, {Zt}t0 is reversible and its invariant distribution  has density

d(x1, x2)  µ(x1, x2)dx1dx2

(3.4)

with respect to the Lebesgue measure on R2d, where µ(x1, x2) is defined in (2.5).

5

Under review as a conference paper at ICLR 2019

In Lemma 3.2, the first two terms L1a and L2a on the right-hand side of (3.3) correspond to the standard Langevin diffusion, while the last term Lsa arises from swapping. The replica exchange Langevin diffusion {Zt}t0 defined in (2.4)-(2.6) is ergodic, which means that, with any initial-
ization, the distribution of Zt converges to the invariant distribution . There are two perspectives to characterize the convergence of the Markov process {Zt}t0: (i) the 2-divergence between the
distribution of Zt and the invariant distribution , and (ii) the convergence of the empirical measure
of {Zt}t0, which is viewed as a random element in the space of measures. In the following, we quantify the convergence of {Zt}t0 from both perspectives. In §3.2, we use Poincare´ inequality to quantify (i), while in §3.3, we apply the large deviation principle (LDP) to characterize (ii). In particular, we show that the term Lsa in (3.3) plays a crucial role in accelerating the convergence.

3.2 CONVERGENCE IN 2-DIVERGENCE

Let µt be the distribution of the replica exchange Langevin diffusion {Zt}t0 at time t, and  be
its invariant distribution. In the following, we quantify the discrepancy between µt and  using the 2-divergence, which is defined as

2(µt  )

=



( dµt d

)2 - 1 d,

where dµt/d is the Radon-Nikodym derivative between µt and . In the following, we characterize

the evolution of 2(µt  ) along time t using the Dirichlet form, which is defined as

 E a(f ) = a(f )d,

where

a(f

)

=

1/2

·

( L

a(f

2)

-

2f

L

a(f

) ).

(3.5)

Here a is called Carre´ du Champ operator and recall that we use  and L a to denote the invariant distribution and infinitesimal generator of {Zt}t0, respectively. In other words, the Dirichlet form is defined as the integration of the Carre´ du Champ operator under the invariant distribution .

To characterize the evolution of the 2-divergence, we take the derivative of 2(µt  ) with respect to time t. Recall that µt is the distribution of Zt, and by (B.2) in the appendix the corresponding semigroup {Pt}t0 is defined as Pt(f (x)) = E[f (Zt) | Z0 = x]. By setting f as dµ0/d and the definition of conditional expectation, we have dµt/d = Pt(dµ0/d), which implies



d dt

2

(µt

 )

=

d dt

[( Pt

dµ0 d

)]2 d

=

2



( ) [ ( )]

Pt

dµ0 d

·d dt

Pt

dµ0 d

d

 ( ) ( ( ))

=2

Pt

dµ0 d

·La

Pt

dµ0 d

d,

(3.6)

where the last equation follows from the definition of the infinitesimal generator in Definition B.2

in

the appendix. L a(f 2)d =

Meanwhile, by Definition B.3 in the 0, which together with (3.5) implies

appendix

and

the

invariance

of

,

we

have



E a(f ) = - f L a(f )d.

(3.7)

Combining (3.6) and (3.7) we obtain

( ( ))

()

d dt

2(µt



)

=

-2E

a

Pt

dµ0 d

= -2E a dµt , d

(3.8)

which shows that the derivative of the 2-divergence between µt and the invariant distribution  is exactly negative twice the Dirichlet form of the Radon-Nykodim derivative dµt/d. In the following theorem, we show that a larger swapping intensity a boosts the Dirichlet form and thus accelerates the convergence. Recall that, as defined in (3.5), E a is the Dirichlet form of the replica exchange Langevin diffusion {Zt}t0 with swapping intensity a.

6

Under review as a conference paper at ICLR 2019

Theorem 3.3. For any fixed function f , E a(f ) is an increasing nonnegative function with respect to a. In particular, we have
( ) E a(f ) = 1 · x1 f (x1, x2) 2 + 2 · x2 f (x1, x2) 2 d(x1, x2)

E 0(f )

 +

a/2

·

s(x1,

x2)

·

( f

(x2,

x1)

-

f

(x1

,

x2

))2

d(x1,

x2

),

(3.9)

Acceleration Effect where the both terms on the right-hand side are nonnegative.

See §C.2 of the appendix for a detailed proof of Theorem 3.3. Combined with (3.8), Theorem 3.3 shows that swapping accelerates the evolution of 2(µt  ). In particular, the Dirichlet form E a on the right-hand side of (3.8) decomposes into two terms. The first term E 0 in (3.9) corresponds to the
replica exchange Langevin diffusion without swapping, that is, a = 0. More specifically, the two nonnegative terms in E 0 characterize the individual dynamics of the two particles, respectively. In particular, larger temperatures 1 and 2 yield a larger E 0, which implies a faster rate of convergence.
Meanwhile, as shown in the proof of Theorem 3.3, the specific form of swapping in (2.7) ensures
the nonnegativity of the second term in (3.9), which further boosts the Dirichlet form and leads to faster evolution of 2(µt  ) in (3.8). It is worth mentioning that Theorem 3.3 does not rely on Assumption 3.3 and holds for all objective functions U (·).

To better understand Theorem 3.3, note that the symmetry of f , which corresponds to
dµt/d(x1, x2) in (3.8), plays a crucial role in the acceleration effect. In specific, when dµt/d(x1, x2) is asymmetric, the second term of the Dirichlet form in (3.9) is positive. Otherwise when dµt/d(x1, x2) is symmetric, the second term in (3.9) vanishes, since dµt/d(x1, x2) - dµt/d(x2, x1) = 0 for all x1 and x2. In other words, the acceleration effect degenerates due to symmetry. Intuitively, at time t the two particles are equivalent and swapping does not change their joint distribution, and hence does not affect the convergence of 2(µt  ).

Based on (3.8), we further establish the exponential convergence of 2(µt  ). The key ingredient is the Poincare´ inequality (Bakry et al., 2013). Furthermore, we show that such an exponential rate of convergence is dictated by the constant in the Poincare´ inequality, which is called the Poincare´ constant. In particular, we show how the swapping intensity a affects the Poincare´ constant and accelerates the exponential convergence.

For a Markov process, the Poincare´ inequality states that the 2-divergence between any probabil-

ity measure and its invariant distribution is uniformly upper bounded by the Dirichlet form of the

Radon-Nykodim derivative, provided that the probability measure of interest is absolutely continu-

ous with respect to the invariant distribution. In specific, we say that {Zt}t0 satisfies the Poincare´ inequality with Poincare´ constant , if for all probability measures   , the following inequality

holds,

() 2(  )   · E a d .
d

(3.10)

Note that the Poincare´ inequality is specified by the invariant distribution  and the Dirichlet form E a.

When the Poincare´ inequality in (3.10) holds, the derivative of the 2-divergence in (3.8) is upper bounded by itself, which implies the exponential rate of convergence. In particular, we have

d dt

2(µt



)



-2-1

·

2(µt



),

which yields

2(µt  )  2(µ0  ) · e-2t/.

(3.11)

Establishing the Poincare´ inequality is highly nontrivial. However, for the replica exchange Langevin diffusion, the following theorem shows that Poincare´ inequality holds under the smoothness and dissipativity conditions in Assumption 3.1, which implies (3.11).

7

Under review as a conference paper at ICLR 2019

Theorem 3.4. Under Assumption 3.1, the replica exchange Langevin diffusion specified in (2.4)(2.6) satisfies the Poincare´ inequality in (3.10). Hence, the second inequality in (3.11) holds, which implies the exponential decay of 2-divergence.
The proof of Theorem 3.4 adapts from the proof in Bakry et al. (2008), where a standard Langevin diffusion with unique driving temperature is considered. See §C.3 of the appendix for a detailed proof.
The second inequality in (3.11) shows that the rate of convergence of 2(µt  ) is dictated by the Poincare´ constant . In specific, a smaller Poincare´ constant leads to a faster rate of convergence. Theorem 3.3 shows that swapping boosts the Dirichlet form and hence requires a smaller Poincare´ constant , which by Theorem 3.4 leads to a faster exponential rate of convergence to the invariant distribution.

3.3 LARGE DEVIATION PRINCIPLE (LDP) ANALYSIS

We focus on the empirical measure of the replica exchange Langevin diffusion {Zt}t0 defined in

(2.4)-(2.6), which is in the same spirit of Polyak averaging (Polyak & Juditsky, 1992) but replaces

the iterates with Dirac measures. In specific, for any fixed time T > 0, the empirical measure of

{Zt}t0 is defined as

1T T = T 0 Zt dt,

(3.12)

where Zt denotes the Dirac measure at Zt. Note that {T }T 0 is a sequence of random measures, which are random elements of P(R2d), that is, the space of probability measures on R2d. We equip
P(R2d) with the topology of weak convergence, which enables us to define open and closed sets of
P (R2d ).

Recall that Lemma 3.2 shows that the replica exchange Langevin diffusion {Zt}t0 is reversible. This fact enables us to apply the Donsker-Varadhan theory (Donsker & Varadhan, 1975), which implies that {Zt}t0 obeys LDP. Formally, we have the following theorem.
Theorem 3.5. The sequence of empirical measures {T }T 0 of the replica exchange Langevin diffusion {Zt}t0 defined in (3.12) obeys LDP. That is to say, for all open sets O and closed sets F in P(R2d), the following inequalities hold,

lim inf
T 

1 T

log P(T



O)



- inf Ia(),
O

lim sup
T 

1 T

log P(T



F)



- inf Ia().
F

Here Ia(·) : P(R2d)  [0, ] is the rate function, which takes the form

 Ia() =

1 ·

 x1 d/d(x1, x2)

2 + 2 ·

 x2 d/d(x1, x2)

2d(x1, x2)

I 0 ( )

 +

a/2

·

s(x1

,

x2)

·

( d

/d(x2,

x1)

-

 d

/d(x1,

x2))2d(x1

,

x2

)

(3.13)

Acceleration Effect
for all   , and Ia() =  otherwise.
See §C.5 of the appendix for a detailed proof of theorem 3.5. The LDP rate function Ia(·) in Theorem 3.5 characterizes the rate of convergence for the empirical measures {T }T 0 towards its population version, which is the invariance distribution of {Zt}t0. More specific, it quantifies the exponential rate of decay of the probability that empirical empirical measures {T }T 0 deviate from the invariant distribution . Recall that, under weak topology, P(R2d) is metrizable via the Le´vy-Prokhorov metric dLP(·, ·) (Billingsley, 2013). We use Br to denote the open ball centered at

8

Under review as a conference paper at ICLR 2019

 with radius r in the metric space (P(R2d), dLP). Then Brc is a closed set and B¯rc is open. Then according to Theorem 3.5, we have

lim inf
T 

1 T

( log P dLP(T , µ)

>

) r

=

lim inf
T 

1 T

log P(T



B¯rc)



- inf I(),
 B¯rc

lim sup
T 

1 T

( log P dLP(T , µ)



) r

=

lim sup
T 

1 T

log P(T



Brc)



- inf I().
 Brc

If we ignore the slight difference between Brc and B¯rc, when T is large, the probability P(dLP(T , µ)  r) has approximated scale of exp(-T infBrc I()). That is to say, infBrc I() characterizes the exponential rate of decay of the probability P(dLP(T , µ)  r) as T goes to infin-
ity. A larger rate function implies a faster exponential rate of decay. Note that LDP includes both
upper and lower bounds in Theorem 3.5 and hence, the exponential rate of convergence character-
ized by LDP is tight.

To see how swapping accelerates the convergence of the empirical measure towards its invariant distribution, note that the LDP rate function in (3.13) decomposes into two terms. The first term corresponds to the LDP rate function of replica exchange Langevin diffusion without swapping, that is, a = 0. In specific, it is the sum of two nonnegative terms, which characterize the individual dynamics of the two particles, respectively. Meanwhile, the second term in (3.13) is nonnegative and boosts the LDP rate function, which accelerates the convergence of the empirical measure. Similar to the convergence of the 2-divergence in Theorem 3.3, a larger swapping intensity a yields a more significant acceleration effect. The acceleration effect also degenerates when the Radon-Nykodim derivative d/d is symmetric. Finally, it is worth noting that, like Theorem 3.3, Theorem 3.5 does not rely on Assumption 3.3 and holds for all objective functions U (·). In summary, Theorems 3.3 and 3.5 together justify the benefit of swapping from two different perspectives.

Note that the LDP rate function given in Theorem 3.5 takes a different form compared with the one obtained in Dupuis et al. (2012). Despite the different the forms, the two results are not contradictory. Our formula is derived from the Donsker-Varadhan theory, which uses the assumption of reversibility, while theirs is obtained from a dual formulation of the LDP rate function. Moreover, one can show that they are equivalent.

3.4 DISCRETIZATION ERROR ANALYSIS

In this section, we lay out the discretization error analysis of replica exchange Langevin diffusion. Our previous discussion in §3.2 and §3.3 focuses on the continuous-time process {Zt}t0 defined in (2.4)-(2.6), which needs to be discretized in practice. However, swapping the positions of particles
makes it hard to analyze the discretization error, since there is no way to incorporate the swapping
of positions into one unified stochastic differential equation. To overcome this difficulty, note that
the two particles in the replica exchange Langevin diffusion swap their positions with a specific rate,
which is equivalent in distribution to swapping their temperatures with the same rate (Dupuis et al.,
2012). We name the later equivalent process as the temperature swapping Langevin diffusion. With a slight abuse of notations, we still use {Zt}t0 to denote the positions of the two particles in the temperature swapping Langevin diffusion. In specific, {Zt}t0 is characterized by the following stochastic differential equation,

dZt = -U (Zt)dt + tdWt.

(3.14)

 Here t isa random matrix that switches between the diagonal matrices diag{ 21 · Id, 22 · Id} and diag{ 22 · Id, 21 · Id}, where Id denotes the d-dimensional identity matrix. The matrix t

characterizes the switching of temperatures, and the rate of switching is same as the one specified

in (2.6) and (2.7). Note that the temperature swapping Langevin diffusion in (3.14) is equivalent

to the replica exchange Langevin diffusion defined in (2.4)-(2.6) in distribution. Furthermore, the

stochastic differential equation in (3.14) enables us to define a continuous-time interpolation of the

discrete-time sequence, which is useful in the discretization error analysis. Hence, for the purpose of

9

Under review as a conference paper at ICLR 2019

optimization, we only need to discretize and analyze the temperature swapping Langevin diffusion in (3.14).

Note that (3.14) defines a Markov jump diffusion, which can be discretized using the Euler scheme.

We denote by (Z(1)(k), Z(2)(k)) and ( (1)(k),  (2)(k)) the positions and temperatures of the two

particles at discrete time k, respectively. Let (Z(1)(0), Z(2)(0)) = Z0 and ( (1)(0),  (2)(0)) =

(1, 2) be the initialization. For all integers k  0, we update the positions of the two particles

sequentially as following,

Z (1) (k

+

1)

=

Z (1) (k)

-



·

U

( Z

(1)(k))

+

 2

·



(1)(k)

·

(1)(k),

Z (2) (k

+

1)

=

Z (2) (k)

-



·

U

( Z

(2)(k))

+

 2

·



(2)(k)

·

(2)(k),

(3.15)

and swap temperatures according to the following rule,

( 

(1)(k

+

1),



(2)(k

+

) 1)

=

( 

(2)(k),



(1)

) (k)

with

probability

a

·



·

( sZ

(1)(k),

Z

(2)

) (k) ,

(3.16)

( 

(1)(k

+

1),



(2)(k

+

) 1)

=

( 

(1)(k),



(2)

) (k)

with

probability

1

-

a

·



·

( sZ

(1)(k),

Z

(2)(k)).

Here {(1)(k)}k0 and {(2)(k)}k0 are two sequences of independent and identically distributed d-dimensional Gaussian random vectors,  > 0 is the stepsize, while a and s(·, ·) are specified in
(2.6). Note that  and a are chosen such that  · a < 1 in order to define a valid probability.

Hereafter we denote by {Z(k)}k0 the iterates of the algorithm specified in (3.15) and (3.16). We use the superscript  to emphasize that the iterates depend on the stepsize . Let {Zt}t0 be the continuous-time interpolation of {Z(k)}k1, which is a continuous-time stochastic process defined

as

Zt

 = Z0 -

t

U

(Zs/

) ds

+



t
s/ dWs ,

00

(3.17)

where

k

=

 diag{ 2 (1)(k)

·

 Id, 2 (2)(k)

·

Id}.

Then

for

all

integers

k



0

and

t

=

k,

we

have Zt = Zk = Z(k).

In the following theorem, we characterize the discretization error by the mean squared error between
the continuous-time temperature swapping Langevin diffusion in (3.14) and the continuous-time
interpolation in (3.17) of the discrete-time algorithm in (3.15) and (3.16). In specific, we consider a fixed time interval [0, T ] and upper bound the mean squared error E[Zt - Zt2] for all t  [0, T ]. The following theorem shows that this error grows linearly with respect to the stepsize .

Theorem 3.6. Under Assumption 3.1, there exists a constant (d, 1, 2, a, L, , , T ) that only

depends on the dimension d, temperature parameters 1 and 2, swapping intensity a, smoothness

constant L and dissipative constants (, ) of U (·), and length of the time interval T , such that for

all t  [0, T ],

[ E Zt

-

Zt 2 ]



(d,

1,

2,

a,

L,

,

,

T

)

·

,

provided that the stepsize  satisfies 0 <  < /L2.

The proof of Theorem 3.6 adapts from the proof framework of Theorem 5.13 in Yin & Zhu (2010). The main obstacle is that we establish a result for the high-dimensional case, while the original proof is for one dimension. We defer the detailed proof to §C of the appendix.

REFERENCES
Dominique Bakry, Franck Barthe, Patrick Cattiaux, and Arnaud Guillin. A simple proof of the Poincare´ inequality for a large class of probability measures. Electronic Communications in Probability, 13:60­66, 2008.

10

Under review as a conference paper at ICLR 2019
Dominique Bakry, Ivan Gentil, and Michel Ledoux. Analysis and geometry of Markov diffusion operators, volume 348. Springer, 2013.
Alexandre Belloni, Tengyuan Liang, Hariharan Narayanan, and Alexander Rakhlin. Escaping the local minima via simulated annealing: Optimization of approximately convex functions. In Conference on Learning Theory, pp. 240­265, 2015.
Patrick Billingsley. Convergence of probability measures. Wiley, 2013.
Se´bastien Bubeck, Ronen Eldan, and Joseph Lehec. Sampling from a log-concave distribution with projected Langevin Monte Carlo. arXiv preprint arXiv:1507.02564, 2015.
Vladim´ir C erny`. Thermodynamical approach to the traveling salesman problem: An efficient simulation algorithm. Journal of optimization theory and applications, 45(1):41­51, 1985.
Xiang Cheng, Niladri S Chatterji, Peter L Bartlett, and Michael I Jordan. Underdamped Langevin MCMC: A non-asymptotic analysis. arXiv preprint arXiv:1707.03663, 2017.
Tzuu-Shuh Chiang, Chii-Ruey Hwang, and Shuenn Jyi Sheu. Diffusion for global optimization in Rn. SIAM Journal on Control and Optimization, 25(3):737­753, 1987.
Arnak Dalalyan and Alexandre B Tsybakov. Sparse regression learning by aggregation and Langevin Monte Carlo. arXiv preprint arXiv:0903.1223, 2009.
Arnak S Dalalyan. Theoretical guarantees for approximate sampling from smooth and log-concave densities. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 79(3): 651­676, 2017.
Monroe D Donsker and SR Srinivasa Varadhan. Asymptotic evaluation of certain Markov process expectations for large time. Communications on Pure and Applied Mathematics, 28(1):1­47, 1975.
Sever Silvestru Dragomir. Some Gronwall-type inequalities and applications. Nova Science Publishers, 2003.
Paul Dupuis, Yufei Liu, Nuria Plattner, and Jimmie D Doll. On the infinite swapping limit for parallel tempering. Multiscale Modeling & Simulation, 10(3):986­1022, 2012.
Alain Durmus, Eric Moulines, et al. Nonasymptotic convergence analysis for the unadjusted Langevin algorithm. The Annals of Applied Probability, 27(3):1551­1587, 2017.
David J Earl and Michael W Deem. Parallel tempering: Theory, applications, and new perspectives. Physical Chemistry Chemical Physics, 7(23):3910­3916, 2005.
Rong Ge, Furong Huang, Chi Jin, and Yang Yuan. Escaping from saddle points online stochastic gradient for tensor decomposition. In Conference on Learning Theory, pp. 797­842, 2015.
Rong Ge, Holden Lee, and Andrej Risteski. Beyond log-concavity: Provable guarantees for sampling multimodal distributions using simulated tempering Langevin Monte Carlo. arXiv preprint arXiv:1710.02736, 2017.
Stuart Geman and Chii-Ruey Hwang. Diffusions for global optimization. SIAM Journal on Control and Optimization, 24(5):1031­1043, 1986.
Charles J Geyer and Elizabeth A Thompson. Annealing Markov chain Monte Carlo with applications to ancestral inference. Journal of the American Statistical Association, 90(431):909­920, 1995.
Basilis Gidas. Global optimization via the Langevin equation. In 24th IEEE Conference on Decision and Control, 1985, volume 24, pp. 774­778. IEEE, 1985.
11

Under review as a conference paper at ICLR 2019
Jack K Hale. Asymptotic behavior of dissipative systems. Number 25. American Mathematical Society, 2010.
Elad Hazan, Kfir Yehuda Levy, and Shai Shalev-Shwartz. On graduated optimization for stochastic non-convex problems. In International Conference on Machine Learning, pp. 1833­1841, 2016.
Chii-Ruey Hwang. Laplace's method revisited: Weak convergence of probability measures. The Annals of Probability, pp. 1177­1182, 1980.
Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping Tak Peter Tang. On large-batch training for deep learning: Generalization gap and sharp minima. arXiv preprint arXiv:1609.04836, 2016.
Enzo Marinari and Giorgio Parisi. Simulated tempering: a new Monte Carlo scheme. EPL (Europhysics Letters), 19(6):451, 1992.
Yurii Nesterov. Introductory lectures on convex optimization: A basic course, volume 87. Springer, 2013.
Ralph Saul Phillips and Einar Hille. Functional analysis and semi-groups. RI, 1957. Boris T Polyak and Anatoli B Juditsky. Acceleration of stochastic approximation by averaging.
SIAM Journal on Control and Optimization, 30(4):838­855, 1992. Maxim Raginsky, Alexander Rakhlin, and Matus Telgarsky. Non-convex learning via stochastic
gradient Langevin dynamics: A nonasymptotic analysis. arXiv preprint arXiv:1702.03849, 2017. Daniel Revuz and Marc Yor. Continuous martingales and Brownian motion, volume 293. Springer,
2013. Daniel Sindhikara, Yilin Meng, and Adrian E Roitberg. Exchange frequency in replica exchange
molecular dynamics. The Journal of chemical physics, 128(2):01B609, 2008. Dawn B Woodard, Scott C Schmidler, Mark Huber, et al. Conditions for rapid mixing of parallel
and simulated tempering on multimodal distributions. The Annals of Applied Probability, 19(2): 617­640, 2009. George Yin and Chao Zhu. Hybrid switching diffusions: Properties and applications, volume 63. Springer, 2010. Chiyuan Zhang, Qianli Liao, Alexander Rakhlin, Brando Miranda, Noah Golowich, and Tomaso Poggio. Theory of deep learning iib: Optimization properties of sgd. arXiv preprint arXiv:1801.02254, 2018. Yuchen Zhang, Percy Liang, and Moses Charikar. A hitting time analysis of stochastic gradient Langevin dynamics. arXiv preprint arXiv:1702.05575, 2017. Zhongrong Zheng. On swapping and simulated tempering algorithms. Stochastic Processes and their Applications, 104(1):131­154, 2003.
12

Under review as a conference paper at ICLR 2019

A DISCUSSION AND CONCLUSION

In this paper, we apply the idea of replica exchange to the Langevin diffusion in the context of nonconvex optimization. In particular, we quantify the benefits of replica exchange compared with the standard Langevin diffusion from two perspectives, that is, the convergence of the 2-divergence and the LDP of the empirical measures. We show from both perspectives that replica exchange accelerates the convergence towards the invariant distribution. In the following, we discuss several related issues.

Flat and sharp minima: The Langevin diffusion yields an invariant distribution that concentrates around the global minima. In particular, as illustrated in Keskar et al. (2016), flat minima generally achieves better generalization than sharp ones. Meanwhile, as observed in Zhang et al. (2018), the invariant distribution of the Langevin diffusion biases more towards the flat minima than the sharp minima. Intuitively, this observation follows from locally integrating the density of the invariant distribution, which is proportional to exp{-U (x)/ }. As specified in (2.3), the invariant distribution of the replica exchange Langevin diffusion takes the same form, and hence processes the same desired property of biasing towards the flat minima.
Choice of swapping intensity: Recall that in §3 we prove that swapping accelerates the exponential rate of convergence of the 2-divergence and increases the LDP rate function of the empirical measures. In particular, a large swapping intensity a leads to a stronger acceleration effect. In continuous time, the swapping intensity a should be as large as possible. However, in discrete time, to ensure the existence of a valid swapping probability in (3.16), a can only be as large as 1/, since by (2.6) we have s(·, ·)  1. This constraint characterizes the tradeoff between the acceleration effect and the discretization effort, since more fine-grained discretization with a smaller stepsize  allows for a larger swapping intensity a. Moreover, intuitively speaking, more frequent swapping makes the particles more volatile, which lowers the accuracy of discretization.

Choice of temperatures: In the replica exchange Langevin diffusion, we use two particles driven

by low and high temperatures to achieve "local exploitation" and "global exploration", respectively.

There is a fundamental tradeoff in the choice of the temperatures, especially the high temperature.

In specific, a larger 2 results in faster global exploration. However, if 2 is too large, by the second

equation in 22dWt.

(2.4), the gradient Consequently, the

term U (·) becomes negligible compared with the white noise term second particle "blindly" explores the whole domain Rd uniformly at

random, without adapting the geometry of the objective function. As discussed in §2, most swaps

happen only when better positions with smaller objective values are discovered by the second parti-

cle. Thus, if 2 is too large, the global exploration is fast but ineffective.

B BACKGROUND
In this section, we provide the background of Markov process, which is necessary for the theoretical analysis. We analyze the properties of Markov processes from the viewpoint of Markov semigroup. A semigroup is a family of linear operators on Banach space C(Rd), the space of bounded continuous functions on Rd equipped with the uniform norm. Formally, we have the following definition. Definition B.1 (Semigroup of Operators). A family {Pt}t0 of linear operators on C(Rd) is called a semigroup if and only if it satisfies the following conditions:
(1) For t = 0, we have Pt = I, which is the identical mapping on C(Rd).
(2) The map t  Pt is continuous in the sense that, for all f  C(Rd), t  Pt(f ) is a continuous map from R+ to C(Rd).
(3) For all f  C(Rd) and s, t > 0, we have Ps+t(f ) = Ps(Pt(f )).
13

Under review as a conference paper at ICLR 2019

Moreover, a semigroup of operators is Markov if and only if the following additional conditions are satisfied:
(4) For all t > 0, we have Pt(1) = 1, where 1 is the constant function with value one.

(5) For all f  0, we have Pt(f )  0.

Recall that a Markov process on Rd is a stochastic process {Xt}t0 satisfying

P(Xt   | Fs) = P(Xt   | Xs)

(B.1)

for all measurable sets  and times s < t. Here Fs = (Xu, u  s), which is the natural filtration

of the Markov process {Xt}t0. Given a Markov process {Xt}t0, we define a family of operators

{Pt}t0 on C(Rd), the space of bounded continuous functions on Rd, as follows

()[

]

Pt f (x) = E f (Xt) | X0 = x .

(B.2)

According to the Markov property in (B.1), we have

Pt+s(f ) = Pt(Ps(f ))

(B.3)

and hence, {Pt}t0 indeed forms a semigroup. We call {Pt}t0 the Markov semigroup associated with the Markov process {Xt}t0.

Given a Markov semigroup, we can define its infinitesimal generator, a linear operator that describes the Markov semigroup's behavior for an infinitesimal t. Formally, we have the following definition. See, e.g., Revuz & Yor (2013) for more details.

Definition B.2 (Infinitesimal Generator of Markov Semigroup). The infinitesimal generator L of a Markov semigroup {Pt}t0 is defined by

L (f ) = lim Pt(f ) - f t0 t

for all f  D(L ). Here D(L ) denotes the subset of C(Rd) such that the above limit exists.

Intuitively, the infinitesimal generator can be viewed as the derivative of the Markov semigroup at time t = 0. It uniquely determines the Markov semigroup according to the semigroup property (B.3). In the following, we define the invariant and reversible measure with respect to a Markov semigroup.
Definition B.3 (Invariance and Reversibility). For a Markov semigroup {Pt}t0 whose infinitesimal generator is L , a probability measure  is invariant with respect to {Pt}t0 if and only if
 L (f )d = 0

for all t  0 and f  C(Rd). A probability measure  is reversible with respect to {Pt}t0 if and only if

f L (g)d = gL (f )d

for all f, g  D(L ). Note that reversibility implies invariance when we plug g = 1 into the definition of reversibility.
We remark that the standard definitions of invariance and reversibility are based on the Markov semigroup {Pt}t0 instead of its infinitesimal generator L , which is equivalent to the following definition. The definitions via infinitesimal generator simplify the proof of our lemmas and theorems.

14

Under review as a conference paper at ICLR 2019

Definition B.4 (Equivalent Definitions of Invariance and Reversibility ). For a Markov semigroup {Pt}t0, a probability measure  is invariant with respect to {Pt}t0 if and only if
 Ptf d = f d
for every t  0 and f  C(Rd). Reversibility is another important concept in Markov semigroup theory. A probability measure µ is reversible for {Pt}t0 if and only if
 f Ptgd = gPtf d
for all t  0 and f, g  C(Rd). Based on the Definition B.2, we can show that this definition is equivalent to Definition B.3.
In the definitions of Markov semigroup and associated concepts, we restrict the test function f to C(Rd), the space of bounded continuous functions. However, for  being the invariant distribution with respect to {Pt}t0, we can always (slightly) extend the definition of Markov semigroup to a larger function space L2(). We use {P¯t}t0 and L¯ to denote the corresponding extended Markov semigroup and infinitesimal generator. One can show that, when  is reversible, L¯ is a self-adjoint operator in the Hilbert space L2(), which is equipped with the inner product f, g = f gd. Furthermore, one can show that L¯ is positive semidefinite. In this paper, for the convenience of discussion, we do not distinguish the slight difference between L and its extension L¯, and also the difference of D(L ), C(Rd), and L2(), since C(Rd) is dense in L2() and D(L ) is dense in C(Rd) according to Hille-Yosida theorem (Phillips & Hille, 1957). When we choose a test function, we also assume that all the related operations are well-defined.

C DETAILED PROOFS
In this section, we present the detailed proofs for all the theorems and lemmas in this paper.

C.1 PROOF OF LEMMA 3.2

Proof. The dynamics in (2.4)-(2.6) defines a Langevin diffusion with jump. Its generator takes the

form

L

a

( f

(x1,

) x2)

=

 - x1

f

(x1,

x2),

x1

U

 (x1)

+

1x1

f

(x1,

x2)





L1a

( f

(x1,

x2

) )

(

)

- x2 f (x1, x2), x2 U (x2) + 2x2 f (x1, x2) + a · s(x1, x2) · f (x2, x1) - f (x1, x2)

L2a

( f

(x1,

) x2)

Lsa(f

(x1

,

) x2)

(C.1)

and its domain D(L a) = Cc2(R2d), which is the space of all twice-differentiable functions with compact support. The first two terms L1a and L2a on the right-hand side of (C.1) correspond to the standard Langevin diffusion, while the last term Lsa arises from swapping. To prove invariance and reversibility, by Definition B.3, we only need to show that





g(x1,

x2)L

a(f

(x1

,

x2

) ) d(x1,

x2)

Rd Rd =



f

(x1,

x2

)L

a(g(x1,

) x2) d(x1

,

x2

)

Rd Rd

(C.2)

for all f, g  D(L a), where  is defined in (3.4).

15

Under review as a conference paper at ICLR 2019

Note that for the Laplacian term in L1a on the right-hand side of (C.1), by integration by parts and

the fact that f and g have compact support, we have that for all fixed x2  Rd,

 ()

- g(x1, x2) exp -U (x1)/1 x1 f (x1, x2)dx1

(C.3)

Rd  

[

( )]



= x1 g(x1, x2) exp -U (x1)/1 , x1 f (x1, x2) dx1

Rd  (

)

()



= exp -U (x1)/1 x1 g(x1, x2) - exp -U (x1)/1 g(x1, x2)x1 U (x1), x1 f (x1, x2) dx1.

Rd

Recall that µ(x1, x2) is defined in (2.5). Hence, (C.3) takes the equivalent form



g(x1,

x2)L1a(f (x1,

) x2) µ(x1,

x2)dx1

=

-



 x1 f (x1, x2), x1 g(x1, x2) µ(x1, x2)dx1,

Rd Rd

and hence,





g(x1,

x2

)L1a(f

(x1

,

x2

) ) µ(x1,

x2)dx1dx2

Rd Rd   



=-

x1 f (x1, x2), x1 g(x1, x2) µ(x1, x2)dx1dx2.

Rd Rd

(C.4)

By switching the positions of f and g in (C.4), we have





f

(x1,

x2)L1a

( g(x1

,

x2

) ) µ(x1,

x2)dx1dx2

Rd Rd   



=-

x1 g(x1, x2), x1 f (x1, x2) µ(x1, x2)dx1dx2.

Rd Rd

(C.5)

By (C.4) and (C.5) we have





g(x1,

x2)L1a(f

(x1

,

x2

) ) µ(x1,

x2)dx1dx2

Rd Rd =



f

(x1,

x2

)L1a(g(x1,

) x2) µ(x1

,

x2

)dx1

dx2

.

Rd Rd

(C.6)

By the same derivation, (C.6) also holds for L2a. Thus, it remains to prove that (C.6) holds for

Lsa as well. For notational simplicity, in the following we use f + and f - to denote f (x1, x2) and

f (x2, x1) respectively, and define g+, g-, µ+, and µ- in a similar way. Then we have





g+

( 1



(µ-/µ+

) ) (f

-

-

f

+)µ+dx1dx2

Rd Rd 



= g+µ-(f - - f +)dx1dx2 + g+µ+(f - - f +)dx1dx2

 {(x1,x2):µ-µ+}

 {(x1,x2):µ->µ+}

= g+µ-(f - - f +)dx1dx2 +  {(x1,x2):µ-µ+}

g-µ-(f + - f -)dx2dx1
{(x1 ,x2 ):µ+ >µ- }

= µ-(g+f - + g-f + - g+f + - g-f -)dx1dx2,
{(x1 ,x2 ):µ- µ+ }

(C.7)

where the third equality follows from symmetry. Similar to (C.7), we also have   f +(1  (µ-/µ+))(g- - g+)µ+dx1dx2 Rd Rd 
= µ-(f +g- + f -g+ - f +g+ - f -g-)dx1dx2.
{(x1 ,x2 ):µ- <µ+ }

(C.8)

Combining (C.7) and (C.8), we obtain





g+

( 1



(µ-/µ+))(f -

-

f +)µ+dx1dx2

=





f +(1  (µ-/µ+))(g- - g+)µ+dx1dx2,

Rd Rd

Rd Rd

16

Under review as a conference paper at ICLR 2019

which is equivalent to





g(x1,

x2)Lsa(f

(x1,

) x2) µ(x1,

x2)dx1dx2

=





f

(x1

,

x2

)Lsa(g(x1,

x2

) ) µ(x1,

x2)dx1dx2

Rd Rd

Rd Rd

by the definition of Lsa in (C.1). In summary, we obtain that (C.2) holds for  defined in (3.4). Thus, {Zt}t0 is a reversible Markov process with the invariant distribution d(x1, x2) 
exp(-U (x1)/1 - U (x2)/2)dx1dx2.

C.2 PROOF OF THEOREM 3.3

Proof. Recall the infinitesimal generator of the replica exchange Langevin diffusion with swapping intensity a defined in (3.3). According to the properties of  and , for i = 1, 2, we have

xi f 2(x1, x2) = 2f (x1, x2) · xi f (x1, x2) xi f 2(x1, x2) = 2f (x1, x2) · xi f (x1, x2) + 2xi f (x1, x2)2.

Then by the definition of the Carre´ du Champ operator a in (3.5), we have

a(f

(x1,

) x2)

=

1/2

·

La(f

(x1,

x2)2)

-

f

(x1,

x2)

·

La

( f

(x1,

) x2)

= 1 ·

x1 f (x1, x2) 2 + 2 ·

x2 f (x1, x2)

2

+

a/2

·

s(x1,

x2)

·

( f

(x2,

x1)

-

f

(x1,

x2))2.

Hence, the Dirichlet form E a is given by

( ) E a(f ) = 1 · x1 f (x1, x2) 2 + 2 · x2 f (x1, x2) 2 d(x1, x2)

 +

a/2

·

s(x1,

x2)

·

( f

(x2,

x1)

-

f

(x1

,

x2

))2

d(x1,

x2

),

which concludes the proof of Theorem 3.3.

C.3 PROOF OF THEOREM 3.4

Proof. Note that the replica exchange Langevin diffusion without swapping, that is, a = 0, shares
the same invariant distribution in (2.5) with the ones with swapping, that is, a > 0. Furthermore, Theorem 3.3 shows that E a(f )  E 0(f ) for all a > 0. Hence it remains to show that the replica exchange Langevin diffusion without swapping satisfies the Poincare´ inequality in (3.10).

Recall that the replica exchange Langevin diffusion without swapping is defined as

dZt(1) = -U (Zt(1))dt + 21dWt(1),

dZt(2)

=

-U (Zt(2))dt

+

 22

dWt(2),

(C.9)

and its infinitesimal generator is given by

L

0(f

(x1,

) x2)

=

 - x1

f

(x1,

x2),

x1

U

 (x1)

+ 

1

·

x1

f

(x1,

x2)

- x2 f (x1, x2), x2 U (x2) + 2 · x2 f (x1, x2).

(C.10)

The Poincare´ inequality for the replica exchange Langevin diffusion in (C.9) is a direct consequence of the existence of a Lyapunov function. In the specific, we have the following lemma, which is adapted from Theorem 1.4 in Bakry et al. (2008).

Lemma C.1 (Lyapunov implies Poincare´). Let {Zt}t0 be the replica exchange Langevin diffusion without swapping on R2d, whose infinitesimal generator is L 0 defined in (C.10). We further assume

that there exists a function V (x1, x2)  1, and constants  > 0, b  0, and r > 0 such that

L

0(V

(x1,

) x2)



-

·

V

(x1,

x2)

+

b

·

1Br (x1,

x2),

(C.11)

where 1Br denotes the indicator function of the centered ball with radius r in R2d. Then {Zt}t0 satisfies the Poincare´ inequality. We call V (x1, x2) the Lyapunov function.

17

Under review as a conference paper at ICLR 2019

Proof. We extend the proof of Theorem 1.4 in Bakry et al. (2008), which characterizes the standard Langevin diffusion with a single temperature, to the setting with two temperatures. For completeness, we provide a detailed proof in §C.4.

When the loss function U (x) satisfies the (, )-dissipative condition in Assumption 3.1, following

Raginsky et al. (2017), we construct the following Lyapunov function

V

(x1,

x2)

=

{ exp /4

·

( x1

2

/1

+

x2

2

)} /2 .

A direct calculation shows that V (x1, x2) satisfies the condition in (C.11). Hence, we apply Lemma C.1 to obtain that the replica exchange Langevin diffusion without swapping satisfies the Poincare´ inequality. In summary, we prove that the Poincare´ inequality holds for the replica exchange Langevin diffusion, which concludes the proof.

C.4 PROOF OF LEMMA C.1

Proof. We first prove the Poincare´ inequality in a more general form. For all functions f (x1, x2) : R2d  R, we show that if there exists a function V (x1, x2)  1 such that (C.11) holds, then there
exists a constant  such that ( )
Var(f )   · 1 · x1 f (x1, x2) 2 + 2 · x2 f (x1, x2) 2 · d(x1, x2),

where 1 and 2 are the temperatures, and (x1, x2) is the invariant distribution. By setting the function f as the Radon-Nykodim derivative d/d, we obtain the Poincare´ inequality for the 2-

divergence in (3.10). Note that for all constants u  R, we have

Var(f )





( f (x1, x2) -

u)2

· d(x1, x2),

where Var(f ) denotes the variance of f (X1, X2) when (X1, X2) follows the invariant distribution

. We use fu to denote the function f - u. By multiplying fu2(x1, x2)/(V (x1, x2)) on the both

sides of (C.11) and integrating them over (x1, x2), we have



 fu(x1, x2)2 · d(x1, x2) 

-L

0(V

(x1,

)/( x2) V

(x1,

) x2)

·

fu(x1,

x2)2

·

d(x1,

x2)

 +

b

·

1Br

(x1,

/( x2) V

(x1,

) x2)

·

fu(x1,

x2)2

·

d(x1,

x2).

(C.12)

In the sequel, we upper bound the two terms on the right-hand side of (C.12).

For the first term on the right-hand side of (C.12), we invoke the divergence theorem, which states

that for a scalar-valued function g, whose value at infinity is zero, and a vector-valued function h,

for the integration under the measure  we have ( )  g, h + g · div h d = div(g · h)d = 0.

(C.13)

In (C.13), by setting d as the Lebesgue measure dx1dx2 and

() g = exp -U (x1)/1 - U (x2)/2

and

h

=

fu(x1,

x2)2/(V

(x1,

) x2)

·

V

(x1,

x2),

we have



-L

0(V

(x1,

)/( x2) V

(x1,

) x2)

·

fu(x1,

x2)2

·

d(x1,

x2)

=

 1/ ·

 x1

[ fu

(x1

,

x2

)2

/V

(x1

,

x2

] ),

x1

V

(x1

,

x2

 )

·

d(x1

,

x2

)

 + 2/ ·

 x2

[ fu

(x1

,

x2

)2

/V

(x1

,

x2

] ),

x2

V

(x1

,

x2

 )

·

d

(x1

,

x2

).

(C.14)

18

Under review as a conference paper at ICLR 2019

Meanwhile, for the first term on the right-hand side of (C.14) we have



 x1

[fu2

(x1

,

x2

)/V

(x1

,

x2

] ),

x1

V

(x1

,

x2

 )

·

d(x1

,

x2

)

( = x1 fu(x1, x2) 2 -

() x1 fu(x1, x2) - fu(x1, x2)/V (x1, x2) · x1 V (x1, x2)

) 2 · d(x1, x2)



 x1 fu(x1, x2) 2 · d(x1, x2),

(C.15)

where the first equality follows from expanding the gradient of fu2(x1, x2)/V (x1, x2) with respect to x1. By a similar derivation, the same inequality holds for the second term on the right-hand side

of (C.14) as well. Hence, plugging them into (C.15), for the first term on the right-hand side of

(C.12) we have



-L

0

( V

(x1,

)/( x2) V

(x1,

) x2)

·

fu(x1,

x2)2

·

d(x1,

x2)

( )  1/ · 1 x1 fu(x1, x2) 2 + 2 x2 fu(x1, x2) 2 · d(x1, x2).

(C.16)

For the second term on the right-hand side of (C.12), we restrict our attention to the bounded domain

Br. Based on the assumption that V (x1, x2)  1, there exists a positive constant k such that



b

·

1Br

(x1,

/( x2) V

(x1,

) x2)

·

fu(x1,

x2)2

·

d(x1,

x2)



 b/ · fu(x1, x2)2 · d(x1, x2)

 k·

Br ( fu(x1, x2) 2 · d(x1, x2) +

)2/ ( ) fu(x1, x2) · d(x1, x2)  Br ,

Br Br

(C.17)

where the second inequality follows from the Poincare´ inequality for measures on a bounded domain

(Bakry etal., 2008). Since (C.17) holds for all functions fu(x1, x2), one can choose a suitable u

such that

Br

fu

d = 0. 
b·

Then we have /(
1Br (x1, x2) V

(x1,

) x2)

·

fu(x1,

x2)2

·

d(x1,

x2)



k·

fu (x1, x2) 2 · d(x1, x2).

(C.18)

Br

Finally, by plugging (C.16) and (C.18) into (C.12), we have that there exists a positive constant 

such that



Var(f )  fu (x1, x2)2 · d(x1, x2) ( )
  · 1 x1 f (x1, x2) 2 + 2 x2 f (x1, x2) 2 · d(x1, x2),

which concludes the proof of Lemma C.1.

C.5 PROOF OF THEOREM 3.5

According to Lemma 3.2, the replica exchange Langevin diffusion {Zt}t0 is reversible. Hence, we

can apply the Donsker-Varadhan theory, which states that for a continuous-time reversible Markov

process with invariant distribution  and infinitesimal generator L , LDP holds and its LDP rate

function takes the explicit form

{  (

)2

I() =

-L d/d , if   ,


, otherwise.

(C.19)

19

Under review as a conference paper at ICLR 2019

 Here L denotes the square root of -L , which is defined as follows.

Let A be a positive semidefinite self-adjoint operator in the Hilbert space (H, ·, ·H), the square root of A is defined as the self-adjoint operator B such that A = B2, which means x, AxH = x, B2xH = Bx, BxH for every x  H. As explained in §B, the infinitesimal generator -L can be extended to a positive semidefinite self-adjoint operator in the Hilbert space L2(). We ignore the slight differences caused by extension. Hence, -L is well-defined here.

Recall that the infinitesimal generator L a of the replica exchange Langevin diffusion is given by (3.3). We first derive the explicit form of  -L a(f )2. Since the square root of a positive semidef-

inite self-adjoint operator is self-adjoint, we have

 -L a(f )

2 

=

 -L

a(f ),

 -L

 a(f ) 

=

 f, -L

a

2
(f

 )

=

 f, -L

a(f

 )

=

 -

f L a(f )d.

Since  is the invariant distribution, by Definition B.3 we have  L a(f 2)d = 0. Then we have

 -L a(f )



2 

=

1/2

·

( L

a(f

2)

-

2f

L

a

(f

) ) d,

which is exactly the Dirichlet form. Then based on (3.3), we obtain

L a(f 2) - 2f L a(f ) = 21 · x1 f (x1, x2) 2 + 22 · x2 f (x1, x2) 2

+

a

·

s(x1

,

x2

)

·

( f

(x2

,

x1

)

-

f

(x1

,

x2

))2

.

Hence, we have that for probability measures   ,

 Ia() =

1

 x1 d/d(x1, x2)

2 + 2

 x2 d/d(x1, x2)

2

+

a/2

·

s(x1,

x2)

·

( d

/d(x2,

x1

)

-

 d

/d(x1,

x2

))2

d,

and I() = , otherwise.

(C.20)

C.6 PROOF OF THEOREM 3.6

Proof. Recall that the temperature swapping Langevin diffusion {Zt}t0 and the continuous-time interpolated process {Zt}t0 are defined in (3.14) and (3.17). For all t  [0, T ], we have

Zt - Zt

 =-

t( U

(Zs)

-

U

(Zs/

)) ds

+



t( s

-

s/

) dWs

.

00

By applying the Cauchy-Schwartz inequality and then taking expectation, we have

[ E Zt

-

Zt 2 ]



2

·

[ E



t

( U

(Zs)

-

U

(Zs/

)) ds

]
2

0[ +2·E



t( s

-

s/

) dWs

]
2
.

0

(C.21)

In the sequel, we upper bound the two terms on the right-hand side of (C.21).

For the first term, by Cauchy-Schwarz inequality, we have

[ E



t

( U

(Zs

)

-

U

(Zs/

)) ds

]
2

0 [ t·E

t

U (Zs) - U (Zs/)

]
2
ds

(0 [ t

] [ t

])

 2L2t · E Zs - Zs2ds + E

Zs - Zs/ 2ds ,

00

(C.22)

20

Under review as a conference paper at ICLR 2019

where the second inequality follows from the L-smoothness of U (·) in Assumption 3.1. In the

following, we upper bound the second term on the right-hand side of (C.22). Note that we have

[ t E

Zs - Zs/

] 2ds



t/ [ E

(k+1)

Zs - Zs/

] 2ds .

0

k=0

k

(C.23)

For

all

integers k  0 and s  [k, (k + 1)), based on the definition of Zs - Zs/ 2 = Zs - Zk2 = -U (Zk) · (s - k)

{Zt

}t0 

+ k

in (3.17),
s2
dWu .

we

have

k

By applying the Cauchy-Schwartz inequality again, we obtain

Zs - Zs/ 2  2 ·

U (Zk) 2 · (s - k)2 + 2 ·

 k

s
dWu

2

=2·

k
U (Zk) - U (x) 2 · (s - k)2 + 2 ·

 k

s
dWu

2
,

k

(C.24)

where x is a stationary point of U (·), and by definition U (x) = 0. Recall that by Assumption

3.1, U (·) is L-smooth. Based on (C.24), we have

Zs - Zs/ 2  2L2 · Zk - x2 · (s - k)2 + 2 ·

 k

s
dWu

2

 4L2 · (Zk2 + x2) · (s - k)2 + 2 ·

k  s k dWu

2
.

k

(C.25)

By integrating the second inequality in (C.25) over the interval [k, (k +1)] and taking expectation,

then plugging it into the right-hand side of (C.23), we obtain

[ (k+1)

]

E Zs - Zs/ 2ds

k



4L2

·

( sup

E[Zk

2

]

+

) x2 · 3/3 +

2·



(k+1)

[ E

s k dWu

]
2
ds.

(C.26)

k0

k k

Note

that

on

the

right-hand

side

of

(C.26),

k

is

a

diagonal

matrix

with

diagonal

entries

 21

or

22, then by Ito^ isometry, we have

[ E

s k dWu

]
2

=

2d

[( E k(j)



s )2] dWu(j)  4d2(s - k),

k j=1

k

where k(j) denotes the j-th diagonal entry of the matrix k, and Wu(j) is the j-th component of

the 2d-dimensional Brownian motion Wu. Hence, we have



(k+1) [ E

 k

s
dWu

]
2
ds 

(k+1)
4d2(s - k)ds = 2d22,

(C.27)

k k

k

which provides an upper bound for the right-hand side of (C.26). Then by plugging (C.27) into

(C.26), we obtain

[ (k+1) E
k

Zs - Zs/

] 2ds



4L2

·

( sup

E[Zk 2 ]

+

) x2

·

3

+

4d22.

k0

(C.28)

Then by plugging (C.28) into (C.23), we have

[ t E
0

Zs - Zs/

] 2ds



(1

+

t/)

·

( 4L2

·

( sup

E[Zk 2 ]

+

) x2

·

3

+

) 4d22 .

k0

(C.29)

The following lemma shows that if the discretization stepsize  falls into the interval (0, /L2), {Zk}k0 are uniformly upper bounded in the L2 sense.

21

Under review as a conference paper at ICLR 2019

Lemma C.2. If 0 <  < /L2, there exists a constant 1(d, 2, L, , ), which depends on the dimension d, the temperature parameter 2, and the smoothness constant L and dissipative constants (, ) of U (·), such that
sup E[Zk2]  1(d, 2, L, , ).
k0
Proof. The proof idea is to show that the sequence {E[Zk2]}k0 satisfies a contractive inequality based on the discretization scheme defined in (3.15). See §C.7 for a detailed proof.

By applying Lemma C.2 to (C.29), we have that there exists a constant 2(d, 2, L, , ) such that

[ t

]

E Zs - Zs/ 2ds  2(d, 2, L, , ) · .

0

Then based on (C.22), we obtain the following inequality

[ E



t( U

(Zs)

-

U

(Zs/

)) ds

]
2

0 ( [ t

]

)

 2L2t · E Zs - Zs2ds + 2(d, 2, L, , ) ·  ,

0

(C.30)

which establishes an upper bound for the first term on the right-hand side of (C.21).

It remains to upper bound the second term on the right-hand side of (C.21). According to Ito^ isom-

etry, we have

[ E



t( s

-

s/

) dWs

]
2

2d 

=

t

[( E s(j

)

-

s/

(j

))2

] ds

0 j=1 0



2d t/ 

(k+1)

[( E s(j

)

-

k

(j))2]ds,

j=1 k=0 k

(C.31)

where s(j) and k(j) are and s are diagonal matrices

the j-th with all

diagonal diagonal

entries entires

of s being

and k, 21 or

respectively. Recall 22. Then for all j

that s , k, and

possible realizations of s(j) and k(j), we have



(k+1)

[( E s(j)

- k(j))2]ds

=

 4( 2

- 2)2

 ·

(k+1)

( P s(j)

=

k

) (j) ds.

(C.32)

k k

To upper bound the probability on the right-hand side of (C.32), we take the expectation conditioning

Zk, which yields



(k+1) ( P s(j)

=

k

(j

) ) ds

=

[ E

(k+1) ( P s(j)

=

k (j )

Zk

)] ds .

(C.33)

k k

Recall that the rate of swapping is specified in (2.6) and (2.7). The conditional probability on the

right-hand side of (C.33) satisfies

( P s(j)

=

k (j )

Zk) = a · s(Zk(1), Zk(2)) · (s - k) + o(s - k),

(C.34)

where Zk(1), Zk(2) are the first and second components of Zk, s(·, ·) is defined in (2.6), and o(·) is the little-o notation, which denotes the higher-order term with respect to s - k. Hence, by

combining (C.32)-(C.34), we have that there exists a constant 3(1, 2, a) such that



(k+1)

[( E s

(j

)

-

k

(j

))2

] ds

=

 4( 2

- 2)2

 ·

(k+1) (

)

a · (s - k) + o(s - k) ds

k k

 3(1, 2, a) · 2.

22

Under review as a conference paper at ICLR 2019

Then based on (C.31), there exists a constant 4(d, 1, 2, a) such that

[ E



t( s

-

s/

) dWs

]
2



2d

·

( t/

+

) 1

·

3(1,

2,

a)

·

2



4(d,

1,

2,

a)

·

t

·

.

0

(C.35)

Finally, by plugging (C.30) and (C.35) into (C.21), we have

[ E Zt

-

Zt

2

]



( 4L2t ·

t[ E Zs

-

Zs

2

] ds

+

2

(d,

2,

L,

,

)

·

) 

+

2

·

4(d,

1,

2,

a)

·

t

·

.

0

Hence, by applying the Gro¨nwall's inequality (Dragomir, 2003), we have that there exists a constant

(d, 1, 2, a, L, , , T ) such that for all t  [0, T ],

[ E Zt

-

Zt 2 ]



(d,

1,

2,

a,

L,

,

,

T

)

·

.

In other words, the mean squared error of discretization grows linearly with respect to the stepsize , which concludes the proof of Theorem 3.6.

C.7 PROOF OF LEMMA C.2

Proof. Recall that for all integers k  0, based on the discretization scheme in (3.15) and (3.16), for

i  {1, 2}, we have

Z (i) (k

+

1)

=

Z (i) (k)

-



·

U

( Z

(i)(k))

+

 2

·



(i)(k)

·

(i)(k),

where (i)(k) is a standard d-dimensional Gaussian random vector and the temperature  (i)(k)

takes value in {1, 2}. Also note that by the definition of the continuous-time interpolated pro-

cess {Zt}t0 in (3.17), we have Z(k) = Zk. Hence, we have

E[Z(k+1) 2 ]

=

[ E

Zk -  · U (Zk)

]
2

+

[ E 2

·



(1)(k)

·



(1)(k)2]

+

[ E 2

·



(2)

(k)

·

(2)(k)2]

+

2

·

E[Z(k+1)

-



·

U (Zk),

 2

·

k

·

] (k) .

(C.36)

Since (k) is independent of Zk and by (3.16) the distribution of  (k) is only determined by Zk, the last term on the right-hand side of (C.36) is zero. Moreover, note that each component of  (k)

only takes value in {1, 2} and 1 < 2. Then by (C.36) we have

E[Z(k+1) 2 ]



[ E

Zk -  · U (Zk)

] 2 + 4d2.

(C.37)

Recall that U (·) is (, )-dissipative and L-smooth by Assumption 3.1. Then we have

[ E

Zk -  · U (Zk)

]
2

=

E[Zk 2 ]

-

2

·

E[Zk ,

U

(Zk

] )

+

2

·

[ E

U (Zk)

]
2

 (1 - 2 + 22L2) · E[Zk2] + 2 + 22L2 · x2,

where x is a stationary point of U (·). Hence, based on (C.37), we have

[ E

Z(k+1)

]
2



(1

-

2

+

22L2)

·

E[Zk 2 ]

+

2(

+

d2)

+

22L2x2.

(C.38)

Note that when   (0, /L2), we have 1 - 2 + 22L2 < 1. Hence, according to (C.38), there
exists a constant 1(d, 2, L, , ) such that sup E[Zk2]  1(d, 2, L, , ),
k0

which concludes the proof of Lemma C.2.

23

