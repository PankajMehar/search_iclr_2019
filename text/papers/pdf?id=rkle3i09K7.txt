Under review as a conference paper at ICLR 2019
ROBUST DETERMINANTAL GENERATIVE CLASSIFIER FOR NOISY LABELS AND ADVERSARIAL ATTACKS
Anonymous authors Paper under double-blind review
ABSTRACT
Large-scale datasets may contain significant proportions of noisy (incorrect) class labels, and it is well-known that modern deep neural networks poorly generalize from such noisy training datasets. In this paper, we propose a novel inference method, Deep Determinantal Generative Classifier (DDGC), which can obtain a more robust decision boundary under any softmax neural classifier pre-trained on noisy datasets. Our main idea is inducing a generative classifier on top of hidden feature spaces of the discriminative deep model. By estimating the parameters of generative classifier using the minimum covariance determinant estimator, we significantly improve the classification accuracy, with neither re-training of the deep model nor changing its architectures. In particular, we show that DDGC not only generalizes well from noisy labels, but also is robust against adversarial perturbations due to its large margin property. Finally, we propose the ensemble version of DDGC to improve its performance, by investigating the layer-wise characteristics of generative classifier. Our extensive experimental results demonstrate the superiority of DDGC given different learning models optimized by various training techniques to handle noisy labels or adversarial examples. For instance, we improve the test accuracy of DenseNet on CIFAR-10 datasets with 60% noisy labels from 53.34% to 74.72%.
1 INTRODUCTION
Deep neural networks (DNNs) are known to generalize well when they are trained on large-scale datasets with clean label annotations. For example, DNNs have achieved state-of-the-art performance on many classification tasks, e.g., speech recognition (Amodei et al., 2016), object detection (Girshick, 2015) and image classification (He et al., 2016). However, as the scale of the training dataset increases, it becomes infeasible to obtain all class labels from domain experts. A common practice is collecting the class labels from data mining on social media (Mahajan et al., 2018) and web data (Krause et al., 2016). However, they may contain missing/noisy (incorrect) labels, and recent studies have shown that modern deep architectures may generalize poorly from the noisy datasets (Zhang et al., 2017; Arpit et al., 2017). For example, in Figure 1(a), the test set accuracy (black line) of DenseNet-100 model (Huang & Liu, 2017) trained on the CIFAR-10 dataset (Krizhevsky & Hinton, 2009) significantly decreases as the noise fraction increases.
To overcome the poor generalization issue of DNNs against noisy labels, several training strategies have been investigated in the literature (Reed et al., 2014; Patrini et al., 2017; Ma et al., 2018b; Hendrycks et al., 2018). Reed et al. (2014) proposed a bootstrapping method which trains deep models with new labels generated by a convex combination of the raw (noisy) labels and their predictions, and Ma et al. (2018b) improved the bootstrapping method by utilizing the dimensionality of subspaces during training. Patrini et al. (2017) modified the loss and posterior distribution to eliminate the influence of noisy labels, and Hendrycks et al. (2018) improved such a loss correction method by utilizing the information from data with true class labels. However, adopting such training methods might incur expensive back-and-forth costs, e.g., additional time and hyperparameter tuning. This motivates our approach of developing a more plausible inference method which can be applied to any pre-trained deep model. Nevertheless, our direction is orthogonal to the prior works, where one can also combine them for even better performance (see Table 3 in Section 3).
1

Under review as a conference paper at ICLR 2019

100 Samples with clean labels Samples with noisy labels
90

Test set accuracy (%)

80

70

60

50 40 30
0

Softmax Generative (sample estimator on noisy labels) Generative (MCD estimator on noisy labels) Generative (MCD estimator + ensemble on noisy) Generative (sample esitmator on clean labels) [ideal]

0.2 0.4 Noise fraction

0.6

(a) Test set accuracy comparison (b) Features on penultimate layer (c) Features on penultimate layer

by varying noise fraction

from test samples by t-SNE

from training samples by t-SNE

Figure 1: Experimental results under DenseNet-100 model and CIFAR-10 dataset. (a) Test accuracy comparison when the labels of a given proportion of training samples are flipped to other labels uniformly at random. Visualization of features on the penultimate layer using t-SNE from (b) test samples (same colors indicate same classes) and (c) training samples when the noise fraction is 20%.

Contributions. It has been observed that DNNs can learn meaningful feature patterns shared by multiple training examples even for datasets with noisy labels (Arpit et al., 2017). We also found that an induced generative classifier (Ng & Jordan, 2002) under linear discriminant analysis (LDA) assumption (with naive estimations on sample mean and covariance) built upon the hidden feature space can outperform the softmax classifier (orange line in Figure 1(a)). In Figure 1(b), the hidden features from test samples projected in a 2-dimensional space using t-SNE (Maaten & Hinton, 2008) are illustrated. Here, one can observe that all ten classes are well-separated in the embedding space, even though the model is trained under a noisy dataset. More importantly, Figure 1(c) plotting noisy training samples implies that outliers induce the class-wise multi-modal distributions in the feature space. Therefore, an LDA-like generative classifier assuming the class-wise unimodal distribution might be more robust, as a discriminative classifier is easier to be overfitted by outliers. This motivates our goal to induce a generative classifier on the pre-trained hidden features of DNNs.
To this end, we propose the so-called deep determinantal generative classifier (DDGC), based on the minimum covariance determinant (MCD) (Rousseeuw, 1984; Rousseeuw & Driessen, 1999) estimation on its parameters. While a naive sample estimator can be highly influenced by outliers, MCD estimator can improve the robustness by removing them. Note that MCD is known to have a near-optimal breakdown point (Hampel, 1971) of almost 50% in most situations, i.e., the number of outliers should be larger than that of normal samples to fool it. We further provide a new theoretical support on the larger margin property of DDGC such that not only does it generalize well from noisy labels (Durrant & Kaba´n, 2010), but also improves the robustness against adversarial perturbations (Pang et al., 2018). In addition, we observe that DNNs tend to have similar hidden features, regardless of whether they are trained with clean or noisy labels at early layers (Morcos et al., 2018), and DDGC built from low-level features can be often more effective. Under the observation, we finally propose an ensemble version of DDGC to incorporate all effects of low and high layers.
We demonstrate the effectiveness of DDGC using modern neural architectures, such as DenseNet (Huang & Liu, 2017) and ResNet (He et al., 2016) trained for image classification tasks including CIFAR (Krizhevsky & Hinton, 2009) and SVHN (Netzer et al., 2011). First, our methods (green and blue lines in Figure 1(a)) significantly outperform the softmax classifier, although they use the same feature representations trained by the noisy dataset. For example, we improve the test accuracy of DenseNet on CIFAR-10 datasets with 60% noisy labels from 53.34% to 74.72%. We also demonstrate that DDGC can be used to further improve various prior training methods (Reed et al., 2014; Patrini et al., 2017) which are specialized to handle the noisy environment. Finally, DDGC is shown to be robust against various adversarial attacks (Goodfellow et al., 2015; Moosavi Dezfooli et al., 2016; Carlini & Wagner, 2017). In particular, we improve the classification accuracy of ResNet against the DeepFool attack (Moosavi Dezfooli et al., 2016) on CIFAR-10 from 0.34% to 7.50%.

2 ROBUST INFERENCE VIA GENERATIVE CLASSIFIER
In this section, we propose a novel inference method which obtains the robust posterior distribution from any softmax neural classifier pre-trained on datasets with noisy labels. Our idea is inducing the generative classifier using fixed features from any pre-trained model. We show the advantages of our method in terms of high breakdown points (Hampel, 1971), generalization error (Durrant &

2

Under review as a conference paper at ICLR 2019

Kaba´n, 2010) and adversarial robustness (Pang et al., 2018). We also investigate the layer-wise characteristics of generative classifiers, and introduce an ensemble of them to improve its performance. We emphasize again that we study inference methods, not requiring any modification on pre-trained deep models. Hence, the proposed methods are easily applicable on top of any pre-trained modern neural classifiers.

2.1 GENERATIVE CLASSIFIER AND MCD ESTIMATOR

Let x be an input and y  {1, · · · , C} be its class label. Without loss of generality, suppose that a

pre-trained softmax neural classifier is given: P (y = c|x) =

exp(wc f (x)+bc) c exp(wc f (x)+bc

),

where

wc

and

bc

are the weight and the bias of the softmax classifier for class c, and f (·)  Rd denotes the output of

the penultimate layer of DNNs. Then, without any modification on the pre-trained softmax neural

classifier, we induce a generative classifier by assuming the class-conditional distribution follows

the multivariate Gaussian distribution. In particular, we define C Gaussian distributions with a tied

covariance , i.e., linear discriminant analysis (LDA) (Fisher, 1936), and a Bernoulli distribution

for the class prior: P (f (x)|y = c) = N (f (x)|µc, ) , P (y = c) = c, where µc is the mean of multivariate Gaussian distribution and c is the normalized prior for class c. We provide an

analytic justification on the LDA (i.e., tied covariance) assumption in Appendix A. Then, based on

the Bayesian rule, we induce a new posterior different from the softmax one as follows:

P (y = c|f (x)) =

P (y = c) P (f (x)|y = c) P (y = c ) P (f (x)|y = c ) =

exp

µc

-1f (x)

-

1 2

µc

-1µc

+

log

c

exp

µc

-1f (x)

-

1 2

µc

-1µc

+ log c

cc

To estimate the parameters of the generative classifier, one can compute the sample class mean and covariance of training samples XN = {(x1, y1), . . . , (xN , yN )}:

.

µ¯c

=

i:yi =c

f (xi) , Nc

¯ =

(f (xi) - µ¯c) (f (xi) - µ¯c) ,

N

c i:yi=c

¯c

=

Nc , N

(1)

where Nc is the number of training samples labeled to be class c. We remark that inducing a generative classifier from a pre-trained softmax classifier under the LDA assumption was studied recently for different purposes (Lee et al., 2018b). Their main focus is on detecting abnormal samples like out-of-distribution (Lee et al., 2018a) and adversarial samples (Ma et al., 2018a). However, our goal is completely different, and even more difficult in the sense of assuming abnormality in training or/and defending it beyond detection. To tackle new challenges, we design a more advanced generative classifier as stated in below.

One can expect that the naive sample estimator (1) can be highly influenced by outliers (i.e., training
samples with noisy labels). In order to improve the robustness, we propose the so-called deep deter-
minantal generative classifier (DDGC), which utilize the minimum covariance determinant (MCD) estimator (Rousseeuw & Driessen, 1999) to estimate its parameters. For each class c, the main idea of MCD is finding a subset XKc for which the determinant of the corresponding sample covariance is minimized:

min det c
XKc XNc

subject to |XKc | = Kc,

(2)

where XNc is the set of training samples labeled to be class c, c is the sample covariance of XKc and 0 < Kc < Nc is a hyperparameter. Then, only using the samples in c XKc , it estimates the
parameters, i.e., µc, , c, of the generative classifier, by following (1). Such a new estimator can be more robust by removing the outliers which might be widely scattered in datasets. The robustness
of MCD estimator has been justified in the literature: it is known to have near-optimal breakdown
points (Hampel, 1971), i.e., the smallest fraction of data points that need to be replaced by arbitrary values (i.e., outliers) to fool the estimator completely. Formally, denote YM as a set obtained by replacing M data points of set Y by some arbitrary values. Then, for a multivariate mean estimator µ = µ(Y) from Y, the breakdown point is defined as follows (see Appendix A for more detailed
explanations including the breakdown point of covariance estimator):

(µ, Y)

=

1 |Y |

min

M  {1, · · · , |Y|} : sup µ(Y) - µ(YM )
YM

=

.

3

Under review as a conference paper at ICLR 2019

While the breakdown point of the naive sample estimator is 0%, the MCD estimator for

the generative classifier under LDA assumption is known to attain its breakdown value of

minc

(Nc -d+1)/2 Nc

 50% (Lopuhaa et al., 1991). Inspired by this fact, we choose the default

value of Kc in (2) by (Nc + d + 1)/2 .

We also establish the following theoretical support that the MCD-based generative classifier, i.e., DDGC, can have smaller errors on parameter estimations and produce a larger margin, compared to the naive sample estimator, under some assumptions for its analytic tractability.

Theorem 1. Assume the followings:

(A1) The distribution of hidden features is P (f (x)|y = c) = N f (x)|µc, 2I (i.e., the con-
ditional Gaussian distribution) and that of outliers is an arbitrary distribution, which has a density function in L1 space (i.e., its absolute value is measurable), with mean µout and covariance matrix o2utI, where I  Rd×d is the identity matrix.

(A2)

µout

=

1 C

c

µc

=

0,

and

1 C

c µcµTc is a diagonal matrix.

(A3)

All classes have the same number of samples (i.e., Nc

=

N C

),

the

same

fraction

out

< 1 of

outliers, and the sample fraction mcd

=

Kc Nc

<

1 of samples selected by MCD estimator.

(A4) The outliers are widely scattered such that 2  o2ut.

(A5)

The number of outliers is not too large such that out

< 1 - mcd and mcd

>

d Nc

.

Let µ,  and µ¯, ¯ be the outputs of the MCD and sample estimators, respectively. Then, µ, µ¯, , ¯ converge to their expectation almost surely as N  , and it holds that



B(µc, µc B(µ¯c, µ¯c

, , ) , , ¯ )

a.s.

lim B(µc, µc N B(µ¯c, µ¯c

, , ) , , ¯ )



exp -

µc - µc

2 2

1 - (1 - out)2

82

   1,

µc - µc 1 a.s. lim µc - µc 1 = 0,
N 

µc - µ¯c

1 a.s. lim
N 

µc - µ¯c

1 = out

µc

1

(µc (µ¯c

- µc - µ¯c

)T -1(µc )T ¯ -1(µ¯c

- µc - µ¯c

) )

a.s.

lim
N 

(µc (µ¯c

- µc - µ¯c

)T -1(µc )T ¯ -1(µ¯c

- µc - µ¯c

) )

=

1 (1 - out)2



1.

(3) (4)
(5)

for all c, c , where B(µc, µc , , ) := exp

- 1 [(µc-µc )T -1(µc-µc )]2
8 (µc-µc )T -1-1(µc-µc )

.

The proof of the above theorem is given in Appendix G, where it is built upon the fact that the
determinants can be expressed as the d-th degree polynomial of outlier ratio. We note that one might enforce the assumptions of the diagonal covariance matrices in A1 and the zero-mean/uncorrelated properties of class mean in A2 to hold under an affine translation of hidden features. In addition, the assumption in A5 holds when Nc is large enough. Nevertheless, we think most assumptions of Theorem 1 are not necessary to claim the superiority of DDGC (they are rather from a limitation of
our proof techniques) and it is an interesting future direction to explore to relax them.

First, (5) implies that the MCD estimator induces a larger margin and improves the robustness to adversarial attacks, since Pang et al. (2018) showed that the margin of a generative classifier corresponds to the Mahalanobis distance between class-conditional distributions and the optimal robustness to adversarial examples is achieved by the maximum margin. More importantly, (3) and (4) together imply that a MCD-based classifier can generalize better since the generalization error of a generative classifier is known to be bounded as follows (Durrant & Kaba´n, 2010):

Px

y

=

arg

max
y

Pµc,(y|x)



B(µc , µc, , ) + D

µc - µc 1,

c c =c

c

for some constant D > 0.

4

Under review as a conference paper at ICLR 2019

Algorithm 1 (Rousseeuw & Driessen, 1999) Approximating MCD for a single Gaussian.

Input: XNc = {xi : i = 1, · · · , Nc} and the maximum number of iterations Imax.

Uniformly sample initial subset XKc  XNc , where |XKc | = (Nc + d + 1)/2 .

Compute

mean

and

covariance

µc

=

1 |X |

f (x),

c

=

1 |X |

(f (x) - µc) (f (x) - µc) .

xX

xX

for i = 1 to Imax do

Compute the Mahalanobis distance: (x) = (f (x) - µc) -c 1 (f (x) - µc) , x  XNc .

Update XKc such that it includes (Nc + d + 1)/2 samples with smallest distance (x).

Compute sample means and covariance, i.e., µc, c, using new subset XKc . breakdown the loop if the determinant of covariance matrix is not decreasing anymore.

end for

Return µc and c

2.2 APPROXIMATION ALGORITHM FOR MCD

Even though the MCD estimator has several advantages, the optimization (2) is computationally intractable (i.e., NP-hard) to solve (Bernholt, 2006). To handle this issue, we aim for computing its approximate solution, following a similar idea to that by (Hubert & Van Driessen, 2004). We design

two step scheme as follows: (a) obtain the mean and covariance, i.e., µc, c, using Algorithm 1 for

each class c, and (b) compute the tied covariance by  =

.c Kcc
c Kc

In

other

words,

we

apply

the

MCD estimator for each class, and combine the individual covariances into a single one due to the

tied covariance assumption of LDA. Even though finding the optimal solution of MCD estimator

under a single Gaussian distribution is still intractable, Algorithm 1 can produce a local optimal so-

lution since it monotonically decreases the determinant under any random initial subset (Rousseeuw & Driessen, 1999). We choose Imax = 2 in our experiments as the additional iterations would not improve the results significantly.

2.3 ENSEMBLE OF GENERATIVE CLASSIFIERS

To further improve the performance of our method, we consider the ensemble of generative classifiers not only from the penultimate features but also from other low-level features in DNNs. Formally, given training data, we extract -th hidden features of DNNs, denoted by f (x)  Rd , and
compute the corresponding parameters of a generative classifier (i.e., µ ,c and  ) using the (approximated version of) MCD estimator. Then, the final posterior distribution is obtained by the sum of all posterior distributions of generative classifiers:

 P (y = c|x) =

exp µ ,c-1f (x) - 0.5µ ,c-1µ ,c + log c ,
c exp µ ,c -1f (x) - 0.5µ ,c -1µ ,c + log c

where  is an ensemble weight at -th layer. In our experiments, we choose the weight of each layer by optimizing NLL loss over the validation set. One can expect that this simple but natural scheme can bring an extra gain in improving the performance due to ensemble effects.
To confirm that ensemble approach is indeed effective, we measure the classification accuracy of the generative classifier from different basic blocks of ResNet-34 (He et al., 2016) trained on CIFAR-10 dataset (Krizhevsky & Hinton, 2009) with various noise fractions, where the corresponding results on DenseNet models (Huang & Liu, 2017) can be found in Appendix D. For computational efficiency, the dimensions of the intermediate features are reduced using average pooling (see Section 3 for more details). First, we found that the performances of the generative classifiers from lowlevel features are more stable, while the accuracy of generative classifier from penultimate layer significantly decreases as the noisy fraction increases as shown in Figure 2(a). We expect that this is because the dimension (i.e., number of channels) of low-level features is usually smaller than that of high-level features. Since the breakdown point of MCD is inversely proportional to the feature dimension, the generative classifiers from low-level features can be more robust. This also coincides with the prior observation in the literature (Morcos et al., 2018) that DNNs tend to have similar hidden features at early layers, regardless of whether they train clean or noisy labels. More

5

Under review as a conference paper at ICLR 2019

100 100 100 Clean data

80

FGSM

80

DeepFool CW

90

80

60 60 70

Test set accuracy (%) Test set accuracy (%)
Test set accuracy (%)

40 40 60

20

Noise fraction = 0% Noise fraction = 40%

Noise fraction = 20%

Noise fraction = 60%

0 2 4 6 8 10 12

Index of basic block

14

20

0 2

4 6 8 10 12 Index of basic block

14

50 Softmax

Generative (identity) + sample estimator

40 Generative (identity) + LTS estimator

Generative (LDA) + sample estimator

Generative (LDA) + MCD [DDGC]

30

0%

20%

40%

Noise fraction

60%

(a) Generalization of generative (b) Robustness of generative (c) Generative classifiers under

classifiers from noisy labels

classifiers to adversarial attacks various assumptions

Figure 2: Experimental results under ResNet-34 model and CIFAR-10 dataset. (a) Test accuracy of generative classifiers computed at different basic blocks. (b) Test accuracy on various adversarial attacks when the model is trained on clean dataset. (c) Test accuracy of generative classifiers from penultimate features under various assumptions: identity covariance and tied covariance (LDA).

Model DenseNet
ResNet

Inference method Softmax
Generative + sample
Generative + MCD (DDGC)
Softmax Generative + sample
Generative + MCD (DDGC)

Ensemble -
-
-
-

Noise = 0% 94.42 94.31 93.73 94.37 93.49
95.01 94.98 94.98 94.73 94.32

20% 80.24 85.08 87.23 85.96 87.25
79.28 81.61 87.23 83.04 87.25

40% 68.61 74.72 80.01 78.34 81.04
61.85 64.60 78.40 68.04 80.01

60% 53.34 59.49 69.17 66.16 74.72
35.02 40.63 61.94 42.74 71.06

Table 1: Effects of ensemble method. We use the CIFAR-10 dataset with various noise fractions. All values are percentages and the best results are highlighted in bold if the gain is bigger than 1%.

importantly, we found that generative classifiers from low-level features are more robust to adversarial attacks like DeepFool (Moosavi Dezfooli et al., 2016) and CW (Carlini & Wagner, 2017), as shown in Figure 2(b). Therefore, we utilize the low-level generative classifiers as well to improve the generalization from noisy label and robustness to adversarial attacks simultaneously.
3 EXPERIMENTAL RESULTS
In this section, we demonstrate the effectiveness of the proposed method using deep convolutional neural networks such as DenseNet (Huang & Liu, 2017) and ResNet (He et al., 2016) on various vision datasets: CIFAR (Krizhevsky & Hinton, 2009) and SVHN (Netzer et al., 2011). Due to the space limit, we provide the more detailed experimental setups and results in Appendix B.
3.1 GENERALIZATION FROM NOISY LABELS
Setup. First, we evaluate the effectiveness of DDGC using deep models trained on datasets with noisy labels. We train DenseNet-100 and ResNet-34 for classifying CIFAR-10, CIFAR-100 and SVHN datasets. Following similar strategies in (Ma et al., 2018b; Vahdat, 2017), the labels of a given proportion of training samples are flipped to other class labels uniformly at random. For ensembles of generative classifiers, we induce the generative classifiers from every end of basic block of DenseNet (or ResNet), where ensemble weights of each layer are tuned on a separate validation set, which consists of 500 images (i.e., only  1% of the number of training samples) with clean labels.1 Similar to (Lee et al., 2018b), the size of feature maps on each convolutional layers is reduced by average pooling for computational efficiency: F × H × W  F × 1, where F is the number of channels and H × W is the spatial dimension.
1For fair comparisons, one might also suggest fine-tuning the softmax classifier (with fixed features) using the validation data to improve the performance. However, the 1% data is often not enough for the purpose as the number of parameters of softmax classifier is too large. We indeed report the performance of the fine-tuned softmax classifier on Table 9 in Appendix E.

6

Under review as a conference paper at ICLR 2019

Dataset CIFAR-10 CIFAR-100
SVHN

Model
ResNet DenseNet ResNet DenseNet ResNet DenseNet

Noise = 0%
95.01 / 94.32 94.42 / 93.49 77.51 / 76.55 76.41 / 73.65 95.96 / 96.09 96.59 / 96.18

Noise = 20% Noise = 40% Softmax / DDGC
79.28 / 87.25 61.85 / 80.01 80.24 / 87.25 68.61 / 81.04 60.92 / 66.08 44.08 / 59.72 57.63 / 62.19 45.08 / 53.98 83.52 / 91.67 72.89 / 87.16 86.92 / 89.50 81.91 / 85.71

Noise = 60%
35.02 / 71.06 53.34 / 74.72 23.43 / 48.85 35.83 / 45.27 61.23 / 80.52 71.18 / 77.67

Table 2: Test accuracy (%) of different models trained on noisy datasets. We use the ensemble version of DDGC, and the best results are highlighted in bold if the gain is bigger than 1%.

Dataset CIFAR-10 CIFAR-100
SVHN

Training method Cross-entropy Bootstrap (hard) Bootstrap (soft) Forward Backward Cross-entropy Bootstrap (hard) Bootstrap (soft) Forward Backward Cross-entropy Bootstrap (hard) Bootstrap (soft) Forward Backward

Noise = 0%
94.49 / 94.35 94.65 / 94.63 94.48 / 94.33 94.32 / 94.25 94.39 / 94.47 75.76 / 76.00 75.67 / 75.62 75.50 / 75.49 76.59 / 76.50 76.64 / 76.43 96.36 / 96.23 96.20 / 96.18 96.35 / 96.26 96.45 / 96.40 96.43 / 96.35

Noise = 20% Noise = 40% Softmax / DDGC
79.49 / 86.05 64.12 / 79.02 82.28 / 87.76 75.79 / 83.35 81.67 / 86.72 69.36 / 79.27 85.23 / 87.31 78.62 / 81.34 76.18 / 81.62 62.35 / 74.75 60.24 / 63.93 47.52 / 53.54 61.84 / 65.16 50.95 / 55.77 61.84 / 64.10 46.88 / 53.15 63.22 / 65.96 51.87 / 56.96 56.43 / 61.28 38.91 / 50.34 83.13 / 88.32 64.30 / 75.25 86.52 / 90.37 62.60 / 83.30 80.91 / 88.43 57.21 / 77.38 88.35 / 91.32 77.87 / 87.74 85.87 / 87.13 70.81 / 76.73

Noise = 60%
60.05 / 71.38 75.34 / 77.00 59.99 / 71.52 72.30 / 74.65 57.02 / 63.58 34.23 / 40.59 38.60 / 44.17 34.70 / 40.45 42.59 / 46.37 22.68 / 35.16 36.06 / 64.35 61.56 / 75.43 36.37 / 54.81 76.44 / 84.17 60.14 / 77.38

Table 3: Test accuracy (%) of ResNet trained on various training methods. We use the ensemble version of DDGC, and the best results are highlighted in bold if the gain is bigger than 1%.

Verification of contributions from each technique. We first evaluate the performance of genera-

tive classifiers with various assumptions: identity covariance (Euclidean) and tied covariance (LDA).

In the case of identity covariance, we also apply a robust estimator called the least trimmed square

(LTS) estimator (Rousseeuw, 1984) which finds a K-subset with smallest error and computes the

sample mean from it, i.e., minµ

K i=1

(

xi -µ

2 2

).

As

shown

in

Figure

2(c),

the

generative

classifiers

with LDA assumption (blue and purple bars) generalize better than the generative classifiers with

identity covariance (orange and green bars) well from noisy labels. Table 1 validates the contribu-

tions of the proposed techniques by incrementally applying our techniques to see the improvement

from adding each component one by one. One can note that the generative classifier on features

extracted from the penultimate layer outperforms the softmax classifier without the MCD estimator

or ensemble method, while it still provides a comparable classification accuracy when the model

is trained on clean dataset (i.e., noise = 0%). On top of that, by utilizing the MCD estimator, the

classification accuracy is further improved compared to that employs only the naive sample estima-

tor. This implies that the proposed method can improve the performance without any information

of clean labels. In addition, the ensemble method significantly improves the classification accuracy.

Finally, Table 2 reports the classification accuracy for all networks and datasets, where the proposed

method significantly outperforms the softmax classifier for all tested cases.

Compatibility and comparison with the state-of-art training methods. We compare the performance of the standard softmax classifier and DDGC when they are combined with other various training methods for noisy environment in Table 3. Here, we use ResNet-44 for all experiments,2 For comparison, we consider the following training methods: Hard/soft bootstrapping (Reed et al., 2014), and forward/backward (Patrini et al., 2017), where more detailed explanations about training methods and network architectures are given in Appendix B. Table 3 shows the classification accuracy of softmax classifier and the ensemble version of DDGC. Note that DDGC always improves the classification accuracy compared to the softmax classifier, where the gains due to ours are more significant than those due to other special training methods.

2For all experiments, we follow the experimental setting in Ma et al. (2018b).

7

Under review as a conference paper at ICLR 2019

Dataset CIFAR-10 CIFAR-100
SVHN

Adversarial attacks FGSM
DeepFool CW
FGSM DeepFool
CW FGSM DeepFool
CW

Noise = 0%
57.04 / 58.09 0.34 / 7.50 0.01 / 3.29 31.72 / 32.40 0.45 / 1.40 0.05 / 4.73 74.18 / 75.38 1.17 / 1.82 0.02 / 3.78

Noise = 20% Noise = 40% Softmax / DDGC
23.05 / 55.16 23.56 / 56.55 0.06 / 55.94 0.02 / 64.96 0.47 / 52.21 0.43 / 59.01 18.16 / 32.85 13.83 / 34.51 0.18 / 10.47 0.15 / 20.82 0.30 / 31.42 0.25 / 41.59 22.27 / 75.26 22.98 / 73.30 0.04 / 71.14 0.01 / 73.33 0.03 / 68.55 0.04 / 69.18

Noise = 60%
19.52 / 54.06 0.00 / 63.88 0.06 / 61.90 9.34 / 36.41 0.07 / 30.55 0.03 / 43.31 24.71 / 66.83 0.01 / 66.30 0.01 / 62.20

Table 4: Test accuracy (%) of ResNet on adversarial attacks. We use the ensemble version of DDGC, and the best results are highlighted in bold if the gain is bigger than 1%.

Dataset CIFAR-10 CIFAR-100
SVHN

Training method
Cross-entropy Adversarial training
Cross-entropy Adversarial training
Cross-entropy Adversarial training

FGSM

DeepFool

CW

Softmax / DDGC

57.04 / 58.09 0.34 / 7.50 0.01 / 3.29

74.55 / 74.56 2.85 / 5.69 0.11 / 1.32

31.72 / 32.40 0.45 / 1.40 0.05 / 4.73

47.31 / 49.47 1.10 / 1.71 0.22 / 4.93

74.18 / 75.38 1.17 / 1.82 0.02 / 3.78

84.90 / 85.53 3.73 / 5.18 0.52 / 2.42

Table 5: Test accuracy (%) of ResNet trained on clean datasets under adversarial training. We use ensemble version of DDGC, and best results are highlighted in bold if the gain is bigger than 1%.

3.2 ROBUSTNESS AGAINST ADVERSARIAL ATTACKS
Setup. We also evaluate if the proposed method can improve the robustness on adversarial attacks (Szegedy et al., 2014). It is well-known that the adversarial (visually imperceptible) perturbation to clean inputs can induce the DNNs to make incorrect predictions at test time. This undesirable property of DNNs has raised major security concerns. To verify that DDGC can improve the robustness to adversarial attacks, we train DenseNet-100 and ResNet-34 for classifying CIFAR-10, CIFAR-100 and SVHN datasets, and generate the adversarial examples using FGSM (Goodfellow et al., 2015), DeepFool (Moosavi Dezfooli et al., 2016) and CW (Carlini & Wagner, 2017) attacks, where the detailed explanations can be found in Appendix B.
Robustness against adversarial attacks. Table 4 shows the classification accuracy of ResNet-34 on adversarial examples, and more results on DenseNet-100 can be found in Appendix F. One can note that DDGC significantly improves the robustness against adversarial attacks since the generative classifiers from low-level features are robust as shown in Figure 2(b). Based on our observations, the adversarial samples are generated in a way that mainly fools the upper layers of DNNs, and thus both clean and adversarial samples produce similar hidden features at lower layers. In Table 5, we also apply DDGC to the "robust" learning models optimized by adversarial training methods (Goodfellow et al., 2015): generating FGSM samples and optimize the cross-entropy loss by treating them as additional training examples. Even though adversarial training requires an extra computational cost, the improvements of robustness on multi-step attack methods such as CW and DeepFool are not significant compared to DDGC. We also consider adaptive attacks based on FGSM against DDGC, and the results show that it is robust against such adaptive attacks (see Appendix C), while proposing stronger adaptive attacks to evaluate its robustness is an interesting future direction.
4 CONCLUSION
We propose a new inference method, easily applicable to any softmax neural classifier pre-trained on datasets with noisy labels. Our main idea is defining the generative classifier on top of fixed features from the pre-trained model. Such "deep generative classifiers" have been largely dismissed for fullysupervised classification settings as they are often substantially outperformed by discriminative deep classifiers (e.g., softmax classifiers). In contrast to this common belief, we show that it is possible to formulate a simple generative classifier that is more robust without sacrificing the discriminative performance. We expect that our work would bring a refreshing angle for other related tasks, e.g., adaptive attacks, memorization (Zhang et al., 2017) and interpretability (Morcos et al., 2018).

8

Under review as a conference paper at ICLR 2019
REFERENCES
Dario Amodei, Sundaram Ananthanarayanan, Rishita Anubhai, Jingliang Bai, Eric Battenberg, Carl Case, Jared Casper, Bryan Catanzaro, Qiang Cheng, Guoliang Chen, et al. Deep speech 2: Endto-end speech recognition in english and mandarin. In ICML, 2016.
Devansh Arpit, Stanislaw Jastrzebski, Nicolas Ballas, David Krueger, Emmanuel Bengio, Maxinder S Kanwal, Tegan Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio, et al. A closer look at memorization in deep networks. In ICML, 2017.
Thorsten Bernholt. Robust estimators are hard to compute. Technical report, Technical Report/Universita¨t Dortmund, SFB 475 Komplexita¨tsreduktion in Multivariaten Datenstrukturen, 2006.
Nicholas Carlini and David Wagner. Adversarial examples are not easily detected: Bypassing ten detection methods. In ACM workshop on AISec, 2017.
Robert J Durrant and Ata Kaba´n. Compressed fisher linear discriminant analysis: Classification of randomly projected data. In ACM SIGKDD, 2010.
Ronald A Fisher. The use of multiple measurements in taxonomic problems. Annals of eugenics, 1936.
Ross Girshick. Fast r-cnn. In ICCV, 2015.
Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. In ICLR, 2015.
Chuan Guo, Mayank Rana, Moustapha Cisse´, and Laurens van der Maaten. Countering adversarial images using input transformations. In ICLR, 2018.
Frank R Hampel. A general qualitative definition of robustness. The Annals of Mathematical Statistics, 1971.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2016.
Dan Hendrycks, Mantas Mazeika, Duncan Wilson, and Kevin Gimpel. Using trusted data to train deep networks on labels corrupted by severe noise. In NIPS, 2018.
Gao Huang and Zhuang Liu. Densely connected convolutional networks. In CVPR, 2017.
Mia Hubert and Katrien Van Driessen. Fast and robust discriminant analysis. Computational Statistics & Data Analysis, 2004.
Jonathan Krause, Benjamin Sapp, Andrew Howard, Howard Zhou, Alexander Toshev, Tom Duerig, James Philbin, and Li Fei-Fei. The unreasonable effectiveness of noisy data for fine-grained recognition. In ECCV, 2016.
Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images. 2009.
Julia A Lasserre, Christopher M Bishop, and Thomas P Minka. Principled hybrids of generative and discriminative models. In CVPR, 2006.
Kimin Lee, Honglak Lee, Kibok Lee, and Jinwoo Shin. Training confidence-calibrated classifiers for detecting out-of-distribution samples. In ICLR, 2018a.
Kimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin. A simple unified framework for detecting out-of-distribution samples and adversarial attacks. In NIPS, 2018b.
Hendrik P Lopuhaa, Peter J Rousseeuw, et al. Breakdown points of affine equivariant estimators of multivariate location and covariance matrices. The Annals of Statistics, 1991.
Xingjun Ma, Bo Li, Yisen Wang, Sarah M Erfani, Sudanthi Wijewickrema, Michael E Houle, Grant Schoenebeck, Dawn Song, and James Bailey. Characterizing adversarial subspaces using local intrinsic dimensionality. In ICLR, 2018a.
9

Under review as a conference paper at ICLR 2019
Xingjun Ma, Yisen Wang, Michael E Houle, Shuo Zhou, Sarah M Erfani, Shu-Tao Xia, Sudanthi Wijewickrema, and James Bailey. Dimensionality-driven learning with noisy labels. In ICML, 2018b.
Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine learning research, 2008.
Dhruv Mahajan, Ross Girshick, Vignesh Ramanathan, Kaiming He, Manohar Paluri, Yixuan Li, Ashwin Bharambe, and Laurens van der Maaten. Exploring the limits of weakly supervised pretraining. arXiv preprint arXiv:1805.00932, 2018.
Seyed Mohsen Moosavi Dezfooli, Alhussein Fawzi, and Pascal Frossard. Deepfool: a simple and accurate method to fool deep neural networks. In CVPR, 2016.
Ari S Morcos, Maithra Raghu, and Samy Bengio. Insights on representational similarity in neural networks with canonical correlation. In NIPS, 2018.
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Reading digits in natural images with unsupervised feature learning. In NIPS workshop, 2011.
Andrew Y Ng and Michael I Jordan. On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes. In NIPS, 2002.
Tianyu Pang, Chao Du, and Jun Zhu. Max-mahalanobis linear discriminant analysis networks. In ICML, 2018.
Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu. Making deep neural networks robust to label noise: A loss correction approach. In CVPR, 2017.
Scott Reed, Honglak Lee, Dragomir Anguelov, Christian Szegedy, Dumitru Erhan, and Andrew Rabinovich. Training deep neural networks on noisy labels with bootstrapping. arXiv preprint arXiv:1412.6596, 2014.
Peter J Rousseeuw. Least median of squares regression. Journal of the American statistical association, 1984.
Peter J Rousseeuw and Katrien Van Driessen. A fast algorithm for the minimum covariance determinant estimator. Technometrics, 1999.
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. Intriguing properties of neural networks. In ICLR, 2014.
Arash Vahdat. Toward robustness against label noise in training deep discriminative neural networks. In NIPS, 2017.
Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding deep learning requires rethinking generalization. In ICLR, 2017.
10

Under review as a conference paper at ICLR 2019

A PRELIMINARIES

Gaussian discriminant analysis. In this section, we describe the basic concepts of the discrimi-

native and generative classifier (Ng & Jordan, 2002). Formally, denote the random variable of the

input and label as x and y = {1, · · · , C}, respectively. For the classification task, the discriminative

classifier directly defines a posterior distribution P (y|x), i.e., learning a direct mapping between

input x and label y. A popular model for discriminative classifier is softmax classifier which de-

fines the posterior distribution as follows: P (y = c|x) =

exp(wc x+bc) c exp(wc x+bc

),

where

wc

and

bc

are

weights and bias for a class c, respectively. In contrast to the discriminative classifier, the generative

classifier defines the class conditional distribution P (x|y) and class prior P (y) in order to indi-

rectly define the posterior distribution by specifying the joint distribution P (x, y) = P (y) P (x|y).

Gaussian discriminant analysis (GDA) is a popular method to define the generative classifier by

assuming that the class conditional distribution follows the multivariate Gaussian distribution and

the class prior follows Bernoulli distribution: P (x|y = c) = N (x|µc, c) , P (y = c) =

,c
c c

where µc and c are the mean and covariance of multivariate Gaussian distribution, and c is the

unnormalized prior for class c. This classifier has been studied in various machine learning areas

(e.g., semi-supervised learning (Lasserre et al., 2006) and incremental learning (Lee et al., 2018b)).

In this paper, we focus on the special case of GDA, also known as the linear discriminant analysis (LDA). In addition to Gaussian assumption, LDA further assumes that all classes share the same covariance matrix, i.e., c = . Since the quadratic term is canceled out with this assumption, the posterior distribution of generative classifier can be represented as follows:

P (y = c|x) =

P (y = c) P (x|y = c) c P (y = c ) P (x|y = c ) =

exp

µc

-1x

-

1 2

µc

-1µc

+

log c

c

exp

µc

-1x

-

1 2

µc

-1µc

+ log c

.

One can note that the above form of posterior distribution is equivalent to the softmax classifier by

considering µc

-1

and

-

1 2

µc

-1µc

+ log c

as

its

weight and bias,

respectively.

This

implies

that x might be fitted in Gaussian distribution during training a softmax classifier.

Breakdown points. The robustness of MCD estimator can be explained by the fact that it has high
breakdown points (Hampel, 1971). Specifically, the breakdown point of an estimator measures the
smallest fraction of observations that need to be replaced by arbitrary values to carry the estimate beyond all bounds. Formally, denote YM as a set obtained by replacing M data points of set Y by some arbitrary values. Then, for a multivariate mean estimator µ = µ(Y) from Y, the breakdown
point is defined as follows (see Appendix A for more detailed explanations including the breakdown
point of covariance estimator):

(µ, Y)

=

1 |Y |

min

M  {1, · · · , |Y|} : sup µ(Y) - µ(YM )
YM

=

.

For a multivariate estimator of covariance , we have

(, Y)

=

1 |Y |

min{M



{1, · · ·

, |Y|}

:

sup max{| log i((Y)) -
Mi

log i((YM ))|}},

where the k-th largest eigenvalue of a general n × n matrix is denoted by k(), k = 1, · · · , n such that 1()  2()  · · ·  n(). This implies that we consider a covariance estimator to
be broken whenever any of the eigenvalues can become arbitrary large or arbitrary close to 0.

B EXPERIMENTAL SETUP
In this section, we describe detailed explanation about all the experiments described in Section 3.
Detailed model architecture and datasets. We consider two state-of-the-art neural network architectures: DenseNet (Huang & Liu, 2017) and ResNet (He et al., 2016). For DenseNet, our model follows the same setup as in Huang & Liu (2017): 100 layers, growth rate k = 12 and dropout rate 0. Also, we use ResNet with 34 and 44 layers, filters = 64 and dropout rate 0.3 The softmax classifier
3ResNet architecture is available at https://github.com/kuangliu/pytorch-cifar.

11

Under review as a conference paper at ICLR 2019
is used, and each model is trained by minimizing the cross-entropy loss. We train DenseNet and ResNet for classifying CIFAR-10 (or 100) and SVHN datasets: the former consists of 50,000 training and 10,000 test images with 10 (or 100) image classes, and the latter consists of 73,257 training and 26,032 test images with 10 digits.4 By following the experimental setup of Ma et al. (2018b), All networks were trained using SGD with momentum 0.9, weight decay 10-4 and an initial learning rate of 0.1. The learning rate is divided by 10 after epochs 40 and 80 for CIFAR-10/SVHN (120 epochs in total), and after epochs 80, 120 and 160 for CIFAR-100 (200 epochs in total). For our method, we extract the hidden features at {34, 46, 56, 67, 79, 89, 99}-th layers and {3, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33}-th layers for DenseNet and ResNet, respectively.
Training method for noisy label learning. We consider the following training methods for noisy label learning:
(a) Hard bootstrapping (Reed et al., 2014): Training with new labels generated by a convex combination (the hard version) of the noisy labels and their predicted labels.
(b) Soft bootstrapping (Reed et al., 2014): Training with new labels generated by a convex combination (the soft version) of the noisy labels and their predictions.
(c) Backward (Patrini et al., 2017): Training via loss correction by multiplying the crossentropy loss by a noise-aware correction matrix.
(d) Forward (Patrini et al., 2017): Training with label correction by multiplying the network prediction by a noise-aware correction matrix.
(e) Cross-entropy: the conventional approach of training with cross-entropy loss.
Adversarial attacks. In this paper, we consider the following attack methods: fast gradient sign method (FGSM) (Goodfellow et al., 2015), DeepFool (Moosavi Dezfooli et al., 2016) and CarliniWagner (CW) (Carlini & Wagner, 2017). The FGSM directly perturbs normal input in the direction of the loss gradient. Formally, non-targeted adversarial examples are constructed as
xadv = x + F GSM sign ( x (y, P (y|x))) , where F GSM is a magnitude of noise, y is the prediction of classifier and is a loss function to measure the distance between the prediction and the ground truth. DeepFool works by finding the closest adversarial examples with geometric formulas. CW is an optimization-based method which arguably the most effective method. Formally, non-targeted adversarial examples are constructed as
arg min d(x, xadv) - (y, P (y|xadv)),
xadv
where  is penalty parameter and d(·, ·) is a metric to quantify the distance between an original image and its adversarial counterpart. However, compared to FGSM and BIM, this method is much slower in practice. For all experiments, L2 distance is used as a constraint. We used the library from (Guo et al., 2018) for generating adversarial samples.5 Table 6 and 7 report the statistics of adversarial attacks including the L mean perturbation and classification accuracy on adversarial attacks.
C ADAPTIVE ATTACKS AGAINST GENERATIVE CLASSIFIER
In this section, we evaluate the robustness of our method by generating adversarial samples which may fool the generative classifiers in a white-box setting, i.e., one can access to the parameters of the generative classifiers. Here, we remark that accessing the parameters of the generative classifiers, i.e., sample means and covariance, is not mild assumption since the information about training data is required to compute them. To attack our method, we generate an adversarial examples using FGSM method as follows:
xadv = x + F GSM sign ( x (y, P (y|x))) , where F GSM is a magnitude of noise, y and is a loss function, i.e., cross-entropy loss, to measure the distance between the prediction and the ground truth. We test two different scenarios using
4We do not use the extra SVHN dataset for training. 5The code is available at https://github.com/facebookresearch/adversarial_image_ defenses.
12

Under review as a conference paper at ICLR 2019

Dataset CIFAR-10 CIFAR-100
SVHN

Data type
Clean FGSM DeepFool
CW
Clean FGSM DeepFool
CW
Clean FGSM DeepFool
CW

Noise = 0% L Acc.
0 95.01% 0.05 57.04% 0.82 0.34% 0.09 0.01%
0 77.51% 0.05 31.72% 2.09 0.45% 0.06 0.05%
0 96.10% 0.05 74.18% 2.32 1.17% 0.16 0.02%

Noise = 20% L Acc.
0 79.28% 0.05 23.05% 0.20 0.06% 0.03 0.47%
0 60.92% 0.05 18.16% 1.00 0.18% 0.03 0.30%
0 83.52% 0.05 22.27% 0.26 0.04% 0.05 0.03%

Noise = 40% L Acc.
0 61.85% 0.05 23.56% 0.08 0.02% 0.02 0.43%
0 44.08% 0.05 13.83% 0.60 0.15% 0.02 0.25%
0 72.89% 0.05 22.98% 0.17 0.01% 0.04 0.04%

Noise = 60% L Acc.
0 35.02% 0.05 19.52% 0.05 0.00% 0.01 0.06%
0 23.43% 0.05 9.34% 0.31 0.07% 0.01 0.03%
0 61.23% 0.05 24.71% 0.16 0.01% 0.03 0.01%

Table 6: The L mean perturbation and classification accuracy of ResNet-34 on clean and adversarial samples.

Dataset CIFAR-10 CIFAR-100
SVHN

Data type
Clean FGSM DeepFool
CW
Clean FGSM DeepFool
CW
Clean FGSM DeepFool
CW

Noise = 0% L Acc.
0 94.42% 0.05 32.63% 0.34 0.09% 0.06 0.08%
0 76.41% 0.05 18.88% 1.14 0.27% 0.03 0.22%
0 96.59% 0.05 70.05% 1.04 0.21% 0.13 0.05%

Noise = 20% L Acc.
0 80.24% 0.05 22.75% 0.09 0.01% 0.04 0.42%
0 57.63% 0.05 12.20% 0.46 0.09% 0.02 0.21%
0 86.91% 0.05 51.69% 0.35 0.09% 0.07 0.10%

Noise = 40% L Acc.
0 68.61% 0.05 22.33% 0.06 0.01% 0.02 0.34%
0 45.08% 0.05 10.09% 0.31 0.02% 0.01 0.10%
0 81.90% 0.05 43.37% 0.25 0.08% 0.06 0.10%

Noise = 60% L Acc.
0 53.33% 0.05 19.57% 0.05 0.02% 0.02 0.09%
0 35.83% 0.05 8.51% 0.25 0.05% 0.01 0.16%
0 71.18% 0.05 31.08% 0.17 0.05% 0.05 0.02%

Table 7: The L mean perturbation and classification accuracy of DenseNet-100 on clean and adversarial samples.

ResNet with 34 layers trained on CIFAR-10 dataset. In the first scenario, we generate the adversarial

images by targeting the posterior distribution of generative classifier from a penultimate layer of

DNNs: P (y = c|f (x)) =

( )exp

µc,L

L-1

f

(x)-

1 2

µc,L

-L 1

µc,L

+log

c

exp

µ
c

,L

-L 1

f

(x)-

1 2

µ
c

,L L-1 µc

,L+log c

c

attack the ensemble of posterior distributions:

. In the second scenario, we

P (y = c|f (x)) =

exp µ ,c-1f (x) - 0.5µ ,c-1µ ,c + log c .
c exp µ ,c -1f (x) - 0.5µ ,c -1µ ,c + log c

Table 8 shows the the classification accuracy on FGSM samples generated by targeting various posterior distributions. We remark that adaptive attacks on generative classifiers are not successfully generating the adversarial samples, i.e., the proposed generative classifier is more robust to adaptive attacks. We found that this is because the posterior distributions from generative classifier are very confident, i.e., predicting the true answer with 100% confidence. Therefore, FGSM-based adaptive attacks are failed since the gradients of cross-entropy loss with respect to input consist of zero ele-

13

Under review as a conference paper at ICLR 2019

Dataset CIFAR-10

Perturbation  = 0 (clean)
 = 0.01  = 0.1

Softmax 95.00% 56.90% 17.77%

DDGC 94.99% 94.19% 93.57%

DDGC + ensemble 94.99% 92.59% 91.47%

Table 8: The classification accuracy on FGSM samples attacking various posterior distributions.

100 100 100 100

Clean data

Clean data

FGSM

FGSM

80

80

DeepFool CW

80

DeepFool 80 CW

60 60 60 60

Test set accuracy (%) Test set accuracy (%) Test set accuracy (%) Test set accuracy (%)

40 40 40 40

20

Noise fraction = 0% Noise fraction = 40%

Noise fraction = 20%

Noise fraction = 60%

0 2 4 6 8 10 12

Index of basic block

14

20

0 2

4 6 8 10 12 14 Index of basic block

20 0 0

Noise fraction = 0% Noise fraction = 40% Noise fraction = 20% Noise fraction = 60%

10 20 30 40 Index of basic block

50

20 0 0

10 20 30 40 Index of basic block

50

(a) Generalization from (b) Robustness to adver- (c) Generalization from (d) Robustness to adver-

noisy labels

sarial attacks

noisy labels

sarial attacks

Figure 3: Layer-wise characteristics of generative classifiers from (a)/(b) ResNet-34 and (c)/(d) DenseNet-100 trained on the CIFAR-10 dataset.

ments. Designing more advanced adaptive attacks such optimization-based method is an interesting future direction to explore.

D LAYER-WISE CHARACTERISTICS OF GENERATIVE CLASSIFIERS
Figure 3 shows the classification accuracy of the generative classifiers from different basic blocks of ResNet-34 (He et al., 2016) and DenseNet-101 (Huang & Liu, 2017). One can note that the generative classifiers from DenseNet and ResNet have different patterns due to the architecture design. In the case of DenseNet, we found that it produces meaning features after 20-th basic blocks. However, we remark that the performances of the generative classifiers from low-level features (from 20 to 40-th layers) of DenseNet are still more robust to adversarial attacks and noisy labels. Because of that, the ensemble of generative classifiers on DenseNet also improves the generalization from noisy labels and robustness to adversarial attacks.

E FINE-TUNING SOFTMAX LAYER USING VALIDATION SET
In this paper, we utilize a validation set, which consists of 500 images (i.e., only  1% of the number of training samples) with clean labels. For fair comparisons, one might also suggest fine-tuning the softmax classifier (with fixed features) using the validation improve the classification accuracy. We indeed measure the classification accuracy of softmax classifier after fine-tuning in Table 9. One can note that the proposed method still outperforms softmax classifiers. Since 1% data is not enough compared to the number of softmax classifiers, fine-tuning can decrease the performance in the case of softmax classifier, while DDGC is still working well (it only trains the ensemble weights).

F MORE EXPERIMENTAL RESULTS ON ADVERSARIAL ATTACKS
In this section, we provide more experimental results on adversarial attacks using DenseNet. First, Table 10 shows the classification accuracy on adversarial attacks when we train DenseNet on noisy datsets. One can note that the proposed method outperforms softmax classifier for all tested cases. We also apply our method to the models optimized by adversarial training method. As shown in Table 11, the proposed method further improves the robustness.
14

Under review as a conference paper at ICLR 2019

Model ResNet DenseNet

Inference Method
Softmax Softmax + fine-tuning (val) Generative + MCD Generative + MCD + ensemble (val) Softmax Softmax + fine-tuning (val) Generative + MCD Generative + MCD + ensemble (val)

CIFAR-10 20% 40% 60% 79.28 61.85 35.02
80.48 69.42 54.16 83.04 68.04 42.74
87.25 80.01 71.06
80.24 68.61 53.34
82.47 74.38 63.25 85.96 78.34 66.16
87.25 81.04 74.72

Noisy Dataset CIFAR-100 20% 40% 60% 60.92 44.08 23.43
51.15 35.17 20.41
63.20 51.71 33.96
66.08 59.72 48.85
57.63 45.08 35.83
48.69 35.97 27.73
58.22 48.54 37.44
62.19 53.98 45.27

20% 83.52 85.10 89.60 91.67 86.92 86.83 88.64 89.50

SVHN 40% 60% 72.89 61.23
81.93 75.06 78.88 66.96
87.16 80.52
81.91 71.18
76.39 68.13 84.08 74.47
85.71 77.67

Table 9: Comparison with softmax classifier fine-tuned with validation data. All values are percentages and the best results are highlighted in bold if gain is bigger than 1%.

Dataset CIFAR-10 CIFAR-100
SVHN

Adversarial attacks FGSM
DeepFool CW
FGSM DeepFool
CW FGSM DeepFool
CW

Noise = 0%
32.63 / 40.01 0.09 / 20.36 0.08 / 8.47 18.88 / 23.87 0.27 / 2.79 0.22 / 13.66 70.05 / 75.74 0.21 / 19.93 0.05 / 24.54

Noise = 20% Noise = 40% Softmax / DDGC
22.75 / 53.06 22.33 / 54.54 0.01 / 65.34 0.01 / 64.25 0.42 / 49.27 0.34 / 54.65 12.20 / 28.42 10.09 / 26.46 0.09 / 18.01 0.02 / 22.74 0.21 / 34.63 0.11 / 34.75 51.69 / 71.11 43.37 / 64.40 0.09 / 56.99 0.08 / 55.03 0.10 / 51.20 0.11 / 46.29

Noise = 60%
19.57 / 52.94 0.02 / 62.28 0.09 / 55.85 8.51 / 18.26 0.05 / 20.25 0.16 / 29.83 31.08 / 50.61 0.05 / 40.59 0.02 / 30.45

Table 10: Test accuracy (%) of DenseNet on adversarial attacks. We use the ensemble version of DDGC, and the best results are highlighted in bold if gain is bigger than 1%.

Dataset CIFAR-10 CIFAR-100
SVHN

Training method
Cross-entropy Adversarial training
Cross-entropy Adversarial training
Cross-entropy Adversarial training

FGSM

DeepFool

CW

Softmax / DDGC

32.63 / 40.01 0.09 / 20.36 0.08 / 8.47

66.12 / 68.18 0.55 / 11.96 0.07 / 5.81

18.88 / 23.87 0.27 / 2.79 0.22 / 13.66

36.67 / 43.26 0.75 / 2.27 0.07 / 12.77

70.05 / 75.74 0.21 / 19.93 0.05 / 24.54

85.23 / 85.95 1.49 / 4.46 0.62 / 9.11

Table 11: Test accuracy (%) on adversarial examples. We use DenseNet trained on CIFAR and SVHN with clean labels, and ensemble version of DDGC. The best results are highlighted in bold if gain is bigger than 1%.

15

Under review as a conference paper at ICLR 2019

G PROOF OF THEOREM 1

In this section, we present a proof of Theorem 1. We start with the following lemma, which shows the properties of convergences of the sample and MCD estimators as the total number of training samples N goes to infinity.

Lemma 1. Suppose we have N number of d-dimensional random samples {x1, · · · , xN }, where out < 1 is the fraction of outliers from an arbitrary distribution, which has a density function in L1 space (i.e. its absolute value is measurable), with zero mean and finite covariance matrix o2utI and the others from N µ, 2I . Let µ¯ and ¯ be the mean and covariance matrix of sample

estimator, and let µ and  be the mean and covariance matrix of MCD estimator which selects the

fraction

d N

< mcd

< 1 of samples from {x1, · · ·

, xN } to optimize its objective (2).

Then the sample

estimator converges to below almost surely as N  ,

µ¯ a.s. (1 - out) µ, ¯ a.s. (1 - out) 2 + outo2ut I + out (1 - out) µµT .

Also, if mcd  1 - out and 2  o2ut, the MCD estimator converges to below almost surely as N  .

µ a.s. µ,

 a.s. 2I.

Proof. To obatin µ¯ and ¯ , consider a random variable z that is from a mixture distribution of two distributions, N µ, 2I and outlier distribution, where its pdf p(z) is consisted of
(1 - out) N (µ, 2I) + out(0, o2utI). Then, one can write

E[z] = (1 - out) µ

and

Var[z]

=

(1

-

out) 2I

+

outo2utI

+

(N

- M )M N2

µµT .

Since x + y  x + y , p(z) is also L1 measurable. By the Strong Law of Large Numbers6, µ¯ a.s. E[z] as N  , and one can easily induce that ¯ a.s. Var[z] as N  .

Similarly, we can obtain µ and  as below. Consider a event Ep be a set of the MCD estimators contain outliers with the fraction p. Then, we have a random variable Zp again, which is from a mixture distribution of two distributions, where its pdf p(Zp) is consisted of (1 - p)N (µ, 2I) + p(0, o2utI). Then,
E[Zp] = (1 - p)µ and Var[Zp] = (1 - p)2I + po2utI + p(1 - p)µµT .

Therefore, for the all MCD estimator µ,   Ep, we have µ a.s. E[Zp] and  a.s. Var[Zp]

as N  .

By definition (2), the objective of the MCD estimator corresponds to their determinant of the covari-
ance matrix. Note that the determinant is continuous funciton. Then, by the Continuous Mapping Theorem7,

det  a.s. lim det  = det (Var[Zp]) ,
N 

as N  ,

and,

det (Var[Zp]) = det (1 - p)2I + po2utI + p(1 - p)µµT = (1 - p)2 + po2ut d-1 (1 - p)2 + po2ut + p(1 - p)µT µ .
For simplicity, consider a polynomial function of p as follows:

f (p) = (1 - p)2 + po2ut + p(1 - p)µT µ (1 - p)2 + po2ut d-1 .

6https://en.wikipedia.org/wiki/Law_of_large_numbers#Strong_law 7https://en.wikipedia.org/wiki/Continuous_mapping_theorem

16

Under review as a conference paper at ICLR 2019

Since 2  o2ut, we have f (p)  (1 - p)2 + p2 + p(1 - p)µT µ (1 - p)2 + p2 d-1  (1 - p)2 + p2 (1 - p)2 + p2 d-1 = f (0).

Note that

min det() a.s. min det (Var[Zp]) , .

XK XN

Ep

Then, for mcd  1 - out, the MCD estimators in E0 converges to a minimum determinant of the covariance matrix of Zp among Ep. Therefore, as N goes to infinity,

min det() a.s. min det (Var[Zp]) = det (Var[Z0]) ,

XK XN

Ep

and,

µ a.s. E[Z0] = µ and  a.s. Var[Z0] = 2I.

Now, we start to prove Theorem 1 with Lemma 1.

First, to show (4), we use Lemma 1 and the assumptions A3 and A5. haveµ¯c a.s. (1 - out) µc and µc a.s. µc. One can easily induce that

lim µc - µc 1 = 0,
N 

lim
N 

µc - µ¯c

1 = out

µc

1.

Then, we

Second, to show (5), consider C number of Gaussian distributions N

µc, 2I

with

1 C

c µc = 0,

by the assumptions A1 and A2. To obtain tied covariance matrix ¯ and , we gather ¯ c and c

for each class c as follow,

¯ =

c Nc¯ c = c Nc

Then by Lemma 1, one can write

c ¯ c ,  = C

c Kcc = c Kc

c c . C

lim ¯ =
N 

(1 - out) 2 + outo2ut

I

+

out

(1

-

out)

1 C

lim  = 2I.
N 

µcµTc ,
c

By

the

assumption

A2,

1 C

c µcµcT = D where D is a diagonal matrix. Then limN ¯ is a

diagonal matrix, and

lim ¯ -1 =
N 

(1 - out) 2 + outo2ut I + out (1 - out) D -1 .

Note that

Nlim(µ¯i - µ¯c)T (µ¯i - µ¯c) = (1 - out)2 (µi - µc)(µi - µc)T , Nlim(µi - µc)T (µi - µc) = (µi - µc)(µi - µc)T ,

and,

Nlim(µ¯c

-

µ¯c

)T

¯ -1(µ¯c

-

µ¯c

)

=

lim
N 

tr

¯ -1(µ¯c - µ¯c )(µ¯c - µ¯c )T

=

i

(1

-

(1 - out)2 (µci - µc out) 2 + outo2ut + out

i)2 (1 -

out)

Di

,

17

Under review as a conference paper at ICLR 2019

where D = diag (D1, ..., Dd). By the assumption A4, for  i,

(1 - out) 2 + outo2ut + out (1 - out) Di  2.

Then we have

lim (µ¯c - µ¯c )T ¯ -1(µ¯c - µ¯c ) = lim tr ¯ -1(µ¯c - µ¯c )(µ¯c - µ¯c )T

N 

N 

=

i

(1 - out)2 (µci - µc i)2 (1 - out) 2 + outo2ut + out (1 - out) Di



lim
N 

(µ¯i

-

µ¯c)T (µ¯i 2

-

µ¯c)

,

Nlim(µi

-

µc)T

-1(µi

-

µc)

=

lim
N 

tr

-1(µi - µc)(µi - µc)T

=

(µi

-

µc)T (µi 2

-

µc) .

Therefore,

lim (µ¯c - µ¯c )T ¯ -1(µ¯c - µ¯c ) N (µc - µc )T -1(µc - µc )

 lim
N 

(µ¯i-µ¯c)T (µ¯i-µ¯c) 2
(µi-µc)T (µi-µc) 2

= (1 - out)2  1.

Third, to show (3), we define estimated error B(µc, µc , , ) as follow,

B(µc, µc , , ) := exp

- 1 [(µc - µc )T -1(µc - µc )]2 8 (µc - µc)T -1-1(µc - µc)

.

Note that

2
[(µc - µc )T -1(µc - µc )]2 = tr -1(µc - µc )(µc - µc )T (µc - µc)T -1-1(µc - µc) tr -1-1(µc - µc )(µc - µc )T

.

Then,

lim
N 

-8

log(B(µ¯c,

µ¯c

, ,

¯ ))

=

lim
N 

tr

tr ¯ -1(µ¯c - µ¯c )(µ¯c - µ¯c )T 2 ¯ -12I¯ -1(µ¯c - µ¯c )(µ¯c - µ¯c )T

=

(1

- out)2 2

(µci-µc i)2

2

i (1-out)2+outo2ut+out(1-out)Di (µci-µc i)2

,

i ((1-out)2+outo2ut+out(1-out)Di)2

lim -8 log(B(µc, µc
N 

, , ))

=

tr

tr (2I)-1(µc - µc )(µc - µc )T ((2I)-12I(2I)-1(µc - µc )(µc -

2
µc

)T )

=

(µc

-

µc

)T (µc 2

-

µc

) .

By the Cauchy-Schwarz inequality8,

(µci - µc i)2
ii

µci - µc i

2

(1 - out) 2 + outo2ut + out (1 - out) Di



(µci - µc i)2 i (1 - out) 2 + outo2ut + out (1 - out) Di

2
.

Then we get

lim -8 log(B(µc, µc , , ))  lim -8 log(B(µ¯c, µ¯c , , ¯ )),

N 

N 

8https://en.wikipedia.org/wiki/Cauchy-schwarz_inequality

18

Under review as a conference paper at ICLR 2019

and

lim -8 log
N 

B(µc, µc B(µ¯c, µ¯c

, , ) , , ¯ )



(µc

- µc

)T (µc 2

-

µc

)

1 - (1 - out)2

.

It implies limN B(µc, µc , , )  limN B(µ¯c, µ¯c , , ¯ ), and

lim
N 

B(µc, µc B(µ¯c, µ¯c

, , ) , , ¯ )



exp

-

1 8

(µc

-

µc

)T (µc 2

-

µc

)

1 - (1 - out)2

 1.

On the other hand, we have

µ¯c a.s. lim µ¯c,
N 

¯c

a.s.

lim
N 

¯c,

µc a.s. lim µc
N 

c

a.s.

lim
N 

c.

by Lemma 1. Then by the Continuous Mapping Theorem9,

¯ a.s. lim ¯ ,
N 

 a.s. lim ,
N 

and,

µc - µc 1 a.s. lim µc - µc 1,
N 

µc - µ¯c 1 a.s. lim µc - µ¯c 1,
N 

(µ¯c - µ¯c )T ¯ -1(µ¯c - µ¯c ) a.s.

lim

(µ¯c

-

µ¯c

)T

¯ -1(µ¯c

-

µ¯c

) ,

(µc - µc )T -1(µc - µc ) N (µc - µc )T -1(µc - µc )

B(µc, µc B(µ¯c, µ¯c

, , ) , , ¯ )

a.s.

lim
N 

B(µc, µc B(µ¯c, µ¯c

, , ) , , ¯ ) .

This completes the proof of Theorem 1.

9https://en.wikipedia.org/wiki/Continuous_mapping_theorem 19

