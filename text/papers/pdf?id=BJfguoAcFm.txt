Under review as a conference paper at ICLR 2019
LEARNING KOLMOGOROV MODELS FOR BINARY RANDOM VARIABLES
Anonymous authors Paper under double-blind review
ABSTRACT
We propose a framework for learning a Kolmogorov model, for a collection of binary random variables. More specifically, we derive conditions that link (in the sense of implications in mathematical logic) outcomes of specific random variables and extract valuable relations from the data. We also propose an efficient algorithm for computing the model and show its first-order optimality, despite the combinatorial nature of the learning problem. We exemplify our general framework to recommendation systems and gene expression data. We believe that the work is a significant step toward interpretable machine learning.
1 INTRODUCTION
Machine learning and artificial intelligence method have permeated a large number of areas (Marr, Sept 2016). These methods are based on machine learning models, which consist of learning an input-output mapping for a given dataset. Despite the plethora of such models (e.g., matrix factorization (Koren et al., 2009), SVD-based models (Koren, 2008), deep neural networks (LeCun et al., 2015), and models inspired from physics (Stark, 2016b)), they lack interpretability: they are not capable of offering insight about the data, nor the underlying process. The lack of interpretablity may have serious consequences in mission-critical systems, ethics, and validation of computeraided diagnosis (Doshi-Velez & Kim, 2017). While there is no consensus around the definition of interpretability, causality (Lipton, 2016) is a vital component: it refers to causal relations within the data and insight about the underlying data-generating process. We thus adopt a generalized version of causality using implication in mathematical logic as our `definition' of interpretable models.
To this end, we propose learning a so-called Kolmogorov Model (KM) associated with a set of binary Random Variables (RVs). In addition to prediction, the interpretability of the model (as defined above) enables learning causal relations.1 We derive a sufficient condition under which the realization of one RV's outcome (causally) implies the outcome of the other. In the context of recommendation systems, causal relations identify groups of items, for which a user liking one item implies that he/she likes all other items in the group. In gene expression analysis, the same relations identify groups of DNA locations for which the expression of a gene in one of them implies its expression in all other locations. The foundation of our approach is to model binary RVs as elementary events on a Kolmogorov space, by an inner product of two vectors (formally stated in Section 2.1), which is based on established results from classical probability theory. To our best knowledge, this specific formulation is novel in the context of learning representation.
The inner product of our formulation is reminiscent of factorization methods such as, matrix factorization (Koren, 2008), non-negative matrix factorization (Lee & Seung, 2001), SVD (Cai et al., 2010), and physics-inspired techniques, non-negative models (Stark, 2016a). It should be noted that the inner product components of these methods is usually based on strong intuition about the data, provided and validated by a human expert. In contrast, the proposed KM is a fully automated approach, deeply rooted in probability theory, which finds an interpretable model (as defined above) of the data without any human intervention. Thus, both the model and the causal relations within the data have a strong mathematical basis. Moreover, in most of the existing approaches, we may need to have one pipeline for learning the representation and another one for mining these relations. However, our approach requires only a single pipeline for both tasks. This is very appealing on a
1Hereafter, for the sake of simplicity, causal relations mean logical relations within the data.
1

Under review as a conference paper at ICLR 2019

conceptual level, and it can drastically simplify coding and validation. Our method also generalizes K-means and some of its variants. Detailed discussions of the relation between our proposed method and these prior works is in Appendix A.3.
In an abstract sense, we formulate a KM learning problem as a coupled combinatorial program, decompose it into two subproblems using the Block-Coordinate Descent (BCD) method, and obtain provably optimal solutions for both. For the first one, we exploit the structure of linear programs on the unit simplex and use low-complexity (yet optimal) Frank-Wolfe algorithm (Frank & Wolfe, 1956). To bypass the inherent complexity of the second subproblem (combinatorial and NP-hard), we propose a semidefinite relaxation, and show its quasi-optimality in recovering the optimal solution of the combinatorial subproblem. Finally, we show the convergence of our algorithm to a stationary point of the original problem. We propose a simple algorithm for mining the causal relations. All the proofs and additional discussions are available in Authors (Oct 2017).

2 SYSTEM MODEL

Notation: Lowercase letter a, uppercase bold letter A, and calligraphic letter A denote vectors, matrices, and sets, respectively. [A]i,j and AT denote element (i, j) and the transpose of A. supp(a) denotes the support set of a. The inequality x  y holds element-wise. I denotes the identity matrix,
1 and 0 the all-one and all-zero vectors (of appropriate dimension). en is the nth elementary basis, P = {p  RD+ | 1T p = 1} the unit simplex, and {n} := {1, · · · , n}.

2.1 PROBLEM FORMULATION

Consider a double-indexed set of binary Random Variables (RVs), Xu,i  A = {1, 2}, taken from a dataset D = {(u, i) | (u, i)  U × I}. Each RV is defined on a sample space , consisting of

elementary events  = {d | 1  d  D}. We denote by P[Xu,i = z], z  A, the probability that RV Xu,i takes the value z  A. Since Xu,i is binary, it is fully characterized by considering one
outcome. Thus, we write the Kolmogorov Model (KM) for Xu,i as

KM: P[Xu,i = 1] = uT i .

(1)

Thus, each RV Xu,i is associated with (characterized by) a Probability Mass Function (PMF) u, u  U, and an indicator vector i, i  I. The model follows from established results in classical
probability theory (Gray, 2009) (formalized in Appendix A.2). Notice that the model in (1) can

approximate with arbitrarily small accuracy the measure corresponding to P[·] for a large enough D.

Problem 1 (Problem Statement) Let pu,i denote the empirical value of P[Xu,i = 1]. We assume that {pu,i} are known for elements of a training set K  D, where K = {(u, i) | (u, i)  U × I}.2 Given samples coming from the model in (1), we wish to infer the parameters of underlying probability distribution: find parameters of the KM, i.e., {i, u} that best describe {pu,i | (u, i)  K}. The resulting problem is a fully parametric statistical inference task. For tractability, we address it using

the minimum mean-squared error as a point estimator. The corresponding optimization problem is

(Q) :

  argmin

uT i - pu,i 2 E

{i , u}  {i},{u} (u,i)K

 s. t. u  P , i  BD, (u, i)  K

.

(2)

We present our solution to this coupled non-convex conspiratorial optimization in the next section. The obtained solution to (Q) can be used for prediction on a test set, as well as extracting causality

structures within training set (see Section 4).

Proposed Approach: While the proposal to model binary RVs as elementary events on a Kolmogorov space is based on established results, the specific learning formulation (Problem 1) is novel. Because this model is rooted in probability theory, (1) defines the outcome of a RV in the strict Kolmogorov sense, and the resulting causal relations (Section 4) also hold from a strict analytical perspective. While causal relations (or association rules) may still be extracted using existing methods, they lead to different relations (as they are based on different heuristics). Additionally, unlike existing methods, the prediction and causal relations mining are done in 'one-shot', thereby simplifying the implementation/validation; see Appendix A.3 for detailed discussions.
2The method for acquiring (estimates of) the empirical probabilities is application-dependent (see Section 5).

2

Under review as a conference paper at ICLR 2019

2.2 ILLUSTRATIVE EXAMPLE: RECOMMENDATION SYSTEMS

In this context, U and I denote the set of users and items respectively, and Xu,i models the preference of user u for item i, (u, i)  K. Thus, P[Xu,i = 1] (or P[Xu,i = 2]) is the probability that user
u likes (or dislikes) item i. Moreover, u determines the profile/taste of user u, i is related to
item i (depending on genre, price, etc.), and the elementary events denote movie genres (e.g., 1 =
"Action", 2 = "SciFi", etc.). The training set, consisting of an empirical probability that user u likes
item i, pu,i, is obtained from the rating that user u has provided for item i. As a concrete illustrative
example, consider a 10-star "recommendation system", having 2 users and 2 items. We then find the D-dimensional (D = 3) KM factorization to obtain , {i }2i=1 and {u}u2=1. D is the size of the Kolmogorov space , the number of elementary events, and the dimension of the factorization (selected via cross-validation to minimize the test error). Solving (Q) results in finding {i }i2=1 and {u}u2=1. An example result is given below:

0

T

0.3 0.1

1 =
1

1 0.2
T
2 0.1

0.3 0.1

0.5  1 
0.8  0

1 }Action
1 }SciFi  1 }Drama

{pu,i }

1 2

To showcase the model's intuition, note that p1,1, the probability that user 1 likes movie 1, is repre-
sented as 1T 1. It is thus expressed as convex/stochastic mixture of movie genres, since elementary events are movie genres in this scenario. We underline that this high degree of interpretability is not

artificially enforced but rather context-dependent. More generally, a KM represents a set of observed

outcomes for RVs as (context-dependent) mixtures of elementary events.

3 PROPOSED ALGORITHM

To approach a solution for problem (2), we use the block-coordinate descent (BCD) method to split (Q) into two sub-problems. Here, we derive our solution approach to each. We first refine the current PMF estimation u, and then that of the indicator i. Given {i(n)} at iteration n, we pose the PMF refinement, -step, as

(Q1) : u(n+1)  argmin f (u)
u P

uT Q(un) u - 2uT

:= iIK i(n)i(n)T

:=

We then pose the indicator vector refinement, -step, as

ru(n)

.

iIK i(n)pu,i

(3)

(Q2) : i(n+1)  argmin g(i)
i BD

iT

Si(n+1)

i - 2iT

vi(n+1)

. (4)

:= uUK u(n+1)u(n+1)T

:= uUK u(n+1)pu,i

Moreover, UK and IK are defined as K = {(u, i) | u  UK  U , i  IK  I}. Recall that having globally optimal solutions for both (Q1) and (Q2) is necessary to show the convergence of BCD (Tseng, 2001) - a challenging task due to the NP-hardness of (Q2).

3.1 -STEP: REFINE PMF ESTIMATE

We use the Frank-Wolfe (FW) algorithm (Frank & Wolfe, 1956) to solve (Q1) as a succession of Linear Programs (LPs) over the unit simplex. While LP solvers generally have similar complexity

as quadratic program solvers, solving an LP reduces to searching for the minimum index - which

is computationally efficient, when the LP is over the unit simplex. We summarized this FW variant

for solving (Q1); see also Jaggi (2013)[Algorithm 1]. Here, we drop the BCD iteration index, n, and just keep the FW iteration number, k, for notation simplicity. We first determine the descent

direction: du(k)  argminsP

f (u(k))

T
s. The constraint s  P greatly simplifies the above

LP and yields: d(uk) = ej , j  argmin1jD [f (u(k))]j ; see Proposition 2 (Appendix A.5). The solution follows from LPs over the unit probability simplex. Thus, finding the descent direction

reduces to searching over the D-dimensional gradient vector (done in O(D)). Then, the current value

is updated using a simple step size rule, u(k) = k/(k + 1). Table 1 shows the -step solution, and Proposition 3 in Appendix A.5 characterizes its convergence.

3

Under review as a conference paper at ICLR 2019

function [u] = FW ( Qu, ru, ) for k = 1, 2, ..., IF W do du(k) = ej , j = argmin [f (u(k))]j
1jD
u(k+1) = (1 - u(k))u(k) + u(k)du(k) Stop if u(k+1) - u(k)  end for end function
Table 1: -step solution using FW

function [^i] = SDR ( Si, ti, Mrnd ) // Repeat to approximate each i , i  IK Solve (5) to find Xi(SDR) Factorize as Xi(SDR) = LTi Li for m = 1, 2, ..., Mrnd do Gen. zero-mean i.i.d Gaussian vector u(im) Compute u^i(m) = sign[ LTi u(im) ] end for Find m = argmin1mD+1 u^i(m)T S~iu^(im) Compute z^i = [ui(m )]1:D [u(im )]D+1 Approximate i , as ^i = (z^i + 1)/2
end function
Table 2: -step solution using SDR

3.2 -STEP: REFINE INDICATOR ESTIMATE

To address the NP-hard nature of (Q2), we propose a solution based on Semi-Definite Relaxation and Randomization (SDR), and establish its quasi-optimality. We use the results of Ma et al. (2002)[Sec
IV-C]) and a series of reformulations to rewrite (Q2) in the following equivalent form (see Authors (Oct 2017) for all the derivations):

Xi  argminXi tr(S~iXi) , s. t. Xi 0, [Xi]k,k = 1, k , rank(Xi) = 1

where Xi = xixiT , S~i = auxiliary variable, and t~i

(1/4)Si -t~Ti /2

-t~i/2 0

, xi =

zi wi

, zi = 2i - 1, wi  {-1, +1} is an

(vi - (1/2)Si1). The problem is then relaxed into a convex program,

Xi(SDR)  argminXi tr(S~iXi) , s. t. Xi 0, [Xi]k,k = 1, k

(5)

Xi(SDR) may be solved using generic solvers. Then, a randomization procedure (Ma et al., 2002) extracts an approximate (binary) solution for (Q2); see Table 2. This evidently raises the issue of the sub-optimality gap for SDR. Based on the results of Tan & Rasmussen (2001) and Luo et al. (2010), we show in Proposition 4 (see Appendix A.5) that SDR (Table 2) is optimal (asymptotically in D) in recovering the binary solution of (Q2).

We highlight that the performance bound in Proposition 4 compares the quality of both the approximate binary solution offered by SDR (with respect to the optimal binary solution of (Q2)), as well as their respective cost functions. The asymptotic optimality is empirically validated in Appendix A.6.

3.3 ALGORITHM DESCRIPTION
The BCD-based algorithm alternates between refining the indicator and PMF vectors; see Algorithm 1. Lemma 2 (Appendix A.5) shows its convergence to a stationary point of (Q).

Algorithm 1 Iterative computation of KMs
// Randomly Initialize {u(1)  P} for n = 1, 2, ... do
Compute Si(n) and ti(n) using (4) Call ^i(n) = SDR(Si(n), ti(n), Mrnd ), i  IK Compute Q(un) and ru(n) using (3) // Initialize FW with {u(n-1)}, from previous iteration Call u(n) = FW(Q(un), ru(n), ), for all u  UK end for

4

Under review as a conference paper at ICLR 2019

4 INTERPRETABILITY VIA CAUSAL RELATION

4.1 CAUSAL RELATIONS

Once a KM is found, we derive causal relations that emerge from (1).

Proposition 1 (Inclusion of Support Set) Consider two random variables Xu,i and Xu,j (belonging to the training set) whose KM are given by the model in (1). If supp(j)  supp(i), then the
following two causal relations hold:

Xu,i = 1 implies Xu,j = 1 , and Xu,j = 2 implies Xu,i = 2 .

(6)

Proof: See Authors (Oct 2017) for the proof. Stated plainly, when the support set condition holds, the first outcome of Xu,i implies the same outcome for Xu,j, and the second outcome for Xu,j implies the second one for Xu,i, thereby implying a mutual causal relation among them (since Xu,i influences Xu,j and vice-versa). Note that our above definition of causality and causal relations is different than conventional ones in Pearl (2009)[Chap 2.8]. Moreover, our definition is distinct from Granger causality, due to the mutual coupling among the RVs in question.
We present next a special case of Proposition 1. When i = 1, then supp(i) = {D}, and supp(j)  supp(i) holds, for any choice of j,  j  IK , where IK defined in Section 3.
Corollary 1 (Maximally Supported RVs) Let {i, u}(u,i)K denote the KM associated with {P[Xu,i = 1]}(u,i)K. We define M as set of RVs for which the support set of the indicator vector is one, i.e., M = {i | i = 1}. Then, the condition supp(j)  supp(i) (Proposition 1) holds trivially  j  IK. Thus, the causal relations in (6) hold, for every i  M.
For maximally supported RVs, the realization of one outcome, Xu,i = 1, determines that of all RVs of the set {Xu,j = 1 | j  IK }.
Example 1 (Causal Relations in Recommendation Systems) In addition to prediction, recommendation systems are designed to accurately mine for association rules: if a user likes item i will he/she like another item j? Thus, the causal relations of Proposition 1 and Corollary 1 will be quite powerful, as we shall see. In the example of Section 2.2, note that supp(1)  supp(2). Then, Proposition 1 yields: if user 1 (or user 2) likes movie 2 implies he/she also likes movie 1. Moreover, X1,2 and X2,2 are maximally supported RVs, since 2 = 1. Thus, Corollary 1 reads: If any user likes item 2, then this causally implies that he/she likes all other items in the training set.

Thus, our approach provides association rules that follow from causal relations between different RVs. Consequently, these relations are stricter (as they are rooted in Kolmogorov probability) than other methods for mining association rules, which are not based on causality.

4.2 CAUSAL RELATIONS MINING (CRM)

In this section, we provide an efficient algorithmic approach to automatically mine the above relations. The above causal relations can be modeled using the adjacency matrix A  B|IK|×|IK|, defined as

[A]i,j = 1, if supp(j)  supp(i), and 0 otherwise, i = j .

(7)

[A]i,j = 1 denotes the inclusion of Xu,j in Xu,i. Note that when A is sparse (resp. dense) is an
indication for a dataset in which few (resp. many) casual relations exist. To quantify the sparsity level, we define an influence score, i = |IK |-1 jIK [A]i,j , which measures the normalized
j=i
number of pairs Xu,i and Xu,j, satisfying the support set condition. These steps are summarized
in the Algorithm 2 (illustrated in Figure 1). Moreover, its complexity is dominated by the pairwise search over IK (see Step 1), which comes at O(|IK |2 - |IK |)  O(|IK |2) operations.

5 SPECIAL CASES AND APPLICATIONS
We highlight relevant special cases and applications of our approach.

5

Under review as a conference paper at ICLR 2019

Algorithm 2 Causal Relations Mining (CRM)

1. Check the support set condition, via a pairwise search to check for pairs i and j satisfying supp(j)  supp(i), (i, j)  IK × IK , i = j (done over the training set K) 2. Build the adjacency matrix A, in (7) , and compute the influence score i, i  IK
3. Find all pairs (i, j) such that ai,j = 1. For each of these pairs it holds that (Proposition 1), Xu,i
and Xu,j are causally related, i.e.,

Xu,i = 1 implies Xu,j = 1, and Xu,j = 1 implies Xu,i = 1

(8)

4. Identify (if possible) maximally supported RVs (Corollary 1), M = {i | i = 1}. For each of them, the relations in (8) hold for all i  IK

Xu,1 Xu,2
Xu,3
a)

a) Check support set condition between Xu,1, and

Xu,1

Xu,2 Xu,1

Xu,2, Xu,3 (Xu,1 is a maximally supported RV Xu,2 here)

b) Check support set condition between Xu,2, and

Xu,3
b)

Xu,3 c)

Xu,1, Xu,3 c) Check support set condition between Xu,3, and

Xu,1, Xu,2

Figure 1: Algorithm for CRM (toy example)

Special Case: Unsupervised Learning Setting. Note that Algorithm 1 is equally applicable to an unsupervised learning task (no prediction needed). Moreover, if the training set has no missing data, i.e., K = D, then an alternate solution to (Q) may be obtained using the binary matrix factorization (MF) (Slawski et al., 2013) method. However, it is not applicable when factorizing a training set K (where K  D). Unlike Algorithm 1, binary MF does not offer prediction. Application: Analysis of Gene Expression. The ability to analyze gene expression data is critical to DNA research (Zhang et al., 2009). This task can be formulated in our proposed framework as follows: P[Xu,i = 1] denotes the probability that the genes being studied are expressed in sample u  U at location i  I of the DNA. In this setting, the set Kolmogorov elementary events, {1, · · · , D}, represents the various genes that might be involved. Consequently, our approach models the probability that a set of genes is expressed as a convex mixture of D various genes. We recall that this intuition follows from our model and is not enforced explicitly. More importantly, the causal relations can identify groups of DNA locations for which the expression of a gene (or its absence) in a given location implies its presence (or its absence) for all other locations in the group. We will numerically show the usefulness of these relations to DNA analysis, in Section 7.2.
6 PRACTICAL CONSIDERATIONS
Overfitting: Regularization parameters (to mitigate overfitting) can be included without any changes to the solution method. An 2-regularization can be included in (Q1): f (u) = uT (Qu + uID)u - 2uT ru + u , where the regularizer u  0 is absorbed into a "new" matrix (Qu + uID). Note that an 1-regularization for u would not work, since u  P. Similarly, an 1-regularization for (Q2) is: g(i) = iT Sii - 2(vi - (µi/2)1)T i + i , where the regularizer µi  0 is absorbed into the linear term, since µi i 1 = µi1T i, for i binary. Optimality Gap: We recall that the proposed SDR method was shown to be quasi-optimal in providing approximate binary solutions to (Q2). Thus, the relaxation does not affect the interpretability, in the sense that Proposition 1 and Corollary 1 still hold. While the derivations pertaining to causal relations (Section 4) assume globally optimal solutions to (Q) - an NP-hard problem, Algorithm 1 guarantees locally optimal ones. Thus, a bound on the gap between these solutions is needed. We highlight this issue as an interesting topic for further investigation. Computational Complexity: The computational complexity of Algorithm 1 is dominated by the solution in (5), which is  O(D4.5) operations per iteration of Algorithm 1 (recalling the negligible cost of the FW method). The added complexity compared to matrix factorization ( O(D3)) and its extensions is not significant, keeping in mind that D min(|IK| , |UK|). Moreover, the computational complexity of Algorithm 2 consists mainly of step 1, which has  O(|IK|2) operations. Non-stationary distributions: The proposed method assumes that distributions of the RVs in the training set are stationary: Indeed, scenarios with time-varying distributions are a limitation (and inter-
6

Under review as a conference paper at ICLR 2019

Training RMSE Normalized Training RMSE
Normalized Influence Score

Artificial data U=20, I = 40, Nrand=103, u=0 , 0.5 Prop.
Prop. (w/ exh. search)
Binary MF (D=4) 0.4 Binary MF (D=8)
Binary MF (D=10)

i = 0,

D=4 D=8 0.3 D=10

Training RMSE vs D ML100K, BCD Iter=5 0.6 Prop.
NNM 0.5
0.4
0.3 D=8, 4 D=8, 4

1 0.9 0.8 0.7

0.2 0.2 0.6

12345 BCD Iterations

D=16
1234 BCD Iterations

5

0.5

0

500

1000

1500

Item Index

(a) Normalized Training RMSE vs Itera-(b) Normalized Training RMSE for KM (c) Influence score i

tions (Setting 1)

vs NNM (Setting 2)

(D = 8, Setting 2)

Figure 2: Performance of proposed method

esting future directions). However, in learning it is quite common to assume that the data-generating distribution is stationary.

7 NUMERICAL RESULTS
7.1 APPLICATION TO RECOMMENDATION SYSTEMS
Experimental Setup: We evaluate the performance of Algorithm 1 under the following. Hereafter, "Prop." refers to the proposed method. Setting 1: An artificial training dataset, where pu,i  K = {U = 20} × {I = 40}, where {pu,i} are i.i.d. and uniformly chosen on the unit interval. We benchmark against a variant on Algorithm 1, where the -step for Q2 is replaced by an exhaustive search. As the data is artificial (unsupervised learning setting), we include the Binary MF in Slawski et al. (2013)[Algorithm 2]. Setting 2: The training set K, is chosen as the MovieLens 100K, with U = 943 users and I = 1682 items, split into 80% for training and 20% for testing. Let {^i}, {^u} the output of Algorithm 1, after 5 iterations. We benchmark against matrix factorization (MF) (Koren et al., 2009), non-negative MF (NMF) (Lee & Seung, 2001), SVD++ (Koren, 2008) (ensuring the dimension of the factorization, k, is close to D), non-negative models (NNM) Stark (2015), and the K-means (K-M) algorithm. The implementation and results use the MyMediaLite package (Gantner et al., 2011).
Training Performance for Unsupervised Learning (Setting 1): Fig 2a shows the resulting normalized training RMSE = ( (u,i)K |pu,i - ^uT ^i|2/|K|)1/2. We observe that the monotone convergence in Lemma 2 is validated numerically, and that the training error decays with increasing model size, D. Note that the training performance of Algorithm 1 is indistinguishable from its exhaustive search variant. Moreover, Algorithm 1 converges to solution whose performance is similar to Binary MF, with a few iterations (except for D = 8 where Algorithm 1 outperforms Binary MF).
Training Performance for Supervised Learning (Setting 2): Recall that Binary MF is not applicable here, due to the supervised learning setting. The same conclusions hold when testing Algorithm 1 on the ML100K (Figure 2b). We underline that while NNMs yield better training performance over Algorithm 1, the latter will have better test performance (since NNMs are indeed defined by relaxing KMs). In Table 3 (Appendix A.6), we empirically verify that the test performance of the proposed method outperforms the benchmarks in Setting 2.
Interpretability via Causal Relations (Setting 2): We numerically evaluate the relations of Algorithm 2. The influence score for each item in the training set, i, is shown in Figure 2c where we displayed items with `high' influence score, i  0.5. Note that each of these high influence items is causally related to at least half of the items in the training set. This confirms the effectiveness of Algorithm 2 for finding causal relations, and that a sparse adjacency matrix is uncommon. We next identify the set of items corresponding to maximally supported RVs, M = {119, 814, 1188, 1190, 1290, 1393, 1462, 1486, 1494, 1530, 1590, 1638}. For each of these items, a user liking one given item, implies he/she likes all other items in the training set. Interestingly, these results remain the same when D = 24, thereby suggesting that procedure for mining causal relations is quite stable.
7

Under review as a conference paper at ICLR 2019

Normalized Training RMSE Influence Score i

0.35 0.3
0.25 0.2

Prop. (D=12) Prop. (D=16) Prop. (D=24) Binary MF (D=12) Binary MF (D=16) Binary MF (D=24)

0.5 Prop. (D=12) Prop. (D=16)
0.4 Prop. (D=24)
0.3
0.2

0.15

0.1

0.1 12345 Iterations

0 0 200 400 600 800 1000 DNA Location

(a) Normalized Training RMSE as a function of iterations (Setting 3)

(b) Influence score for each DNA location (Setting 3)

Figure 3: Training performance of proposed method for REGED0 dataset

7.2 APPLICATION TO GENE EXPRESSION

Experimental Setup: Following the problem statement in Section 5, we show the usefulness Algorithm 2 for gene expression. We first define another setting. Setting 3: We use the REGED0 dataset 3. Element (u, i) in the input matrix, [L]u,i represents the level of gene expression for sample u at location i of the DNA. We obtain the training set as pu,i := [L]u,i/Lmax, where pu,i denotes the (empirical) probability that the gene is expressed in sample u at location i. After running Algorithm 1, we use Algorithm 2 to mine causal relations. As this is unsupervised learning setting, we include the binary MF (Slawski et al., 2013) method.
Results: While Fig 3a shows the training performance for several values of D, Figure 3b plots the corresponding influence score that is obtained with our method. Fig 3a reveals a huge gap ( 3× less) between the training error of Algorithm 1 and Binary MF (unlike Figure 2a where both algorithms yield similar performance). This drastic degradation in the performance of binary MF compared to the small artificial of Figure 2a may be attributed to increasing the data/problem size (though we were unable to empirically verify this claim). Thus, we opted to use the solution of Algorithm 1 as a basis for finding causal relations. We identified 10 DNA locations corresponding to the highest i as: {813, 250, 774, 706, 380, 49, 477, 162, 740, 702}. For instance, the highest influence score of .1612 at DNA location 813 allowed to identify a set, S, of 161 different locations which are causally related to DNA location 813. More specifically, the expression (or absence) of a given gene in location 813 implies its expression (or absence) in all other DNA locations in S. While similar relations are possible using gene analysis methods, the above causal relations follow from our rigorous mathematical framework.

8 CONCLUSION
We have proposed a framework for learning a Kolmogorov model, associated with a collection of binary random variables. Interpretability of the model (as defined by logical implication and causality) was harnessed by deriving causal relations, i.e., by finding sufficient conditions that bind outcomes of certain random variables. We also proposed an algorithm for computing a Kolmogorov model, a combinatorial non-convex problem, and showed its convergence to a stationary point of the problem using results from block-coordinate descent. The combinatorial nature of the problem was addressed using a semi-definite relaxation. We also proposed an efficient algorithm to mine for the causal relations inherent to our model. Our results suggest that increased interpretability and improved prediction, do not cause a significant increase in complexity.

3http://www.causality.inf.ethz.ch/data/REGED.html 8

Under review as a conference paper at ICLR 2019
REFERENCES
Anonymous Authors. Learning elementary representations of random variables. Technical Report, Oct 2017. URL https://tinyurl.com/y7gpu4dc.
Jian-Feng Cai, Emmanuel J. Cands, and Zuowei Shen. A singular value thresholding algorithm for matrix completion. SIAM Journal on Optimization, 20(4):1956­1982, 2010. doi: 10.1137/ 080738970.
Mark Davenport and Justin Romberg. An overview of low-rank matrix recovery from incomplete observations. IEEE Journal of Selected Topics in Signal Processing, 10(4):608­622, June 2016. ISSN 1932-4553. doi: 10.1109/JSTSP.2016.2539100.
Finale Doshi-Velez and Been Kim. Towards a rigorous science of interpretable machine learning. arXiv, 2017.
Marguerite Frank and Philip Wolfe. An algorithm for quadratic programming. Naval Research Logistics Quarterly, 3(1-2):95­110, 1956. ISSN 1931-9193.
Zeno Gantner, Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. Mymedialite: A free recommender system library. In Proceedings of the Fifth ACM Conference on Recommender Systems, RecSys '11, pp. 305­308. ACM, 2011. ISBN 978-1-4503-0683-6.
Robert M. Gray. Probability, Random Processes, and Ergodic Properties. Springer, 2nd edition, 2009. ISBN 1441910891, 9781441910899.
Martin Jaggi. Revisiting Frank-Wolfe: Projection-free sparse convex optimization. In Proceedings of the 30th International Conference on Machine Learning, volume 28, pp. 427­435, 2013.
Y. Koren, Robert Bell, and Chris Volinsky. Matrix factorization techniques for recommender systems. Computer, 42(8):30­37, Aug 2009. ISSN 0018-9162. doi: 10.1109/MC.2009.263.
Yehuda Koren. Factorization meets the neighborhood: A multifaceted collaborative filtering model. In Proceedings of the 14th ACM International Conference on Knowledge Discovery and Data Mining, KDD, pp. 426­434. ACM, 2008. ISBN 978-1-60558-193-4.
Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature, 521, 2015. doi: 10.1038/nature14539.
Daniel Lee and Sebastian Seung. Algorithms for non-negative matrix factorization. In Advances in Neural Information Processing Systems (NIPS), pp. 556­562. MIT Press, 2001.
Zachary Chase Lipton. The mythos of model interpretability. CoRR, abs/1606.03490, 2016.
Stuart Lloyd. Least squares quantization in PCM. IEEE Trans. Inf. Theor., 28(2):129­137, September 2006. ISSN 0018-9448. doi: 10.1109/TIT.1982.1056489.
Zhi-Quan Luo, Wing-Kin Ma, A.M.-C. So, Yinyu Ye, and Shuzhong Zhang. Semidefinite relaxation of quadratic optimization problems. IEEE Signal Processing Magazine,, 27(3):20­34, May 2010. ISSN 1053-5888. doi: 10.1109/MSP.2010.936019.
Wing-Kin Ma, T. N. Davidson, Kon Max Wong, Zhi-Quan Luo, and Pak-Chung Ching. Quasimaximum-likelihood multiuser detection using semi-definite relaxation with application to synchronous CDMA. IEEE Transactions on Signal Processing, 50(4):912­922, April 2002.
Bill Marr. The top 10 AI and machine learning use cases everyone should know about. Forbes Magazine, Sept 2016.
Judea Pearl. Causality: Models, Reasoning and Inference. Cambridge University Press, New York, NY, USA, 2nd edition, 2009. ISBN 052189560X, 9780521895606.
Martin Slawski, Matthias Hein, and Pavlo Lutsik. Matrix factorization with binary components. In Advances in Neural Information Processing Systems (NIPS), pp. 3210­3218, 2013.
9

Under review as a conference paper at ICLR 2019
Cyril J. Stark. Expressive recommender systems through normalized nonnegative models. CoRR, abs/1511.04775, 2015.
Cyril J. Stark. Expressive recommender systems through normalized nonnegative models. In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, pp. 1081­1087, 2016a.
Cyril J. Stark. Recommender systems inspired by the structure of quantum theory. CoRR, abs/1601.06035, 2016b.
Peng Hui Tan and L. K. Rasmussen. The application of semidefinite programming for detection in CDMA. IEEE Journal on Selected Areas in Communications, 19(8):1442­1449, Aug 2001. ISSN 0733-8716. doi: 10.1109/49.942507.
P. Tseng. Convergence of a block coordinate descent method for nondifferentiable minimization. Journal of Optimization Theory and Applications, 109(3):475­494, 2001. ISSN 0022-3239. doi: 10.1023/A:1017501703105.
Joyce Jiyoung Whang, Inderjit S. Dhillon, and David F. Gleich. Non-exhaustive, overlapping k-means. In Proceedings of the 2015 SIAM International Conference on Data Mining, pp. 936­944, 2015. doi: 10.1137/1.9781611974010.105.
Zhong-Yuan Zhang, Tao Li, Chris Ding, Xian-Wen Ren, and Xiang-Sun Zhang. Binary matrix factorization for analyzing gene expression data. Data Mining and Knowledge Discovery, 20(1): 28, 2009. ISSN 1573-756X. doi: 10.1007/s10618-009-0145-2. URL http://dx.doi.org/ 10.1007/s10618-009-0145-2.
10

Under review as a conference paper at ICLR 2019

A SUPPLEMENTARY MATERIAL FOR LEARNING KOLMOGOROV MODELS FOR BINARY RANDOM VARIABLES

A.1 DEFINITIONS

A.2 KOLMOGOROV MODEL FOR A RANDOM VARIABLE

Let (, M, µ) be a finite probability space. Here  is the sample space, the event class M is the
power set of , and µ assigns probabilities to the sets in M. Let Xu,i denote a doubly-indexed set of random variables on the given probability space, having output alphabet in A, where elements of
A are indexed by z, i.e., A(z) represents the zth element in A. Also, let P[Xu,i = A(z)]  [0, 1] denote the probability that outcome A(z) occurs, for 1  z  |A|. We let  = {d | 1  d  D}, where {d} the set of all D-elementary events. Since Xu,i is binary, i.e., A = {1, 2}, we write the
KM for Xu,i as,

P[Xu,i = 1] = uT i,1 P[Xu,i = 2] = uT i,2 = 1 - uT i,1,

(A.1)

where u is a Probability Mass Function (PMF) vector on the unit simplex, P, and {i,1, i,2}  BD are binary indicator vectors representing the support of its probability measure. Moreover, the last
equality follows from i,1 + i,2 = 1, which in turn follows from the outcomes of each RV summing to one. Since Xu,i is binary, it is fully characterized by considering one outcome,

P[Xu,i = 1] = uT i,

(A.2)

A.3 RELATED WORK
Matrix Factorization Methods: Note that, (Q) can be re-written as a low-rank matrix factorization problem, over the set of binary and stochastic matrices (see Appendix A.4. Thus, the proposed approach is connected to factorization methods: Matrix Factorization (MF) (Koren et al., 2009), Nonnegative Matrix Factorization (Lee & Seung, 2001), SVD (Cai et al., 2010) (and their many variants/extensions) have gained widespread applicability, covering areas in sound processing, (medical) image reconstruction, recommendation systems and prediction problems (Davenport & Romberg, 2016). These techniques model elements of the training set as inner product of two arbitrary vectors, and consequently, this inner product does not represent a RV (in a mathematical sense), when viewed in the context of the proposed model (see Section 2.1). Consequently, the analytical guarantees of Section 4, which underpin the causal relations, do not hold for general factorization methods.
Binary MF: We underline that most MF methods also rely on BCD methods (alternating minimization), for which globally optimal solutions to each subproblem are needed for convergence. Thus, these methods cannot be directly applied to (Q), due to the binary constraints on i. The authors are unaware generic solution approaches for (Q). Nonetheless, the Binary MF method (Slawski et al., 2013) can solve (Q) when the problem is feasible and the training set spans the entire data set, i.e., K = D. However, the method operates in the unsupervised learning setting only, without providing prediction (see Section 5). This indeed limits the applicability of binary MF to practical scenarios, since real-world data will have missing/erroneous data.
Clustering Methods: Consider a special case of (Q), where i is constrained to have one nonzero element. The resulting problem becomes the well-known K-means clustering (Lloyd, 2006). The K-means algorithms (and its variants K-medoids, fuzzy K-means and K-SVD), have become pervasive in an abundance of applications such as clustering, classification, image segmentation, DNA analysis, online dictionary learning, source coding, etc. Our approach generalizes K-means, by allowing for overlapping clusters. While a similar generalization of the classical K-means algorithm was considered in (Whang et al., 2015), the number of points per cluster is determined explicitly.
Nonnegative Models: Non-Negative Models (NNMs) (Stark, 2016a) are recent attempts at interpretable models. For reasons of computational tractability (Stark, 2016a), NNMs are defined by relaxing i in (1). However, this relaxation impairs the highly interpretable nature of the model in (1), making causal relations less accurate.

1

Under review as a conference paper at ICLR 2019

A.4 PROBLEM FORMULATION IN MATRIX FORM

Let  = [1, · · · , I ],   BD×I denote the aggregate indicator matrix (containing all the

individual indicator vectors),  = [1, · · · , U ],   RD+×U the aggregate matrix of PMF vectors,

and [P ](u,i)

=

p(u,i), (u, i)



U

× I,

P



U ×I
R+

the aggregate matrix of known probabilities.

Then, (Q) can be written in equivalent matrix form,

 min E(, ) =

M

T  - P

,

2 F

 s. t.   BD×I ,   RD+×U , T 1 = 1 .

(A.3)

where  denotes the Hadamard product, and M  BU×I is a mask matrix having Mu,i = 1, (u, i)  K.

A.5 MAIN RESULTS

Below, we summarized the results used in the paper; see Authors (Oct 2017) for the proofs. We use following known result to find the descent direction for the FW method (the proof is known).

Proposition 2 Consider the following Linear Program (LP), (PP S) x = argmin cT x, s. t. 1T x = 1, x  0
xRn
Its optimal solution is given by
x = ej , where j = argmin1jn cT ej
Thus, the solution reduces to searching over the vector c.

We show the convergence of the FW algorithm (Table 1).
Proposition 3 Let u be the optimal solution to (Q1). Then the sequence of iterates {u(k)} satisfies (Jaggi, 2013)[Theorem 1],
f (u(k+1)) - f (u) 2  O(1/k), k = 1, 2, · · ·

Proof: The linear convergence rate for all FW variants, was proved in Jaggi (2013)[Theorem 1].

Quasi-optimality of SDR: The question was studied extensively in the context of binary detection for multi-antenna communication (Tan & Rasmussen, 2001). Interestingly, (Q2) can be recast as a noiseless binary detection problem, where SDR has been to be optimal. The results is formalized below.

Proposition 4 Let g(i ) and g(^i) denote the optimal solutions to the binary QP in (Q2), and its SDR after randomization (Table 2), respectively. The approximation quality is defined as (Luo et al.,
2010),

  g(i )/g(^i)  1.

(A.4)

It holds that  = 1, with probability 1 - exp-O(D), asymptotically in D. Thus, the relaxation is quasi-optimal.

Proof: See (Authors, Oct 2017).

Lemma 2 Let tn E({i(n)}, {u(n)}), n = 1, 2, ... be the sequence of iterates, resulting from the updates in Algorithm 1. Then, {tn} is non-increasing in n, and converges to a stationary point of (Q) in (2), almost surely.

Proof: The convergence is shown in (Authors, Oct 2017).

2

Under review as a conference paper at ICLR 2019

A.6 ADDITIONAL NUMERICAL RESULTS

Prediction Performance (Setting 2): Since the range of the predicted variable is different

for MF/NMF/SVD++, and KM/NNM, we use the normalized test RMSE, i.e., NRMSE = ( (u,i)K¯ |[R](u,i) - R^u,i|2/|K¯|)1/2 where K¯ is the test set, and  = (Rmax - Rmin)-1 = 1/4 is

the normalization for MF/NMF/SVD++. For KMs/NNMs the same metric reduces to NRMSE =

(u,i)K¯ |[R](u,i)/Rmax - ^uT ^i|2/|K¯|

1/2
. The best values for u and µi, were picked from a

coarse two-dimensional grid by cross-validation, using a held-out validation set. The Normalized

RMSE results are shown in Table 3. We observe a significant gap between KMs, and well known

collaborative filtering methods, especially as D increases. Moreover, the drop in performance for

NNMs for increasing D may be due to over-fitting.

Table 3: Normalized Test RMSE (Setting 2). The dimension of factorization for MF/SVD++, k, is equal to D (unless stated in the corresponding entry). The normalized test RMSE for all other methods are taken from the following repository: http://www.mymedialite.net/examples/datasets.html (`-' indicates the unavailability of the correspond test RMSE from the repository.

KM NNM MF SVD++ K-M NMF

D=4
0.199 0.194 0.229 0.228 0.210
-

D=8
0.2013 0.2255 0.228(k = 10) 0.227(k = 10) .2096
-

D = 16
0.1900 0.2057
- 0.227(k = 20)
0.2105 -

D = 24 0.1861 0.2118 0.226(k = 40) 0.226(k = 50) 0.2105 0.192(k = 100)

Asymptotic optimality of SDR for -step solution: Table 4 is a numerical validation of Proposition 4 where we computed the error rate of SDR (compared to the exhaustive search), aggregated over all iterations. We observe that the approximation error decreases, with increasing D (following Proposition 4).
Table 4: Error rate for SDR (Artificial Dataset, U = 20, I = 40).

D = 4 D = 8 D = 10

SDR Accuracy ×10-3 7.5

4.4

4.0

3

