{"notes":[{"id":"BJgK6iA5KX","original":"SJxgJXW5tX","number":821,"cdate":1538087872768,"ddate":null,"tcdate":1538087872768,"tmdate":1538156049956,"tddate":null,"forum":"BJgK6iA5KX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"AutoLoss: Learning Discrete Schedule for Alternate Optimization","abstract":"Many machine learning problems involve iteratively and alternately optimizing different task objectives with respect to different sets of parameters. Appropriately scheduling the optimization of a task objective or a set of parameters is usually crucial to the quality of convergence. In this paper, we present AutoLoss, a meta-learning framework that automatically learns and determines the optimization schedule. AutoLoss provides a generic way to represent and learn the discrete optimization schedule from metadata, allows for a dynamic and data-driven schedule in ML problems that involve alternating updates of different parameters or from different loss objectives.\n\nWe apply AutoLoss on four ML tasks: d-ary quadratic regression, classification using a multi-layer perceptron (MLP), image generation using GANs, and multi-task neural machine translation (NMT). We show that the AutoLoss controller is able to capture the distribution of better optimization schedules that result in higher quality of convergence on all four tasks. The trained AutoLoss controller is generalizable -- it can guide and improve the learning of a new task model with different specifications, or on different datasets.","keywords":["Meta Learning","AutoML","Optimization Schedule"],"authorids":["ICLR.cc/2019/Conference/Paper821/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a unified formulation for iterative alternate optimization and develop AutoLoss, a framework to automatically learn and generate optimization schedules.","pdf":"/pdf/1862afde0808b26572a07cc8613e7bbe7e5a269a.pdf","paperhash":"anonymous|autoloss_learning_discrete_schedule_for_alternate_optimization","_bibtex":"@inproceedings{    \nanonymous2019autoloss:,    \ntitle={AutoLoss: Learning Discrete Schedule for Alternate Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgK6iA5KX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJlt6oA9Fm","original":"BJe55Pm5YX","number":822,"cdate":1538087872942,"ddate":null,"tcdate":1538087872942,"tmdate":1538156049737,"tddate":null,"forum":"SJlt6oA9Fm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Selective Convolutional Units: Improving CNNs via Channel Selectivity","abstract":"Bottleneck structures with identity (e.g., residual) connection are now emerging popular paradigms for designing deep convolutional neural networks (CNN), for processing large-scale features efficiently. In this paper, we focus on the information-preserving nature of the bottleneck structures and utilize this to enable a convolutional layer to have a new functionality of channel-selectivity, i.e., focusing its computations on important channels. In particular, we propose Selective Convolutional Unit (SCU), an easy-to-use architectural unit that improves parameter efficiency of various modern CNNs with bottlenecks. During training, SCU gradually learns the channel-selectivity on-the-fly via the alternative usage of (a) pruning unimportant channels, and (b) rewiring the pruned parameters to important channels. The rewired parameters emphasize the target channel in a way that selectively enlarges the convolutional kernels corresponding to it. Our experimental results demonstrate that the SCU-based models without any post-processing generally achieve both model compression and accuracy improvement compared to the baselines, consistently for all tested architectures.","keywords":["convolutional neural networks","channel-selectivity","channel re-wiring","bottleneck architectures","deep learning"],"authorids":["ICLR.cc/2019/Conference/Paper822/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a new module that improves any ResNet-like architectures by enforcing \"channel selective\" behavior to convolutional layers","pdf":"/pdf/a75205e2a4c52793066be593c3657d863fa9c552.pdf","paperhash":"anonymous|selective_convolutional_units_improving_cnns_via_channel_selectivity","_bibtex":"@inproceedings{    \nanonymous2019selective,    \ntitle={Selective Convolutional Units: Improving CNNs via Channel Selectivity},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJlt6oA9Fm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJxKajC5t7","original":"B1eJAoXtFQ","number":823,"cdate":1538087873111,"ddate":null,"tcdate":1538087873111,"tmdate":1538156049527,"tddate":null,"forum":"HJxKajC5t7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Self-Binarizing Networks","abstract":"We present a method to train self-binarizing neural networks, that is, networks that evolve their weights and activations during training to become binary. To obtain similar binary networks, existing methods rely on the sign activation function. This function, however, has no gradients for non-zero values, which makes standard backpropagation impossible. To circumvent the difficulty of training a network relying on the sign activation function, these methods alternate between floating-point and binary representations of the network during training, which is sub-optimal and inefficient. We approach the binarization task by training on a unique representation involving a smooth activation function, which is iteratively sharpened during training until it becomes a binary representation equivalent to the sign activation function. Additionally, we introduce a new technique to perform binary batch normalization that simplifies the conventional batch normalization by transforming it into a simple comparison operation. This is unlike existing methods, which are forced to the retain the conventional floating-point-based batch normalization. Our binary networks, apart from displaying advantages of lower memory and computation as compared to conventional floating-point and binary networks, also show higher classification accuracy than existing state-of-the-art methods on multiple benchmark datasets.","keywords":["Binarization","Convolutional Neural Networks","Deep Learning","Deep Neural Networks"],"authorids":["ICLR.cc/2019/Conference/Paper823/Authors"],"authors":["Anonymous"],"TL;DR":"A method to binarize both weights and activations of a deep neural network that is efficient in computation and memory usage and performs better than the state-of-the-art.","pdf":"/pdf/826ba0af1a9860a3a83f7d562f9dbc0d4da8ab57.pdf","paperhash":"anonymous|selfbinarizing_networks","_bibtex":"@inproceedings{    \nanonymous2019self-binarizing,    \ntitle={Self-Binarizing Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxKajC5t7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJeY6sR9KX","original":"rke6jAwtF7","number":824,"cdate":1538087873290,"ddate":null,"tcdate":1538087873290,"tmdate":1538156049313,"tddate":null,"forum":"BJeY6sR9KX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Aligning Artificial Neural Networks to the Brain yields Shallow Recurrent Architectures","abstract":"Deep artificial neural networks with spatially repeated processing (a.k.a., deep convolutional ANNs) have been established as the best class of candidate models of visual processing in the primate ventral visual processing stream. Over the past five years, these ANNs have evolved from a simple feedforward eight-layer architecture in AlexNet to extremely deep and branching NASNet architectures, demonstrating increasingly better object categorization performance. Here we ask, as ANNs have continued to evolve in performance, are they also strong candidate models for the brain? To answer this question, we developed Brain-Score, a composite of neural and behavioral benchmarks that score any ANN on how brain-like it is, together with an online platform where ANNs can be submitted to receive a Brain-Score and their rank relative to other models. Deploying our framework on dozens of state-of-the-art ANNs, we found that ResNet and DenseNet families of models are the closest models from the Machine Learning community to primate ventral visual stream. Curiously, best current ImageNet models, such as PNASNet, were not the top-performing models on Brain-Score. Despite high scores, these deep models are often hard to map onto the brain's anatomy due to their vast number of layers and missing biologically-important connections, such as recurrence. To further map onto anatomy and validate our approach, we built CORnet-S: a neural network developed by using Brain-Score as a guide with the anatomical constraints of compactness and recurrence. Although a shallow model with four anatomically mapped areas with recurrent connectivity, CORnet-S is a top model on Brain-Score and outperforms similarly compact models on ImageNet.","keywords":["Computational Neuroscience","Brain-Inspired","Neural Networks","Simplified Models","Recurrent Neural Networks","Computer Vision"],"authorids":["ICLR.cc/2019/Conference/Paper824/Authors"],"authors":["Anonymous"],"pdf":"/pdf/99e2c1b628d1064ebfa247473cc0b491dbc515ef.pdf","paperhash":"anonymous|aligning_artificial_neural_networks_to_the_brain_yields_shallow_recurrent_architectures","_bibtex":"@inproceedings{    \nanonymous2019aligning,    \ntitle={Aligning Artificial Neural Networks to the Brain yields Shallow Recurrent Architectures},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJeY6sR9KX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJfFTjA5KQ","original":"BJgMD039FX","number":825,"cdate":1538087873467,"ddate":null,"tcdate":1538087873467,"tmdate":1538156049101,"tddate":null,"forum":"SJfFTjA5KQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Unification of  Recurrent   Neural Network Architectures and Quantum Inspired Stable Design ","abstract":"Various architectural advancements in the design of recurrent neural networks~(RNN) have been focusing on improving the empirical stability and representability by sacrificing the complexity of the architecture. However, more remains to be done to fully understand the fundamental trade-off between these conflicting requirements. Towards answering this question, we forsake the purely bottom-up approach of data-driven machine learning to understand, instead,  the physical origin and dynamical properties of existing RNN architectures.  This facilitates designing new RNNs with smaller complexity overhead and provable stability guarantee. First, we define a family of  deep recurrent neural networks,  $n$-$t$-ORNN, according to the order of nonlinearity $n$ and the range of temporal memory scale $t$ in their underlying dynamics embodied in the form of discretized ordinary differential equations. We show that most of the existing proposals of RNN architectures belong to different orders of $n$-$t$-ORNNs.    We then propose a new RNN ansatz, namely the Quantum-inspired  Universal computing  Neural Network~(QUNN), to leverage the reversibility, stability, and universality of quantum computation for stable and universal RNN.  QUNN   provides a complexity reduction in the number of training parameters from being polynomial in both data and correlation time to only linear in correlation time.  Compared to Long-Short-Term Memory (LSTM), QUNN of the same number of hidden layers facilitates higher nonlinearity and longer memory span with provable stability. Our work opens new directions in designing minimal RNNs based on additional knowledge about the dynamical nature of both the data and different training architectures.","keywords":["theory and analysis of RNNs architectures","reversibe evolution","stability of deep neural network","learning representations of outputs or states","quantum inspired embedding"],"authorids":["ICLR.cc/2019/Conference/Paper825/Authors"],"authors":["Anonymous"],"TL;DR":"We provide theoretical proof of various recurrent neural network designs representable dynamics' nonlinearity and memory scale, and propose a new RNN ansatz inspired by quantum physics.","pdf":"/pdf/5a26b67c5ba83aaf758ec469732814d4541556d1.pdf","paperhash":"anonymous|unification_of_recurrent_neural_network_architectures_and_quantum_inspired_stable_design","_bibtex":"@inproceedings{    \nanonymous2019unification,    \ntitle={Unification of  Recurrent   Neural Network Architectures and Quantum Inspired Stable Design },    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJfFTjA5KQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hklc6oAcFX","original":"H1e4vFh5tX","number":826,"cdate":1538087873654,"ddate":null,"tcdate":1538087873654,"tmdate":1538156048898,"tddate":null,"forum":"Hklc6oAcFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Co-manifold learning with missing data","abstract":" Representation learning is typically applied to only one mode of a data matrix, either its rows or columns. Yet in many applications, there is an underlying geometry to both the rows and the columns. We propose utilizing this coupled structure to perform co-manifold learning: uncovering the underlying geometry of both the rows and the columns of a given matrix, where we focus on a missing data setting. Our unsupervised approach consists of three components.  We first solve a family of optimization problems to estimate a complete matrix at multiple scales of smoothness. We then use this collection of smooth matrix estimates to compute pairwise distances on the rows and columns based on a new multi-scale metric that implicitly introduces a coupling between the rows and the columns.  Finally, we construct row and column representations from these multi-scale metrics.  We demonstrate that our approach outperforms competing methods in both data visualization and clustering.  ","keywords":["nonlinear dimensionality reduction","missing data","manifold learning","co-clustering","optimization"],"authorids":["ICLR.cc/2019/Conference/Paper826/Authors"],"authors":["Anonymous"],"TL;DR":"Nonlinear representations of observations and features of a data matrix with missing entries and coupled geometries","pdf":"/pdf/0e05f0174402db00e32dfec4533cc85d71de07fc.pdf","paperhash":"anonymous|comanifold_learning_with_missing_data","_bibtex":"@inproceedings{    \nanonymous2019co-manifold,    \ntitle={Co-manifold learning with missing data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hklc6oAcFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJlc6iA5YX","original":"BkeX4Nw9YX","number":827,"cdate":1538087873833,"ddate":null,"tcdate":1538087873833,"tmdate":1538156048692,"tddate":null,"forum":"BJlc6iA5YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"ACE: Artificial Checkerboard Enhancer to Induce and Evade Adversarial Attacks","abstract":"The checkerboard phenomenon is one of the well-known visual artifacts in the computer vision field. The origins and solutions of checkerboard artifacts in the pixel space have been studied for a long time, but their effects on the gradient space have rarely been investigated. In this paper, we revisit the checkerboard artifacts in the gradient space which turn out to be the weak point of a network architecture. We explore image-agnostic property of gradient checkerboard artifacts and propose a simple yet effective defense method by utilizing the artifacts. We introduce our defense module, dubbed Artificial Checkerboard Enhancer (ACE), which induces adversarial attacks on designated pixels. This enables the model to deflect attacks by shifting only a single pixel in the image with a remarkable defense rate. We provide extensive experiments to support the effectiveness of our work for various attack scenarios using state-of-the-art attack methods. Furthermore, we show that ACE is even applicable to large-scale datasets including ImageNet dataset and can be easily transferred to various pretrained networks.","keywords":["Adversarial Examples","Neural Network Security","Deep Neural Network","Checkerboard Artifact"],"authorids":["ICLR.cc/2019/Conference/Paper827/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a novel aritificial checkerboard enhancer (ACE) module which guides attacks to a pre-specified pixel space and successfully defends it with a simple padding operation.","pdf":"/pdf/0a044815727fef5d73d3f921c6b233499620845e.pdf","paperhash":"anonymous|ace_artificial_checkerboard_enhancer_to_induce_and_evade_adversarial_attacks","_bibtex":"@inproceedings{    \nanonymous2019ace:,    \ntitle={ACE: Artificial Checkerboard Enhancer to Induce and Evade Adversarial Attacks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJlc6iA5YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hkl5aoR5tm","original":"SkedZEqcKX","number":828,"cdate":1538087874000,"ddate":null,"tcdate":1538087874000,"tmdate":1538156048487,"tddate":null,"forum":"Hkl5aoR5tm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"On Self Modulation for Generative Adversarial Networks","abstract":"Training Generative Adversarial Networks (GANs) is notoriously challenging. We propose and study an architectural modification, self-modulation, which improves GAN performance across different data sets, architectures, losses, regularizers, and hyperparameter settings. Intuitively, self-modulation allows the intermediate feature maps of a generator to change as a function of the input noise vector. While reminiscent of other conditioning techniques, it requires no labeled data. In a large-scale empirical study we observe a relative decrease of 5%-35% in FID. Furthermore, all else being equal, adding this modification to the generator leads to improved performance in 124/144 (86%) of the studied settings. Self-modulation is a simple architectural change that requires no additional parameter tuning, which suggests that it can be applied readily to any GAN.","keywords":["unsupervised learning","generative adversarial networks","deep generative modelling"],"authorids":["ICLR.cc/2019/Conference/Paper828/Authors"],"authors":["Anonymous"],"TL;DR":"A simple GAN modification that improves performance across many losses, architectures, regularization schemes, and datasets. ","pdf":"/pdf/181b90e18f809a4a325e432f60d6314f1b407a65.pdf","paperhash":"anonymous|on_self_modulation_for_generative_adversarial_networks","_bibtex":"@inproceedings{    \nanonymous2019on,    \ntitle={On Self Modulation for Generative Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hkl5aoR5tm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJzqpj09YQ","original":"SyxAhGTcFm","number":829,"cdate":1538087874175,"ddate":null,"tcdate":1538087874175,"tmdate":1538156048278,"tddate":null,"forum":"SJzqpj09YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Spectral Inference Networks: Unifying Deep and Spectral Learning","abstract":"We present Spectral Inference Networks, a framework for learning eigenfunctions of linear operators by stochastic optimization. Spectral Inference Networks generalize Slow Feature Analysis to generic symmetric operators, and are closely related to Variational Monte Carlo methods from computational physics. As such, they can be a powerful tool for unsupervised representation learning from video or graph-structured data. We cast training Spectral Inference Networks as a bilevel optimization problem, which allows for online learning of multiple eigenfunctions. We show results of training Spectral Inference Networks on problems in quantum mechanics and feature learning for videos on synthetic datasets. Our results demonstrate that Spectral Inference Networks accurately recover eigenfunctions of linear operators and can discover interpretable representations from video in a fully unsupervised manner.","keywords":["spectral learning","unsupervised learning","manifold learning","dimensionality reduction"],"authorids":["ICLR.cc/2019/Conference/Paper829/Authors"],"authors":["Anonymous"],"TL;DR":"We show how to learn spectral decompositions of linear operators with deep learning, and use it for unsupervised learning without a generative model.","pdf":"/pdf/3f810c4e2639cf662a748a92cd363640961e687a.pdf","paperhash":"anonymous|spectral_inference_networks_unifying_deep_and_spectral_learning","_bibtex":"@inproceedings{    \nanonymous2019spectral,    \ntitle={Spectral Inference Networks: Unifying Deep and Spectral Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJzqpj09YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Bkg5aoAqKm","original":"Bye6Yq35YX","number":830,"cdate":1538087874345,"ddate":null,"tcdate":1538087874345,"tmdate":1538156048067,"tddate":null,"forum":"Bkg5aoAqKm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Fast Binary Functional Search on Graph","abstract":"The large-scale search is an essential task in modern information systems. Numerous learning based models are proposed to capture semantic level similarity measures for searching or ranking. However, these measures are usually complicated and beyond metric distances. As Approximate Nearest Neighbor Search (ANNS) techniques have specifications on metric distances, efficient searching by advanced measures is still an open question. In this paper, we formulate large-scale search as a general task, Optimal Binary Functional Search (OBFS), which contains ANNS as special cases. We analyze existing OBFS methods' limitations and explain they are not applicable for complicated searching measures. We propose a flexible graph-based solution for OBFS, Search on L2 Graph (SL2G). SL2G approximates gradient decent in Euclidean space, with accessible conditions. Experiments demonstrate SL2G's efficiency in searching by advanced matching measures (i.e., Neural Network based measures).","keywords":["Binary Functional Search","Large-scale Search","Approximate Nearest Neighbor Search"],"authorids":["ICLR.cc/2019/Conference/Paper830/Authors"],"authors":["Anonymous"],"TL;DR":"Efficient Search by Neural Network based searching measures.","pdf":"/pdf/b7f06788fb2a748faf143e0e0dab1c826e0d32f4.pdf","paperhash":"anonymous|fast_binary_functional_search_on_graph","_bibtex":"@inproceedings{    \nanonymous2019fast,    \ntitle={Fast Binary Functional Search on Graph},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkg5aoAqKm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Bke96sC5tm","original":"BylyDcTcYm","number":831,"cdate":1538087874510,"ddate":null,"tcdate":1538087874510,"tmdate":1538156047859,"tddate":null,"forum":"Bke96sC5tm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning","abstract":"Model-based reinforcement learning (RL) methods can be broadly categorized as global model methods, which depend on learning models that provide sensible predictions in a wide range of states, or local model methods, which iteratively refit simple models that are used for policy improvement. While predicting future states that will result from the current actions is difficult, local model methods only attempt to understand system dynamics in the neighborhood of the current policy, making it possible to produce local improvements without ever learning to predict accurately far into the future. The main idea in this paper is that we can learn representations that make it easy to retrospectively infer simple dynamics given the data from the current policy, thus enabling local models to be used for policy learning in complex systems. We evaluate our approach against other model-based and model-free RL methods on a suite of robotics tasks, including manipulation tasks on a real Sawyer robotic arm directly from camera images.","keywords":["model-based reinforcement learning","structured representation learning","robotics"],"authorids":["ICLR.cc/2019/Conference/Paper831/Authors"],"authors":["Anonymous"],"pdf":"/pdf/29031d74629b883626388899f6f0a678086506df.pdf","paperhash":"anonymous|solar_deep_structured_representations_for_modelbased_reinforcement_learning","_bibtex":"@inproceedings{    \nanonymous2019solar:,    \ntitle={SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bke96sC5tm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1espiA9YQ","original":"HJgwv_s5Y7","number":832,"cdate":1538087874678,"ddate":null,"tcdate":1538087874678,"tmdate":1538156047643,"tddate":null,"forum":"r1espiA9YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Towards More Theoretically-Grounded Particle Optimization Sampling for Deep Learning","abstract":"Many deep-learning based methods such as Bayesian deep learning (DL) and deep reinforcement learning (RL) have heavily relied on the ability of a model being able to efficiently explore via Bayesian sampling. Particle-optimization sampling (POS) is a recently developed technique to generate high-quality samples from a target distribution by iteratively updating a set of interactive particles, with a representative algorithm the Stein variational gradient descent (SVGD). Though obtaining significant empirical success, the {\\em non-asymptotic} convergence behavior of SVGD remains unknown. In this paper, we generalize POS to a stochasticity setting by injecting random noise in particle updates, called stochastic particle-optimization sampling (SPOS). Notably, for the first time, we develop {\\em non-asymptotic convergence theory} for the SPOS framework, characterizing convergence of a sample approximation w.r.t.\\! the number of particles and iterations under both convex- and noncovex-energy-function settings. Interestingly, we provide theoretical understanding of a pitfall of SVGD that can be avoided in the proposed SPOS framework, {\\it i.e.}, particles tend to collapse to a local mode in SVGD under some particular conditions. Our theory is based on the analysis of nonlinear stochastic differential equations, which serves as an extension and a complementary development to the asymptotic convergence theory for SVGD such as (Liu, 2017). With such theoretical guarantees, SPOS can be safely and effectively applied on both Bayesian DL and deep RL tasks. Extensive results demonstrate the effectiveness of our proposed framework.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper832/Authors"],"authors":["Anonymous"],"pdf":"/pdf/2e16c0caeecd6f0a70b31e2ba4dba6b90a54d84b.pdf","paperhash":"anonymous|towards_more_theoreticallygrounded_particle_optimization_sampling_for_deep_learning","_bibtex":"@inproceedings{    \nanonymous2019towards,    \ntitle={Towards More Theoretically-Grounded Particle Optimization Sampling for Deep Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1espiA9YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Bylj6oC5K7","original":"Ske5kV4cKX","number":833,"cdate":1538087874860,"ddate":null,"tcdate":1538087874860,"tmdate":1538156047431,"tddate":null,"forum":"Bylj6oC5K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Logit Regularization Methods for Adversarial Robustness","abstract":"While great progress has been made at making neural networks effective across a wide range of tasks, many are surprisingly vulnerable to small, carefully chosen perturbations of their input, known as adversarial examples. In this paper, we advocate for and experimentally investigate the use of logit regularization techniques as an adversarial defense, which can be used in conjunction with other methods for creating adversarial robustness at little to no cost. We demonstrate that much of the effectiveness of one recent adversarial defense mechanism can be attributed to logit regularization and show how to improve its defense against both white-box and black-box attacks, in the process creating a stronger black-box attacks against PGD-based models.\n","keywords":["adversarial"],"authorids":["ICLR.cc/2019/Conference/Paper833/Authors"],"authors":["Anonymous"],"TL;DR":"Logit regularization methods help explain and improve state of the art adversarial defenses","pdf":"/pdf/e9c2bf2cd826b46016825ad0131402099c694fd5.pdf","paperhash":"anonymous|logit_regularization_methods_for_adversarial_robustness","_bibtex":"@inproceedings{    \nanonymous2019logit,    \ntitle={Logit Regularization Methods for Adversarial Robustness},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bylj6oC5K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJej6jR5Fm","original":"rkxwdqp5tX","number":834,"cdate":1538087875035,"ddate":null,"tcdate":1538087875035,"tmdate":1538156047220,"tddate":null,"forum":"HJej6jR5Fm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Meta-Learning to Guide Segmentation","abstract":"There are myriad kinds of segmentation, and ultimately the `\"right\" segmentation of a given scene is in the eye of the annotator. Standard approaches require large amounts of labeled data to learn just one particular kind of segmentation. As a first step towards relieving this annotation burden, we propose the problem of guided segmentation: given varying amounts of pixel-wise labels, segment unannotated pixels by propagating supervision locally (within an image) and non-locally (across images). We propose guided networks, which extract a latent task representation---guidance---from variable amounts and classes (categories, instances, etc.) of pixel supervision and optimize our architecture end-to-end for fast, accurate, and data-efficient segmentation by meta-learning. To span the few-shot and many-shot learning regimes, we examine guidance from as little as one pixel per concept to as much as 1000+ images, and compare to full gradient optimization at both extremes. To explore generalization, we analyze guidance as a bridge between different levels of supervision to segment classes as the union of instances. Our segmentor concentrates different amounts of supervision of different types of classes into an efficient latent representation, non-locally propagates this supervision across images, and can be updated quickly and cumulatively when given more supervision.","keywords":["meta-learning","few-shot learning","visual segmentation"],"authorids":["ICLR.cc/2019/Conference/Paper834/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a meta-learning approach for guiding visual segmentation tasks from varying amounts of supervision.","pdf":"/pdf/3ac16d4d3a45c356c87356f19da22b72633ebd66.pdf","paperhash":"anonymous|metalearning_to_guide_segmentation","_bibtex":"@inproceedings{    \nanonymous2019meta-learning,    \ntitle={Meta-Learning to Guide Segmentation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJej6jR5Fm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryGs6iA5Km","original":"Hyg-Tz65t7","number":835,"cdate":1538087875216,"ddate":null,"tcdate":1538087875216,"tmdate":1538156047009,"tddate":null,"forum":"ryGs6iA5Km","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"How Powerful are Graph Neural Networks?","abstract":"Graph Neural Networks (GNNs) for representation learning of graphs broadly follow a neighborhood aggregation framework, where the representation vector of a node is computed by recursively aggregating and transforming feature vectors of its neighboring nodes. Many GNN variants have been proposed and have achieved state-of-the-art results on both node and graph classification tasks. However, despite GNNs revolutionizing graph representation learning, there is limited understanding of their representational properties and limitations. Here, we present a theoretical framework for analyzing the expressive power of GNNs in capturing different graph structures. Our results characterize the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they cannot learn to distinguish certain simple graph structures. We then develop a simple architecture that is provably the most expressive among the class of GNNs and is as powerful as the Weisfeiler-Lehman graph isomorphism test. We empirically validate our theoretical findings on a number of graph classification benchmarks, and demonstrate that our model achieves state-of-the-art performance.","keywords":["graph neural networks","theory","deep learning","representational power","graph isomorphism","deep multisets"],"authorids":["ICLR.cc/2019/Conference/Paper835/Authors"],"authors":["Anonymous"],"TL;DR":"We develop theoretical foundations for expressive power of GNNs and design a provably most powerful GNN.","pdf":"/pdf/acd1a73827c779cf7f0ea7c39da0f0d9c32aaa5d.pdf","paperhash":"anonymous|how_powerful_are_graph_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019how,    \ntitle={How Powerful are Graph Neural Networks?},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryGs6iA5Km},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1xipsA5K7","original":"S1xCQxO5Y7","number":836,"cdate":1538087875382,"ddate":null,"tcdate":1538087875382,"tmdate":1538156046800,"tddate":null,"forum":"H1xipsA5K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Two-layer Neural Networks with Symmetric Inputs","abstract":"We give a new algorithm for learning a two-layer neural network under a very general class of input distributions. Assuming there is a ground-truth two-layer network \ny = A \\sigma(Wx) + \\xi,\nwhere A, W are weight matrices, \\xi represents noise, and the number of neurons in the hidden layer is no larger than the input or output,  our algorithm is guaranteed to recover the parameters A, W of the ground-truth network. The only requirement on the input x is that it is symmetric, which still allows highly complicated and structured input. \n\nOur algorithm is based on the method-of-moments framework and extends several results in tensor decompositions. We use spectral algorithms to avoid the complicated non-convex optimization in learning neural networks. Experiments show that our algorithm can robustly learn the ground-truth neural network with a small number of samples for many symmetric input distributions.","keywords":["Neural Network","Optimization","Symmetric Inputs","Moment-of-moments"],"authorids":["ICLR.cc/2019/Conference/Paper836/Authors"],"authors":["Anonymous"],"TL;DR":"We give an algorithm for learning a two-layer neural network with symmetric input distribution. ","pdf":"/pdf/ab33fd107eba22bdb51d89c615590553daf03c7e.pdf","paperhash":"anonymous|learning_twolayer_neural_networks_with_symmetric_inputs","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Two-layer Neural Networks with Symmetric Inputs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1xipsA5K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1x2aiRqFX","original":"BkeMaOi5t7","number":837,"cdate":1538087875546,"ddate":null,"tcdate":1538087875546,"tmdate":1538156046587,"tddate":null,"forum":"S1x2aiRqFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Differentiable Expected BLEU for Text Generation","abstract":"Neural text generation models such as recurrent networks are typically trained by maximizing data log-likelihood based on cross entropy. Such training objective shows a discrepancy from test criteria like the BLEU metric. Recent work optimizes expected BLEU under the model distribution using policy gradient, while such algorithm can suffer from high variance and become impractical. In this paper, we propose a new Differentiable Expected BLEU (DEBLEU) objective that permits direct optimization of neural generation models with gradient descent. We leverage the decomposability and sparsity of BLEU, and reformulate it with moderate approximations, making the evaluation of the objective and its gradient efficient, comparable to common cross-entropy loss. We further devise a simple training procedure with ground-truth masking and annealing for stable optimization. Experiments on neural machine translation and image captioning show our method significantly improves over both cross-entropy and policy gradient training.","keywords":["text generation","BLEU","differentiable","gradient descent","maximum likelihood learning","policy gradient","machine translation"],"authorids":["ICLR.cc/2019/Conference/Paper837/Authors"],"authors":["Anonymous"],"TL;DR":"A new differentiable expected BLEU objective that is end-to-end trainable with gradient descent for neural text generation models","pdf":"/pdf/3f04f582cf9897abacd3f6adf8a61179dcb14c52.pdf","paperhash":"anonymous|differentiable_expected_bleu_for_text_generation","_bibtex":"@inproceedings{    \nanonymous2019differentiable,    \ntitle={Differentiable Expected BLEU for Text Generation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1x2aiRqFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkgnpiR9Y7","original":"r1elfJzqF7","number":838,"cdate":1538087875731,"ddate":null,"tcdate":1538087875731,"tmdate":1538156046382,"tddate":null,"forum":"HkgnpiR9Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Recycling the discriminator for improving the inference mapping of GAN","abstract":"Generative adversarial networks (GANs) have achieved outstanding success in generating the high-quality data. Focusing on the generation process, existing GANs learn a unidirectional mapping from the latent vector to the data. Later, various studies point out that the latent space of GANs is semantically meaningful and can be utilized in advanced data analysis and manipulation. In order to analyze the real data in the latent space of GANs, it is necessary to investigate the inverse generation mapping from the data to the latent vector. To tackle this problem, the bidirectional generative models introduce an encoder to establish the inverse path of the generation process. Unfortunately, this effort leads to the degradation of generation quality because the imperfect generator rather interferes the encoder training and vice versa. \nIn this paper, we propose an effective algorithm to infer the latent vector based on existing unidirectional GANs by preserving their generation quality.\nIt is important to note that we focus on increasing the accuracy and efficiency of the inference mapping but not influencing the GAN performance (i.e., the quality or the diversity of the generated sample).\nFurthermore, utilizing the proposed inference mapping algorithm, we suggest a new metric for evaluating the GAN models by measuring the reconstruction error of unseen real data.\nThe experimental analysis demonstrates that the proposed algorithm achieves more accurate inference mapping than the existing method and provides the robust metric for evaluating GAN performance. ","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper838/Authors"],"authors":["Anonymous"],"pdf":"/pdf/4565c705d620e8928226d545ab5423b812f5f05c.pdf","paperhash":"anonymous|recycling_the_discriminator_for_improving_the_inference_mapping_of_gan","_bibtex":"@inproceedings{    \nanonymous2019recycling,    \ntitle={Recycling the discriminator for improving the inference mapping of GAN},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkgnpiR9Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1MhpiRqFm","original":"BJgs6l99FQ","number":839,"cdate":1538087875904,"ddate":null,"tcdate":1538087875904,"tmdate":1538156046151,"tddate":null,"forum":"B1MhpiRqFm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Boltzmann Weighting Done Right in Reinforcement Learning","abstract":"The Boltzmann softmax operator can trade-off well between exploration and exploitation according to current estimation in an exponential weighting scheme, which is a promising way to address the exploration-exploitation dilemma in reinforcement learning. Unfortunately, the Boltzmann softmax operator is not a non-expansion, which may lead to unstable or even divergent learning behavior when used in estimating the value function. The convergence of value iteration is guaranteed in a restricted set of non-expansive operators and how to characterize the effect of such non-expansive operators in value iteration remains an open problem. In this paper, we propose a new technique to analyze the error bound of value iteration with the the Boltzmann softmax operator. We then propose the dynamic Boltzmann softmax(DBS) operator to enable the convergence to the optimal value function in value iteration. We also present convergence rate analysis of the algorithm. Using Q-learning as an application, we show that the DBS operator can be applied in a model-free reinforcement learning algorithm. Finally, we demonstrate the effectiveness of the DBS operator in a toy problem called GridWorld and a suite of Atari games. Experimental results show that outperforms DQN substantially in benchmark games. ","keywords":["Reinforcement Learning","Boltzmann Softmax Operator","Exploration-Exploitation Dilemma"],"authorids":["ICLR.cc/2019/Conference/Paper839/Authors"],"authors":["Anonymous"],"pdf":"/pdf/29e7e036064114b61e1574b91a9ed0a5f28f2dd1.pdf","paperhash":"anonymous|boltzmann_weighting_done_right_in_reinforcement_learning","_bibtex":"@inproceedings{    \nanonymous2019boltzmann,    \ntitle={Boltzmann Weighting Done Right in Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1MhpiRqFm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJe3TsR5K7","original":"ryxkdPtcKm","number":840,"cdate":1538087876079,"ddate":null,"tcdate":1538087876079,"tmdate":1538156045936,"tddate":null,"forum":"HJe3TsR5K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Joint Wasserstein Auto-Encoders for Joint Distribution Matching","abstract":"We study the joint distribution matching problem which aims at learning bidirectional mappings to match the joint distribution of two domains. This problem occurs in unsupervised image-to-image translation and video-to-video synthesis tasks, which, however, has two critical challenges: (i) it is difficult to exploit sufficient information from the joint distribution; (ii) how to theoretically and experimentally evaluate the generalization performance remains an open question. To address the above challenges, we propose a new optimization problem and design a novel Joint Wasserstein Auto-Encoders (JWAE) to minimize the Wasserstein distance of the joint distributions in two domains. We theoretically prove that the generalization ability of the proposed method can be guaranteed by minimizing the Wasserstein distance of joint distributions. To verify the generalization ability, we apply our method to unsupervised video-to-video synthesis by performing video frame interpolation and producing visually smooth videos in two domains, simultaneously. Both qualitative and quantitative comparisons demonstrate the superiority of our method over several state-of-the-arts.","keywords":["joint distribution matching","video-to-video synthesis","Wasserstein distance"],"authorids":["ICLR.cc/2019/Conference/Paper840/Authors"],"authors":["Anonymous"],"TL;DR":"Learning Joint Wasserstein Auto-Encoders for Joint Distribution Matching","pdf":"/pdf/44f17663f2e769ad85ad6a9f298813e265ed6685.pdf","paperhash":"anonymous|learning_joint_wasserstein_autoencoders_for_joint_distribution_matching","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Joint Wasserstein Auto-Encoders for Joint Distribution Matching},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJe3TsR5K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rylhToC5YQ","original":"SklUHxncFX","number":841,"cdate":1538087876245,"ddate":null,"tcdate":1538087876245,"tmdate":1538156045734,"tddate":null,"forum":"rylhToC5YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Unsupervised Neural Multi-Document Abstractive Summarization","abstract":"Abstractive summarization has been studied using neural sequence transduction methods with datasets of large, paired document-summary examples. However, such datasets are rare and the models trained from them do not generalize to other domains. Recently, some progress has been made in learning sequence-to-sequence mappings with only unpaired examples. In our work, we consider the setting where there are only documents and no summaries provided and propose an end-to-end, neural model architecture to perform unsupervised abstractive summarization. Our proposed model consists of an auto-encoder trained so that the mean of the representations of the input documents decodes to a reasonable summary. We consider variants of the proposed architecture and perform an ablation study to show the importance of specific components. We apply our model to the summarization of business and product reviews and show that the generated summaries are fluent, show relevancy in terms of word-overlap, representative of the average sentiment of the input documents, and are highly abstractive compared to baselines. The code to reproduce results is available at github.com/REDACTED.","keywords":["unsupervised learning","abstractive summarization","reviews","text generation"],"authorids":["ICLR.cc/2019/Conference/Paper841/Authors"],"authors":["Anonymous"],"TL;DR":"We propose an end-to-end neural model for unsupervised multi-document abstractive summarization, applying it to business and product reviews.","pdf":"/pdf/4630a6d4b3bd013131d6e26194769de8c05ed784.pdf","paperhash":"anonymous|unsupervised_neural_multidocument_abstractive_summarization","_bibtex":"@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Neural Multi-Document Abstractive Summarization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylhToC5YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJl2ps0qKQ","original":"HkeCV5pqF7","number":842,"cdate":1538087876420,"ddate":null,"tcdate":1538087876420,"tmdate":1538156045528,"tddate":null,"forum":"SJl2ps0qKQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning to Decompose Compound Questions with Reinforcement Learning","abstract":"As for knowledge-based question answering, a fundamental problem is to relax the assumption of answerable questions from simple questions to compound questions. Traditional approaches firstly detect topic entity mentioned in questions, then traverse the knowledge graph to find relations as a multi-hop path to answers, while we propose a novel approach to leverage simple-question answerer to answer compound questions. Our model consists of two components: (i) a novel learning-to-decompose agent that learns a policy to decompose a compound question into simple questions and (ii) a simple-question answerer that classifies the corresponding relation to answers. Experiments demonstrate that our model learns complex rules of compositionality as policy, which benefits a simple neural network to achieve state-of-the-art results on the most challenging research dataset. We analyze the interpretable decomposition process as well as generated partitions.","keywords":["Compound Question Decomposition","Reinforcement Learning","Knowledge-Based Question Answering","Learning-to-decompose"],"authorids":["ICLR.cc/2019/Conference/Paper842/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a learning-to-decompose agent that helps a simple-question answerer to answer compound question over knowledge graph.","pdf":"/pdf/91e8d02212378cb6963e832dacd0a39229ce2aad.pdf","paperhash":"anonymous|learning_to_decompose_compound_questions_with_reinforcement_learning","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Decompose Compound Questions with Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJl2ps0qKQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJl6TjRcY7","original":"Hyl_T8KcF7","number":843,"cdate":1538087876585,"ddate":null,"tcdate":1538087876585,"tmdate":1538156045324,"tddate":null,"forum":"BJl6TjRcY7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Neural Probabilistic Motor Primitives for Humanoid Control","abstract":"Transferring functional properties from one or multiple expert policies to a student policy is an important challenge in control. Expert robustness is of particular interest; we would like to not only transfer the expert behavior but also its ability to recover from perturbations.  With this in mind, we explore approaches for policy cloning and propose linear feedback policy cloning as a simple option for certain settings.  We show that it can be surprisingly straightforward to clone ex-pert policies for seemingly complex behaviors without the student requiring any environment interactions. We then propose a latent-variable architecture that bottlenecks a sensory-motor primitive space,  which,  again,  can be trained entirely offline to compress thousands of expert policies.  We show this resulting neural probabilistic motor primitive system produces robust one-shot imitation of whole-body humanoid behaviors.  In addition, we analyze the resulting latent space and demonstrate the ability to reuse this system. We encourage readers to view a supplementary video (https://youtu.be/44tPXdUCc-g ) summarizing our results.","keywords":["Motor Primitives","Distillation","Reinforcement Learning","Continuous Control","Humanoid Control","Motion Capture","One-Shot Imitation"],"authorids":["ICLR.cc/2019/Conference/Paper843/Authors"],"authors":["Anonymous"],"TL;DR":"Neural Probabilistic Motor Primitives compress motion capture tracking policies into one flexible model capable of one-shot imitation and reuse as a low-level controller.","pdf":"/pdf/a83c14a721e29fbb4c676eab17e795b27adfdc15.pdf","paperhash":"anonymous|neural_probabilistic_motor_primitives_for_humanoid_control","_bibtex":"@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Probabilistic Motor Primitives for Humanoid Control},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJl6TjRcY7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJeapjA5FX","original":"HkxBgsacK7","number":844,"cdate":1538087876762,"ddate":null,"tcdate":1538087876762,"tmdate":1538156045110,"tddate":null,"forum":"BJeapjA5FX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"GEOMETRIC AUGMENTATION FOR ROBUST NEURAL NETWORK CLASSIFIERS","abstract":"We introduce a novel geometric perspective and unsupervised model augmentation framework for transforming traditional deep (convolutional) neural networks into adversarially robust classifiers. Class-conditional probability densities based on Bayesian nonparametric mixtures of factor analyzers (BNP-MFA) over the input space are used to design soft decision labels for feature to label isometry. Classconditional distributions over features are also learned using BNP-MFA to develop plug-in maximum a posterior (MAP) classifiers to replace the traditional multinomial logistic softmax classification layers. This novel unsupervised augmented framework, which we call geometrically robust networks (GRN), is applied to CIFAR-10, CIFAR-100, and to Radio-ML (a time series dataset for radio modulation recognition). We demonstrate the robustness of GRN models to adversarial attacks from fast gradient sign method, Carlini-Wagner, and projected gradient descent.","keywords":["Bayesian nonparametric","robust","deep neural network","classifier","unsupervised learning","geometric"],"authorids":["ICLR.cc/2019/Conference/Paper844/Authors"],"authors":["Anonymous"],"TL;DR":"We develop a statistical-geometric unsupervised learning augmentation framework for deep neural networks to make them robust to adversarial attacks.","pdf":"/pdf/2192f3eb60d60878d29534558e1494bd1ec29eec.pdf","paperhash":"anonymous|geometric_augmentation_for_robust_neural_network_classifiers","_bibtex":"@inproceedings{    \nanonymous2019geometric,    \ntitle={GEOMETRIC AUGMENTATION FOR ROBUST NEURAL NETWORK CLASSIFIERS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJeapjA5FX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJgTTjA9tX","original":"r1ejl6AKYQ","number":845,"cdate":1538087876930,"ddate":null,"tcdate":1538087876930,"tmdate":1538156044704,"tddate":null,"forum":"rJgTTjA9tX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"The Comparative Power of ReLU Networks and Polynomial Kernels in the Presence of Sparse Latent Structure","abstract":"There has been a large amount of interest, both in the past and particularly recently, into the relative advantage of different families of universal function approximators, for instance neural networks, polynomials, rational functions, etc. However, current research has focused almost exclusively on understanding this problem in a worst case setting: e.g. characterizing the best L1 or L_{infty} approximation in a box (or sometimes, even under an adversarially constructed data distribution.) In this setting many classical tools from approximation theory can be effectively used.\n\nHowever, in typical applications we expect data to be high dimensional, but structured -- so, it would only be important to approximate the desired function well on the relevant part of its domain, e.g. a small manifold on which real input data actually lies. Moreover, even within this domain the desired quality of approximation may not be uniform; for instance in classification problems, the approximation needs to be more accurate near the decision boundary. These issues, to the best of our knowledge, have remain unexplored until now.\n\t\nWith this in mind, we analyze the performance of neural networks and polynomial kernels in a natural regression setting where the data enjoys sparse latent structure, and the labels depend in a simple way on the latent variables. We give an almost-tight theoretical analysis of the performance of both neural networks and polynomials for this problem, as well as verify our theory with simulations. Our results both involve new (complex-analytic) techniques, which may be of independent interest, and show substantial qualitative differences with what is known in the worst-case setting.","keywords":["theory","representational power","universal approximators","polynomial kernels","latent sparsity","beyond worst case","separation result"],"authorids":["ICLR.cc/2019/Conference/Paper845/Authors"],"authors":["Anonymous"],"TL;DR":"Beyond-worst-case analysis of the representational power of  ReLU nets & polynomial kernels  -- in particular in the presence of sparse latent structure.","pdf":"/pdf/7feceaed0bc654b643c4b5b607c360e1ce0f3215.pdf","paperhash":"anonymous|the_comparative_power_of_relu_networks_and_polynomial_kernels_in_the_presence_of_sparse_latent_structure","_bibtex":"@inproceedings{    \nanonymous2019the,    \ntitle={The Comparative Power of ReLU Networks and Polynomial Kernels in the Presence of Sparse Latent Structure},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJgTTjA9tX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyepTiR9FQ","original":"S1xulja9YX","number":846,"cdate":1538087877101,"ddate":null,"tcdate":1538087877101,"tmdate":1538156044494,"tddate":null,"forum":"SyepTiR9FQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"PointGrow: Autoregressively Learned Point Cloud Generation with Self-Attention","abstract":"A point cloud is an agile 3D representation, efficiently modeling an object's surface geometry. However, these surface-centric properties also pose challenges on designing tools to recognize and synthesize point clouds. This work presents a novel autoregressive model, PointGrow, which generates realistic point cloud samples from scratch or conditioned from given semantic contexts. Our model operates recurrently, with each point sampled according to a conditional distribution given its previously-generated points. Since point cloud object shapes are typically encoded by long-range interpoint dependencies, we augment our model with dedicated self-attention modules to capture these relations. Extensive evaluation demonstrates that PointGrow achieves satisfying performance on both unconditional and conditional point cloud generation tasks, with respect to fidelity, diversity and semantic preservation. Further, conditional PointGrow learns a smooth manifold of given images where 3D shape interpolation and arithmetic calculation can be performed inside.","keywords":["point cloud generation","autoregressive models","self-attention"],"authorids":["ICLR.cc/2019/Conference/Paper846/Authors"],"authors":["Anonymous"],"TL;DR":"An autoregressive deep learning model for generating diverse point clouds.","pdf":"/pdf/c9e3a37e38f9e26e022541f58fc54c96ea91602f.pdf","paperhash":"anonymous|pointgrow_autoregressively_learned_point_cloud_generation_with_selfattention","_bibtex":"@inproceedings{    \nanonymous2019pointgrow:,    \ntitle={PointGrow: Autoregressively Learned Point Cloud Generation with Self-Attention},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyepTiR9FQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJgTps0qtQ","original":"Bklk-sTct7","number":847,"cdate":1538087877275,"ddate":null,"tcdate":1538087877275,"tmdate":1538156044288,"tddate":null,"forum":"SJgTps0qtQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Exploiting Environmental Variation to Improve Policy Robustness in  Reinforcement Learning","abstract":"Conventional reinforcement learning rarely considers how the physical variations in the environment (eg. mass, drag, etc.) affect the policy learned by the agent. In this paper, we explore how changes in the environment affect  policy generalization. We observe experimentally that, for each task we considered, there exists an optimal environment setting that results in the most robust policy that generalizes well to future environments. We propose a novel method to exploit this observation to develop robust actor policies, by automatically developing a sampling curriculum over environment settings to use in training. Ours is a model-free approach and experiments demonstrate that the performance of our method is on par with the best policies found by an exhaustive grid search, while bearing a significantly lower computational cost.","keywords":["Reinforcement Learning","Policy Robustness","Policy generalization","Automated Curriculum"],"authorids":["ICLR.cc/2019/Conference/Paper847/Authors"],"authors":["Anonymous"],"TL;DR":"By formulating the learning curriculum as a bandit problem, we present a principled approach to motivating policy robustness in continuous controls tasks.","pdf":"/pdf/4eccff5dd6ccd2dd8a84b0e817db7733c56cdb1c.pdf","paperhash":"anonymous|exploiting_environmental_variation_to_improve_policy_robustness_in_reinforcement_learning","_bibtex":"@inproceedings{    \nanonymous2019exploiting,    \ntitle={Exploiting Environmental Variation to Improve Policy Robustness in  Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJgTps0qtQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SkGT6sRcFX","original":"B1x1Xta5KQ","number":848,"cdate":1538087877444,"ddate":null,"tcdate":1538087877444,"tmdate":1538156044082,"tddate":null,"forum":"SkGT6sRcFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Infinitely Deep Infinite-Width Networks","abstract":"Infinite-width neural networks have been extensively used to study the theoretical properties underlying the extraordinary empirical success of standard, finite-width neural networks. Nevertheless, until now, infinite-width networks have been limited to at most two hidden layers. To address this shortcoming, we study the initialisation requirements of these networks and show that the main challenge for constructing them is defining the appropriate sampling distributions for the weights. Based on these observations, we propose a principled approach to weight initialisation that correctly accounts for the functional nature of the hidden layer activations and facilitates the construction of arbitrarily many infinite-width layers, thus enabling the construction of arbitrarily deep infinite-width networks. The main idea of our approach is to iteratively reparametrise the hidden-layer activations into appropriately defined reproducing kernel Hilbert spaces and use the canonical way of constructing probability distributions over these spaces for specifying the required weight distributions in a principled way. Furthermore, we examine the practical implications of this construction for standard, finite-width networks. In particular, we derive a novel weight initialisation scheme for standard, finite-width networks that takes into account the structure of the data and information about the task at hand. We demonstrate the effectiveness of this weight initialisation approach on the MNIST, CIFAR-10 and Year Prediction MSD datasets.","keywords":["Infinite-width networks","initialisation","kernel methods","reproducing kernel Hilbert spaces","Gaussian processes"],"authorids":["ICLR.cc/2019/Conference/Paper848/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a method for the construction of arbitrarily deep infinite-width networks, based on which we derive a novel weight initialisation scheme for finite-width networks and demonstrate its competitive performance.","pdf":"/pdf/e99c6267511df6941bfe62d71a1549e15f3d9620.pdf","paperhash":"anonymous|infinitely_deep_infinitewidth_networks","_bibtex":"@inproceedings{    \nanonymous2019infinitely,    \ntitle={Infinitely Deep Infinite-Width Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkGT6sRcFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1g0piA9tQ","original":"HJgyvUoqYm","number":849,"cdate":1538087877629,"ddate":null,"tcdate":1538087877629,"tmdate":1538156043879,"tddate":null,"forum":"H1g0piA9tQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Evaluation Methodology for Attacks Against Confidence Thresholding Models","abstract":"Current machine learning algorithms can be easily fooled by adversarial examples. One possible solution path is to make models that use confidence thresholding to avoid making mistakes. Such models refuse to make a prediction when they are not confident of their answer. We propose to evaluate such models in terms of tradeoff curves with the goal of high success rate on clean examples and low failure rate on adversarial examples. Existing untargeted attacks developed for models that do not use confidence thresholding tend to underestimate such models' vulnerability. We propose the MaxConfidence family of attacks, which are optimal in a variety of theoretical settings, including one realistic setting: attacks against linear models. Experiments show the attack attains good results in practice. We show that simple defenses are able to perform well on MNIST but not on CIFAR, contributing further to previous calls that MNIST should be retired as a benchmarking dataset for adversarial robustness research.  We release code for these evaluations as part of the cleverhans (Papernot et al 2018) library  (ICLR reviewers should be careful not to look at who contributed these features to cleverhans to avoid de-anonymizing this submission).","keywords":["adversarial examples"],"authorids":["ICLR.cc/2019/Conference/Paper849/Authors"],"authors":["Anonymous"],"TL;DR":"We present metrics and an optimal attack for evaluating models that defend against adversarial examples using confidence thresholding","pdf":"/pdf/58ee81bbb9ab33424599a4a7ac6ff9642b54721a.pdf","paperhash":"anonymous|evaluation_methodology_for_attacks_against_confidence_thresholding_models","_bibtex":"@inproceedings{    \nanonymous2019evaluation,    \ntitle={Evaluation Methodology for Attacks Against Confidence Thresholding Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1g0piA9tQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SkeRTsAcYm","original":"ryg5G0OqYm","number":850,"cdate":1538087877800,"ddate":null,"tcdate":1538087877800,"tmdate":1538156043665,"tddate":null,"forum":"SkeRTsAcYm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Phase-Aware Speech Enhancement with Deep Complex U-Net","abstract":"Most deep learning-based models for speech enhancement have mainly focused on estimating the magnitude of spectrogram while reusing the phase from noisy speech for reconstruction. This is due to the difficulty of estimating the phase of clean speech. To improve speech enhancement performance, we tackle the phase estimation problem in three ways. First, we propose Deep Complex U-Net, an advanced U-Net structured model incorporating well-defined complex-valued building blocks to deal with complex-valued spectrograms. Second, we propose a polar coordinate-wise complex-valued masking method to reflect the distribution of complex ideal ratio masks. Third, we define a novel loss function, weighted source-to-distortion ratio (wSDR) loss, which is designed to directly correlate with a quantitative evaluation measure. Our model was evaluated on a mixture of the Voice Bank corpus and DEMAND database, which has been widely used by many deep learning models for speech enhancement. Ablation experiments were conducted on the mixed dataset showing that all three proposed approaches are empirically valid. Experimental results show that the proposed method achieves state-of-the-art performance in all metrics, outperforming previous approaches by a large margin.","keywords":["speech enhancement","deep learning","complex neural networks","phase estimation"],"authorids":["ICLR.cc/2019/Conference/Paper850/Authors"],"authors":["Anonymous"],"TL;DR":"This paper proposes a novel complex masking method for speech enhancement along with a loss function for efficient phase estimation.","pdf":"/pdf/da6374351fa9e59f7d0e1972cb0619c1930a9dd8.pdf","paperhash":"anonymous|phaseaware_speech_enhancement_with_deep_complex_unet","_bibtex":"@inproceedings{    \nanonymous2019phase-aware,    \ntitle={Phase-Aware Speech Enhancement with Deep Complex U-Net},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkeRTsAcYm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJfRpoA9YX","original":"BJgoJPF9YX","number":851,"cdate":1538087877965,"ddate":null,"tcdate":1538087877965,"tmdate":1538156043450,"tddate":null,"forum":"BJfRpoA9YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Adversarial Information Factorization","abstract":"We propose a novel generative model architecture designed to learn representations for images that factor out a single attribute from the rest of the representation. A single object may have many attributes which when altered do not change the identity of the object itself. Consider the human face; the identity of a particular person is independent of whether or not they happen to be wearing glasses. The attribute of wearing glasses can be changed without changing the identity of the person. However, the ability to manipulate and alter image attributes without altering the object identity is not a trivial task. Here, we are interested in learning a representation of the image that separates the identity of an object (such as a human face) from an attribute (such as 'wearing glasses'). We demonstrate the success of our factorization approach by using the learned representation to synthesize the same face with and without a chosen attribute. We refer to this specific synthesis process as image attribute manipulation. We further demonstrate that our model achieves competitive scores, with state of the art, on a facial attribute classification task.","keywords":["disentangled representations","factored representations","generative adversarial networks","variational auto encoders","generative models"],"authorids":["ICLR.cc/2019/Conference/Paper851/Authors"],"authors":["Anonymous"],"TL;DR":"Learn representations for images that factor out a single attribute.","pdf":"/pdf/1f69d9d1a453fe728fc3e0470ffcb5c295173d25.pdf","paperhash":"anonymous|adversarial_information_factorization","_bibtex":"@inproceedings{    \nanonymous2019adversarial,    \ntitle={Adversarial Information Factorization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJfRpoA9YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyMRaoAqKX","original":"HJeStoT5KQ","number":852,"cdate":1538087878137,"ddate":null,"tcdate":1538087878137,"tmdate":1538156043245,"tddate":null,"forum":"HyMRaoAqKX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Implicit Autoencoders","abstract":"In this paper, we describe the \"implicit autoencoder\" (IAE), a generative autoencoder in which both the generative path and the recognition path are parametrized by implicit distributions. We use two generative adversarial networks to define the reconstruction and the regularization cost functions of the implicit autoencoder, and derive the learning rules based on maximum-likelihood learning. Using implicit distributions allows us to learn more expressive posterior and conditional likelihood distributions for the autoencoder. Learning an expressive conditional likelihood distribution enables the latent code to only capture the abstract and high-level information of the data, while the remaining information is captured by the implicit conditional likelihood distribution. For example, we show that implicit autoencoders can disentangle the global and local information, and perform deterministic or stochastic reconstructions of the images. We further show that implicit autoencoders can disentangle discrete underlying factors of variation from the continuous factors in an unsupervised fashion, and perform clustering and semi-supervised learning.","keywords":["Unsupervised Learning","Generative Models","Variational Inference","Generative Adversarial Networks."],"authorids":["ICLR.cc/2019/Conference/Paper852/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.","pdf":"/pdf/da06659e17b1194be8568839f6f8229e6c483a3d.pdf","paperhash":"anonymous|implicit_autoencoders","_bibtex":"@inproceedings{    \nanonymous2019implicit,    \ntitle={Implicit Autoencoders},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyMRaoAqKX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SkVRTj0cYQ","original":"rJlLsXTqt7","number":853,"cdate":1538087878309,"ddate":null,"tcdate":1538087878309,"tmdate":1538156043032,"tddate":null,"forum":"SkVRTj0cYQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Differentially Private Federated Learning: A Client Level Perspective","abstract":"Federated learning is a recent advance in privacy protection. \nIn this context, a trusted curator aggregates parameters optimized in decentralized fashion by multiple clients. The resulting model is then distributed back to all clients, ultimately converging to a joint representative model without explicitly having to share the data. \nHowever, the protocol is vulnerable to differential attacks, which could originate from any party contributing during federated optimization. In such an attack, a client's contribution during training and information about their data set is revealed through analyzing the distributed model. \nWe tackle this problem and propose an algorithm for client sided differential privacy preserving federated optimization. The aim is to hide clients' contributions during training, balancing the trade-off between privacy loss and model performance. \nEmpirical studies suggest that given a sufficiently large number of participating clients, our proposed procedure can maintain client-level differential privacy at only a minor cost in model performance. ","keywords":["Machine Learning","Federated Learning","Privacy","Security","Differential Privacy"],"authorids":["ICLR.cc/2019/Conference/Paper853/Authors"],"authors":["Anonymous"],"TL;DR":"Ensuring that models learned in federated fashion do not reveal a client's participation.","pdf":"/pdf/b0820366c53400ca4be650c144b551219c0b5fe2.pdf","paperhash":"anonymous|differentially_private_federated_learning_a_client_level_perspective","_bibtex":"@inproceedings{    \nanonymous2019differentially,    \ntitle={Differentially Private Federated Learning: A Client Level Perspective},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkVRTj0cYQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r14Aas09Y7","original":"rJx2zoLuFm","number":854,"cdate":1538087878485,"ddate":null,"tcdate":1538087878485,"tmdate":1538156042830,"tddate":null,"forum":"r14Aas09Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"COCO-GAN: Conditional Coordinate Generative Adversarial Network","abstract":"Recent advancements on Generative Adversarial Network (GAN) have inspired a wide range of works that generate synthetic images. However, the current processes have to generate an entire image at once, and therefore resolutions are limited by memory or computational constraints. In this work, we propose COnditional COordinate GAN (COCO-GAN), which generates a specific patch of an image conditioned on a spatial position rather than the entire image at a time. The generated patches are later combined together to form a globally coherent full-image. With this process, we show that the generated image can achieve competitive quality to state-of-the-arts and the generated patches are locally smooth between consecutive neighbors. One direct implication of the COCO-GAN is that it can be applied onto any coordinate systems including the cylindrical systems which makes it feasible for generating panorama images. The fact that the patch generation process is independent to each other inspires a wide range of new applications: firstly, \"Patch-Inspired Image Generation\" enables us to generate the entire image based on a single patch. Secondly, \"Partial-Scene Generation\" allows us to generate images within a customized target region. Finally, thanks to COCO-GAN's patch generation and massive parallelism, which enables combining patches for generating a full-image with higher resolution than state-of-the-arts.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper854/Authors"],"authors":["Anonymous"],"pdf":"/pdf/bf2303ebb30ce5efafa0b3af69b587e16c8ba8ef.pdf","paperhash":"anonymous|cocogan_conditional_coordinate_generative_adversarial_network","_bibtex":"@inproceedings{    \nanonymous2019coco-gan:,    \ntitle={COCO-GAN: Conditional Coordinate Generative Adversarial Network},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r14Aas09Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJxyAjRcFX","original":"rygOhrv5Km","number":855,"cdate":1538087878657,"ddate":null,"tcdate":1538087878657,"tmdate":1538156042624,"tddate":null,"forum":"HJxyAjRcFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Harmonizing Maximum Likelihood with GANs for Multimodal Conditional Generation","abstract":"Recent advances in conditional image generation tasks, such as image-to-image translation and image inpainting, are largely contributed by the success of conditional GAN models, which are often optimized by the joint use of the GAN loss with the reconstruction loss. However, we show that this training recipe shared by almost all existing methods always leads to a suboptimal generator and has one critical side effect: lack of diversity in output samples. In order to accomplish both training stability and multimodal output generation, we propose novel training schemes with a new set of losses that simply replace the reconstruction loss, and thus applicable to any conditional generation tasks. We show this by performing thorough experiments on image-to-image translation, super-resolution, and image inpainting tasks with Cityscapes, and CelebA dataset. A quantitative evaluation also confirms that our methods achieve great diversity of outputs while retaining or even improving the quality of images.","keywords":["conditional GANs","conditional image generation","multimodal generation","reconstruction loss","maximum likelihood estimation","moment matching"],"authorids":["ICLR.cc/2019/Conference/Paper855/Authors"],"authors":["Anonymous"],"TL;DR":"We prove that the mode collapse in conditional GANs is largely attributed to a mismatch between reconstruction loss and GAN loss and introduce a set of novel loss functions as alternatives for reconstruction loss.","pdf":"/pdf/2021a9991ef92be8a8000c861dbda15c49c62e4a.pdf","paperhash":"anonymous|harmonizing_maximum_likelihood_with_gans_for_multimodal_conditional_generation","_bibtex":"@inproceedings{    \nanonymous2019harmonizing,    \ntitle={Harmonizing Maximum Likelihood with GANs for Multimodal Conditional Generation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxyAjRcFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1xJAsA5F7","original":"rJlM0fFYKX","number":856,"cdate":1538087878834,"ddate":null,"tcdate":1538087878834,"tmdate":1538156042419,"tddate":null,"forum":"B1xJAsA5F7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Multimodal Graph-to-Graph Translation for Molecule Optimization","abstract":"We view molecule optimization as a graph-to-graph translation problem. The goal is to learn to map from one molecular graph to another with better properties based on an available corpus of paired molecules. Since molecules can be optimized in different ways, there are multiple viable translations for each input graph. A key challenge is therefore to model diverse translation outputs. Our primary contributions include a junction tree encoder-decoder for learning diverse graph translations along with a novel adversarial training method for aligning distributions of molecules. Diverse output distributions in our model are explicitly realized by low-dimensional latent vectors that modulate the translation process. We evaluate our model on multiple molecule optimization tasks and show that our model outperforms previous state-of-the-art baselines by a significant margin. \n","keywords":["graph-to-graph translation","adversarial training"],"authorids":["ICLR.cc/2019/Conference/Paper856/Authors"],"authors":["Anonymous"],"TL;DR":"We introduce a graph-to-graph encoder-decoder framework for learning diverse graph translations.","pdf":"/pdf/c77f0698d8431fed2eb42a3c042a9ceccf35451e.pdf","paperhash":"anonymous|learning_multimodal_graphtograph_translation_for_molecule_optimization","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Multimodal Graph-to-Graph Translation for Molecule Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1xJAsA5F7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJgyAoRqFQ","original":"rkxjtqpctX","number":857,"cdate":1538087879004,"ddate":null,"tcdate":1538087879004,"tmdate":1538156042210,"tddate":null,"forum":"HJgyAoRqFQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"State-Denoised Recurrent Neural Networks","abstract":"Recurrent neural networks (RNNs) are difficult to train on sequence processing tasks, not only because input noise may be amplified through feedback, but also because any inaccuracy in the weights has similar consequences as input noise. We describe a method for denoising the hidden state during training to achieve more robust representations thereby improving generalization performance. Attractor dynamics are incorporated into the hidden state to `clean up' representations at each step of a sequence. The attractor dynamics are trained through an auxillary denoising loss to recover previously experienced hidden states from noisy versions of those states. This state-denoised recurrent neural network (SDRNN) performs multiple steps of internal processing for each external sequence step. On a range of tasks, we show that the SDRNN outperforms a generic RNN as well as a variant of the SDRNN with attractor dynamics on the hidden state but without the auxillary loss. We argue that attractor dynamics---and corresponding connectivity constraints---are an essential component of the deep learning arsenal and should be invoked not only for recurrent networks but also for improving deep feedforward nets and intertask transfer.","keywords":["recurrent nets","attractor nets","denoising","sequence processing"],"authorids":["ICLR.cc/2019/Conference/Paper857/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a mechanism for denoising the internal state of an RNN to improve generalization performance.","pdf":"/pdf/e739554c0f3d38f53d82206aafb0f5335ecb5305.pdf","paperhash":"anonymous|statedenoised_recurrent_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019state-denoised,    \ntitle={State-Denoised Recurrent Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJgyAoRqFQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJe10iC5K7","original":"r1xUnj69FQ","number":858,"cdate":1538087879171,"ddate":null,"tcdate":1538087879171,"tmdate":1538156041999,"tddate":null,"forum":"rJe10iC5K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Modeling Parts, Structure, and System Dynamics via Predictive Learning","abstract":"Humans easily recognize object parts and their hierarchical structure by watching how they move; they can then predict how each part moves in the future. In this paper, we propose a novel formulation that simultaneously learns a hierarchical, disentangled object representation and a dynamics model for object parts from unlabeled videos in a self-supervised manner. Our Parts, Structure, and Dynamics (PSD) model learns to first recognize the object parts via a layered image representation; second, predict hierarchy via a structural descriptor that composes low-level concepts into a hierarchical structure; and third, model the system dynamics by predicting the future. Experiments on multiple real and synthetic datasets demonstrate that our PSD model works well on all three tasks: segmenting object parts, building their hierarchical structure, and capturing their motion distributions.","keywords":["Self-Supervised Learning","Visual Prediction","Hierarchical Models"],"authorids":["ICLR.cc/2019/Conference/Paper858/Authors"],"authors":["Anonymous"],"TL;DR":"Learning object parts, hierarchical structure, and dynamics by watching how they move","pdf":"/pdf/977b962d32ff4e6c3227fd82b1d74d33c0aba99b.pdf","paperhash":"anonymous|modeling_parts_structure_and_system_dynamics_via_predictive_learning","_bibtex":"@inproceedings{    \nanonymous2019modeling,    \ntitle={Modeling Parts, Structure, and System Dynamics via Predictive Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJe10iC5K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1gkAoA5FQ","original":"ByemWlJOYm","number":859,"cdate":1538087879347,"ddate":null,"tcdate":1538087879347,"tmdate":1538156041771,"tddate":null,"forum":"r1gkAoA5FQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A bird's eye view on coherence, and a worm's eye view on cohesion","abstract":"Generating coherent and cohesive long-form texts is a challenging problem in natural language generation. Previous works relied on a large amount of human-generated texts to train language models, however, few attempted to explicitly model the desired linguistic properties of natural language text, such as coherence and cohesion. In this work, we train two expert discriminators for coherence and cohesion, respectively, to provide hierarchical feedback for text generation. We also propose a simple variant of policy gradient, called 'negative-critical sequence training', using margin rewards, in which the 'baseline' is constructed from randomly generated negative samples. We demonstrate the effectiveness of our approach through empirical studies, showing significant improvements over the strong baseline -- attention-based bidirectional MLE-trained neural language model -- in a number of automated metrics. The proposed discriminators can serve as baseline architectures to promote further research to better extract, encode, and transfer essential qualities from texts.","keywords":["text generation","natural language processing","neural language model"],"authorids":["ICLR.cc/2019/Conference/Paper859/Authors"],"authors":["Anonymous"],"TL;DR":"We encode linguistic properties, such as, coherence and cohesion, into expert discriminators and improve text generation.","pdf":"/pdf/2a20cc6cd28e2d96ac0c0f37352d5b827afea198.pdf","paperhash":"anonymous|a_birds_eye_view_on_coherence_and_a_worms_eye_view_on_cohesion","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A bird's eye view on coherence, and a worm's eye view on cohesion},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1gkAoA5FQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ByxkCj09Fm","original":"rJeepspct7","number":860,"cdate":1538087879513,"ddate":null,"tcdate":1538087879513,"tmdate":1538156041565,"tddate":null,"forum":"ByxkCj09Fm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"DEEP HIERARCHICAL MODEL FOR HIERARCHICAL SELECTIVE CLASSIFICATION AND ZERO SHOT LEARNING","abstract":"Object recognition in real-world image scenes is still an open problem. A large number of object classes with complex relationships between them makes the classification problem particularly challenging. Standard N-way discrete classifiers treat all classes as disconnected and unrelated, and therefore unable to learn from their semantic relationships. In this work, we present a hierarchical interclass relationship model, and train it using a newly proposed probability-based loss function. We show the model advantages deploying it in two scenarios. The first one, selective classification, deals with the problem of low-confidence classification,\nwherein a model is unable to make a successful exact classification.\nIn this case, our model returns a corresponding closest super-class. In the second scenario, the proposed method is used for the zero-shot learning problem. In this case, given a new input, the model returns its hierarchically related group, rather than generating a true unseen group. Extensive experiments with the two scenarios show that the proposed hierarchical model provides significantly better semantic generalization ability compared to a regular N-way classifier, and yields more accurate and meaningful super-class predictions.","keywords":["deep learning","large-scale classificaion","heirarchical classification","zero-shot learning"],"authorids":["ICLR.cc/2019/Conference/Paper860/Authors"],"authors":["Anonymous"],"TL;DR":"propose a new heirarchical probability bases loss funcsion which yeilds a better semantic classifier. We show our model advantages on two applications.","pdf":"/pdf/c3560cef4cdb6de08ec66ce030515886deaf23c2.pdf","paperhash":"anonymous|deep_hierarchical_model_for_hierarchical_selective_classification_and_zero_shot_learning","_bibtex":"@inproceedings{    \nanonymous2019deep,    \ntitle={DEEP HIERARCHICAL MODEL FOR HIERARCHICAL SELECTIVE CLASSIFICATION AND ZERO SHOT LEARNING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByxkCj09Fm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyexAiA5Fm","original":"r1etI4s9YX","number":861,"cdate":1538087879679,"ddate":null,"tcdate":1538087879679,"tmdate":1538156041350,"tddate":null,"forum":"HyexAiA5Fm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Scalable Unbalanced Optimal Transport using Generative Adversarial Networks","abstract":"Generative adversarial networks (GANs) are an expressive class of neural generative models with tremendous success in modeling high-dimensional continuous measures. In this paper, we present a scalable method for unbalanced optimal transport (OT) based on the generative-adversarial framework. We formulate unbalanced OT as a problem of simultaneously learning a transport map and a scaling factor that push a source measure to a target measure in a cost-optimal manner, and propose a new algorithm based on stochastic alternating gradient updates, similar in practice to GANs. We also provide theoretical justification for this formulation, showing that it is closely related to an existing static formulation by Liero et al. (2018), and perform numerical experiments demonstrating how this methodology could be applied to population modeling. ","keywords":["unbalanced optimal transport","generative adversarial networks","population modeling"],"authorids":["ICLR.cc/2019/Conference/Paper861/Authors"],"authors":["Anonymous"],"TL;DR":"We propose new methodology for unbalanced optimal transport using generative adversarial networks.","pdf":"/pdf/0cbc2a0742b25232d52d3e5aa2be1f3d30034daa.pdf","paperhash":"anonymous|scalable_unbalanced_optimal_transport_using_generative_adversarial_networks","_bibtex":"@inproceedings{    \nanonymous2019scalable,    \ntitle={Scalable Unbalanced Optimal Transport using Generative Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyexAiA5Fm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1lg0jAcYm","original":"H1xy9x29F7","number":862,"cdate":1538087879855,"ddate":null,"tcdate":1538087879855,"tmdate":1538156041139,"tddate":null,"forum":"S1lg0jAcYm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"ARM: Augment-REINFORCE-Merge Gradient for Stochastic Binary Networks","abstract":"To backpropagate the gradients through stochastic binary layers, we propose the augment-REINFORCE-merge (ARM) estimator that is unbiased and has low variance. Exploiting data augmentation, REINFORCE, and reparameterization, the ARM estimator achieves adaptive variance reduction for Monte Carlo integration by merging two expectations via common random numbers. The variance-reduction mechanism of the ARM estimator can also be attributed to antithetic sampling in an augmented space. Experimental results show the ARM estimator provides state-of-the-art performance in auto-encoding variational Bayes and maximum likelihood inference, for discrete latent variable models with one or multiple stochastic binary layers. Python code is available at https://github.com/ABC-anonymous-1.","keywords":["Antithetic sampling","data augmentation","deep discrete latent variable models","variance reduction","variational auto-encoder"],"authorids":["ICLR.cc/2019/Conference/Paper862/Authors"],"authors":["Anonymous"],"pdf":"/pdf/2d7c3c4f1bbc35e6fe66b5018deffc5af59f2583.pdf","paperhash":"anonymous|arm_augmentreinforcemerge_gradient_for_stochastic_binary_networks","_bibtex":"@inproceedings{    \nanonymous2019arm:,    \ntitle={ARM: Augment-REINFORCE-Merge Gradient for Stochastic Binary Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lg0jAcYm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryxxCiRqYX","original":"Skg-px6cYX","number":863,"cdate":1538087880027,"ddate":null,"tcdate":1538087880027,"tmdate":1538156040929,"tddate":null,"forum":"ryxxCiRqYX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Deep Layers as Stochastic Solvers","abstract":"We provide a novel perspective on the forward pass through a block of layers in a deep network. In particular, we show that a forward pass through a standard dropout layer followed by a linear layer and a non-linear activation is equivalent to optimizing a convex optimization objective with a single iteration of a $\\tau$-nice Proximal Stochastic Gradient method. We further show that replacing standard Bernoulli dropout with additive dropout is equivalent to optimizing the same convex objective with a variance-reduced proximal method. By expressing both fully-connected and convolutional layers as special cases of a high-order tensor product, we unify the underlying convex optimization problem in the tensor setting and derive a formula for the Lipschitz constant $L$ used to determine the optimal step size of the above proximal methods. We conduct experiments with standard convolutional networks applied to the CIFAR-10 and CIFAR-100 datasets, and show that replacing a block of layers with multiple iterations of the corresponding solver, with step size set via $L$, consistently improves classification accuracy.","keywords":["deep networks","optimization"],"authorids":["ICLR.cc/2019/Conference/Paper863/Authors"],"authors":["Anonymous"],"TL;DR":"A framework that links deep network layers to stochastic optimization algorithms; can be used to improve model accuracy and inform network design.","pdf":"/pdf/092fb55b36fad28ae39167851f97198bf9dc3ffa.pdf","paperhash":"anonymous|deep_layers_as_stochastic_solvers","_bibtex":"@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Layers as Stochastic Solvers},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxxCiRqYX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJex0o05F7","original":"rJl_NF85tQ","number":864,"cdate":1538087880202,"ddate":null,"tcdate":1538087880202,"tmdate":1538156040724,"tddate":null,"forum":"HJex0o05F7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A Generalized Active Learning Approach for Unsupervised Anomaly Detection","abstract":"This work presents a new approach to active anomaly detection. We show that a prior needs to be assumed on what the anomalies are, in order to have performance guarantees in unsupervised anomaly detection. We argue that active anomaly detection has, in practice, the same cost of unsupervised anomaly detection but with the possibility of much better results. To solve this problem, we present a new layer that can be attached to any deep learning model designed for unsupervised anomaly detection to transform it into an active anomaly detection method, presenting results on both synthetic and real anomaly detection datasets.","keywords":["Anomaly Detection","Active  Learning","Unsupervised Learning"],"authorids":["ICLR.cc/2019/Conference/Paper864/Authors"],"authors":["Anonymous"],"TL;DR":"A new approach to active anomaly detection. We present a new layer that can be attached to any deep learning model designed for unsupervised anomaly detection to transform it into an active anomaly detection method.","pdf":"/pdf/d52f3180d40fa2afc1c793f6837125228aa79f97.pdf","paperhash":"anonymous|a_generalized_active_learning_approach_for_unsupervised_anomaly_detection","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A Generalized Active Learning Approach for Unsupervised Anomaly Detection},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJex0o05F7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyMxAi05Km","original":"BJg9JIhqYm","number":865,"cdate":1538087880369,"ddate":null,"tcdate":1538087880369,"tmdate":1538156040517,"tddate":null,"forum":"HyMxAi05Km","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Dual Learning: Theoretical Study and Algorithmic Extensions","abstract":"Dual learning has been successfully applied in many machine learning applications, including machine translation, image-to-image  transformation, etc. The high-level idea of dual learning is very intuitive: if we map an x from one domain to another and then map it back, we should recover the original x. Although its effectiveness has been empirically verified, theoretical understanding of dual learning is still missing. In this paper, we conduct a theoretical study to understand why and when dual learning can improve a mapping function. Based on the theoretical discoveries, we extend dual learning by introducing more related mappings and propose highly symmetric frameworks, cycle dual learning and multipath dual learning, in both of which we can leverage the feedback signals from additional domains to improve the qualities of the mappings. We prove that both cycle dual learning and multipath dual learning can boost the performance of standard dual learning under mild conditions. Experiments on WMT 14 English↔German and MultiUN English↔French translations verify our theoretical findings on dual learning, and the results on the translations among English, French, and Spanish of MultiUN demonstrate the efficacy of cycle dual learning and multipath dual learning.","keywords":["machine translation","dual learning"],"authorids":["ICLR.cc/2019/Conference/Paper865/Authors"],"authors":["Anonymous"],"pdf":"/pdf/f84de5d29f36270196d323a68d415f4b226d35b0.pdf","paperhash":"anonymous|dual_learning_theoretical_study_and_algorithmic_extensions","_bibtex":"@inproceedings{    \nanonymous2019dual,    \ntitle={Dual Learning: Theoretical Study and Algorithmic Extensions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyMxAi05Km},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1eZCjA9KX","original":"HJxSr_FctX","number":866,"cdate":1538087880546,"ddate":null,"tcdate":1538087880546,"tmdate":1538156040307,"tddate":null,"forum":"B1eZCjA9KX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"IncSQL: Training Incremental Text-to-SQL Parsers with Non-Deterministic Oracles","abstract":"We present a sequence-to-action parsing approach for the natural language to SQL task that incrementally fills the slots of a SQL query with feasible actions from a pre-defined inventory. To account for the fact that typically there are multiple correct SQL queries with the same or very similar semantics, we draw inspiration from syntactic parsing techniques and propose to train our sequence-to-action models with non-deterministic oracles. We evaluate our models on the WikiSQL dataset and achieve an execution accuracy of 83.7% on the test set, a 2.1% absolute improvement over the models trained with traditional static oracles assuming a single correct target SQL query. When further combined with the execution-guided decoding strategy, our model sets a new state-of-the-art performance at an execution accuracy of 87.1%.","keywords":["semantic parsing","non-deterministic oracles","natural language to SQL","incremental parsing","sequence prediction"],"authorids":["ICLR.cc/2019/Conference/Paper866/Authors"],"authors":["Anonymous"],"TL;DR":"We design incremental sequence-to-action parsers for text-to-SQL task and achieve SOTA results. We further improve by using non-deterministic oracles to allow multiple correct action sequences. ","pdf":"/pdf/2ad29c4a27386931a85355b9abce5de773accb04.pdf","paperhash":"anonymous|incsql_training_incremental_texttosql_parsers_with_nondeterministic_oracles","_bibtex":"@inproceedings{    \nanonymous2019incsql:,    \ntitle={IncSQL: Training Incremental Text-to-SQL Parsers with Non-Deterministic Oracles},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1eZCjA9KX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1eZRiC9YX","original":"HJxg1PlgKQ","number":867,"cdate":1538087880721,"ddate":null,"tcdate":1538087880721,"tmdate":1538156040094,"tddate":null,"forum":"B1eZRiC9YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Sufficient Conditions for Robustness to Adversarial Examples: a Theoretical and Empirical Study with Bayesian Neural Networks","abstract":"We prove, under two sufficient conditions, that idealised models can have no adversarial examples. We discuss which idealised models satisfy our conditions, and show that idealised Bayesian neural networks (BNNs) satisfy these. We continue by studying near-idealised BNNs using HMC inference, demonstrating the theoretical ideas in practice. We experiment with HMC on synthetic data derived from MNIST for which we know the ground-truth image density, showing that near-perfect epistemic uncertainty correlates to density under image manifold, and that adversarial images lie off the manifold in our setting. This suggests why MC dropout, which can be seen as performing approximate inference, has been observed to be an effective defence against adversarial examples in practice; We highlight failure-cases of non-idealised BNNs relying on dropout, suggesting a new attack for dropout models and a new defence as well. Lastly, we demonstrate the defence on a cats-vs-dogs image classification task with a VGG13 variant.","keywords":["Bayesian deep learning","Bayesian neural networks","adversarial examples"],"authorids":["ICLR.cc/2019/Conference/Paper867/Authors"],"authors":["Anonymous"],"TL;DR":"We prove that idealised Bayesian neural networks can have no adversarial examples, and give empirical evidence with real-world BNNs.","pdf":"/pdf/5f32fed6bf08335d741e0d2db8d94aaa32cc2244.pdf","paperhash":"anonymous|sufficient_conditions_for_robustness_to_adversarial_examples_a_theoretical_and_empirical_study_with_bayesian_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019sufficient,    \ntitle={Sufficient Conditions for Robustness to Adversarial Examples: a Theoretical and Empirical Study with Bayesian Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1eZRiC9YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1GWAoRcKX","original":"SylGY4p5FX","number":868,"cdate":1538087880910,"ddate":null,"tcdate":1538087880910,"tmdate":1538156039889,"tddate":null,"forum":"H1GWAoRcKX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A Teacher Student Network For Faster Video Classification","abstract":"Over the past few years, various tasks involving videos such as classification, description, summarization and question answering have received a lot of attention. Current models for these tasks compute an encoding of the video by treating it as a sequence of images and going over every image in the sequence, which becomes computationally expensive for longer videos. In this paper, we focus on the task of video classification and aim to reduce the computational cost by using the idea of distillation. Specifically, we propose a Teacher-Student network wherein the teacher looks at all the frames in the video but the student looks at only a small fraction of the frames in the video. The idea is to then train the student to minimize  (i)  the difference between the final representation computed by the student and the teacher and/or (ii) the difference between the distributions predicted by the teacher and the student. This smaller student network which involves fewer computations but still learns to mimic the teacher can then be employed at inference time for video classification. We experiment with the YouTube-8M dataset and show  that the proposed student network can reduce the inference time by upto 30% with a negligent drop in the performance. ","keywords":["video classification","efficient computation","knowledge distillation","teacher-student"],"authorids":["ICLR.cc/2019/Conference/Paper868/Authors"],"authors":["Anonymous"],"TL;DR":"Teacher-Student framework for efficient video classification using fewer frames ","pdf":"/pdf/b2e92652dd0a0aac936aa2b618b6961e2a97032f.pdf","paperhash":"anonymous|a_teacher_student_network_for_faster_video_classification","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A Teacher Student Network For Faster Video Classification},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1GWAoRcKX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJMZRsC9Y7","original":"r1e2Bha5Km","number":869,"cdate":1538087881085,"ddate":null,"tcdate":1538087881085,"tmdate":1538156039682,"tddate":null,"forum":"SJMZRsC9Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A NON-LINEAR  THEORY FOR SENTENCE EMBEDDING","abstract":"This paper revisits the Random Walk model for sentence embedding in the context of non-extensive statistics. We propose a non-extensive algebra to compute the discourse vector. We argue that by doing so we are taking into account high non-linearity in the semantic space. Furthermore, we show that by considering a non-extensive algebra, the compounding effect of the vector length is mitigated. Overall, we show that the proposed model leads to good sentence embedding. We evaluate the embedding method on textual similarity tasks.","keywords":["sentence embedding","generative models"],"authorids":["ICLR.cc/2019/Conference/Paper869/Authors"],"authors":["Anonymous"],"pdf":"/pdf/d296c11ba5cab54f2a3104a4dc52d6c2150f96bd.pdf","paperhash":"anonymous|a_nonlinear_theory_for_sentence_embedding","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A NON-LINEAR  THEORY FOR SENTENCE EMBEDDING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJMZRsC9Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyNbRj09Y7","original":"BylHzsT5FQ","number":870,"cdate":1538087881255,"ddate":null,"tcdate":1538087881255,"tmdate":1538156039475,"tddate":null,"forum":"SyNbRj09Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Visual Imitation Learning with Recurrent Siamese Networks","abstract":"People are incredibly skilled at imitating others by simply observing them. They achieve this even in the presence of significant morphological differences and capabilities. Further, people are able to do this from raw perceptions of the actions of others, without direct access to the abstracted demonstration actions and with only partial state information. People therefore solve a difficult problem of understanding the salient features of both observations of others and the relationship to their own state when learning to imitate specific tasks.\nHowever, we can attempt to reproduce a similar demonstration via trail and error and through this gain more understanding of the task space.\nTo reproduce this ability an agent would need to both learn how to recognize the differences between itself and some demonstration and at the same time learn to minimize the distance between its own performance and that of the demonstration.\nIn this paper we propose an approach using only visual information to learn a distance metric between agent behaviour and a given video demonstration.\nWe train an RNN-based siamese model to compute distances in space and time between motion clips while training an RL policy to minimize this distance.\nFurthermore, we examine a particularly challenging form of this problem where the agent must learn an imitation based task given a single demonstration.\nWe demonstrate our approach in the setting of deep learning based control for physical simulation of humanoid walking in both 2D with $10$ degrees of freedom (DoF) and 3D with $38$ DoF.","keywords":["Reinforcement Learning","Imitation Learning","Deep Learning"],"authorids":["ICLR.cc/2019/Conference/Paper870/Authors"],"authors":["Anonymous"],"TL;DR":"Learning a vision-based recurrent distance function to allow agents to imitate behaviours from noisy video data.","pdf":"/pdf/41f0d0ef757216eed4d618f46ecc3c8b7857dc8c.pdf","paperhash":"anonymous|visual_imitation_learning_with_recurrent_siamese_networks","_bibtex":"@inproceedings{    \nanonymous2019visual,    \ntitle={Visual Imitation Learning with Recurrent Siamese Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyNbRj09Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkgW0oA9FX","original":"Hyx6kDqqYX","number":871,"cdate":1538087881448,"ddate":null,"tcdate":1538087881448,"tmdate":1538156039266,"tddate":null,"forum":"rkgW0oA9FX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Graph HyperNetworks for Neural Architecture Search","abstract":"Neural architecture search (NAS) automatically finds the best task-specific neural network topology, outperforming many manual architecture designs. However, it can be prohibitively expensive as the search requires training thousands of different networks, while each training run can last for hours. In this work, we propose the Graph HyperNetwork (GHN) to amortize the search cost: given an architecture, it directly generates the weights by running inference on a graph neural network. GHNs model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and prematured early stopping. To perform NAS, we randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast - they can search nearly 10× faster than other random search methods on CIFAR-10 and ImageNet. GHNs can be further extended to the anytime prediction setting, where they have found networks with better speed-accuracy tradeoff than the state-of-the-art manual designs.","keywords":["neural","architecture","search","graph","network","hypernetwork","meta","learning","anytime","prediction"],"authorids":["ICLR.cc/2019/Conference/Paper871/Authors"],"authors":["Anonymous"],"pdf":"/pdf/3a7be09010d1c68ae0d25b9a88a883e8b10d9834.pdf","paperhash":"anonymous|graph_hypernetworks_for_neural_architecture_search","_bibtex":"@inproceedings{    \nanonymous2019graph,    \ntitle={Graph HyperNetworks for Neural Architecture Search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgW0oA9FX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyxzRsR9Y7","original":"S1lsmBj5tm","number":872,"cdate":1538087881639,"ddate":null,"tcdate":1538087881639,"tmdate":1538156039056,"tddate":null,"forum":"HyxzRsR9Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Self-Imitating Diverse Policies","abstract":"The success of popular algorithms for deep reinforcement learning, such as policy-gradients and Q-learning, relies heavily on the availability of an informative reward signal at each timestep of the sequential decision-making process. When rewards are only sparsely available during an episode, or a rewarding feedback is provided only after episode termination, these algorithms perform sub-optimally due to the difficultly in credit assignment. Alternatively, trajectory-based policy optimization methods, such as cross-entropy method and evolution strategies, do not require per-timestep rewards, but have been found to suffer from high sample complexity by completing forgoing the temporal nature of the problem. Improving the efficiency of RL algorithms in real-world problems with sparse or episodic rewards is therefore a pressing need. In this work, we introduce a self-imitation learning algorithm that exploits and explores well in the sparse and episodic reward settings. We view each policy as a state-action visitation distribution and formulate policy optimization as a divergence minimization problem. We show that with Jensen-Shannon divergence, this divergence minimization problem can be reduced into a policy-gradient algorithm with shaped rewards learned from experience replays. Experimental results indicate that our algorithm works comparable to existing algorithms in environments with dense rewards, and significantly better in environments with sparse and episodic rewards. We then discuss limitations of self-imitation learning, and propose to solve them by using Stein variational policy gradient descent with the Jensen-Shannon kernel to learn multiple diverse policies. We demonstrate its effectiveness on a number of challenging tasks.","keywords":["Reinforcement-learning","Imitation-learning","Ensemble-training"],"authorids":["ICLR.cc/2019/Conference/Paper872/Authors"],"authors":["Anonymous"],"TL;DR":"Policy optimization by using past good rollouts from the agent; learning shaped rewards via divergence minimization; SVPG with JS-kernel for population-based exploration.","pdf":"/pdf/463cb67172293382d2bcc67b38d761f419e5fa70.pdf","paperhash":"anonymous|learning_selfimitating_diverse_policies","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Self-Imitating Diverse Policies},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyxzRsR9Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BygMAiRqK7","original":"ryer3ml5t7","number":873,"cdate":1538087881823,"ddate":null,"tcdate":1538087881823,"tmdate":1538156038853,"tddate":null,"forum":"BygMAiRqK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs","abstract":"Building on the success of deep learning, two modern approaches to learn a probability model of the observed data are Generative Adversarial Networks (GANs) and Variational AutoEncoders (VAEs). VAEs consider an explicit probability model for the data and compute a generative distribution by maximizing a variational lower-bound on the log-likelihood function. GANs, however, compute a generative model by minimizing a distance between observed and generated probability distributions without considering an explicit model for the observed data. The lack of having explicit probability models in GANs prohibits computation of sample likelihoods in their frameworks and limits their use in statistical inference problems. In this work, we show that an optimal transport GAN with the entropy regularization can be viewed as a generative model that maximizes a lower-bound on sample likelihoods, an approach that VAEs are based on. In particular, our proof constructs an explicit probability model for GANs that can be used to compute likelihood statistics within GAN’s framework. Our numerical results on several datasets demonstrate consistent trends with the proposed theory.\n","keywords":["GAN","VAE","likelihood estimation","statistical inference"],"authorids":["ICLR.cc/2019/Conference/Paper873/Authors"],"authors":["Anonymous"],"TL;DR":"A statistical approach to compute sample likelihoods in Generative Adversarial Networks","pdf":"/pdf/c43f837351c77718ec14481117ec1016277a32be.pdf","paperhash":"anonymous|entropic_gans_meet_vaes_a_statistical_approach_to_compute_sample_likelihoods_in_gans","_bibtex":"@inproceedings{    \nanonymous2019entropic,    \ntitle={Entropic GANs meet VAEs: A Statistical Approach to Compute Sample Likelihoods in GANs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BygMAiRqK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1gMCsAqY7","original":"H1l3OTpYY7","number":874,"cdate":1538087882016,"ddate":null,"tcdate":1538087882016,"tmdate":1538156038640,"tddate":null,"forum":"H1gMCsAqY7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Slimmable Neural Networks","abstract":"We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width multipliers, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models will be released.","keywords":["Slimmable neural networks","mobile deep learning","accuracy-efficiency trade-offs"],"authorids":["ICLR.cc/2019/Conference/Paper874/Authors"],"authors":["Anonymous"],"TL;DR":"We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.","pdf":"/pdf/768191e00d556b151589c980c372271282c72a29.pdf","paperhash":"anonymous|slimmable_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019slimmable,    \ntitle={Slimmable Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1gMCsAqY7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJlfAo09KX","original":"SJec3AK5Fm","number":875,"cdate":1538087882198,"ddate":null,"tcdate":1538087882198,"tmdate":1538156038436,"tddate":null,"forum":"HJlfAo09KX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Guaranteed Recovery of One-Hidden-Layer Neural Networks via Cross Entropy","abstract":"We study model recovery for data classification, where the training labels are generated from a one-hidden-layer fully -connected neural network with sigmoid activations, and the goal is to recover the weight vectors of the neural network. We prove that under Gaussian inputs, the empirical risk function using cross entropy exhibits strong convexity and smoothness uniformly in a local neighborhood of the ground truth, as soon as the sample complexity is sufficiently large. This implies that if initialized in this neighborhood, which can be achieved via the tensor method, gradient descent converges linearly to a critical point that is provably close to the ground truth without requiring a fresh set of samples at each iteration. To the best of our knowledge, this is the first global convergence guarantee established for the empirical risk minimization using cross entropy via gradient descent for learning one-hidden-layer neural networks, at the near-optimal sample and computational complexity with respect to the network input dimension.","keywords":["cross entropy","neural networks","parameter recovery"],"authorids":["ICLR.cc/2019/Conference/Paper875/Authors"],"authors":["Anonymous"],"TL;DR":"We provide the first theoretical analysis of guaranteed recovery of one-hidden-layer neural networks under cross entropy loss for classification problems.","pdf":"/pdf/28df4734fd8a152b0297b6c078605ef964201dc3.pdf","paperhash":"anonymous|guaranteed_recovery_of_onehiddenlayer_neural_networks_via_cross_entropy","_bibtex":"@inproceedings{    \nanonymous2019guaranteed,    \ntitle={Guaranteed Recovery of One-Hidden-Layer Neural Networks via Cross Entropy},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJlfAo09KX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJGfCjA5FX","original":"S1esrn69FX","number":876,"cdate":1538087882367,"ddate":null,"tcdate":1538087882367,"tmdate":1538156038227,"tddate":null,"forum":"BJGfCjA5FX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"PAIRWISE AUGMENTED GANS WITH ADVERSARIAL RECONSTRUCTION LOSS","abstract":"We propose a novel autoencoding model called Pairwise Augmented GANs. We train a generator and an encoder jointly and in an adversarial manner. The generator network learns to sample realistic objects. In turn the encoder network at the same time in turn is trained to map the true data distribution to the prior in a latent space. To ensure good reconstructions we introduce an augmented adversarial reconstruction loss. Here we train a discriminator to distinguish two types of pairs: the object with its augmentation and the one with its reconstruction. We show that such adversarial loss compares objects based on the content rather than on the exact match. We experimentally demonstrate that our model generates samples and reconstructions of quality competitive with state-of-the-art on datasets MNIST, CIFAR10, CelebA and achieves good quantitative results on CIFAR10. ","keywords":["Computer vision","Deep learning","Unsupervised Learning","Generative Adversarial Networks"],"authorids":["ICLR.cc/2019/Conference/Paper876/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a novel autoencoding model with augmented adversarial reconstruction loss. We intoduce new metric for content-based assessment of reconstructions. ","pdf":"/pdf/53cfa3a254e9e0492222136aff1cc7e08aaec29c.pdf","paperhash":"anonymous|pairwise_augmented_gans_with_adversarial_reconstruction_loss","_bibtex":"@inproceedings{    \nanonymous2019pairwise,    \ntitle={PAIRWISE AUGMENTED GANS WITH ADVERSARIAL RECONSTRUCTION LOSS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJGfCjA5FX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJeXCo0cYX","original":"S1gFtMvqt7","number":877,"cdate":1538087882537,"ddate":null,"tcdate":1538087882537,"tmdate":1538156038020,"tddate":null,"forum":"rJeXCo0cYX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"BabyAI: First Steps Towards Grounded Language Learning With a Human In the Loop","abstract":"Allowing humans to interactively train artificial agents to understand language instructions is desirable for both practical and scientific reasons, but given the poor data efficiency of the current learning methods, this goal may require substantial research efforts. Here, we introduce the BabyAI research platform to support investigations towards including humans in the loop for grounded language learning. The BabyAI platform comprises an extensible suite of 19 levels of increasing difficulty. The levels gradually lead the agent towards acquiring a combinatorially rich synthetic language which is a proper subset of English. The platform also provides a heuristic expert agent for the purpose of simulating a human teacher. We report baseline results and estimate the amount of human involvement that would be required to train a neural network-based agent on some of the BabyAI levels. We put forward strong evidence that current deep learning methods are not yet sufficiently sample efficient when it comes to learning a language with compositional properties.","keywords":["language","learning","efficiency","imitation learning","reinforcement learning"],"authorids":["ICLR.cc/2019/Conference/Paper877/Authors"],"authors":["Anonymous"],"TL;DR":"We present the BabyAI platform for studying data efficiency of language learning with a human in the loop","pdf":"/pdf/bf4af01e2a614a830528cf59e8344cd0a3a1d40f.pdf","paperhash":"anonymous|babyai_first_steps_towards_grounded_language_learning_with_a_human_in_the_loop","_bibtex":"@inproceedings{    \nanonymous2019babyai:,    \ntitle={BabyAI: First Steps Towards Grounded Language Learning With a Human In the Loop},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJeXCo0cYX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BygmRoA9YQ","original":"BylaDpzcFQ","number":878,"cdate":1538087882715,"ddate":null,"tcdate":1538087882715,"tmdate":1538156037812,"tddate":null,"forum":"BygmRoA9YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Mixture of Pre-processing Experts Model for Noise Robust Deep Learning on Resource Constrained Platforms","abstract":"Deep learning on an edge device requires energy efficient operation due to ever diminishing power budget. Intentional low quality data during the data acquisition for longer battery life, and natural noise from the low cost sensor degrade the quality of target output which hinders adoption of deep learning on an edge device. To overcome these problems,  we propose simple yet efficient mixture of pre-processing experts (MoPE) model to handle various image distortions including low resolution and noisy images.  We also propose to use adversarially trained auto encoder as a pre-processing expert for the noisy images.  We evaluate our proposed method for various machine learning tasks including object detection on MS-COCO 2014 dataset, multiple object tracking problem on MOT-Challenge dataset, and human activity recognition on UCF 101 dataset. Experimental results show that the proposed method achieves better detection, tracking and activity recognition accuracies under noise without sacrificing accuracies for the clean images. The overheads of our proposed MoPE are 0.67% and 0.17% in terms of memory and computation compared to the baseline object detection network.","keywords":["noise robust","object detection"],"authorids":["ICLR.cc/2019/Conference/Paper878/Authors"],"authors":["Anonymous"],"pdf":"/pdf/022230a0202c5e581793f5758069ca5636073409.pdf","paperhash":"anonymous|mixture_of_preprocessing_experts_model_for_noise_robust_deep_learning_on_resource_constrained_platforms","_bibtex":"@inproceedings{    \nanonymous2019mixture,    \ntitle={Mixture of Pre-processing Experts Model for Noise Robust Deep Learning on Resource Constrained Platforms},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BygmRoA9YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SkfQAiA9YX","original":"H1l2DgOcFm","number":879,"cdate":1538087882884,"ddate":null,"tcdate":1538087882884,"tmdate":1538156037605,"tddate":null,"forum":"SkfQAiA9YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"In search of theoretically grounded pruning","abstract":"Deep learning relies on resource-heavy linear algebra operations which can be prohibitively expensive when deploying to constrained embedded and mobile devices, or even when training large-scale networks. One way to reduce a neural network's resource requirements is to sparsify its weight matrices - a process often referred to as pruning. It is typically achieved by removing least important weights as measured by some salience criterion, with pruning by magnitude being the most popular option. This, however, often makes close to random judgments. In this paper we aim to closely investigate the concept of model weight importance, with a particular focus on the magnitude criterion and its most suitable substitute. To this end we identify a suitable Statistical framework and derive deep model parameter asymptotic theory to use with it. Thus, we derive a statistically-grounded pruning criterion which we compare with the magnitude pruning both qualitatively and quantitatively. We find this criterion to better capture parameter salience, by accounting for its estimation uncertainty. This results in improved performance and easier post-pruned re-training.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper879/Authors"],"authors":["Anonymous"],"pdf":"/pdf/2dc2a07619bd7dbae1ec080e6e0e1f648afbafcd.pdf","paperhash":"anonymous|in_search_of_theoretically_grounded_pruning","_bibtex":"@inproceedings{    \nanonymous2019in,    \ntitle={In search of theoretically grounded pruning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkfQAiA9YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyM7AiA5YX","original":"HJgb2VkcK7","number":880,"cdate":1538087883067,"ddate":null,"tcdate":1538087883067,"tmdate":1538156037400,"tddate":null,"forum":"HyM7AiA5YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Complement Objective Training","abstract":"Learning with a primary objective, such as softmax cross entropy for classification and sequence generation, has been the norm for training deep neural networks for years. Although being a widely-adopted approach, using cross entropy as the primary objective exploits mostly the information from the ground-truth class for maximizing data likelihood, and largely ignores information from the complement (incorrect) classes. We argue that, in addition to the primary objective, training also using a complement objective that leverages information from the complement classes can be effective in improving model performance. This motivates us to study a new training paradigm that maximizes the likelihood of the ground-truth class while neutralizing the probabilities of the complement classes. We conduct extensive experiments on multiple tasks ranging from computer vision to natural language understanding. The experimental results confirm that, compared to the conventional training with just one primary objective, training also with the complement objective further improves the performance of the state-of-the-art models across all tasks. In addition to the accuracy improvement, we also show that models trained with both primary and complement objectives are more robust to adversarial attacks.\n","keywords":["optimization","entropy","image recognition","natural language understanding","adversarial attacks","deep learning"],"authorids":["ICLR.cc/2019/Conference/Paper880/Authors"],"authors":["Anonymous"],"TL;DR":"We propose Complement Objective Training (COT), a new training paradigm that optimizes both the primary and complement objectives for effectively learning the parameters of neural networks.","pdf":"/pdf/a5a7e0d36115d51b2b4afee6f53b96d24da83d9d.pdf","paperhash":"anonymous|complement_objective_training","_bibtex":"@inproceedings{    \nanonymous2019complement,    \ntitle={Complement Objective Training},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyM7AiA5YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyNmRiCqtm","original":"H1g5ihTcYm","number":881,"cdate":1538087883242,"ddate":null,"tcdate":1538087883242,"tmdate":1538156037189,"tddate":null,"forum":"HyNmRiCqtm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"CDeepEx: Contrastive Deep Explanations","abstract":"We propose a method which can visually explain the classification decision of deep neural networks (DNNs). There are many proposed methods in machine learning and computer vision seeking to clarify the decision of machine learning black boxes, specifically DNNs.  All of these methods try to gain insight into why the network \"chose class A\" as an answer. Humans, when searching for explanations, ask two types of questions. The first question is, \"Why did you choose this answer?\" The second question asks, \"Why did you not choose answer B over A?\" The previously proposed methods are either not able to provide the latter directly or efficiently.\n\nWe introduce a method capable of answering the second question both directly and efficiently. In this work, we limit the inputs to be images. In general, the proposed method generates explanations in the input space of any model capable of efficient evaluation and gradient evaluation. We provide results, showing the superiority of this approach for gaining insight into the inner representation of machine learning models.","keywords":["Deep learning","Explanation","Network interpretation","Contrastive explanation"],"authorids":["ICLR.cc/2019/Conference/Paper881/Authors"],"authors":["Anonymous"],"TL;DR":"A method to answer \"why not class B?\" for explaining deep networks","pdf":"/pdf/1aadb277cd4bc6423d0eb1f8a5886508b53feb34.pdf","paperhash":"anonymous|cdeepex_contrastive_deep_explanations","_bibtex":"@inproceedings{    \nanonymous2019cdeepex:,    \ntitle={CDeepEx: Contrastive Deep Explanations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyNmRiCqtm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SkxXCi0qFX","original":"BkeI1C5ctQ","number":882,"cdate":1538087883410,"ddate":null,"tcdate":1538087883410,"tmdate":1538156036984,"tddate":null,"forum":"SkxXCi0qFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"ProMP: Proximal Meta-Policy Search","abstract":"Credit assignment in Meta-reinforcement learning (Meta-RL) is still poorly understood. Existing methods either neglect credit assignment to pre-adaptation behavior or implement it naively. This leads to poor sample-efficiency during meta-training as well as ineffective task identification strategies.\nThis paper provides a theoretical analysis of credit assignment in gradient-based Meta-RL. Building on the gained insights we develop a novel meta-learning algorithm that overcomes both the issue of poor credit assignment and previous difficulties in estimating meta-policy gradients. By controlling the statistical distance of both pre-adaptation and adapted policies during meta-policy search, the proposed algorithm endows efficient and stable meta-learning. Our approach leads to superior pre-adaptation policy behavior and consistently outperforms previous Meta-RL algorithms in sample-efficiency, wall-clock time, and asymptotic performance.","keywords":["Meta-Reinforcement Learning","Meta-Learning","Reinforcement-Learning"],"authorids":["ICLR.cc/2019/Conference/Paper882/Authors"],"authors":["Anonymous"],"TL;DR":"A novel and theoretically grounded meta-reinforcement learning algorithm","pdf":"/pdf/78928953c05f5e5563196c1067bd5f3215c59929.pdf","paperhash":"anonymous|promp_proximal_metapolicy_search","_bibtex":"@inproceedings{    \nanonymous2019promp:,    \ntitle={ProMP: Proximal Meta-Policy Search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkxXCi0qFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1gVRi0qFQ","original":"BkxO02acYm","number":883,"cdate":1538087883589,"ddate":null,"tcdate":1538087883589,"tmdate":1538156036779,"tddate":null,"forum":"B1gVRi0qFQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Online abstraction with MDP homomorphisms for Deep Learning","abstract":"Abstraction of Markov Decision Processes is a useful tool for solving complex problems, as it can ignore unimportant aspects of an environment, simplifying the process of learning an optimal policy. In this paper, we propose a new algorithm for finding abstract MDPs in environments with continuous state spaces. It is based on MDP homomorphisms, a structure-preserving mapping between MDPs. We demonstrate our algorithm's ability to learns abstractions from collected experience and show how to reuse the abstractions to guide exploration in new tasks the agent encounters. Our novel task transfer method beats a baseline based on a deep Q-network.","keywords":["reinforcement learning","abstraction","mdp homomorphism","deep learning","robotics"],"authorids":["ICLR.cc/2019/Conference/Paper883/Authors"],"authors":["Anonymous"],"TL;DR":"We create abstract models of environments from experience and use them to learn new tasks faster.","pdf":"/pdf/03a3376e005459b1cb8bbdcd49c493c72b0acba7.pdf","paperhash":"anonymous|online_abstraction_with_mdp_homomorphisms_for_deep_learning","_bibtex":"@inproceedings{    \nanonymous2019online,    \ntitle={Online abstraction with MDP homomorphisms for Deep Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1gVRi0qFQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SkgVRiC9Km","original":"H1x75JUqKQ","number":884,"cdate":1538087883767,"ddate":null,"tcdate":1538087883767,"tmdate":1538156036574,"tddate":null,"forum":"SkgVRiC9Km","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations","abstract":"Deep networks have achieved impressive results across a variety of important tasks. However, a known weakness is a failure to perform well when evaluated on data which differ from the training distribution, even if these differences are very small, as is the case with adversarial examples.  We propose \\emph{Fortified Networks}, a simple transformation of existing networks, which “fortifies” the hidden layers in a deep network by identifying when the hidden states are off of the data manifold, and maps these hidden states back to parts of the data manifold where the network performs well. Our principal contribution is to show that fortifying these hidden states improves the robustness of deep networks and our experiments (i) demonstrate improved robustness to standard adversarial attacks in both black-box and white-box threat models; (ii) suggest that our improvements are not primarily due to the problem of deceptively good results due to degraded quality in the gradient signal (the gradient masking problem) and (iii) show the advantage of doing this fortification in the hidden layers instead of the input space.  We demonstrate improvements in adversarial robustness on three datasets (MNIST, Fashion MNIST, CIFAR10), across several attack parameters, both white-box and black-box settings, and the most widely studied attacks (FGSM, PGD, Carlini-Wagner).  We show that these improvements are achieved across a wide variety of hyperparameters.  ","keywords":["adversarial examples","adversarial training","autoencoders","hidden state"],"authorids":["ICLR.cc/2019/Conference/Paper884/Authors"],"authors":["Anonymous"],"TL;DR":"Better adversarial training by learning to map back to the data manifold with autoencoders in the hidden states.  ","pdf":"/pdf/96278b003cba15c10da0f905dd6adef7885c6ba4.pdf","paperhash":"anonymous|fortified_networks_improving_the_robustness_of_deep_networks_by_modeling_the_manifold_of_hidden_representations","_bibtex":"@inproceedings{    \nanonymous2019fortified,    \ntitle={Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkgVRiC9Km},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJxNAjC5F7","original":"BygSmgJ9Ym","number":885,"cdate":1538087883942,"ddate":null,"tcdate":1538087883942,"tmdate":1538156036372,"tddate":null,"forum":"rJxNAjC5F7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Hash Codes via Hamming Distance Targets","abstract":"We present a powerful new loss function and training scheme for learning binary hash codes with any differentiable model and similarity function.\nOur loss function improves over prior methods by using log likelihood loss on top of an accurate approximation for the probability that two inputs fall within a Hamming distance target.\nOur novel training scheme obtains a good estimate of the true gradient by better sampling inputs and evaluating loss terms between all pairs of inputs in each minibatch.\nTo fully leverage the resulting hashes, we use multi-indexing.\nWe demonstrate that these techniques provide large improvements to a similarity search tasks.\nWe report the best results to date on competitive information retrieval tasks for Imagenet and SIFT 1M, improving recall from 73% to 84% and reducing query cost by a factor of 2-8, respectively.","keywords":["information retrieval","learning to hash","cbir"],"authorids":["ICLR.cc/2019/Conference/Paper885/Authors"],"authors":["Anonymous"],"TL;DR":"We present a new loss function for training any differentiable model to hash that can vastly improve recall and lookup speed.","pdf":"/pdf/d02a9d387f3c34f7aba0ac69ec265860632792c9.pdf","paperhash":"anonymous|learning_hash_codes_via_hamming_distance_targets","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Hash Codes via Hamming Distance Targets},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJxNAjC5F7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryzECoAcY7","original":"rkeLkpaqKX","number":886,"cdate":1538087884115,"ddate":null,"tcdate":1538087884115,"tmdate":1538156036158,"tddate":null,"forum":"ryzECoAcY7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Hierarchical Reinforcement Learning with Limited Policies and Hindsight","abstract":"We introduce a new hierarchical reinforcement learning framework that can accelerate\nlearning in tasks involving long time horizons and sparse rewards. Our\napproach improves sample efficiency by enabling agents to learn a hierarchy\nof short policies that operate at different time scales. The policy hierarchies\ncan support an arbitrary number of levels, and all policies within the hierarchy\nare trained in parallel and end-to-end. Our framework is the first hierarchical\nreinforcement learning approach that can learn hierarchies with more than\ntwo levels of policies in continuous tasks. We demonstrate experimentally in\nboth grid world and simulated robotics domains that our approach can significantly\nboost sample efficiency. A video illustrating our results is available at\nhttps://www.youtube.com/watch?v=i04QF7Yi50Y.","keywords":["Hierarchical Reinforcement Learning","Reinforcement Learning","Deep Reinforcement Learning"],"authorids":["ICLR.cc/2019/Conference/Paper886/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a new hierarchical RL framework that can improve performance in tasks involving long time horizons and sparse rewards.","pdf":"/pdf/72634f0f295a6efedf7ffeb7385e4934f9068d41.pdf","paperhash":"anonymous|hierarchical_reinforcement_learning_with_limited_policies_and_hindsight","_bibtex":"@inproceedings{    \nanonymous2019hierarchical,    \ntitle={Hierarchical Reinforcement Learning with Limited Policies and Hindsight},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryzECoAcY7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyG4RiR5Ym","original":"H1g51a6qYQ","number":887,"cdate":1538087884281,"ddate":null,"tcdate":1538087884281,"tmdate":1538156035951,"tddate":null,"forum":"SyG4RiR5Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Neural Distribution Learning for generalized time-to-event prediction","abstract":"Predicting the time to the next event is an important task in various domains. \nHowever, due to censoring and irregularly sampled sequences, time-to-event prediction has resulted in limited success only for particular tasks, architectures and data. \nUsing recent advances in probabilistic programming and density networks, we make the case for a generalized parametric survival approach, sequentially predicting a distribution over the time to the next event. \nUnlike previous work, the proposed method can use asynchronously sampled features for censored, discrete, and multivariate data. \nFurthermore, it achieves good performance and near perfect calibration for probabilistic predictions without using rigid network-architectures, multitask approaches, complex learning schemes or non-trivial adaptations of cox-models. \nWe firmly establish that this can be achieved in the standard neural network framework by simply switching out the output layer and loss function.","keywords":["Deep Learning","Survival Analysis","Event prediction","Time Series","Probabilistic Programming","Density Networks"],"authorids":["ICLR.cc/2019/Conference/Paper887/Authors"],"authors":["Anonymous"],"TL;DR":"We present a general solution to event prediction that has been there all along; Discrete Time Parametric Survival Analysis.","pdf":"/pdf/70d59622126e6320d731d83362ff0896b7a5f448.pdf","paperhash":"anonymous|neural_distribution_learning_for_generalized_timetoevent_prediction","_bibtex":"@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Distribution Learning for generalized time-to-event prediction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyG4RiR5Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1EERs09YQ","original":"BJl_didwtm","number":888,"cdate":1538087884451,"ddate":null,"tcdate":1538087884451,"tmdate":1538156035745,"tddate":null,"forum":"S1EERs09YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Discovery of natural language concepts in individual units","abstract":"Although deep convolutional networks have achieved improved performance in many natural language tasks, they have been treated as black boxes because they are difficult to interpret. Especially, little is known about how they represent language in their intermediate layers. In an attempt to understand the representations of deep convolutional networks trained on language tasks, we show that individual units are selectively responsive to specific morphemes, words, and phrases, rather than responding to arbitrary and uninterpretable patterns. In order to quantitatively analyze such intriguing phenomenon, we propose a concept alignment method based on how units respond to replicated text. We conduct analyses with different architectures on multiple datasets for classification and translation tasks and provide new insights into how deep models understand natural language.","keywords":["interpretability of deep neural networks","natural language representation"],"authorids":["ICLR.cc/2019/Conference/Paper888/Authors"],"authors":["Anonymous"],"TL;DR":"We show that individual units in CNN representations learned in NLP tasks are selectively responsive to natural language concepts.","pdf":"/pdf/865b01f81e00b76e37c63fbbb5326bbd94a9bff3.pdf","paperhash":"anonymous|discovery_of_natural_language_concepts_in_individual_units","_bibtex":"@inproceedings{    \nanonymous2019discovery,    \ntitle={Discovery of natural language concepts in individual units},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1EERs09YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyerAiCqt7","original":"rylSeaacYm","number":889,"cdate":1538087884616,"ddate":null,"tcdate":1538087884616,"tmdate":1538156035539,"tddate":null,"forum":"SyerAiCqt7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Hierarchical Bayesian Modeling for Clustering Sparse Sequences in the Context of Group Profiling","abstract":"This paper proposes a hierarchical Bayesian model for clustering sparse sequences.This is a mixture model and does not need the data to be represented by a Gaussian mixture and that gives significant modelling freedom.It also generates a very interpretable profile for the discovered latent groups.The data that was used for the work have been contributed by a restaurant loyalty program company. The data is a collection of sparse sequences where each entry of each sequence is the number of user visits of one week to some restaurant. This algorithm successfully clustered the data and calculated the expected user affiliation in each cluster.","keywords":["Hierarchical Bayesian Modeling","Sparse sequence clustering","Group profiling","User group modeling"],"authorids":["ICLR.cc/2019/Conference/Paper889/Authors"],"authors":["Anonymous"],"TL;DR":"Hierarchical Bayesian Modeling for Clustering Sparse Sequences ; user group modeling using behavioral data","pdf":"/pdf/e225ca65da818ff565dc7fd35e03ce02f8043003.pdf","paperhash":"anonymous|hierarchical_bayesian_modeling_for_clustering_sparse_sequences_in_the_context_of_group_profiling","_bibtex":"@inproceedings{    \nanonymous2019hierarchical,    \ntitle={Hierarchical Bayesian Modeling for Clustering Sparse Sequences in the Context of Group Profiling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyerAiCqt7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1lrAiA5Ym","original":"B1xtTwa9KQ","number":890,"cdate":1538087884784,"ddate":null,"tcdate":1538087884784,"tmdate":1538156035333,"tddate":null,"forum":"r1lrAiA5Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Backpropamine: training self-modifying neural networks with differentiable neuromodulated plasticity","abstract":"The impressive lifelong learning in animal brains is primarily enabled by plastic changes in synaptic connectivity. Importantly, these changes are not passive, but are actively controlled by neuromodulation, which is itself under the control of the brain. The resulting self-modifying abilities of the brain play an important role in learning and adaptation, and are a major basis for biological reinforcement learning. Here we show for the first time that artificial neural networks with such neuromodulated plasticity can be trained with gradient descent. Extending previous work on differentiable Hebbian plasticity, we propose a differentiable formulation for the neuromodulation of plasticity. We show that neuromodulated plasticity improves the performance of neural networks on both reinforcement learning and supervised learning tasks. In one task, neuromodulated plastic LSTMs with millions of parameters outperform standard LSTMs on a benchmark language modeling task (controlling for the number of parameters). We conclude that differentiable neuromodulation of plasticity offers a powerful new framework for training neural networks.","keywords":["meta-learning","reinforcement learning","plasticity","neuromodulation","Hebbian learning","recurrent neural networks"],"authorids":["ICLR.cc/2019/Conference/Paper890/Authors"],"authors":["Anonymous"],"TL;DR":"Neural networks can be trained to modify their own connectivity, improving their online learning performance on challenging tasks.","pdf":"/pdf/f5ddac3575912659887f5c2d4209f491f5cf8b4f.pdf","paperhash":"anonymous|backpropamine_training_selfmodifying_neural_networks_with_differentiable_neuromodulated_plasticity","_bibtex":"@inproceedings{    \nanonymous2019backpropamine:,    \ntitle={Backpropamine: training self-modifying neural networks with differentiable neuromodulated plasticity},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1lrAiA5Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1erRoCqtX","original":"BJeneLxqKQ","number":891,"cdate":1538087884952,"ddate":null,"tcdate":1538087884952,"tmdate":1538156035121,"tddate":null,"forum":"r1erRoCqtX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"LSH Microbatches for Stochastic Gradients:  Value in Rearrangement","abstract":"   Metric embeddings are   immensely useful representations of associations between entities   (images, users, search queries, words, and more).  Embeddings are learned by  optimizing a loss objective of the general form of a sum over example associations. Typically, the optimization uses stochastic gradient updates over minibatches of examples that are arranged  independently at random. In this work, we propose the use of {\\em structured arrangements} through randomized {\\em microbatches} of examples that are more likely to include similar ones. We make a principled argument for the properties of our arrangements  that accelerate the training and present efficient algorithms to generate microbatches that respect the marginal  distribution of training examples.  Finally, we observe experimentally that our structured arrangements accelerate training by 3-20\\%. Structured arrangements emerge as a powerful and novel performance knob for SGD that is independent and complementary to other SGD  hyperparameters and thus is a candidate for wide deployment.","keywords":["Stochastic Gradient Descent","Metric Embeddings","Locality  Sensitive Hashing","Microbatches","Sample coordination"],"authorids":["ICLR.cc/2019/Conference/Paper891/Authors"],"authors":["Anonymous"],"TL;DR":"Accelerating SGD by arranging examples differently","pdf":"/pdf/c1ea205f7792cf0a31ef31c7d5979b989a87864a.pdf","paperhash":"anonymous|lsh_microbatches_for_stochastic_gradients_value_in_rearrangement","_bibtex":"@inproceedings{    \nanonymous2019lsh,    \ntitle={LSH Microbatches for Stochastic Gradients:  Value in Rearrangement},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1erRoCqtX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJlr0j0ctX","original":"Sklbqh35FX","number":892,"cdate":1538087885129,"ddate":null,"tcdate":1538087885129,"tmdate":1538156034912,"tddate":null,"forum":"BJlr0j0ctX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Label Smoothing and Logit Squeezing: A Replacement for Adversarial Training?","abstract":"Adversarial training is one of the strongest defenses against adversarial attacks, but it requires adversarial examples to be generated for every mini-batch during optimization.  The expense of producing these examples during training often precludes adversarial training from use on large and high-resolution image datasets.  In this study, we explore the mechanisms by which adversarial training improves classifier robustness, and show that these mechanisms can be effectively mimicked using simple regularization methods, including label smoothing and logit squeezing. Remarkably, using these simple regularization methods in combination with Gaussian noise injection, we are able to achieve strong adversarial robustness -- often exceeding that of adversarial training -- using no adversarial examples.","keywords":["adversarial machine learning","machine learning security"],"authorids":["ICLR.cc/2019/Conference/Paper892/Authors"],"authors":["Anonymous"],"TL;DR":"Achieving strong adversarial robustness and exceeding adversarial training without training on adversarial examples","pdf":"/pdf/db134cd1eac34f98b68a9f313aa344b159c0d270.pdf","paperhash":"anonymous|label_smoothing_and_logit_squeezing_a_replacement_for_adversarial_training","_bibtex":"@inproceedings{    \nanonymous2019label,    \ntitle={Label Smoothing and Logit Squeezing: A Replacement for Adversarial Training?},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJlr0j0ctX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJeB0sC9Fm","original":"ByxkkZ39F7","number":893,"cdate":1538087885300,"ddate":null,"tcdate":1538087885300,"tmdate":1538156034705,"tddate":null,"forum":"HJeB0sC9Fm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Detecting Memorization in ReLU Networks","abstract":"We propose a new notion of 'non-linearity' of a network layer with respect to an input batch that is based on its proximity to a linear system, which is reflected in the non-negative rank of the activation matrix.\nWe measure this non-linearity by applying non-negative factorization to the activation matrix.\nConsidering batches of similar samples, we find that high non-linearity in deep layers is indicative of memorization. Furthermore, by applying our approach layer-by-layer, we find that the mechanism for memorization consists of distinct phases. We perform experiments on fully-connected and convolutional neural networks trained on several image and audio datasets. Our results demonstrate that as an indicator for memorization, our technique can be used to perform early stopping.","keywords":["Memorization","Generalization","ReLU","Non-negative matrix factorization"],"authorids":["ICLR.cc/2019/Conference/Paper893/Authors"],"authors":["Anonymous"],"TL;DR":"We use the non-negative rank of ReLU activation matrices as a complexity measure and show it (negatively) correlates with good generalization.","pdf":"/pdf/5821f59dc5ee92460f4d733b6b5a0c136790fee2.pdf","paperhash":"anonymous|detecting_memorization_in_relu_networks","_bibtex":"@inproceedings{    \nanonymous2019detecting,    \ntitle={Detecting Memorization in ReLU Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJeB0sC9Fm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1grRoR9tQ","original":"Bkgzvl_tKX","number":894,"cdate":1538087885466,"ddate":null,"tcdate":1538087885466,"tmdate":1538156034505,"tddate":null,"forum":"S1grRoR9tQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation","abstract":"We propose a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables. Inspired by dropout, a popular tool for regularization and model ensemble, we assign sparse priors to the weights in deep neural networks (DNN) in order to achieve automatic ``dropout'' and avoid over-fitting. By alternatively sampling from posterior distribution through stochastic gradient Markov Chain Monte Carlo (SG-MCMC) and optimizing latent variables via stochastic approximation (SA), the trajectory of the target weights is proved to converge to the true posterior distribution conditioned on optimal latent variables. This ensures a stronger regularization on the over-fitted parameter space and more accurate uncertainty quantification on the decisive variables. Simulations from large-p-small-n regressions showcase the robustness of this method when applied to models with latent variables. Additionally, its application on the convolutional neural networks (CNN) leads to state-of-the-art performance on MNIST and Fashion MNIST datasets and improved resistance to adversarial attacks. ","keywords":["generalized stochastic approximation","stochastic gradient Markov chain Monte Carlo","adaptive algorithm","EM algorithm","convolutional neural networks","Bayesian inference","sparse prior","spike and slab prior","local trap"],"authorids":["ICLR.cc/2019/Conference/Paper894/Authors"],"authors":["Anonymous"],"TL;DR":"a robust Bayesian deep learning algorithm to infer complex posteriors with latent variables","pdf":"/pdf/966aae233aa4a48a5cea9b413188c6e070a72601.pdf","paperhash":"anonymous|bayesian_deep_learning_via_stochastic_gradient_mcmc_with_a_stochastic_approximation_adaptation","_bibtex":"@inproceedings{    \nanonymous2019bayesian,    \ntitle={Bayesian Deep Learning via Stochastic Gradient MCMC with a Stochastic Approximation Adaptation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1grRoR9tQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rylIAsCqYm","original":"BkldQ6a5Km","number":895,"cdate":1538087885635,"ddate":null,"tcdate":1538087885635,"tmdate":1538156034297,"tddate":null,"forum":"rylIAsCqYm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A2BCD: Asynchronous Acceleration with Optimal Complexity","abstract":"\tIn this paper, we propose the Asynchronous Accelerated Nonuniform Randomized Block Coordinate Descent algorithm (A2BCD). We prove A2BCD converges linearly to a solution of the convex minimization problem at the same rate as NU_ACDM, so long as the maximum delay is not too large. This is the first asynchronous Nesterov-accelerated algorithm that attains any provable speedup. Moreover, we then prove that these algorithms both have optimal complexity. Asynchronous algorithms complete much faster iterations, and A2BCD has optimal complexity. Hence we observe in experiments that A2BCD is the top-performing coordinate descent algorithm, converging up to 4-5x faster than NU_ACDM on some data sets in terms of wall-clock time. To motivate our theory and proof techniques, we also derive and analyze a continuous-time analog of our algorithm and prove it converges at the same rate.","keywords":["asynchronous","optimization","parallel","accelerated","complexity"],"authorids":["ICLR.cc/2019/Conference/Paper895/Authors"],"authors":["Anonymous"],"TL;DR":"We prove the first-ever convergence proof of an asynchronous accelerated algorithm that attains a speedup.","pdf":"/pdf/f25155c8afbd21da2b3054ec55e0f403a58dd3c4.pdf","paperhash":"anonymous|a2bcd_asynchronous_acceleration_with_optimal_complexity","_bibtex":"@inproceedings{    \nanonymous2019a2bcd:,    \ntitle={A2BCD: Asynchronous Acceleration with Optimal Complexity},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylIAsCqYm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJeUAj05tQ","original":"HkgOEpp9Fm","number":896,"cdate":1538087885816,"ddate":null,"tcdate":1538087885816,"tmdate":1538156034078,"tddate":null,"forum":"SJeUAj05tQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"DADAM: A consensus-based distributed adaptive gradient method for online optimization","abstract":"Online and stochastic optimization methods such as SGD, ADAGRAD and ADAM are key algorithms in solving large-scale machine learning problems including deep learning. A number of schemes that are based on communications of nodes with a central server have been recently proposed in the literature to parallelize them. A bottleneck of such centralized algorithms lies on the high communication cost incurred by the central node. In this paper, we present a new consensus-based distributed adaptive moment estimation method (DADAM) for online optimization over a decentralized network that enables data parallelization, as well as decentralized computation. Such a framework note only can be extremely useful for learning agents with access to only local data in a communication constrained environment, but as shown in this work also outperform centralized adaptive algorithms such as ADAM for certain realistic classes of loss functions. We analyze the convergence properties of the proposed algorithm and provide a \\textit{dynamic regret} bound on the convergence rate of adaptive moment estimation methods in both stochastic and deterministic settings. Empirical results demonstrate that DADAM works well in practice and compares favorably to competing online optimization methods.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper896/Authors"],"authors":["Anonymous"],"pdf":"/pdf/bf78174116a6956ac5b266953645ee3bf0a8a26d.pdf","paperhash":"anonymous|dadam_a_consensusbased_distributed_adaptive_gradient_method_for_online_optimization","_bibtex":"@inproceedings{    \nanonymous2019dadam:,    \ntitle={DADAM: A consensus-based distributed adaptive gradient method for online optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJeUAj05tQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BklUAoAcY7","original":"r1gsNT6ct7","number":897,"cdate":1538087885988,"ddate":null,"tcdate":1538087885988,"tmdate":1538156033873,"tddate":null,"forum":"BklUAoAcY7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Unsupervised Learning  of Sentence Representations Using Sequence Consistency","abstract":"Computing universal distributed representations of sentences is a fundamental task in natural language processing. We propose a simple, yet surprisingly powerful unsupervised method to learn such representations by enforcing consistency constraints on sequences of tokens. We consider two classes of such constraints -- sequences that form a sentence and between two sequences that form a sentence when merged. We learn a sentence encoder by training it to distinguish between consistent and inconsistent examples. Extensive evaluation on several transfer learning and linguistic probing tasks shows improved performance over strong unsupervised and supervised baselines, substantially surpassing them in several cases. ","keywords":["sentence representation","unsupervised learning","LSTM"],"authorids":["ICLR.cc/2019/Conference/Paper897/Authors"],"authors":["Anonymous"],"TL;DR":"Good sentence encoders can be learned by training them to distinguish between consistent and inconsistent (pairs of) sequences that are generated in an unsupervised manner.","pdf":"/pdf/859793322ccb5c22c25d3eef060054b2ac0135c4.pdf","paperhash":"anonymous|unsupervised_learning_of_sentence_representations_using_sequence_consistency","_bibtex":"@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Learning  of Sentence Representations Using Sequence Consistency},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BklUAoAcY7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1e8CsRctX","original":"S1gnlDT5Y7","number":898,"cdate":1538087886184,"ddate":null,"tcdate":1538087886184,"tmdate":1538156033659,"tddate":null,"forum":"B1e8CsRctX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Generative Ensembles for Robust Anomaly Detection","abstract":"Deep generative models are capable of learning probability distributions over large, high-dimensional datasets such as images, video and natural language. Generative models trained on samples from p(x) ought to assign low likelihoods to out-of-distribution (OoD) samples from q(x), making them suitable for anomaly detection applications. We show that in practice, likelihood models are themselves susceptible to OoD errors, and even assign large likelihoods to images from other natural datasets. To mitigate these issues, we propose Generative Ensembles, a model-independent technique for OoD detection that combines density-based anomaly detection with uncertainty estimation. Our method outperforms ODIN and VIB baselines on image datasets, and achieves comparable performance to a classification model on the Kaggle Credit Fraud dataset.","keywords":["Anomaly Detection","Uncertainty","Out-of-Distribution","Generative Models"],"authorids":["ICLR.cc/2019/Conference/Paper898/Authors"],"authors":["Anonymous"],"TL;DR":"We use generative models to perform out-of-distribution detection, and improve their robustness with uncertainty estimation.","pdf":"/pdf/014f9db90d72ed3ff854e4693291eb4756e669b3.pdf","paperhash":"anonymous|generative_ensembles_for_robust_anomaly_detection","_bibtex":"@inproceedings{    \nanonymous2019generative,    \ntitle={Generative Ensembles for Robust Anomaly Detection},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1e8CsRctX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJfUCoR5KX","original":"rkxf5YPqYX","number":899,"cdate":1538087886355,"ddate":null,"tcdate":1538087886355,"tmdate":1538156033455,"tddate":null,"forum":"rJfUCoR5KX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A Systematic Study of Binary Neural Networks' Optimisation","abstract":"Binary neural networks using the Straight-Through-Estimator (STE) have been shown to achieve state-of-the-art results, but their training process is not well-founded. This is due to the discrepancy between the evaluated function in the forward path, and the weight updates in the back-propagation, updates which do not correspond to gradients of the forward path. Efficient convergence and accuracy of binary models often rely on careful fine-tuning and various ad-hoc techniques. In this work, we empirically identify and study the effectiveness of the various ad-hoc techniques commonly used in the literature, providing best-practices for efficient training of binary models. We show that adapting learning rates using second moment methods is crucial for the successful use of the STE, and that other optimisers can easily get stuck in local minima. We also find that many of the commonly employed tricks are only effective towards the end of the training, with these methods making early stages of the training considerably slower. Our analysis disambiguates necessary from unnecessary ad-hoc techniques for training of binary neural networks, paving the way for future development of solid theoretical foundations for these. Our newly-found insights further lead to new procedures which make training of existing binary neural networks notably faster.","keywords":["binary neural networks","quantized neural networks","straight-through-estimator"],"authorids":["ICLR.cc/2019/Conference/Paper899/Authors"],"authors":["Anonymous"],"pdf":"/pdf/d5df7d63fdd9bd8833a4ddc9bf4069735f50a9c6.pdf","paperhash":"anonymous|a_systematic_study_of_binary_neural_networks_optimisation","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A Systematic Study of Binary Neural Networks' Optimisation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJfUCoR5KX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJxwAo09KQ","original":"H1ey6H0KY7","number":900,"cdate":1538087886521,"ddate":null,"tcdate":1538087886521,"tmdate":1538156033246,"tddate":null,"forum":"HJxwAo09KQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learned optimizers that outperform on wall-clock and validation loss","abstract":"Deep learning has shown that learned functions can dramatically outperform hand-designed functions on perceptual tasks. Analogously, this suggests that learned update functions may similarly outperform current hand-designed optimizers, especially for specific tasks. However, learned optimizers are notoriously difficult to train and have yet to demonstrate wall-clock speedups over hand-designed optimizers, and thus are rarely used in practice. Typically, learned optimizers are trained by truncated backpropagation through an unrolled optimization process. The resulting gradients are either strongly biased (for short truncations) or have exploding norm (for long truncations). In this work we propose a training scheme which overcomes both of these difficulties, by dynamically weighting two unbiased gradient estimators for a variational loss on optimizer performance. This allows us to train neural networks to perform optimization faster than well tuned first-order methods. Moreover, by training the optimizer against validation loss, as opposed to training loss, we are able to use it to train models which generalize better than those trained by first order methods. We demonstrate these results on problems where our learned optimizer trains convolutional networks in a fifth of the wall-clock time compared to tuned first-order methods, and with an improvement","keywords":["Learned Optimizers","Meta-Learning"],"authorids":["ICLR.cc/2019/Conference/Paper900/Authors"],"authors":["Anonymous"],"TL;DR":"We analyze problems when training learned optimizers, address those problems via variational optimization using two complementary gradient estimators, and train optimizers that are 5x faster in wall-clock time than baseline optimizers (e.g. Adam).","pdf":"/pdf/2c94269a1648cac4ba5ccf7f1c3b5c505a09e1be.pdf","paperhash":"anonymous|learned_optimizers_that_outperform_on_wallclock_and_validation_loss","_bibtex":"@inproceedings{    \nanonymous2019learned,    \ntitle={Learned optimizers that outperform on wall-clock and validation loss},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxwAo09KQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1lwRjR9YX","original":"rkeAAJ0tFm","number":901,"cdate":1538087886690,"ddate":null,"tcdate":1538087886690,"tmdate":1538156033037,"tddate":null,"forum":"S1lwRjR9YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Stability of Stochastic Gradient Method with Momentum for Strongly Convex Loss Functions","abstract":"While momentum-based methods, in conjunction with the stochastic gradient descent, are widely used when training machine learning models, there is little theoretical understanding on the generalization error of such methods. In practice, the momentum parameter is often chosen in a heuristic fashion with little theoretical guidance. In this work, we use the framework of algorithmic stability to provide an upper-bound on the generalization error for the class of strongly convex loss functions, under mild technical assumptions. Our bound decays to zero inversely with the size of the training set, and increases as the momentum parameter is increased. We also develop an upper-bound on the expected true risk,  in terms of the number of training steps, the size of the training set, and the momentum parameter.","keywords":["Generalization Error","Stochastic Gradient Descent","Uniform Stability"],"authorids":["ICLR.cc/2019/Conference/Paper901/Authors"],"authors":["Anonymous"],"TL;DR":"Stochastic gradient method with momentum generalizes.","pdf":"/pdf/62858886f6aa92813c508398ab739d72ac04e92b.pdf","paperhash":"anonymous|stability_of_stochastic_gradient_method_with_momentum_for_strongly_convex_loss_functions","_bibtex":"@inproceedings{    \nanonymous2019stability,    \ntitle={Stability of Stochastic Gradient Method with Momentum for Strongly Convex Loss Functions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lwRjR9YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJfvAoC9YQ","original":"BkxV7iMctm","number":902,"cdate":1538087886857,"ddate":null,"tcdate":1538087886857,"tmdate":1538156032828,"tddate":null,"forum":"BJfvAoC9YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Feature Transformers: A Unified Representation Learning Framework for Lifelong Learning","abstract":"Despite the recent advances in representation learning, lifelong learning continues\nto be one of the most challenging and unconquered problems. Catastrophic forgetting\nand data privacy constitute two of the important challenges for a successful\nlifelong learner. Further, existing techniques are designed to handle only specific\nmanifestations of lifelong learning, whereas a practical lifelong learner is expected\nto switch and adapt seamlessly to different scenarios. In this paper, we present a\nsingle, unified mathematical framework for handling the myriad variants of lifelong\nlearning, while alleviating these two challenges. We utilize an external memory\nto store only the features representing past data and learn richer and newer\nrepresentations incrementally through transformation neural networks - feature\ntransformers. We define, simulate and demonstrate exemplary performance on a\nrealistic lifelong experimental setting using the MNIST rotations dataset, paving\nthe way for practical lifelong learners. To illustrate the applicability of our method\nin data sensitive domains like healthcare, we study the pneumothorax classification\nproblem from X-ray images, achieving near gold standard performance.\nWe also benchmark our approach with a number of state-of-the art methods on\nMNIST rotations and iCIFAR100 datasets demonstrating superior performance.","keywords":["continual learning","deep learning","lifelong learning","new task learning","representation learning"],"authorids":["ICLR.cc/2019/Conference/Paper902/Authors"],"authors":["Anonymous"],"TL;DR":"Single generic mathematical framework for lifelong learning paradigms with data privacy","pdf":"/pdf/d3be9720223e6c94973c2833be4f4ee03d7803ef.pdf","paperhash":"anonymous|feature_transformers_a_unified_representation_learning_framework_for_lifelong_learning","_bibtex":"@inproceedings{    \nanonymous2019feature,    \ntitle={Feature Transformers: A Unified Representation Learning Framework for Lifelong Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJfvAoC9YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hygv0sC5F7","original":"S1xAXZq5YX","number":903,"cdate":1538087887027,"ddate":null,"tcdate":1538087887027,"tmdate":1538156032624,"tddate":null,"forum":"Hygv0sC5F7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"When Will Gradient Methods Converge to Max-margin Classifier under ReLU Models?","abstract":"We study the implicit bias of gradient descent methods in solving a binary classification problem over a linearly separable dataset. The classifier is described by a nonlinear ReLU model and the objective function adopts the exponential loss function. We first characterize the landscape of the loss function and show that there can exist spurious asymptotic local minima besides asymptotic global minima. We then show that gradient descent (GD) can converge to either a global or a local max-margin direction, or may diverge from the desired max-margin direction in a general context. For stochastic gradient descent (SGD), we show that it converges in expectation to either the global or the local max-margin direction if SGD converges. We further explore the implicit bias of these algorithms in learning a multi-neuron network under certain stationary conditions, and show that the learned classifier maximizes the margins of each sample pattern partition under the ReLU activation.","keywords":["gradient method","max-margin","ReLU model"],"authorids":["ICLR.cc/2019/Conference/Paper903/Authors"],"authors":["Anonymous"],"TL;DR":"We study the implicit bias of gradient methods in solving a binary classification problem with nonlinear ReLU models.","pdf":"/pdf/f4b7688b3c9bea0e4a93a377dad1dccc965aab65.pdf","paperhash":"anonymous|when_will_gradient_methods_converge_to_maxmargin_classifier_under_relu_models","_bibtex":"@inproceedings{    \nanonymous2019when,    \ntitle={When Will Gradient Methods Converge to Max-margin Classifier under ReLU Models?},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hygv0sC5F7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1gDCiCqtQ","original":"Skgcrnp5FQ","number":904,"cdate":1538087887203,"ddate":null,"tcdate":1538087887203,"tmdate":1538156032414,"tddate":null,"forum":"S1gDCiCqtQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Representations in Model-Free Hierarchical Reinforcement Learning","abstract":"Common approaches to Reinforcement Learning (RL) are seriously challenged by large-scale applications involving huge state spaces and sparse delayed reward feedback. Hierarchical Reinforcement Learning (HRL) methods attempt to address this scalability issue by learning action selection policies at multiple levels of temporal abstraction. Abstraction can be had by identifying a relatively small set of states that are likely to be useful as subgoals, in concert with the learning of corresponding skill policies to achieve those subgoals. Many approaches to subgoal discovery in HRL depend on the analysis of a model of the environment, but the need to learn such a model introduces its own problems of scale. Once subgoals are identified, skills may be learned through intrinsic motivation, introducing an internal reward signal marking subgoal attainment. In this paper, we present a novel model-free method for subgoal discovery using incremental unsupervised learning over a small memory of the most recent experiences of the agent. When combined with an intrinsic motivation learning mechanism, this method learns subgoals and skills together, based on experiences in the environment. Thus, we offer an original approach to HRL that does not require the acquisition of a model of the environment, suitable for large-scale applications. We demonstrate the efficiency of our method on two RL problems with sparse delayed feedback: a variant of the rooms environment and the ATARI 2600 game called Montezuma's Revenge.\n","keywords":["Reinforcement Learning","Model-Free Hierarchical Reinforcement Learning","Subgoal Discovery","Unsupervised Learning","Temporal Difference","Temporal Abstraction","Intrinsic Motivation","Markov Decision Processes","Deep Reinforcement Learning","Optimization"],"authorids":["ICLR.cc/2019/Conference/Paper904/Authors"],"authors":["Anonymous"],"TL;DR":"We offer an original approach to model-free deep hierarchical reinforcement learning, including unsupervised subgoal discovery and unified temporal abstraction and intrinsic motivation learning. ","pdf":"/pdf/e4b525030cb6bdfaf77fc3492532d0ba948049a4.pdf","paperhash":"anonymous|learning_representations_in_modelfree_hierarchical_reinforcement_learning","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Representations in Model-Free Hierarchical Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1gDCiCqtQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJePRoAct7","original":"ryecpWtdYX","number":905,"cdate":1538087887378,"ddate":null,"tcdate":1538087887378,"tmdate":1538156032200,"tddate":null,"forum":"HJePRoAct7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Graph U-Net","abstract":"We consider the problem of representation learning for graph data. Convolutional neural networks can naturally operate on images, but have significant challenges in dealing with graph data. Given images are special cases of graphs with nodes lie on 2D lattices, graph embedding tasks have a natural correspondence with image pixel-wise prediction tasks such as segmentation. While encoder-decoder architectures like U-Net have been successfully applied on many image pixel-wise prediction tasks, similar methods are lacking for graph data. This is due to the fact that pooling and up-sampling operations are not natural on graph data. To address these challenges, we propose novel graph pooling (gPool) and unpooling (gUnpool) operations in this work. The gPool layer adaptively selects some nodes to form a smaller graph based on their scalar projection values on a trainable projection vector. We further propose the gUnpool layer as the inverse operation of the gPool layer. The gUnpool layer restores the graph into its original structure using the position information of nodes selected in the corresponding gPool layer. Based on our proposed gPool and gUnpool layers, we develop an encoder-decoder model on graph, known as the graph U-Net. Our experimental results on node classification tasks demonstrate that our methods achieve consistently better performance than previous models.","keywords":["graph","pooling","unpooling","U-Net"],"authorids":["ICLR.cc/2019/Conference/Paper905/Authors"],"authors":["Anonymous"],"TL;DR":"We propose the graph U-Net based on our novel graph pooling and unpooling layer for network embedding.","pdf":"/pdf/843dc5045adb7c9b7e0697e94707f9a91a51805b.pdf","paperhash":"anonymous|graph_unet","_bibtex":"@inproceedings{    \nanonymous2019graph,    \ntitle={Graph U-Net},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJePRoAct7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkgd0iA9FQ","original":"B1lbnopqFX","number":906,"cdate":1538087887543,"ddate":null,"tcdate":1538087887543,"tmdate":1538156031983,"tddate":null,"forum":"rkgd0iA9FQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Convergence Guarantees for RMSProp and ADAM in Non-Convex Optimization and an Empirical Comparison to Nesterov Acceleration","abstract":"RMSProp and ADAM continue to be extremely popular algorithms for training neural nets but their theoretical convergence properties have remained unclear. Further, recent work has seemed to suggest that these algorithms have worse generalization properties when compared to carefully tuned stochastic gradient descent or its momentum variants. In this work, we make progress towards a deeper understanding of ADAM and RMSProp in two ways. First, we provide proofs that these adaptive gradient algorithms are guaranteed to reach criticality for smooth non-convex objectives, and we give bounds on the running time.\n\nNext we design experiments to empirically study the convergence and generalization properties of RMSProp and ADAM against Nesterov's Accelerated Gradient method on a variety of common autoencoder setups. Through these experiments we demonstrate the interesting sensitivity that ADAM has to its momentum parameter \\beta_1. We show that at very high values of the momentum parameter (\\beta_1 = 0.99) ADAM outperforms a carefully tuned NAG on most of our experiments, in terms of getting lower training and test losses. On the other hand, NAG can sometimes do better when ADAM's \\beta_1 is set to the most commonly used value: \\beta_1 = 0.9, indicating the importance of tuning the hyperparameters of ADAM to get better generalization performance.\n\nWe also report experiments on different autoencoders to demonstrate that NAG has better abilities in terms of reducing the gradient norms, and it also produces iterates which exhibit an increasing trend for the minimum eigenvalue of the Hessian of the loss function at the iterates. ","keywords":["adaptive gradient descent","deeplearning","ADAM","RMSProp","autoencoders"],"authorids":["ICLR.cc/2019/Conference/Paper906/Authors"],"authors":["Anonymous"],"TL;DR":"In this paper we prove convergence to criticality of (stochastic and deterministic) RMSProp and deterministic ADAM for smooth non-convex objectives and we demonstrate an interesting beta_1 sensitivity for ADAM on autoencoders. ","pdf":"/pdf/4b66a45f3f489d084fdb60acf19c7b2bd4a131b6.pdf","paperhash":"anonymous|convergence_guarantees_for_rmsprop_and_adam_in_nonconvex_optimization_and_an_empirical_comparison_to_nesterov_acceleration","_bibtex":"@inproceedings{    \nanonymous2019convergence,    \ntitle={Convergence Guarantees for RMSProp and ADAM in Non-Convex Optimization and an Empirical Comparison to Nesterov Acceleration},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgd0iA9FQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJxdAoCcYX","original":"r1lwtgyqtQ","number":907,"cdate":1538087887717,"ddate":null,"tcdate":1538087887717,"tmdate":1538156031767,"tddate":null,"forum":"HJxdAoCcYX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Characterizing Malicious Edges targeting on Graph Neural Networks","abstract":"Deep neural networks on graph structured data have shown increasing success in various applications. However, due to recent studies about vulnerabilities of machine learning models, researchers are encouraged to explore the robustness of graph neural networks (GNNs). So far there are two work targeting to attack GNNs by adding/deleting edges to fool graph based classification tasks. Such attacks are challenging to be detected since the manipulation is very subtle compared with traditional graph attacks. In this paper we propose the first detection mechanism against these two proposed attacks. Given a perturbed graph, we propose a novel graph generation method together with link prediction as preprocessing to detect potential malicious edges. We also propose novel features which can be leveraged to perform outlier detection when the number of added malicious edges are large. Different detection components are proposed and tested, and we also evaluate the performance of final detection pipeline. Extensive experiments are conducted to show that the proposed detection mechanism can achieve AUC above 90% against the two attack strategies on both Cora and Citeseer datasets. We also provide in-depth analysis of different attack strategies and corresponding suitable detection methods. Our results shed light on several principles for detecting different types of attacks.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper907/Authors"],"authors":["Anonymous"],"pdf":"/pdf/1251a91d41cdff7bbfa593ebcbb1d9d77907452c.pdf","paperhash":"anonymous|characterizing_malicious_edges_targeting_on_graph_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019characterizing,    \ntitle={Characterizing Malicious Edges targeting on Graph Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxdAoCcYX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1luCsCqFm","original":"SklJW9q9Fm","number":908,"cdate":1538087887883,"ddate":null,"tcdate":1538087887883,"tmdate":1538156031562,"tddate":null,"forum":"r1luCsCqFm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learn From Neighbour: A Curriculum That Train Low Weighted Samples By Imitating","abstract":"Deep neural networks, which gain great success in a wide spectrum of applications, are often time, compute and storage hungry. Curriculum learning proposed to boost training of network by a syllabus from easy to hard. However, the relationship between data complexity and network training is unclear: why hard example harm the performance at beginning but helps at end. In this paper, we aim to investigate on this problem. Similar to internal covariate shift in network forward pass, the distribution changes in weight of top layers also affects training of preceding layers during the backward pass. We call this phenomenon inverse \"internal covariate shift\". Training hard examples aggravates the distribution shifting and damages the training. To address this problem, we introduce a curriculum loss that consists of two parts: a) an adaptive weight that mitigates large early punishment; b) an additional representation loss for low weighted samples. The intuition of the loss is very simple. We train top layers on \"good\" samples to reduce large shifting, and encourage \"bad\" samples to learn from \"good\" sample. In detail, the adaptive weight assigns small values to hard examples, reducing the influence of noisy gradients. On the other hand, the less-weighted hard sample receives the proposed representation loss. Low-weighted data gets nearly no training signal and can stuck in embedding space for a long time. The proposed representation loss aims to encourage their training. This is done by letting them learn a better representation from its superior neighbours but not participate in learning of top layers. In this way, the fluctuation of top layers is reduced and hard samples also received signals for training. We found in this paper that curriculum learning needs random sampling between tasks for better training. Our curriculum loss is easy to combine with existing stochastic algorithms like SGD. Experimental result shows an consistent improvement over several benchmark datasets.","keywords":["Curriculum Learning","Internal Covariate Shift"],"authorids":["ICLR.cc/2019/Conference/Paper908/Authors"],"authors":["Anonymous"],"pdf":"/pdf/4ae687244ce452107e640d4936afefc3321e8a50.pdf","paperhash":"anonymous|learn_from_neighbour_a_curriculum_that_train_low_weighted_samples_by_imitating","_bibtex":"@inproceedings{    \nanonymous2019learn,    \ntitle={Learn From Neighbour: A Curriculum That Train Low Weighted Samples By Imitating},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1luCsCqFm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyM_RsCqYm","original":"Syg46pTcK7","number":909,"cdate":1538087888059,"ddate":null,"tcdate":1538087888059,"tmdate":1538156031346,"tddate":null,"forum":"HyM_RsCqYm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Hierarchical Bayesian Modeling for Clustering Sparse Sequences in the Context of Group Profiling","abstract":"This paper proposes a hierarchical Bayesian model for clustering sparse sequences.This is a mixture model and does not need the data to be represented by a Gaussian mixture and that gives significant modelling freedom.It also generates a very interpretable profile for the discovered latent groups.The data that was used for the work have been contributed by a restaurant loyalty program company. The data is a collection of sparse sequences where each entry of each sequence is the number of user visits of one week to some restaurant. This algorithm successfully clustered the data and calculated the expected user affiliation in each cluster.","keywords":["Hierarchical Bayesian Modeling","Sparse Sequence Clustering","User group Modeling","group profile creation"],"authorids":["ICLR.cc/2019/Conference/Paper909/Authors"],"authors":["Anonymous"],"TL;DR":"Hierarchical Bayesian Modeling for Clustering Sparse Sequences; User group modeling","pdf":"/pdf/65f67af1c54ee0e750ac1141ea450be6e2cdd40d.pdf","paperhash":"anonymous|hierarchical_bayesian_modeling_for_clustering_sparse_sequences_in_the_context_of_group_profiling","_bibtex":"@inproceedings{    \nanonymous2019hierarchical,    \ntitle={Hierarchical Bayesian Modeling for Clustering Sparse Sequences in the Context of Group Profiling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyM_RsCqYm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyzdRiR9Y7","original":"SyeafOTqFm","number":910,"cdate":1538087888236,"ddate":null,"tcdate":1538087888236,"tmdate":1538156031139,"tddate":null,"forum":"HyzdRiR9Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Universal Transformers","abstract":"Recurrent neural networks (RNNs) sequentially process data by updating their state with each new data point, and have long been the de facto choice for sequence modeling tasks. However, their inherently sequential computation makes them slow to train. Feed-forward and convolutional architectures have recently been shown to achieve superior results on some sequence modeling tasks such as machine translation, with the added advantage that they concurrently process all inputs in the sequence, leading to easy parallelization and faster training times. Despite these successes, however, popular feed-forward sequence models like the Transformer fail to generalize in many simple tasks that recurrent models handle with ease, e.g. copying strings or even simple logical inference when the string or formula lengths exceed those observed at training time. We propose the Universal Transformer (UT), a parallel-in-time self-attentive recurrent sequence model which can be cast as a generalization of the Transformer model and which addresses these issues. UTs combine the parallelizability and global receptive field of feed-forward sequence models like the Transformer with the recurrent inductive bias of RNNs. We also add a dynamic per-position halting mechanism and find that it improves accuracy on several tasks. In contrast to the standard Transformer, under certain assumptions UTs can be shown to be Turing-complete. Our experiments show that UTs outperform standard Transformers on a wide range of algorithmic and language understanding tasks, including the challenging LAMBADA language modeling task where UTs achieve a new state of the art, and machine translation where UTs achieve a 0.9 BLEU improvement over Transformers on the WMT14 En-De dataset.","keywords":["sequence-to-sequence","rnn","transformer","machine translation","language understanding","learning to execute"],"authorids":["ICLR.cc/2019/Conference/Paper910/Authors"],"authors":["Anonymous"],"TL;DR":"We introduce the Universal Transformer, a self-attentive parallel-in-time recurrent sequence model that outperforms Transformers and LSTMs on a wide range of sequence-to-sequence tasks, including machine translation.","pdf":"/pdf/f2985e6a75a285300197cb5e19f55128f1bd0309.pdf","paperhash":"anonymous|universal_transformers","_bibtex":"@inproceedings{    \nanonymous2019universal,    \ntitle={Universal Transformers},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyzdRiR9Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyVuRiC5K7","original":"r1gNKqKqK7","number":911,"cdate":1538087888410,"ddate":null,"tcdate":1538087888410,"tmdate":1538156030929,"tddate":null,"forum":"SyVuRiC5K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"LEARNING TO PROPAGATE LABELS: TRANSDUCTIVE PROPAGATION NETWORK FOR FEW-SHOT LEARNING","abstract":"The goal of few-shot learning is to learn a classifier that generalizes well even when trained with a limited number of training instances per class. The recently introduced meta-learning approaches tackle this problem by learning a generic classifier across a large number of multiclass classification tasks and generalizing the model to a new task. Yet, even with such meta-learning, the low-data problem in the novel classification task still remains. In this paper, we propose Transductive Propagation Network (TPN), a novel meta-learning framework for transductive inference that classifies the entire test set at once to alleviate the low-data problem. Specifically, we propose to learn to propagate labels from labeled instances to unlabeled test instances, by learning a graph construction module that exploits the manifold structure in the data. TPN jointly learns both the parameters of feature embedding and the graph construction in an end-to-end manner.  We validate TPN on multiple benchmark datasets, on which it largely outperforms existing few-shot learning approaches and achieves the state-of-the-art results. ","keywords":["few-shot learning","meta-learning","label propagation","manifold learning"],"authorids":["ICLR.cc/2019/Conference/Paper911/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a novel meta-learning framework for transductive inference that classifies the entire test set at once to alleviate the low-data problem.","pdf":"/pdf/660610b23322752adb258d886072234513fd8b67.pdf","paperhash":"anonymous|learning_to_propagate_labels_transductive_propagation_network_for_fewshot_learning","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={LEARNING TO PROPAGATE LABELS: TRANSDUCTIVE PROPAGATION NETWORK FOR FEW-SHOT LEARNING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyVuRiC5K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJlY0jA5F7","original":"B1g7yV69tX","number":912,"cdate":1538087888590,"ddate":null,"tcdate":1538087888590,"tmdate":1538156030723,"tddate":null,"forum":"HJlY0jA5F7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Improving Sample-based Evaluation for Generative Adversarial Networks","abstract":"In this paper, we propose an improved quantitative evaluation framework for Generative Adversarial Networks (GANs) on generating domain-specific images, where we improve conventional evaluation methods on two levels: the feature representation and the evaluation metric. Unlike most existing evaluation frameworks which transfer the representation of ImageNet inception model to map images onto the feature space, our framework uses a specialized encoder to acquire fine-grained domain-specific representation. Moreover, for datasets with multiple classes, we propose Class-Aware Frechet Distance (CAFD), which employs a Gaussian mixture model on the feature space to better fit the multi-manifold feature distribution. Experiments and analysis on both the feature level and the image level were conducted to demonstrate improvements of our proposed framework over the recently proposed state-of-the-art FID method. To our best knowledge, we are the first to provide counter examples where FID gives inconsistent results with human judgments. It is shown in the experiments that our framework is able to overcome the shortness of FID and improves robustness. Code will be made available.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper912/Authors"],"authors":["Anonymous"],"TL;DR":"This paper improves existing sample-based evaluation for GANs and contains some insightful experiments.","pdf":"/pdf/c0c84392e5674aac1bf1b37376733f470d291079.pdf","paperhash":"anonymous|improving_samplebased_evaluation_for_generative_adversarial_networks","_bibtex":"@inproceedings{    \nanonymous2019improving,    \ntitle={Improving Sample-based Evaluation for Generative Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJlY0jA5F7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1xtAjR5tX","original":"ByxXipK5KQ","number":913,"cdate":1538087888768,"ddate":null,"tcdate":1538087888768,"tmdate":1538156030513,"tddate":null,"forum":"S1xtAjR5tX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Improving Sequence-to-Sequence Learning via Optimal Transport","abstract":"Sequence-to-sequence models are commonly trained via maximum likelihood estimation (MLE). However, standard MLE training considers a word-level objective, predicting the next word given the previous ground-truth partial sentence. This procedure focuses on modeling local syntactic patterns, and may fail to capture long-range semantic structure. We present a novel solution to alleviate these issues. Our approach imposes global sequence-level guidance via new supervision based on optimal transport, enabling the overall characterization and preservation of semantic features. We further show that this method can be understood as a Wasserstein gradient flow trying to match our model to the ground truth sequence distribution. Extensive experiments are conducted to validate the utility of the proposed approach, showing consistent improvements over a wide variety of NLP tasks, including machine translation, abstractive text summarization, and image captioning.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper913/Authors"],"authors":["Anonymous"],"pdf":"/pdf/b29d2852affb3a98fcb536e9c8fd39af797df4e7.pdf","paperhash":"anonymous|improving_sequencetosequence_learning_via_optimal_transport","_bibtex":"@inproceedings{    \nanonymous2019improving,    \ntitle={Improving Sequence-to-Sequence Learning via Optimal Transport},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1xtAjR5tX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1fF0iR9KX","original":"H1lWyATqKX","number":914,"cdate":1538087888942,"ddate":null,"tcdate":1538087888942,"tmdate":1538156030305,"tddate":null,"forum":"H1fF0iR9KX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Geometry aware convolutional filters for omnidirectional images representation","abstract":"Due to their wide field of view, omnidirectional cameras are frequently used by autonomous vehicles, drones and robots for navigation and other computer vision tasks. The images captured by such cameras, are often analyzed and classified with techniques designed for planar images that unfortunately fail to properly handle the native geometry of such images. That results in suboptimal performance, and lack of truly meaningful visual features. In this paper we aim at improving popular deep convolutional neural networks so that they can properly take into account the specific properties of omnidirectional data. In particular we propose an algorithm that adapts convolutional layers, which often serve as a core building block of a CNN, to the properties of omnidirectional images. Thus, our filters have a shape and size that adapts with the location on the omnidirectional image. We show that our method  achieves better results compared to existing deep neural network techniques for omnidirectional image classification. Finally we show that our method is not limited to spherical surfaces and is able to incorporate the knowledge about any kind of omnidirectional  geometry inside the deep learning network.\n","keywords":["omnidirectional images","classification","deep learning","graph signal processing"],"authorids":["ICLR.cc/2019/Conference/Paper914/Authors"],"authors":["Anonymous"],"pdf":"/pdf/820a99c44a2cb19d62bd02fc37f07a506225db67.pdf","paperhash":"anonymous|geometry_aware_convolutional_filters_for_omnidirectional_images_representation","_bibtex":"@inproceedings{    \nanonymous2019geometry,    \ntitle={Geometry aware convolutional filters for omnidirectional images representation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1fF0iR9KX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyeFAsRctQ","original":"r1xxdIvLFQ","number":915,"cdate":1538087889121,"ddate":null,"tcdate":1538087889121,"tmdate":1538156030099,"tddate":null,"forum":"HyeFAsRctQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Verification of Non-Linear Specifications for Neural Networks","abstract":"Prior work on neural network verification has focused on specifications that are linear functions of the output of the network, e.g., invariance of the classifier output under adversarial perturbations of the input. In this paper, we extend verification algorithms to be able to certify richer properties of neural networks. To do this we introduce the class of convex-relaxable specifications, which constitute nonlinear specifications that can be verified using a convex relaxation. We show that a number of important properties of interest can be modeled within this class, including conservation of energy in a learned dynamics model of a physical system; semantic consistency of a classifier's output labels under adversarial perturbations and bounding errors in a system that predicts the summation of handwritten digits. Our experimental evaluation shows that our method is able to effectively verify these specifications. Moreover, our evaluation exposes the failure modes in models which cannot be verified to satisfy these specifications. Thus, emphasizing the importance of training models not just to fit training data but also to be consistent with specifications.","keywords":["Verification","Convex Optimization","Adversarial Robustness"],"authorids":["ICLR.cc/2019/Conference/Paper915/Authors"],"authors":["Anonymous"],"pdf":"/pdf/49b4f01f62d66e3d170aecf1f85768e9820ab571.pdf","paperhash":"anonymous|verification_of_nonlinear_specifications_for_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019verification,    \ntitle={Verification of Non-Linear Specifications for Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyeFAsRctQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJeKCi0qYX","original":"H1eqbtO5K7","number":916,"cdate":1538087889297,"ddate":null,"tcdate":1538087889297,"tmdate":1538156029889,"tddate":null,"forum":"HJeKCi0qYX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"MILE: A Multi-Level Framework for Scalable Graph Embedding","abstract":"Recently there has been a surge of interest in designing graph embedding methods. Few, if any, can scale to a large-sized graph with millions of nodes due to both computational complexity and memory requirements. In this paper, we relax this limitation by introducing the MultI-Level Embedding (MILE) framework – a generic methodology allowing contemporary graph embedding methods to scale to large graphs. MILE repeatedly coarsens the graph into smaller ones using a hybrid matching technique to maintain the backbone structure of the graph. It then applies existing embedding methods on the coarsest graph and refines the embeddings to the original graph through a novel graph convolution neural network that it learns. The proposed MILE framework is agnostic to the underlying graph embedding techniques and can be applied to many existing graph embedding methods without modifying them. We employ our framework on several popular graph embedding techniques and conduct embedding for real-world graphs. Experimental results on five large-scale datasets demonstrate that MILE significantly boosts the speed (order of magnitude) of graph embedding while also often generating embeddings of better quality for the task of node classification. MILE can comfortably scale to a graph with 9 million nodes and 40 million edges, on which existing methods run out of memory or take too long to compute on a modern workstation.","keywords":["Network Embedding","Graph Convolutional Networks","Deep Learning"],"authorids":["ICLR.cc/2019/Conference/Paper916/Authors"],"authors":["Anonymous"],"TL;DR":"A generic framework to scale existing graph embedding techniques to large graphs.","pdf":"/pdf/d2c5d142e6ef127ef8d750958493d5f89b6cc3f7.pdf","paperhash":"anonymous|mile_a_multilevel_framework_for_scalable_graph_embedding","_bibtex":"@inproceedings{    \nanonymous2019mile:,    \ntitle={MILE: A Multi-Level Framework for Scalable Graph Embedding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJeKCi0qYX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1lYRjC9F7","original":"r1l2yRT9KX","number":917,"cdate":1538087889476,"ddate":null,"tcdate":1538087889476,"tmdate":1538156029680,"tddate":null,"forum":"r1lYRjC9F7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset","abstract":"Generating musical audio directly with neural networks is notoriously difficult because it requires coherently modeling structure at many different timescales. Fortunately, most music is also highly structured and can be represented as discrete note events played on musical instruments. Herein, we show that by using notes as an intermediate representation, we can train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure on timescales spanning six orders of magnitude (~0.1 ms to ~100 s). This large advance in the state of the art is enabled by our release of the new MAESTRO (MIDI and Audio Edited for Synchronous TRacks and Organization) dataset, composed of over 172 hours of virtuosic piano performances captured with fine alignment (~3 ms) between note labels and audio waveforms. The networks and the dataset together present a promising approach toward creating new expressive and interpretable neural models of music.","keywords":["music","piano transcription","transformer","wavnet","audio synthesis","dataset","midi"],"authorids":["ICLR.cc/2019/Conference/Paper917/Authors"],"authors":["Anonymous"],"TL;DR":"We train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure, enabled by the new MAESTRO dataset.","pdf":"/pdf/18d62fe54d28d81bb4b423b686552b88d0643382.pdf","paperhash":"anonymous|enabling_factorized_piano_music_modeling_and_generation_with_the_maestro_dataset","_bibtex":"@inproceedings{    \nanonymous2019enabling,    \ntitle={Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1lYRjC9F7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ByecAoAqK7","original":"rJxYDSacFm","number":918,"cdate":1538087889645,"ddate":null,"tcdate":1538087889645,"tmdate":1538156029479,"tddate":null,"forum":"ByecAoAqK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Zero-shot Dual Machine Translation","abstract":"Neural Machine Translation (NMT) systems rely on large amounts of parallel data.This is a major challenge for low-resource languages. Building on recent work onunsupervised and semi-supervised methods, we present an approach that combineszero-shot and dual learning. The latter relies on reinforcement learning, to exploitthe duality of the machine translation task, and requires only monolingual datafor the target language pair. Experiments on the UN corpus show that a zero-shotdual system, trained on English-French and English-Spanish, outperforms by largemargins a standard NMT system in zero-shot translation performance on Spanish-French (both directions). We also evaluate onnewstest2014. These experimentsshow that the zero-shot dual method outperforms the LSTM-based unsupervisedNMT system proposed in (Lample et al., 2018b), on the en→fr task, while onthe fr→en task it outperforms both the LSTM-based and the Transformers-basedunsupervised NMT systems.","keywords":["unsupervised","machine translation","dual learning","zero-shot"],"authorids":["ICLR.cc/2019/Conference/Paper918/Authors"],"authors":["Anonymous"],"TL;DR":"A multilingual NMT model with reinforcement learning (dual learning) aiming to improve zero-shot translation directions.","pdf":"/pdf/bccab057a76a9d26379a6f111b25349cd0618508.pdf","paperhash":"anonymous|zeroshot_dual_machine_translation","_bibtex":"@inproceedings{    \nanonymous2019zero-shot,    \ntitle={Zero-shot Dual Machine Translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByecAoAqK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkeqCoA5tX","original":"Byxs-Aa5Y7","number":919,"cdate":1538087889808,"ddate":null,"tcdate":1538087889808,"tmdate":1538156029274,"tddate":null,"forum":"rkeqCoA5tX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"LEARNING GENERATIVE MODELS FOR DEMIXING OF STRUCTURED SIGNALS FROM THEIR SUPERPOSITION USING GANS","abstract":"Recently, Generative Adversarial Networks (GANs) have emerged as popular alternative for modeling complex high dimensional distributions. Most of the existing works implicitly assume that the clean samples from the target distribution are easily available. However, in many applications this assumption is violated. In this paper, we consider the problem of learning GANs under the observation setting when the samples from target distribution are given by superposition of two structured components. We propose two novel frameworks: denoising-GAN and demixing-GAN. The denoising-GAN assumes access to clean samples from the second component and try to learn the other distribution, whereas demixing-GAN learns the distribution of the components in the same time. Through of comprehensive numerical experiments, we demonstrate that proposed frameworks can generate clean samples from unknown distributions, and provide competitive performance in tasks such as denoising, demixing, and compressive sensing. ","keywords":["Generative Models","GANs","Denosing","Demixing","Structured Recovery"],"authorids":["ICLR.cc/2019/Conference/Paper919/Authors"],"authors":["Anonymous"],"pdf":"/pdf/270ee3a226733f3db9069174acfd72382758d1cf.pdf","paperhash":"anonymous|learning_generative_models_for_demixing_of_structured_signals_from_their_superposition_using_gans","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={LEARNING GENERATIVE MODELS FOR DEMIXING OF STRUCTURED SIGNALS FROM THEIR SUPERPOSITION USING GANS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkeqCoA5tX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkl5CjC9Fm","original":"B1l5SqacYX","number":920,"cdate":1538087889978,"ddate":null,"tcdate":1538087889978,"tmdate":1538156029071,"tddate":null,"forum":"rkl5CjC9Fm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Dual Importance Weight GAN","abstract":"Generative Adversarial Networks (GAN) are trained to generate a sample image of interest. To this end, generative network of GAN learns implicit distribution of true dataset from the classification samples with candidate generated samples. However, in real implementation of GAN, training the generative network with limited number of candidate samples guarantees to properly represent neither true distribution nor the distribution of generator outputs. In this paper, we propose dual importance weights for the candidate samples represented in the latent space of auto-encoder. The auto-encoder is pre-trained with real target dataset. Therefore, the latent space representation allows us to compare real distribution and the distribution of generated samples explicitly. Dual importance weights iteratively maximize the representation of generated samples for both distributions: current generator outputs and real dataset. Proposed generative model not only resolves mode collapse problem of GAN but also improves the convergence on target distribution. Experimental evaluation shows that the proposed network learns complete modes of target distribution more stable and faster than state of the art methods. ","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper920/Authors"],"authors":["Anonymous"],"pdf":"/pdf/b412aa2d4ec85c8f7f738a2c0a96571ac67e0aec.pdf","paperhash":"anonymous|dual_importance_weight_gan","_bibtex":"@inproceedings{    \nanonymous2019dual,    \ntitle={Dual Importance Weight GAN},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkl5CjC9Fm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkgqCiRqKQ","original":"SklJfA69tm","number":921,"cdate":1538087890147,"ddate":null,"tcdate":1538087890147,"tmdate":1538156028855,"tddate":null,"forum":"rkgqCiRqKQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Inferring Reward Functions from Demonstrators with Unknown Biases","abstract":"Our goal is to infer reward functions from demonstrations. In order to infer the correct reward function, we must account for the systematic ways in which the demonstrator is suboptimal. Prior work in inverse reinforcement learning can account for specific, known biases, but cannot handle demonstrators with unknown biases. In this work, we explore the idea of learning the demonstrator's planning algorithm (including their unknown biases), along with their reward function. What makes this challenging is that any demonstration could be explained either by positing a term in the reward function, or by positing a particular systematic bias. We explore what assumptions are sufficient for avoiding this impossibility result: either access to tasks with known rewards which enable estimating the planner separately, or that the demonstrator is sufficiently close to optimal that this can serve as a regularizer. In our exploration with synthetic models of human biases, we find that it is possible to adapt to different biases and perform better than assuming a fixed model of the demonstrator, such as Boltzmann rationality.","keywords":["Inverse reinforcement learning","differentiable planning"],"authorids":["ICLR.cc/2019/Conference/Paper921/Authors"],"authors":["Anonymous"],"TL;DR":"When we infer preferences from behavior, we can try to improve accuracy by jointly learning a bias model and preferences, though this requires new assumptions to make progress.","pdf":"/pdf/5386d88f6508dbd1c0e8d3b2bb767c7bdc61b798.pdf","paperhash":"anonymous|inferring_reward_functions_from_demonstrators_with_unknown_biases","_bibtex":"@inproceedings{    \nanonymous2019inferring,    \ntitle={Inferring Reward Functions from Demonstrators with Unknown Biases},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgqCiRqKQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryfcCo0ctQ","original":"HklXNp29FQ","number":922,"cdate":1538087890327,"ddate":null,"tcdate":1538087890327,"tmdate":1538156028644,"tddate":null,"forum":"ryfcCo0ctQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Convergent Reinforcement Learning with Function Approximation: A Bilevel Optimization Perspective","abstract":" We study reinforcement learning algorithms with nonlinear function approximation in the online setting. By formulating both the problems of value function estimation and policy learning as bilevel optimization problems, we propose online Q-learning and actor-critic algorithms for these two problems respectively.   Our algorithms are gradient-based methods and thus are computationally efficient. Moreover, by approximating the iterates using differential equations,   we establish convergence guarantees for the proposed algorithms. Thorough numerical experiments are conducted to back up our theory.","keywords":["reinforcement learning","Deep Q-networks","actor-critic algorithm","ODE approximation"],"authorids":["ICLR.cc/2019/Conference/Paper922/Authors"],"authors":["Anonymous"],"pdf":"/pdf/b5090a93bdd9dbc5fb39e9816dc1ed3b3652c393.pdf","paperhash":"anonymous|convergent_reinforcement_learning_with_function_approximation_a_bilevel_optimization_perspective","_bibtex":"@inproceedings{    \nanonymous2019convergent,    \ntitle={Convergent Reinforcement Learning with Function Approximation: A Bilevel Optimization Perspective},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryfcCo0ctQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BkMq0oRqFQ","original":"B1gQV_8KKX","number":923,"cdate":1538087890499,"ddate":null,"tcdate":1538087890499,"tmdate":1538156028435,"tddate":null,"forum":"BkMq0oRqFQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Normalization Gradients are Least-squares Residuals","abstract":"Batch Normalization (BN) and its variants have seen widespread adoption in the deep learning community because they improve the training of deep neural networks. Discussions of why this normalization works so well remain unsettled.  We make explicit the relationship between ordinary least squares and partial derivatives computed when back-propagating through BN. We recast the back-propagation of BN as a least squares fit, which zero-centers and decorrelates partial derivatives from normalized activations. This view, which we term {\\em gradient-least-squares}, is an extensible and arithmetically accurate description of BN. Our view offers a unified interpretation of BN and related work; we motivate, from a regression perspective, two improvements to BN, and evaluate on CIFAR-10.","keywords":["Deep Learning","Normalization","Least squares","Gradient regression"],"authorids":["ICLR.cc/2019/Conference/Paper923/Authors"],"authors":["Anonymous"],"TL;DR":"Batch Normalization and its variants work by performing a least-squares fit during back-propagation, which zero-centers and decorrelates partial derivatives from normalized activations.","pdf":"/pdf/f908a8a98dd5669d57361e1b7ebad10bb139fb23.pdf","paperhash":"anonymous|normalization_gradients_are_leastsquares_residuals","_bibtex":"@inproceedings{    \nanonymous2019normalization,    \ntitle={Normalization Gradients are Least-squares Residuals},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkMq0oRqFQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJgsCjCqt7","original":"rJeTqnk_KQ","number":924,"cdate":1538087890666,"ddate":null,"tcdate":1538087890666,"tmdate":1538156028230,"tddate":null,"forum":"SJgsCjCqt7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Variational Autoencoders with Jointly Optimized Latent Dependency Structure","abstract":"We propose a method for learning the dependency structure between latent variables in deep latent variable models.  Our general modeling and inference framework combines the complementary strengths of deep generative models and probabilistic graphical models. In particular, we express the latent variable space of a variational autoencoder (VAE) in terms of a Bayesian network with a learned, flexible dependency structure.  The network parameters, variational parameters as well as the latent topology are optimized simultaneously with a single variational objective.  Inference is formulated via a sampling procedure that produces expectations over latent variable structures and incorporates top-down and bottom-up reasoning over latent variable values.  We validate our framework in extensive experiments on MNIST, Omniglot, and CIFAR-10. Comparisons to state-of-the-art structured variational autoencoder baselines show improvements in terms of the expressiveness of the learned model.","keywords":["deep generative models","structure learning"],"authorids":["ICLR.cc/2019/Conference/Paper924/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a method for learning latent dependency structure in variational autoencoders.","pdf":"/pdf/c94ddfeefe34b8890aabb5cbf8135fbe611c0ac9.pdf","paperhash":"anonymous|variational_autoencoders_with_jointly_optimized_latent_dependency_structure","_bibtex":"@inproceedings{    \nanonymous2019variational,    \ntitle={Variational Autoencoders with Jointly Optimized Latent Dependency Structure},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJgsCjCqt7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BkloRs0qK7","original":"BJeNwd_qK7","number":925,"cdate":1538087890843,"ddate":null,"tcdate":1538087890843,"tmdate":1538156028021,"tddate":null,"forum":"BkloRs0qK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A comprehensive, application-oriented study of catastrophic forgetting in DNNs","abstract":"We present a large-scale empirical study of catastrophic forgetting (CF) in modern Deep Neural Network (DNN) models that perform sequential (or: incremental) learning.\nA new experimental protocol is proposed that takes into account typical constraints encountered in application scenarios.\nAs the investigation is empirical, we evaluate CF behavior on the hitherto largest number of visual classification datasets, from each of which we construct a representative number of Sequential Learning Tasks (SLTs) in close alignment to previous works on CF.\nOur results clearly indicate that there is no model that avoids CF for all investigated datasets and SLTs under application conditions. We conclude with a discussion of potential solutions and workarounds to CF, notably for the EWC and IMM models.","keywords":["incremental learning","deep neural networks","catatrophic forgetting","sequential learning"],"authorids":["ICLR.cc/2019/Conference/Paper925/Authors"],"authors":["Anonymous"],"TL;DR":"We check DNN models for catastrophic forgetting using a new evaluation scheme that reflects typical application conditions, with surprising results.","pdf":"/pdf/c7cb211b6888b6b0096f4635441d5ca00ccc9b1d.pdf","paperhash":"anonymous|a_comprehensive_applicationoriented_study_of_catastrophic_forgetting_in_dnns","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A comprehensive, application-oriented study of catastrophic forgetting in DNNs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkloRs0qK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hkes0iR9KX","original":"HkgK-kCtF7","number":926,"cdate":1538087891010,"ddate":null,"tcdate":1538087891010,"tmdate":1538156027812,"tddate":null,"forum":"Hkes0iR9KX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"DEEP GEOMETRICAL GRAPH Classification WITH DYNAMIC POOLING","abstract":"Most of the existing Graph Neural Networks (GNNs) are the mere extension of the Convolutional Neural Networks (CNNs) to graphs. Generally, they consist of several steps of message passing between the nodes followed by a global indiscriminate feature pooling function. However, most of the times the nodes are unlabeled or their labels (or the given feature vectors of the nodes) provide no information about the similarity between the nodes and the locations of the nodes in the graph. Accordingly, message passing may not propagate helpful information throughout the graph. We show that this conventional approach fails to learn to solve even simple graph classification tasks. We alleviate this serious shortcoming of the GNNs by making them a two step method where in the second step, the message passing block is given the continuous features obtained by the embedding algorithm in the first step. The GNN learns to solve the given task by inferring the topological structure of the graph encoded in the spatial distribution of the embedded vectors. The second challenge we address in this paper is designing a pooling algorithm applicable to graphs. We turn the problem of graph down-sampling into a column sampling problem, i.e., the sampling algorithm samples a subset of the nodes whose feature vectors preserve the spatial distribution of all the feature vectors. We apply the proposed approach to several established benchmark data sets and it is shown that the proposed geometrical approach strongly improves the state-of-the-art for several data-sets.","keywords":["Graph classification","Deep Learning","Graph pooling","Embedding"],"authorids":["ICLR.cc/2019/Conference/Paper926/Authors"],"authors":["Anonymous"],"TL;DR":"A deep learning based graph classification method plus a new adaptive method for graph pooling. ","pdf":"/pdf/8b727d5824842c38ea8dcf3b8774affc3c560d58.pdf","paperhash":"anonymous|deep_geometrical_graph_classification_with_dynamic_pooling","_bibtex":"@inproceedings{    \nanonymous2019deep,    \ntitle={DEEP GEOMETRICAL GRAPH Classification WITH DYNAMIC POOLING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hkes0iR9KX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryxsCiAqKm","original":"ryepiKs5YQ","number":927,"cdate":1538087891179,"ddate":null,"tcdate":1538087891179,"tmdate":1538156027604,"tddate":null,"forum":"ryxsCiAqKm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Spectral Convolutional Networks on Hierarchical Multigraphs","abstract":"Spectral Graph Convolutional Networks (GCNs) are a generalization of convolutional networks to learning on graph-structured data. Applications of spectral GCNs have been successful, but limited to a few problems where the graph is fixed, such as shape correspondence and node classification. In this work, we address this limitation by revisiting a particular family of spectral graph networks, Chebyshev GCNs, showing its efficacy in solving graph classification tasks with a variable graph structure and size. Current GCNs also restrict graphs to have at most one edge between any pair of nodes. To this end, we propose a novel multigraph network that learns from multi-relational graphs. We explicitly model different types of edges: annotated edges, learned edges with abstract meaning, and hierarchical edges. We also experiment with different ways to fuse the representations extracted from different edge types. This restriction is sometimes implied from a dataset, however, we relax this restriction for all kinds of datasets. We achieve state-of-the-art results on a variety of chemical, social, and vision graph classification benchmarks.","keywords":["graph convolution","hierarchical models","neural networks","multigraph","deep learning"],"authorids":["ICLR.cc/2019/Conference/Paper927/Authors"],"authors":["Anonymous"],"TL;DR":"A novel approach to graph classification based on spectral graph convolutional networks and its extension to multigraphs with learnable relations and hierarchical structure. We show state-of-the art results on chemical, social and image datasets.","pdf":"/pdf/2780766fb8a334a6488b6abc29ffd6f8348d30a8.pdf","paperhash":"anonymous|spectral_convolutional_networks_on_hierarchical_multigraphs","_bibtex":"@inproceedings{    \nanonymous2019spectral,    \ntitle={Spectral Convolutional Networks on Hierarchical Multigraphs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxsCiAqKm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkgs0oAqFQ","original":"BJeRQ_nqYX","number":928,"cdate":1538087891356,"ddate":null,"tcdate":1538087891356,"tmdate":1538156027393,"tddate":null,"forum":"rkgs0oAqFQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Rethinking Knowledge Graph Propagation for Zero-Shot Learning","abstract":"Graph convolutional neural networks have recently shown great potential for the task of zero-shot learning. These models are highly sample efficient as related concepts in the graph structure share statistical strength allowing generalization to new classes when faced with a lack of data. However, we find that the extensive use of Laplacian smoothing at each layer in current approaches can easily dilute the knowledge from distant nodes and consequently decrease the performance in zero-shot learning. In order to still enjoy the benefit brought by the graph structure while preventing the dilution of knowledge from distant nodes, we propose a Dense Graph Propagation (DGP) module with carefully designed direct links among distant nodes. DGP allows us to exploit the hierarchical graph structure of the knowledge graph through additional connections. These connections are added based on a node's relationship to its ancestors and descendants. A weighting scheme is further used to weigh their contribution depending on the distance to the node. Combined with finetuning of the representations in a two-stage training approach our method outperforms state-of-the-art zero-shot learning approaches.","keywords":["Dense graph propagation","zero-shot learning"],"authorids":["ICLR.cc/2019/Conference/Paper928/Authors"],"authors":["Anonymous"],"TL;DR":"We rethink the way information can be exploited more efficiently in the knowledge graph in order to improve performance on the Zero-Shot Learning task and propose a dense graph propagation (DGP) module for this purpose.","pdf":"/pdf/e2bc39d191235b44aa49d8a22bff2ef1f2e5e214.pdf","paperhash":"anonymous|rethinking_knowledge_graph_propagation_for_zeroshot_learning","_bibtex":"@inproceedings{    \nanonymous2019rethinking,    \ntitle={Rethinking Knowledge Graph Propagation for Zero-Shot Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgs0oAqFQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hke20iA9Y7","original":"HkeJa7p5FX","number":929,"cdate":1538087891541,"ddate":null,"tcdate":1538087891541,"tmdate":1538156027186,"tddate":null,"forum":"Hke20iA9Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Efficient Training on Very Large Corpora via Gramian Estimation","abstract":"We study the problem of learning similarity functions over very large corpora using neural network embedding models. These models are typically trained using SGD with random sampling of unobserved pairs, with a sample size that grows quadratically with the corpus size, making it expensive to scale.\nWe propose new efficient methods to train these models without having to sample unobserved pairs. Inspired by matrix factorization, our approach relies on adding a global quadratic penalty and expressing this term as the inner-product of two generalized Gramians. We show that the gradient of this term can be efficiently computed by maintaining estimates of the Gramians, and develop variance reduction schemes to improve the quality of the estimates. We conduct large-scale experiments that show a significant improvement both in training time and generalization performance compared to sampling methods.","keywords":["similarity learning","pairwise learning","matrix factorization","Gramian estimation","variance reduction","neural embedding models","recommender systems"],"authorids":["ICLR.cc/2019/Conference/Paper929/Authors"],"authors":["Anonymous"],"TL;DR":"We develop efficient methods to train neural embedding models with a dot-product structure, by reformulating the objective function in terms of generalized Gram matrices, and maintaining estimates of those matrices.","pdf":"/pdf/570ccd4b03b9dec54fd5778b94c5b594b08c1852.pdf","paperhash":"anonymous|efficient_training_on_very_large_corpora_via_gramian_estimation","_bibtex":"@inproceedings{    \nanonymous2019efficient,    \ntitle={Efficient Training on Very Large Corpora via Gramian Estimation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hke20iA9Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1g30j0qF7","original":"BygW0PTqtm","number":930,"cdate":1538087891708,"ddate":null,"tcdate":1538087891708,"tmdate":1538156026969,"tddate":null,"forum":"B1g30j0qF7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Bayesian Convolutional Neural Networks with Many Channels are Gaussian Processes","abstract":"There is a previously identified equivalence between wide fully connected neural networks (FCNs) and Gaussian processes (GPs). This equivalence enables, for instance, test set predictions that would have resulted from a fully Bayesian, infinitely wide trained FCN to be computed without ever instantiating an FCN, but by instead evaluating the corresponding GP. In this work, we derive an analogous equivalence for multi-layer convolutional neural networks (CNNs) both with and without pooling layers. Surprisingly, in the absence of pooling layers, the corresponding GP is identical for CNNs with and without weight sharing. This means that translation equivariance in SGD-trained finite CNNs has no corresponding property in the Bayesian treatment of the infinite-width limit -- a qualitative difference between the two regimes that is not present in the FCN case. We confirm experimentally that in some scenarios, while the performance of trained finite CNNs becomes similar to that of the corresponding GP with increasing channel count, with careful tuning SGD-trained CNNs can significantly outperform their corresponding GPs. Finally, we introduce a Monte Carlo method to estimate the GP corresponding to a NN architecture, even in cases where the analytic form has too many terms to be computationally feasible.","keywords":["Deep Convolutional Neural Networks","Gaussian Processes"],"authorids":["ICLR.cc/2019/Conference/Paper930/Authors"],"authors":["Anonymous"],"TL;DR":"Finite-width SGD trained CNNs vs. infinitely wide fully Bayesian CNNs. Who wins?","pdf":"/pdf/f12f1a69d6d2e9f8ba0f5573bb744e41101b785d.pdf","paperhash":"anonymous|bayesian_convolutional_neural_networks_with_many_channels_are_gaussian_processes","_bibtex":"@inproceedings{    \nanonymous2019bayesian,    \ntitle={Bayesian Convolutional Neural Networks with Many Channels are Gaussian Processes},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1g30j0qF7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BklhAj09K7","original":"BJeLJ6KUFm","number":931,"cdate":1538087891880,"ddate":null,"tcdate":1538087891880,"tmdate":1538156026749,"tddate":null,"forum":"BklhAj09K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Unsupervised Domain Adaptation for Distance Metric Learning","abstract":"Unsupervised domain adaptation is a promising avenue to enhance the performance of deep neural networks on a target domain, using labels only from a source domain. However, the two predominant methods, domain discrepancy reduction learning and semi-supervised learning, are not readily applicable when source and target domains do not share a common label space. This paper addresses the above scenario by learning a representation space that retains discriminative power on both the (labeled) source and (unlabeled) target domains while keeping representations for the two domains well-separated. Inspired by a theoretical analysis, we first reformulate the disjoint classification task, where the source and target domains correspond to non-overlapping class labels, to a verification one. To handle both within and cross domain verifications, we propose a Feature Transfer Network (FTN) to separate the target feature space from the original source space while aligned with a transformed source space. Moreover, we present a non-parametric multi-class entropy minimization loss to further boost the discriminative power of FTNs on the target domain. In experiments, we first illustrate how FTN works in a controlled setting of adapting from MNIST-M to MNIST with disjoint digit classes between the two domains and then demonstrate the effectiveness of FTNs through state-of-the-art performances on a cross-ethnicity face recognition problem.\n","keywords":["domain adaptation","distance metric learning","face recognition"],"authorids":["ICLR.cc/2019/Conference/Paper931/Authors"],"authors":["Anonymous"],"TL;DR":"A new theory of unsupervised domain adaptation for distance metric learning and its application to face recognition across diverse ethnicity variations.","pdf":"/pdf/05d61078a2c461cf8941ca1f36805e8ea5673d8d.pdf","paperhash":"anonymous|unsupervised_domain_adaptation_for_distance_metric_learning","_bibtex":"@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Domain Adaptation for Distance Metric Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BklhAj09K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1en0sRqKm","original":"SylrH0p5tX","number":932,"cdate":1538087892053,"ddate":null,"tcdate":1538087892053,"tmdate":1538156026535,"tddate":null,"forum":"S1en0sRqKm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"On the Computational Inefficiency of Large Batch Sizes for Stochastic Gradient Descent","abstract":"Increasing the mini-batch size for stochastic gradient descent offers significant opportunities to reduce wall-clock training time, but there are a variety of theoretical and systems challenges that impede the widespread success of this technique (Daset al., 2016; Keskar et al., 2016). We investigate these issues, with an emphasis on time to convergence and total computational cost, through an extensive empirical analysis of network training across several architectures and problem domains, including image classification, image segmentation, and language modeling.  Although it is common practice to increase the batch size in order to fully exploit available computational resources, we find a substantially more nuanced picture. Our main finding is that across a wide range of network architectures and problem domains, increasing the batch size beyond a certain point yields no decrease in wall-clock time to convergence for either train or test loss.  This batch size is usually substantially below the capacity of current systems.  We show that popular training strategies for large batch size optimization begin to fail before we can populate all available compute resources, and we show that the point at which these methods break down depends more on attributes like model architecture and data complexity than it does directly on the size of the dataset.","keywords":["Deep learning","large batch training","scaling rules","stochastic gradient descent"],"authorids":["ICLR.cc/2019/Conference/Paper932/Authors"],"authors":["Anonymous"],"TL;DR":"Large batch training results in rapidly diminishing returns in wall-clock time to convergence to find a good model.","pdf":"/pdf/779ab8c3f35f53393b64ff46209b4044b4427d59.pdf","paperhash":"anonymous|on_the_computational_inefficiency_of_large_batch_sizes_for_stochastic_gradient_descent","_bibtex":"@inproceedings{    \nanonymous2019on,    \ntitle={On the Computational Inefficiency of Large Batch Sizes for Stochastic Gradient Descent},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1en0sRqKm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1enCo0cK7","original":"HylWXNj5Y7","number":933,"cdate":1538087892218,"ddate":null,"tcdate":1538087892218,"tmdate":1538156026324,"tddate":null,"forum":"B1enCo0cK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"One Bit Matters: Understanding Adversarial Examples as the Abuse of Redundancy","abstract":"Adversarial examples have somewhat disrupted the enormous success of machine learning (ML) and are causing concern with regards to its trustworthiness: A small perturbation of an input results in an arbitrary failure of an otherwise seemingly well-trained ML system. While studies are being conducted to discover the intrinsic properties of adversarial examples, such as their transferability and universality, there is insufficient theoretic analysis to help understand the phenomenon in a way that can influence the design process of ML experiments. In this paper, we deduce an information-theoretic model which explains adversarial attacks universally as the abuse of feature redundancies in ML algorithms. We prove that feature redundancy is a necessary condition for the existence of adversarial examples. Our model helps to explain the major questions raised in many anecdotal studies on adversarial examples. Our theory is backed up by empirical measurements of the information content of benign and adversarial examples on both image and text datasets. Our measurements show that typical adversarial examples introduce just enough redundancy to overflow the decision making of a machine learner trained on corresponding benign examples. We conclude with actionable recommendations to improve the robustness of machine learners against adversarial examples.","keywords":["adversarial examples","information theory","robust neural networks"],"authorids":["ICLR.cc/2019/Conference/Paper933/Authors"],"authors":["Anonymous"],"TL;DR":"A new theoretical explanation for the existence of adversarial examples","pdf":"/pdf/798ae8f944a2e7cd9542845816f87e35fbb44be9.pdf","paperhash":"anonymous|one_bit_matters_understanding_adversarial_examples_as_the_abuse_of_redundancy","_bibtex":"@inproceedings{    \nanonymous2019one,    \ntitle={One Bit Matters: Understanding Adversarial Examples as the Abuse of Redundancy},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1enCo0cK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryG2Cs09Y7","original":"BJeorAp9KQ","number":934,"cdate":1538087892403,"ddate":null,"tcdate":1538087892403,"tmdate":1538156026117,"tddate":null,"forum":"ryG2Cs09Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"FEATURE PRIORITIZATION AND REGULARIZATION IMPROVE STANDARD ACCURACY AND ADVERSARIAL ROBUSTNESS","abstract":"Adversarial training has been successfully applied to build robust models at a certain cost. While the robustness of a model increases, the standard classification accuracy declines. This phenomenon is suggested to be an inherent trade-off between standard accuracy and robustness. We propose a model that employs feature prioritization by a nonlinear attention module and L2 regularization as implicit denoising to improve the adversarial robustness and the standard accuracy relative to adversarial training. Focusing sharply on the regions of interest, the attention maps encourage the model to rely heavily on features extracted from the most relevant areas while suppressing the unrelated background. Penalized by a regularizer, the model extracts similar features for the natural and adversarial images, effectively ignoring the added perturbation. In addition to qualitative evaluation, we also propose a novel experimental strategy that quantitatively demonstrates that our model is almost ideally aligned with salient data characteristics. Additional experimental results illustrate the power of our model relative to the state of the art methods","keywords":["adversarial robustness","feature prioritization","regularization"],"authorids":["ICLR.cc/2019/Conference/Paper934/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a model that employs feature prioritization and regularization to improve the adversarial robustness and the standard accuracy.","pdf":"/pdf/8ddd67de2adcf93474aa10992aeb0094967d2199.pdf","paperhash":"anonymous|feature_prioritization_and_regularization_improve_standard_accuracy_and_adversarial_robustness","_bibtex":"@inproceedings{    \nanonymous2019feature,    \ntitle={FEATURE PRIORITIZATION AND REGULARIZATION IMPROVE STANDARD ACCURACY AND ADVERSARIAL ROBUSTNESS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryG2Cs09Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJl6AjC5F7","original":"B1eWmCoqYm","number":935,"cdate":1538087892584,"ddate":null,"tcdate":1538087892584,"tmdate":1538156025907,"tddate":null,"forum":"BJl6AjC5F7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning to Represent Edits","abstract":"We introduce the problem of learning distributed representations of edits. By combining a\n\"neural editor\" with an \"edit encoder\", our models learn to represent the salient\ninformation of an edit and can be used to apply edits to new inputs.\nWe experiment on natural language and source code edit data. Our evaluation yields\npromising results that suggest that our neural network models learn to capture\nthe structure and semantics of edits. We hope that this interesting task and\ndata source will inspire other researchers to work further on this problem.","keywords":["Representation Learning","Source Code","Natural Language","edit"],"authorids":["ICLR.cc/2019/Conference/Paper935/Authors"],"authors":["Anonymous"],"pdf":"/pdf/9e9037316ac54c796eaaee3ff7d0c053f08e7d3b.pdf","paperhash":"anonymous|learning_to_represent_edits","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Represent Edits},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJl6AjC5F7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJlpCsC5Km","original":"ByloBTTcY7","number":936,"cdate":1538087892754,"ddate":null,"tcdate":1538087892754,"tmdate":1538156025689,"tddate":null,"forum":"BJlpCsC5Km","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Gibbs-regularized GANs with variational discriminator reparameterization","abstract":" We propose a novel approach to regularizing generative adversarial networks (GANs) leveraging learned {\\em structured Gibbs distributions}.  Our method consists of reparameterizing the discriminator to be an explicit function of two densities: the generator PDF $q$ and a structured Gibbs distribution $\\nu$.  Leveraging recent work on invertible pushforward density estimators, this reparameterization is made possible by assuming the generator is invertible, which enables the analytic evaluation of the generator PDF $q$.  We further propose optimizing the Jeffrey divergence, which balances mode coverage with sample quality.  The combination of this loss and  reparameterization allows us to effectively regularize the generator by imposing structure from domain knowledge on $\\nu$, as in classical graphical models. Applying our method to a vehicle trajectory forecasting task, we observe that we are able to obtain quantitatively superior mode coverage as well as better-quality samples compared to traditional methods.","keywords":["deep generative models","graphical models","trajectory forecasting","GANs","density estimation","structured prediction"],"authorids":["ICLR.cc/2019/Conference/Paper936/Authors"],"authors":["Anonymous"],"TL;DR":"We reparameterize a GAN's discriminator into a form that admits regularization using a structured Gibbs distribution","pdf":"/pdf/709b680834a332747d758df32c764e9901039643.pdf","paperhash":"anonymous|learning_gibbsregularized_gans_with_variational_discriminator_reparameterization","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Gibbs-regularized GANs with variational discriminator reparameterization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJlpCsC5Km},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkgpCoRctm","original":"H1eDnUo9YQ","number":937,"cdate":1538087892979,"ddate":null,"tcdate":1538087892979,"tmdate":1538156025483,"tddate":null,"forum":"rkgpCoRctm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Detecting Out-Of-Distribution Samples Using Low-Order Deep Features Statistics","abstract":"The ability to detect when an input sample was not drawn from the training distribution is an important  desirable property of deep neural networks. In this paper, we show that a simple ensembling of first and second order deep feature statistics can be exploited to effectively differentiate in-distribution and out-of-distribution samples. Specifically, we observe that  the mean and standard deviation within feature maps  differs greatly between in-distribution and out-of-distribution samples. Based on this observation, we propose a simple and  efficient plug-and-play detection procedure that does not require re-training, pre-processing or changes to the model.  The proposed method outperforms the state-of-the-art by a large margin in all standard benchmarking tasks, while being much simpler to implement and execute. Notably, our method improves the true negative rate from 86.6% to 96.8% when 95% of in-distribution (CIFAR-100) are correctly detected using a DenseNet and the out-of-distribution dataset is TinyImageNet resize. The source code of our method will be made publicly available.","keywords":["computer vision","out-of-distribution detection","image classification"],"authorids":["ICLR.cc/2019/Conference/Paper937/Authors"],"authors":["Anonymous"],"TL;DR":"Detecting out-of-distribution samples by using low-order feature statistics without requiring any change in underlying DNN.","pdf":"/pdf/75cfbe00298525441b85e896568b720c40aa1b8d.pdf","paperhash":"anonymous|detecting_outofdistribution_samples_using_loworder_deep_features_statistics","_bibtex":"@inproceedings{    \nanonymous2019detecting,    \ntitle={Detecting Out-Of-Distribution Samples Using Low-Order Deep Features Statistics},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgpCoRctm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkl6As0cF7","original":"SkgpPa69Y7","number":938,"cdate":1538087893149,"ddate":null,"tcdate":1538087893149,"tmdate":1538156025269,"tddate":null,"forum":"rkl6As0cF7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Probabilistic Recursive Reasoning for Mutli-Agent Reinforcement Learning","abstract":"Humans are capable of attributing latent mental contents such as beliefs, or intentions to others. The social skill is critical in everyday life to reason about the potential consequences of their behaviors so as to plan ahead. It is known that humans use this reasoning ability recursively, i.e. considering what others believe about their own beliefs.  In this paper, we introduce a probabilistic recursive reasoning (PR2) framework for multi-agent reinforcement learning (RL). Our hypothesis is that it is beneficial for each agent to consider how the opponents would react to its future behaviors. Under the PR2 framework, we adopt variational Bayes methods to approximate the opponents' conditional policy, to which each agent finds the  best response and then improve their own policy. We develop  decentralized-training-decentralized-execution  algorithms, PR2-Q and PR2-Actor-Critic, that are proved to converge in the self-play scenario.  Our methods are tested on both the matrix game and the differential game, which have a non-trivial equilibrium where common gradient-based methods fail to converge.  Our experiments show that it is critical to reason about how the opponents believe about what the agent believes. We expect our work to offer a new idea of embedding opponent modeling into the multi-agent RL context.  ","keywords":["Multi-agent Reinforcement Learning","Recursive Reasoning"],"authorids":["ICLR.cc/2019/Conference/Paper938/Authors"],"authors":["Anonymous"],"TL;DR":"We proposed a novel probabilisitic recursive reasoning (PR2) framework for multi-agent deep reinforcement learning tasks.","pdf":"/pdf/08148d090a8de435832f612f1bf9ca9118c12f94.pdf","paperhash":"anonymous|probabilistic_recursive_reasoning_for_mutliagent_reinforcement_learning","_bibtex":"@inproceedings{    \nanonymous2019probabilistic,    \ntitle={Probabilistic Recursive Reasoning for Mutli-Agent Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkl6As0cF7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Bkg6RiCqY7","original":"rJlsyL6cKm","number":939,"cdate":1538087893315,"ddate":null,"tcdate":1538087893315,"tmdate":1538156025050,"tddate":null,"forum":"Bkg6RiCqY7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Decoupled Weight Decay Regularization","abstract":"L$_2$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is \\emph{not} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L$_2$ regularization (often calling it ``weight decay'' in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by \\emph{decoupling} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments will be available after the review process.","keywords":["optimization","regularization","weight decay","Adam"],"authorids":["ICLR.cc/2019/Conference/Paper939/Authors"],"authors":["Anonymous"],"pdf":"/pdf/3d3e5d918f0deb88a4bf7756c4fbdf92a3aa1b9d.pdf","paperhash":"anonymous|decoupled_weight_decay_regularization","_bibtex":"@inproceedings{    \nanonymous2019decoupled,    \ntitle={Decoupled Weight Decay Regularization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkg6RiCqY7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1GaAjRcF7","original":"HJlzwzQqKm","number":940,"cdate":1538087893486,"ddate":null,"tcdate":1538087893486,"tmdate":1538156024843,"tddate":null,"forum":"r1GaAjRcF7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Differentiable Greedy Networks","abstract":"Optimal selection of a subset of items from a given set is a hard problem that requires combinatorial optimization. In this paper, we propose a subset selection algorithm that is trainable with gradient based methods yet achieves near optimal performance via submodular optimization. We focus on the task of identifying a relevant set of sentences for claim verification in the context of the FEVER task. Conventional methods for this task look at sentences on their individual merit and thus do not optimize the informativeness of sentences as a set. We show that our proposed method which builds on the idea of unfolding a greedy algorithm into a computational graph allows both interpretability and gradient based training. The proposed differentiable greedy network (DGN) outperforms discrete optimization algorithms as well as other baseline methods in terms of precision and recall.","keywords":["submodular optimization","fact verification","differentiable module","deep unfolding"],"authorids":["ICLR.cc/2019/Conference/Paper940/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a subset selection algorithm that is trainable with gradient based methods yet achieves near optimal performance via submodular optimization.","pdf":"/pdf/be28a51d3a63c6692d0b4a879ed956652173e307.pdf","paperhash":"anonymous|differentiable_greedy_networks","_bibtex":"@inproceedings{    \nanonymous2019differentiable,    \ntitle={Differentiable Greedy Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1GaAjRcF7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BklACjAqFm","original":"BkeI_CacY7","number":941,"cdate":1538087893713,"ddate":null,"tcdate":1538087893713,"tmdate":1538156024627,"tddate":null,"forum":"BklACjAqFm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Successor Uncertainties: exploration and uncertainty in temporal difference learning","abstract":"We consider the problem of balancing exploration and exploitation in sequential decision making problems. To explore efficiently, it is vital to consider the uncertainty over all consequences of a decision, and not just those that follow immediately; the uncertainties need to be propagated according to the dynamics of the problem. To this end, we develop Successor Uncertainties, a probabilistic model for the state-action function of a Markov Decision Process that propagates uncertainties in a coherent and scalable way. Our model achieves this by combining successor features and online Bayesian uncertainty estimation. We relate our approach to other classical and contemporary methods for exploration and present an empirical analysis of successor uncertainties.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper941/Authors"],"authors":["Anonymous"],"pdf":"/pdf/9b9679607e4c1731693b79061e46dbb211bfd418.pdf","paperhash":"anonymous|successor_uncertainties_exploration_and_uncertainty_in_temporal_difference_learning","_bibtex":"@inproceedings{    \nanonymous2019successor,    \ntitle={Successor Uncertainties: exploration and uncertainty in temporal difference learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BklACjAqFm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Bkx0RjA9tX","original":"Bklwu0TqK7","number":942,"cdate":1538087893880,"ddate":null,"tcdate":1538087893880,"tmdate":1538156024414,"tddate":null,"forum":"Bkx0RjA9tX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Generative Question Answering: Learning to Answer the Whole Question","abstract":"Discriminative  question  answering  models  can  overfit  to  superficial  biases  in datasets,  because their loss function saturates when any clue makes the answer likely.  We introduce generative models of the joint distribution of questions and answers, which are trained to explain the whole question, not just to answer it.Our  question  answering  (QA)  model  is  implemented  by  learning  a  prior  over answers,  and  a  conditional  language  model  to  generate  the  question  given  the answer—allowing scalable and interpretable many-hop reasoning as the question is generated word-by-word.  Our model achieves competitive performance with specialised discriminative models on the SQUAD and CLEVR benchmarks, indicating that it is a more general architecture for language understanding and reasoning than previous work. The model greatly improves generalisation both from biased training data and to adversarial testing data, achieving a new state-of-the-art on ADVERSARIAL SQUAD. We will release our code.","keywords":["Question answering","question generation","reasoning","squad","clevr"],"authorids":["ICLR.cc/2019/Conference/Paper942/Authors"],"authors":["Anonymous"],"TL;DR":"Question answering models that model the joint distribution of questions and answers can learn more than discriminative models","pdf":"/pdf/bd627440b6d7f8f9f7e6376656ef48b847d11ab6.pdf","paperhash":"anonymous|generative_question_answering_learning_to_answer_the_whole_question","_bibtex":"@inproceedings{    \nanonymous2019generative,    \ntitle={Generative Question Answering: Learning to Answer the Whole Question},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkx0RjA9tX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1gRCiA5Ym","original":"HkltZ9a9Fm","number":943,"cdate":1538087894051,"ddate":null,"tcdate":1538087894051,"tmdate":1538156024209,"tddate":null,"forum":"r1gRCiA5Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Jumpout: Improved Dropout for Deep Neural Networks with Rectified Linear Units","abstract":"Dropout is a simple yet effective technique to improve the generalization\nperformance and prevent overfitting in deep neural networks (DNNs). In this\npaper, we discuss three novel observations about dropout to better understand\nthe generalization of DNNs with rectified linear unit (ReLU) activations: 1)\ndropout is a smoothing technique that encourages each local linear model of a\nDNN to be trained on data points from nearby regions; 2) a constant dropout\nrate can result in effective neural-deactivation rates that are significantly\ndifferent for layers with different fractions of activated neurons; and 3) the\nrescaling factor of dropout causes an inconsistency to occur between the\nnormalization during training and testing conditions when batch normalization\nis also used.  The above leads to three simple but nontrivial improvements to\ndropout resulting in our proposed method \"Jumpout.\" Jumpout samples the\ndropout rate using a monotone decreasing distribution (such as the right part\nof a truncated Gaussian), so the local linear model at each data point is\ntrained, with high probability, to work better for data points from nearby\nthan from more distant regions. Instead of tuning a dropout rate for each\nlayer and applying it to all samples, jumpout moreover adaptively normalizes\nthe dropout rate at each layer and every training sample/batch, so the\neffective dropout rate applied to the activated neurons are kept the same.\nMoreover, we rescale the outputs of jumpout for a better trade-off that keeps\nboth the variance and mean of neurons more consistent between training and\ntest phases, which mitigates the incompatibility between dropout and batch\nnormalization. Compared to the original dropout, jumpout shows significantly\nimproved performance on CIFAR10, CIFAR100, Fashion- MNIST, STL10, SVHN,\nImageNet-1k, etc., while introducing negligible additional memory and\ncomputation costs.","keywords":["Dropout","deep neural networks with ReLU","local linear model"],"authorids":["ICLR.cc/2019/Conference/Paper943/Authors"],"authors":["Anonymous"],"TL;DR":"Jumpout applies three simple yet effective modifications to dropout, based on novel understandings about the generalization performance of DNN with ReLU in local regions.","pdf":"/pdf/08b0b5bf155d92c61aad4547f7de0c958181d9a6.pdf","paperhash":"anonymous|jumpout_improved_dropout_for_deep_neural_networks_with_rectified_linear_units","_bibtex":"@inproceedings{    \nanonymous2019jumpout:,    \ntitle={Jumpout: Improved Dropout for Deep Neural Networks with Rectified Linear Units},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1gRCiA5Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1eCCoR5tm","original":"SJlJ0O_qFm","number":944,"cdate":1538087894218,"ddate":null,"tcdate":1538087894218,"tmdate":1538156023991,"tddate":null,"forum":"B1eCCoR5tm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Pseudosaccades: A simple ensemble scheme for improving classification performance of deep nets","abstract":"We describe a simple ensemble approach that, unlike conventional ensembles,\nuses multiple random data sketches (‘pseudosaccades’) rather than multiple classifiers\nto improve classification performance. Using this simple, but novel, approach\nwe obtain statistically significant improvements in classification performance on\nAlexNet, GoogLeNet, ResNet-50 and ResNet-152 baselines on Imagenet data –\ne.g. of the order of 0.3% to 0.6% in Top-1 accuracy and similar improvements in\nTop-k accuracy – essentially nearly for free.","keywords":["Ensemble classification","random subspace","data sketching"],"authorids":["ICLR.cc/2019/Conference/Paper944/Authors"],"authors":["Anonymous"],"TL;DR":"Inspired by saccades we describe a simple, cheap, effective way to improve deep net performance on an image labelling task.","pdf":"/pdf/a9ec0296dd47dbd5ad016d98de10f927212f77b7.pdf","paperhash":"anonymous|pseudosaccades_a_simple_ensemble_scheme_for_improving_classification_performance_of_deep_nets","_bibtex":"@inproceedings{    \nanonymous2019pseudosaccades:,    \ntitle={Pseudosaccades: A simple ensemble scheme for improving classification performance of deep nets},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1eCCoR5tm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1gARiAcFm","original":"B1eGDiactQ","number":945,"cdate":1538087894387,"ddate":null,"tcdate":1538087894387,"tmdate":1538156023778,"tddate":null,"forum":"S1gARiAcFm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Modeling Dynamics of Biological Systems with Deep Generative Neural Networks","abstract":"Biological data often contains measurements of dynamic entities such as cells or organisms in various states of progression. However, biological systems are notoriously difficult to describe analytically due to their many interacting components, and in many cases, the technical challenge of taking longitudinal measurements. This leads to difficulties in studying the features of the dynamics, for examples the drivers of the transition. To address this problem, we present a deep neural network framework we call Dynamics Modeling Network or DyMoN. DyMoN is a neural network framework trained as a deep generative Markov model whose next state is a probability distribution based on the current state. DyMoN is well-suited to the idiosyncrasies of biological data, including noise, sparsity, and the lack of longitudinal measurements in many types of systems. Thus, DyMoN can be trained using probability distributions derived from the data in any way, such as trajectories derived via dimensionality reduction methods, and does not require longitudinal measurements. We show the advantage of learning deep models over shallow models such as Kalman filters and hidden Markov models that do not learn representations of the data, both in terms of learning embeddings of the data and also in terms training efficiency, accuracy and ability to multitask. We perform three case studies of applying DyMoN to different types of biological systems and extracting features of the dynamics in each case by examining the learned model. ","keywords":["neural networks","markovian dynamics","single-cell biology","calcium imaging","stochastic dynamics","generative models"],"authorids":["ICLR.cc/2019/Conference/Paper945/Authors"],"authors":["Anonymous"],"TL;DR":"Dynamics Modeling Networks (DyMoN) offer advantages in representation, generation, visualization and feature extraction over shallow learning techniques for modeling stochastic dynamical systems in biology.","pdf":"/pdf/991e2b1de4ebb49b53f18bc824b362fe744afffd.pdf","paperhash":"anonymous|modeling_dynamics_of_biological_systems_with_deep_generative_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019modeling,    \ntitle={Modeling Dynamics of Biological Systems with Deep Generative Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1gARiAcFm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJl11nCctX","original":"SygjnkmcF7","number":946,"cdate":1538087894564,"ddate":null,"tcdate":1538087894564,"tmdate":1538156023570,"tddate":null,"forum":"SJl11nCctX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"TFGAN: Improving Conditioning for Text-to-Video Synthesis","abstract":"Developing conditional generative models for text-to-video synthesis is an extremely challenging yet an important topic of research in machine learning. In this work, we address this problem by introducing Text-Filter conditioning Generative Adversarial Network (TFGAN), a GAN model with novel conditioning scheme that aids improving the text-video associations. With a combination of this conditioning scheme and a deep GAN architecture, TFGAN generates photo-realistic videos from text on very challenging real-world video datasets. In addition, we construct a benchmark synthetic dataset of moving shapes to systematically evaluate our conditioning scheme. Extensive experiments demonstrate that TFGAN significantly outperforms the existing approaches, and can also generate videos of novel categories not seen during training.\n","keywords":["Conditional GAN","Video Generation","Text-to-Video Synthesis","Conditional Generative Models","Deep Generative Models"],"authorids":["ICLR.cc/2019/Conference/Paper946/Authors"],"authors":["Anonymous"],"TL;DR":"An effective text-conditioning GAN framework for generating videos from text","pdf":"/pdf/059c7c20d075a8066b344f47beab9a6724fb7cb3.pdf","paperhash":"anonymous|tfgan_improving_conditioning_for_texttovideo_synthesis","_bibtex":"@inproceedings{    \nanonymous2019tfgan:,    \ntitle={TFGAN: Improving Conditioning for Text-to-Video Synthesis},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJl11nCctX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJekyhCctQ","original":"HylvtrgcK7","number":947,"cdate":1538087894732,"ddate":null,"tcdate":1538087894732,"tmdate":1538156023366,"tddate":null,"forum":"SJekyhCctQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Detecting Adversarial Examples Via Neural Fingerprinting","abstract":"Deep neural networks are vulnerable to adversarial examples: input data that has been manipulated to cause dramatic model output errors. To defend against such attacks, we propose NeuralFingerprinting: a simple, yet effective method to detect adversarial examples that verifies whether model behavior is consistent with a set of fingerprints. These fingerprints are encoded into the model response during training and are inspired by the use of biometric and cryptographic signatures. In contrast to previous defenses, our method does not rely on knowledge of the adversary and can scale to large networks and input data. The benefits of our method are that 1) it is fast, 2) it is prohibitively expensive for an attacker to reverse-engineer which fingerprints were used, and 3) it does not assume knowledge of the adversary. In this work, we 1) theoretically analyze NeuralFingerprinting for linear models and 2) show that NeuralFingerprinting significantly improves on state-of-the-art detection mechanisms for deep neural networks, by detecting the strongest known adversarial attacks with 98-100% AUC-ROC scores on the MNIST, CIFAR-10 and MiniImagenet (20 classes) datasets.  In particular, we consider several threat models, including the most conservative one in which the attacker has full knowledge of the defender's strategy. In all settings, the detection accuracy of NeuralFingerprinting generalizes well to unseen test-data and is robust over a wide range of hyperparameters.","keywords":["Adversarial Attacks","Deep Neural Networks"],"authorids":["ICLR.cc/2019/Conference/Paper947/Authors"],"authors":["Anonymous"],"TL;DR":"Novel technique for detecting adversarial examples -- robust across gradient-based and gradient-free attacks, AUC-ROC >95%","pdf":"/pdf/4034fc12e381bf618f8e5da5b923f44bf8255d7a.pdf","paperhash":"anonymous|detecting_adversarial_examples_via_neural_fingerprinting","_bibtex":"@inproceedings{    \nanonymous2019detecting,    \ntitle={Detecting Adversarial Examples Via Neural Fingerprinting},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJekyhCctQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rygkk305YQ","original":"B1g1HvhqKQ","number":948,"cdate":1538087894902,"ddate":null,"tcdate":1538087894902,"tmdate":1538156023151,"tddate":null,"forum":"rygkk305YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Hierarchical Generative Modeling for Controllable Speech Synthesis","abstract":"This paper proposes a neural end-to-end text-to-speech (TTS) model which can control latent attributes in the generated speech that are rarely annotated in the training data, such as speaking style, accent, background noise, and recording conditions. The model is formulated as a conditional generative model with two levels of hierarchical latent variables. The first level is a categorical variable, which represents attribute groups (e.g. clean/noisy) and provides interpretability. The second level, conditioned on the first, is a multivariate Gaussian variable, which characterizes specific attribute configurations (e.g. noise level, speaking rate) and enables disentangled fine-grained control over these attributes. This amounts to using a Gaussian mixture model (GMM) for the latent distribution. Extensive evaluation demonstrates its ability to control the aforementioned attributes. In particular, it is capable of consistently synthesizing high-quality clean speech regardless of the quality of the training data for the target speaker.","keywords":["speech synthesis","representation learning","deep generative model","sequence-to-sequence model"],"authorids":["ICLR.cc/2019/Conference/Paper948/Authors"],"authors":["Anonymous"],"TL;DR":"Building a TTS model with Gaussian Mixture VAEs enables fine-grained control of speaking style, noise condition, and more.","pdf":"/pdf/9aaa58e7ae3839296299c2c54b804dc05779ce52.pdf","paperhash":"anonymous|hierarchical_generative_modeling_for_controllable_speech_synthesis","_bibtex":"@inproceedings{    \nanonymous2019hierarchical,    \ntitle={Hierarchical Generative Modeling for Controllable Speech Synthesis},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rygkk305YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJe1y3CqtX","original":"ryxcCppqF7","number":949,"cdate":1538087895084,"ddate":null,"tcdate":1538087895084,"tmdate":1538156022942,"tddate":null,"forum":"rJe1y3CqtX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Deep Reinforcement Learning of Universal Policies with Diverse Environment Summaries","abstract":"Deep reinforcement learning has enabled robots to complete complex tasks in simulation. However, the resulting policies do not transfer to real robots due to model errors in the simulator. One solution is to randomize the simulation environment, so that the resulting, trained policy achieves high performance in expectation over a variety of configurations that could represent the real-world. However, the distribution over simulator configurations must be carefully selected to represent the relevant dynamic modes of the system, as otherwise it can be unlikely to sample challenging configurations frequently enough. Moreover, the ideal distribution to improve the policy changes as the policy (un)learns to solve tasks in certain configurations. In this paper, we propose to use an inexpensive, kernel-based summarization method method that identifies configurations that lead to diverse behaviors. Since failure modes for the given task are naturally diverse, the policy trains on a mixture of representative and challenging configurations, which leads to more robust policies. In experiments, we show that the proposed method achieves the same performance as domain randomization in simple cases, but performs better when domain randomization does not lead to diverse dynamic modes.","keywords":["Domain Randomization","Diverse Summaries","Reinforcement learning"],"authorids":["ICLR.cc/2019/Conference/Paper949/Authors"],"authors":["Anonymous"],"TL;DR":"As an alternative to domain randomization, we summarize simulator configurations to ensure that the policy is trained on a diverse set of induced state-trajectories.","pdf":"/pdf/dfa4e50fdab1517a7e1d0d98b8779c3a601acab4.pdf","paperhash":"anonymous|deep_reinforcement_learning_of_universal_policies_with_diverse_environment_summaries","_bibtex":"@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Reinforcement Learning of Universal Policies with Diverse Environment Summaries},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJe1y3CqtX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1lJJnR5Ym","original":"S1x-r2T5KX","number":950,"cdate":1538087895251,"ddate":null,"tcdate":1538087895251,"tmdate":1538156022728,"tddate":null,"forum":"H1lJJnR5Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Exploration by random distillation","abstract":"We introduce an exploration bonus for deep reinforcement learning methods that is easy to implement and adds minimal overhead to the computation performed. The bonus is the error of a neural network predicting features of the observations given by a fixed randomly initialized neural network. We also introduce a method to flexibly combine intrinsic and extrinsic rewards. We find that the random network distillation (RND) bonus combined with this increased flexibility enables significant progress on several hard exploration Atari games. In particular we establish state of the art performance on Montezuma's Revenge, a game famously difficult for deep reinforcement learning methods. To the best of our knowledge, this is the first method that achieves better than average human performance on this game without using demonstrations or having access the underlying state of the game, and occasionally completes the first level. This suggests that relatively simple methods that scale well can be sufficient to tackle challenging exploration problems.","keywords":["reinforcement learning","exploration","curiosity"],"authorids":["ICLR.cc/2019/Conference/Paper950/Authors"],"authors":["Anonymous"],"TL;DR":"A simple exploration bonus is introduced and achieves state of the art performance in 3 hard exploration Atari games.","pdf":"/pdf/044c44326fb23a7edfdbf8e6eb009d388a882002.pdf","paperhash":"anonymous|exploration_by_random_distillation","_bibtex":"@inproceedings{    \nanonymous2019exploration,    \ntitle={Exploration by random distillation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1lJJnR5Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SkgkJn05YX","original":"Hke6nDo9Fm","number":951,"cdate":1538087895411,"ddate":null,"tcdate":1538087895411,"tmdate":1538156022521,"tddate":null,"forum":"SkgkJn05YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"RANDOM MASK: Towards Robust Convolutional Neural Networks","abstract":"Robustness of neural networks has recently been highlighted by the adversarial examples, i.e., inputs added with well-designed  perturbations which are imperceptible to humans but can cause the network to give incorrect outputs. In this paper, we design a new CNN architecture that by itself has good robustness. We introduce a simple but powerful technique, Random Mask, to modify existing CNN structures. We show that CNN with Random Mask achieves state-of-the-art performance against black-box adversarial attacks without applying any adversarial training. We next investigate the adversarial examples which “fool” a CNN with Random Mask. Surprisingly, we find that these adversarial examples often “fool” humans as well. This raises fundamental questions on how to define adversarial examples and robustness properly.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper951/Authors"],"authors":["Anonymous"],"pdf":"/pdf/192c93afed6f68d131bd66ee8949b56c07d26299.pdf","paperhash":"anonymous|random_mask_towards_robust_convolutional_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019random,    \ntitle={RANDOM MASK: Towards Robust Convolutional Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkgkJn05YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1xeyhCctQ","original":"r1gxupaqFX","number":952,"cdate":1538087895601,"ddate":null,"tcdate":1538087895601,"tmdate":1538156022310,"tddate":null,"forum":"B1xeyhCctQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Bias Also Matters: Bias Attribution for Deep Neural Network Explanation","abstract":"The gradient of a deep neural network (DNN) w.r.t. the input provides\ninformation that can be used to explain the output prediction in terms of the\ninput features and has been widely studied to assist in interpreting DNNs.  In\na linear model (i.e., $g(x)=wx+b$), the gradient corresponds solely to the\nweights $w$. Such a model can reasonably locally linearly approximate a smooth\nnonlinear DNN, and hence the weights of this local model are the gradient.\nThe other part, however, of a local linear model, i.e., the bias $b$, is\nusually overlooked in attribution methods since it is not part of the\ngradient. In this paper, we observe that since the bias in a DNN also has a\nnon-negligible contribution to the correctness of predictions, it can also\nplay a significant role in understanding DNN behaviors. In particular, we\nstudy how to attribute a DNN's bias to its input features. We propose a\nbackpropagation-type algorithm ``bias back-propagation (BBp)'' that starts at\nthe output layer and iteratively attributes the bias of each layer to its\ninput nodes as well as combining the resulting bias term of the previous\nlayer. This process stops at the input layer, where summing up the\nattributions over all the input features exactly recovers $b$. Together with\nthe backpropagation of the gradient generating $w$, we can fully recover the\nlocally linear model $g(x)=wx+b$. Hence, the attribution of the DNN outputs to\nits inputs is decomposed into two parts, the gradient $w$ and the bias\nattribution, providing separate and complementary explanations. We study\nseveral possible attribution methods applied to the bias of each layer in BBp.\nIn experiments, we show that BBp can generate complementary and highly\ninterpretable explanations of DNNs in addition to gradient-based attributions.","keywords":["explainable AI","interpreting deep neural networks","bias","attribution method","piecewise linear activation function","backpropagation"],"authorids":["ICLR.cc/2019/Conference/Paper952/Authors"],"authors":["Anonymous"],"TL;DR":"Attribute the bias terms of deep neural networks to input features by a backpropagation-type algorithm; Generate complementary and highly interpretable explanations of DNNs in addition to gradient-based attributions.","pdf":"/pdf/454fcd18c486384174c3abc2c15b42b6515ac45f.pdf","paperhash":"anonymous|bias_also_matters_bias_attribution_for_deep_neural_network_explanation","_bibtex":"@inproceedings{    \nanonymous2019bias,    \ntitle={Bias Also Matters: Bias Attribution for Deep Neural Network Explanation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1xeyhCctQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1geJhC9Km","original":"Syxe6C6ctm","number":953,"cdate":1538087895772,"ddate":null,"tcdate":1538087895772,"tmdate":1538156022102,"tddate":null,"forum":"S1geJhC9Km","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Feature quantization for parsimonious and meaningful predictive models","abstract":"For regulatory and interpretability reasons, the logistic regression is still widely used by financial institutions to learn the refunding probability of a loan given the applicant's characteristics from historical data. Although logistic regression handles naturally both continuous and categorical data, a preprocessing step to quantize them is usually performed for improving simultaneously prediction accuracy and user interpretability: continuous features are discretized by assigning factor levels to intervals; some levels of categorical features (with numerous levels) are grouped.\nHowever, a better predictive accuracy can be reached by embedding this quantization estimation step directly into the predictive estimation step itself. A related information criterion has then to be optimized on a huge and untractable discontinuous quantization set, requiring to introduce a specific two-step optimization strategy: first, the optimization problem is relaxed in order to deal with smooth functions; second, a particular neural network is involved through a stochastic gradient algorithm to optimize the resulting criterion, giving access to good candidates for the initial optimization problem. The good performances of this approach are illustrated on simulated and real data from Crédit Agricole Consumer Finance (a major European historic player in the consumer credit market).","keywords":["discretization","grouping","interpretability","shallow neural networks"],"authorids":["ICLR.cc/2019/Conference/Paper953/Authors"],"authors":["Anonymous"],"TL;DR":"We tackle discretization of continuous features and grouping of factor levels as a representation learning problem and provide a rigorous way of estimating the best quantization to yield good performance and interpretability.","pdf":"/pdf/d09eaaa21d7b16e7acb32d15f35b3c1df45e3cb4.pdf","paperhash":"anonymous|feature_quantization_for_parsimonious_and_meaningful_predictive_models","_bibtex":"@inproceedings{    \nanonymous2019feature,    \ntitle={Feature quantization for parsimonious and meaningful predictive models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1geJhC9Km},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJxgknCcK7","original":"rkgWtPhcYX","number":954,"cdate":1538087895940,"ddate":null,"tcdate":1538087895940,"tmdate":1538156021887,"tddate":null,"forum":"rJxgknCcK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Scalable Reversible Generative Models with Free-form Continuous Dynamics","abstract":"A promising class of generative models maps points from a simple distribution to a complex distribution through an invertible neural network.   Likelihood-based training  of  these  models  requires  restricting  their  architectures  to  allow  cheap computation of Jacobian determinants.  Alternatively, the Jacobian trace can be used if the transformation is specified by an ordinary differential equation. In this paper, we use Hutchinson’s trace estimator to give a scalable unbiased estimate of the log-density.  The result is a continuous-time invertible generative model with unbiased density estimation and one-pass sampling, while allowing unrestricted neural network architectures. We demonstrate our approach on high-dimensional density  estimation,  image  generation,  and  variational  inference,  achieving  the state-of-the-art among exact likelihood methods with efficient sampling.","keywords":["generative models","density estimation","approximate inference","ordinary differential equations"],"authorids":["ICLR.cc/2019/Conference/Paper954/Authors"],"authors":["Anonymous"],"TL;DR":"We use continuous time dynamics to define a generative model with exact likelihoods and efficient sampling that is parameterized by unrestricted neural networks.","pdf":"/pdf/b26b11a971f38107136bf68aa2fd8948bdc74aa4.pdf","paperhash":"anonymous|scalable_reversible_generative_models_with_freeform_continuous_dynamics","_bibtex":"@inproceedings{    \nanonymous2019scalable,    \ntitle={Scalable Reversible Generative Models with Free-form Continuous Dynamics},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJxgknCcK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SkzeJ3A9F7","original":"SkgD99aqtm","number":955,"cdate":1538087896110,"ddate":null,"tcdate":1538087896110,"tmdate":1538156021680,"tddate":null,"forum":"SkzeJ3A9F7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Beyond Games: Bringing Exploration to Robots in Real-world","abstract":"Exploration has been a long standing problem in both model-based and model-free learning methods for sensorimotor control. While there has been major advances over the years, most of these successes have been demonstrated in either video games or simulation environments. This is primarily because the rewards (even the intrinsic ones) are non-differentiable since they are function of the environment (which is a black-box). In this paper, we focus on the policy optimization aspect of the intrinsic reward function. Specifically, by using a local approximation, we formulate intrinsic reward as a differentiable function so as to perform policy optimization using likelihood maximization -- much like supervised learning instead of reinforcement learning. This leads to a significantly sample efficient exploration policy. Our experiments clearly show that our approach outperforms both on-policy and off-policy optimization approaches like REINFORCE and DQN respectively. But most importantly, we are able to implement an exploration policy on a robot which learns to interact with objects completely from scratch just using data collected via the differentiable exploration module.","keywords":["Exploration","curiosity","manipulation"],"authorids":["ICLR.cc/2019/Conference/Paper955/Authors"],"authors":["Anonymous"],"pdf":"/pdf/2ed67a548dd537b453643e5d2d0bfc68c96ffc2d.pdf","paperhash":"anonymous|beyond_games_bringing_exploration_to_robots_in_realworld","_bibtex":"@inproceedings{    \nanonymous2019beyond,    \ntitle={Beyond Games: Bringing Exploration to Robots in Real-world},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkzeJ3A9F7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SkelJnRqt7","original":"HkeNU955FX","number":956,"cdate":1538087896282,"ddate":null,"tcdate":1538087896282,"tmdate":1538156021475,"tddate":null,"forum":"SkelJnRqt7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Neural separation of observed and unobserved distributions","abstract":"Separating mixed distributions is a long standing challenge for machine learning and signal processing. Applications include: single-channel multi-speaker separation (cocktail party problem), singing voice separation and separating reflections from images. Most current methods either rely on making strong assumptions on the source distributions (e.g. sparsity, low rank, repetitiveness) or rely on having training samples of each source in the mixture. In this work, we tackle the scenario of extracting an unobserved distribution additively mixed with a signal from an observed (arbitrary) distribution. We introduce a new method: Neural Egg Separation - an iterative method that learns to separate the known distribution from progressively finer estimates of the unknown distribution. In some settings, Neural Egg Separation is initialization sensitive, we therefore introduce GLO Masking which ensures a good initialization. Extensive experiments show that our method outperforms current methods that use the same level of supervision and often achieves similar performance to full supervision. ","keywords":["source separation","non-adversarial training","source unmixing","iterative neural training","generative modeling"],"authorids":["ICLR.cc/2019/Conference/Paper956/Authors"],"authors":["Anonymous"],"TL;DR":"An iterative neural method for extracting signals that are only observed mixed with other signals","pdf":"/pdf/20a53b512be032b01ed97f9619ffcc4c6b7050cd.pdf","paperhash":"anonymous|neural_separation_of_observed_and_unobserved_distributions","_bibtex":"@inproceedings{    \nanonymous2019neural,    \ntitle={Neural separation of observed and unobserved distributions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkelJnRqt7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJlg1n05YX","original":"Sklkvtp5Km","number":957,"cdate":1538087896451,"ddate":null,"tcdate":1538087896451,"tmdate":1538156021262,"tddate":null,"forum":"rJlg1n05YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Penetrating the Fog: the Path to Efficient CNN Models","abstract":"With the increasing demand to deploy convolutional neural networks (CNNs) on mobile platforms, the sparse kernel approach was proposed, which could save more parameters than the standard convolution while maintaining accuracy. However, despite the great potential, no prior research has pointed out how to craft an sparse kernel design with such potential (i.e., effective design), and all prior works just adopt simple combinations of existing sparse kernels such as group convolution. Meanwhile due to the large design space it is also impossible to try all combinations of existing sparse kernels. In this paper, we are the first in the field to consider how to craft an effective sparse kernel design by eliminating the large design space. Specifically, we present a sparse kernel scheme to illustrate how to reduce the space from three aspects. First, in terms of composition we remove designs composed of repeated layers. Second, to remove designs with large accuracy degradation, we find an unified property named~\\emph{information field} behind various sparse kernel designs, which could directly indicate the final accuracy. Last, we remove designs in two cases where a better parameter efficiency could be achieved. Additionally, we provide detailed efficiency analysis on the final 4 designs in our scheme. Experimental results validate the idea of our scheme by showing that our scheme is able to find designs which are more efficient in using parameters and computation with similar or higher accuracy.","keywords":["Efficient CNN models","Computer Vision"],"authorids":["ICLR.cc/2019/Conference/Paper957/Authors"],"authors":["Anonymous"],"TL;DR":"We are the first in the field to show how to craft an effective sparse kernel design from three aspects: composition, performance and efficiency.","pdf":"/pdf/09dd80df69fc22779a3fa0bb14dedb8f31fa2232.pdf","paperhash":"anonymous|penetrating_the_fog_the_path_to_efficient_cnn_models","_bibtex":"@inproceedings{    \nanonymous2019penetrating,    \ntitle={Penetrating the Fog: the Path to Efficient CNN Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJlg1n05YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rygZJ2RcF7","original":"HJgdo-69tQ","number":958,"cdate":1538087896632,"ddate":null,"tcdate":1538087896632,"tmdate":1538156021050,"tddate":null,"forum":"rygZJ2RcF7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Out-of-Sample Extrapolation with Neuron Editing","abstract":"While neural networks can be trained to map from one specific dataset to another, they usually do not learn a generalized transformation that can extrapolate accurately outside the space of training. For instance, a generative adversarial network (GAN) exclusively trained to transform images of cars from light to dark might not have the same effect on images of horses. This is because neural networks are good at generation within the manifold of the data that they are trained on. However, generating new samples outside of the manifold or extrapolating \"out-of-sample\" is a much harder problem that has been less well studied. To address this, we introduce a technique called neuron editing that learns how neurons encode an edit for a particular transformation in a latent space. We use an autoencoder to decompose the variation within the dataset into activations of different neurons and generate transformed data by defining an editing transformation on those neurons. By performing the transformation in a latent trained space, we encode fairly complex and non-linear transformations to the data with much simpler distribution shifts to the neuron's activations. We showcase our technique on image domain/style transfer and two biological applications: removal of batch artifacts representing unwanted noise and modeling the effect of drug treatments to predict synergy between drugs.","keywords":["generative adversarial networks","computational biology","generating","generation","extrapolation","out-of-sample","neural network inference"],"authorids":["ICLR.cc/2019/Conference/Paper958/Authors"],"authors":["Anonymous"],"TL;DR":"We reframe the generation problem as one of editing existing points, and as a result extrapolate better than traditional GANs.","pdf":"/pdf/85b6f6aec1bc2cb6cbd511b6282d2b97c6467066.pdf","paperhash":"anonymous|outofsample_extrapolation_with_neuron_editing","_bibtex":"@inproceedings{    \nanonymous2019out-of-sample,    \ntitle={Out-of-Sample Extrapolation with Neuron Editing},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rygZJ2RcF7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hke-JhA9Y7","original":"rylSWld5YX","number":959,"cdate":1538087896802,"ddate":null,"tcdate":1538087896802,"tmdate":1538156020844,"tddate":null,"forum":"Hke-JhA9Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning concise representations for regression by evolving networks of trees","abstract":" We propose and study a method for learning interpretable representations for the task of regression. Features are represented as networks of multi-type expression trees comprised of activation functions common in neural networks in addition to other elementary functions. Differentiable features are trained via gradient descent, and the performance of features in a linear model is used to weight the rate of change among subcomponents of each representation. The search process maintains an archive of representations with accuracy-complexity trade-offs to assist in generalization and interpretation. We compare several stochastic optimization approaches within this framework. We benchmark these variants on 99 open-source regression problems in comparison to state-of-the-art machine learning approaches. Our main finding is that this approach produces the highest average test scores across problems while producing representations that are orders of magnitude smaller than the next best performing method (gradient boosting). We also report a negative result in which attempts to directly optimize the disentanglement of the representation results in more highly correlated features.  ","keywords":["regression","stochastic optimization","evolutionary compution","feature engineering"],"authorids":["ICLR.cc/2019/Conference/Paper959/Authors"],"authors":["Anonymous"],"TL;DR":"Representing the network architecture as a set of syntax trees and optimizing their structure leads to accurate and concise regression models. ","pdf":"/pdf/1545965aaf68cee8839bd3b3ecf2a5c3781b357b.pdf","paperhash":"anonymous|learning_concise_representations_for_regression_by_evolving_networks_of_trees","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning concise representations for regression by evolving networks of trees},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hke-JhA9Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BkxWJnC9tX","original":"HJgfgkRqKm","number":960,"cdate":1538087896963,"ddate":null,"tcdate":1538087896963,"tmdate":1538156020631,"tddate":null,"forum":"BkxWJnC9tX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Diversity and Depth in Per-Example Routing Models","abstract":"Routing models, a form of conditional computation where examples are routed through a subset of components in a larger network, have shown promising results in recent works. Surprisingly, routing models to date have lacked important properties, such as architectural diversity and large numbers of routing decisions. Both architectural diversity and routing depth can increase the representational power of a routing network. In this work, we address both of these deficiencies. We discuss the significance of architectural diversity in routing models, and explain the tradeoffs between capacity and optimization when increasing routing depth. In our experiments, we find that adding architectural diversity to routing models significantly improves performance, cutting the error rates of a strong baseline by 35% on an Omniglot setup. However, when scaling up routing depth, we find that modern routing techniques struggle with optimization. We conclude by discussing both the positive and negative results, and suggest directions for future research.","keywords":["conditional computation","routing models","depth"],"authorids":["ICLR.cc/2019/Conference/Paper960/Authors"],"authors":["Anonymous"],"TL;DR":"Per-example routing models benefit from architectural diversity, but still struggle to scale to a large number of routing decisions.","pdf":"/pdf/3b6a5d3e7328905af1cec0c99ac260245e31beb5.pdf","paperhash":"anonymous|diversity_and_depth_in_perexample_routing_models","_bibtex":"@inproceedings{    \nanonymous2019diversity,    \ntitle={Diversity and Depth in Per-Example Routing Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkxWJnC9tX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyxZJn05YX","original":"SylsaGzUY7","number":961,"cdate":1538087897134,"ddate":null,"tcdate":1538087897134,"tmdate":1538156020423,"tddate":null,"forum":"SyxZJn05YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Feature Intertwiners","abstract":"A well-trained model should classify objects with unanimous score for every category. This requires the high-level semantic features should be alike among samples, despite a wide span in resolution, texture, deformation, etc. Previous works focus on re-designing the loss function or proposing new regularization constraints on the loss. In this paper, we address this problem via a new perspective. For each category, it is assumed that there are two sets in the feature space: one with more reliable information and the other with less reliable source. We argue that the reliable set could guide the feature learning of the less reliable set during training - in spirit of student mimicking teacher’s behavior and thus pushing towards a more compact class centroid in the high-dimensional space. Such a scheme also benefits the reliable set since samples become more closer within the same category - implying that it is easilier for the classifier to identify. We refer to this mutual learning process as feature intertwiner and embed the spirit into object detection. It is well-known that objects of low resolution are more difficult to detect due to the loss of detailed information during network forward pass. We thus regard objects of high resolution as the reliable set and objects of low resolution as the less reliable set. Specifically, an intertwiner is achieved by minimizing the distribution divergence between two sets. We design a historical buffer to represent all previous samples in the reliable set and utilize them to guide the feature learning of the less reliable set. The design of obtaining an effective feature representation for the reliable set is further investigated, where we introduce the optimal transport (OT) algorithm into the framework. Samples in the less reliable set are better aligned with the reliable set with aid of OT metric. Incorporated with such a plug-and-play intertwiner, we achieve an evident improvement over previous state-of-the-arts on the COCO object detection benchmark.","keywords":["feature learning","computer vision","deep learning"],"authorids":["ICLR.cc/2019/Conference/Paper961/Authors"],"authors":["Anonymous"],"TL;DR":"A feature intertwiner module to leverage features from one accurate set to help the learning of another less reliable set.","pdf":"/pdf/128a4d0207433e4890b7e9344ace2e6b1865dcef.pdf","paperhash":"anonymous|feature_intertwiners","_bibtex":"@inproceedings{    \nanonymous2019feature,    \ntitle={Feature Intertwiners},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxZJn05YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1zW13R5tm","original":"BJlWMAbdKX","number":962,"cdate":1538087897306,"ddate":null,"tcdate":1538087897306,"tmdate":1538156020215,"tddate":null,"forum":"H1zW13R5tm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Bamboo: Ball-Shape Data Augmentation Against Adversarial Attacks from All Directions","abstract":"Deep neural networks (DNNs) are widely adopted in real-world cognitive applications because of their high accuracy. The robustness of DNN models, however, has been recently challenged by adversarial attacks where small disturbance on input samples may result in misclassification. State-of-the-art defending algorithms, such as adversarial training or robust optimization, improve DNNs' resilience to adversarial attacks by paying high computational costs. Moreover, these approaches are usually designed to defend one or a few known attacking techniques only. The effectiveness to defend other types of attacking methods, especially those that have not yet been discovered or explored, cannot be guaranteed. This work aims for a general approach of enhancing the robustness of DNN models under adversarial attacks. In particular, we propose Bamboo -- the first data augmentation method designed for improving the general robustness of DNN without any hypothesis on the attacking algorithms. Bamboo augments the training data set with a small amount of data uniformly sampled on a fixed radius ball around each training data and hence, effectively increase the distance between natural data points and decision boundary. Our experiments show that Bamboo substantially improve the general robustness against arbitrary types of attacks and noises, achieving better results comparing to previous adversarial training methods, robust optimization methods and other data augmentation methods with the same amount of data points.","keywords":["DNN robustness","Adversarial attack","Data augmentation"],"authorids":["ICLR.cc/2019/Conference/Paper962/Authors"],"authors":["Anonymous"],"TL;DR":"The first data augmentation method specially designed for improving the general robustness of DNN without any hypothesis on the attacking algorithms.","pdf":"/pdf/6896bc9431ad602b5f7330cd8759094e753c037b.pdf","paperhash":"anonymous|bamboo_ballshape_data_augmentation_against_adversarial_attacks_from_all_directions","_bibtex":"@inproceedings{    \nanonymous2019bamboo:,    \ntitle={Bamboo: Ball-Shape Data Augmentation Against Adversarial Attacks from All Directions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1zW13R5tm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkMW1hRqKX","original":"rke4OqhcK7","number":963,"cdate":1538087897472,"ddate":null,"tcdate":1538087897472,"tmdate":1538156020004,"tddate":null,"forum":"rkMW1hRqKX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Optimal Completion Distillation for Sequence Learning","abstract":"We present Optimal Completion Distillation (OCD), a training procedure for optimizing sequence to sequence models based on edit distance. OCD is efficient, has no hyper-parameters of its own, and does not require pre-training or joint optimization with conditional log-likelihood. Given a partial sequence generated by the model, we first identify the set of optimal suffixes that minimize the total edit distance, using an efficient dynamic programming algorithm.  Then, for each position of the generated sequence, we use a target distribution which puts equal probability on the first token of all the optimal suffixes. OCD achieves the state-of-the-art performance on end-to-end speech recognition, on both Wall Street Journal and Librispeech datasets, achieving $9.3\\%$ WER and $4.8\\%$ WER, respectively.","keywords":["Sequence Learning","Edit Distance","Speech Recognition","Deep Reinforcement Learning"],"authorids":["ICLR.cc/2019/Conference/Paper963/Authors"],"authors":["Anonymous"],"TL;DR":"Optimal Completion Distillation (OCD) is a training procedure for optimizing sequence to sequence models based on edit distance which achieves state-of-the-art on end-to-end Speech Recognition tasks.","pdf":"/pdf/496b76a206dba05254e649b9e3058b3665c024cf.pdf","paperhash":"anonymous|optimal_completion_distillation_for_sequence_learning","_bibtex":"@inproceedings{    \nanonymous2019optimal,    \ntitle={Optimal Completion Distillation for Sequence Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkMW1hRqKX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Bklzkh0qFm","original":"S1xxzkCcFX","number":964,"cdate":1538087897637,"ddate":null,"tcdate":1538087897637,"tmdate":1538156019798,"tddate":null,"forum":"Bklzkh0qFm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Relational Graph Attention Networks","abstract":"In this paper we present Relational Graph Attention Networks, an extension of Graph Attention Networks to incorporate both node features and relational information into a masked attention mechanism, extending graph-based attention methods to a wider variety of problems, specifically, predicting the properties of molecules. We demonstrate that our attention mechanism gives competitive results on a molecular toxicity classification task (Tox21), enhancing the performance of its spectral-based convolutional equivalent. We also investigate the model on a series of transductive knowledge base completion tasks, where its performance is noticeably weaker. We provide insights as to why this may be, and suggest when it is appropriate to incorporate an attention layer into a graph architecture.","keywords":["RGCN","attention","graph convolutional networks","semi-supervised learning","graph classification","molecules"],"authorids":["ICLR.cc/2019/Conference/Paper964/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a new model for relational graphs and evaluate it on relational transductive and inductive tasks.","pdf":"/pdf/c05d7ab6a0a780c490f1f734aa58193a74b50b23.pdf","paperhash":"anonymous|relational_graph_attention_networks","_bibtex":"@inproceedings{    \nanonymous2019relational,    \ntitle={Relational Graph Attention Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bklzkh0qFm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJgzJh0qtQ","original":"HketzJA5Ym","number":965,"cdate":1538087897812,"ddate":null,"tcdate":1538087897812,"tmdate":1538156019587,"tddate":null,"forum":"SJgzJh0qtQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A SINGLE SHOT PCA-DRIVEN ANALYSIS OF NETWORK STRUCTURE TO REMOVE REDUNDANCY","abstract":"Deep learning models have outperformed traditional methods in many fields such\nas natural language processing and computer vision. However, despite their\ntremendous success, the methods of designing optimal Convolutional Neural Networks\n(CNNs) are still based on heuristics or grid search. The resulting networks\nobtained using these techniques are often overparametrized with huge computational\nand memory requirements. This paper focuses on a structured, explainable\napproach towards optimal model design that maximizes accuracy while keeping\ncomputational costs tractable. We propose a single-shot analysis of a trained CNN\nthat uses Principal Component Analysis (PCA) to determine the number of filters\nthat are doing significant transformations per layer, without the need for retraining.\nIt can be interpreted as identifying the dimensionality of the hypothesis space\nunder consideration. The proposed technique also helps estimate an optimal number\nof layers by looking at the expansion of dimensions as the model gets deeper.\nThis analysis can be used to design an optimal structure of a given network on\na dataset, or help to adapt a predesigned network on a new dataset. We demonstrate\nthese techniques by optimizing VGG and AlexNet networks on CIFAR-10,\nCIFAR-100 and ImageNet datasets.","keywords":["deep learning","model compression","pruning","PCA"],"authorids":["ICLR.cc/2019/Conference/Paper965/Authors"],"authors":["Anonymous"],"TL;DR":"We present a single shot analysis of a trained neural network to remove redundancy and identify optimal network structure","pdf":"/pdf/24bdde0b474f890711e4dc02615ca038609a17f5.pdf","paperhash":"anonymous|a_single_shot_pcadriven_analysis_of_network_structure_to_remove_redundancy","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A SINGLE SHOT PCA-DRIVEN ANALYSIS OF NETWORK STRUCTURE TO REMOVE REDUNDANCY},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJgzJh0qtQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyzMyhCcK7","original":"r1xsVYhKtm","number":966,"cdate":1538087897979,"ddate":null,"tcdate":1538087897979,"tmdate":1538156019376,"tddate":null,"forum":"HyzMyhCcK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"ProxQuant: Quantized Neural Networks via Proximal Operators","abstract":"To make deep neural networks feasible in resource-constrained environments (such as mobile devices), it is beneficial to quantize models by using low-precision weights. One common technique for quantizing neural networks is the straight-through gradient method, which enables back-propagation through the quantization mapping. Despite its empirical success, little is understood about why the straight-through gradient method works.\nBuilding upon a novel observation that the straight-through gradient method is in fact identical to the well-known Nesterov’s dual-averaging algorithm on a quantization constrained optimization problem, we propose a more principled alternative approach, called ProxQuant , that formulates quantized network training as a regularized learning problem instead and optimizes it via the prox-gradient method. ProxQuant does back-propagation on the underlying full-precision vector and applies an efficient prox-operator in between stochastic gradient steps to encourage quantizedness. For quantizing ResNets and LSTMs, ProxQuant outperforms state-of-the-art results on binary quantization and is on par with state-of-the-art on multi-bit quantization. For binary quantization, our analysis shows both theoretically and experimentally that ProxQuant is more stable than the straight-through gradient method (i.e. BinaryConnect), challenging the indispensability of the straight-through gradient method and providing a powerful alternative.","keywords":["Model quantization","Optimization","Regularization"],"authorids":["ICLR.cc/2019/Conference/Paper966/Authors"],"authors":["Anonymous"],"TL;DR":"A principled framework for model quantization using the proximal gradient method.","pdf":"/pdf/bebf97fe48477be14aec8b508483d340650bf185.pdf","paperhash":"anonymous|proxquant_quantized_neural_networks_via_proximal_operators","_bibtex":"@inproceedings{    \nanonymous2019proxquant:,    \ntitle={ProxQuant: Quantized Neural Networks via Proximal Operators},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyzMyhCcK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1xzyhR9Y7","original":"BklnKGFtKX","number":967,"cdate":1538087898154,"ddate":null,"tcdate":1538087898154,"tmdate":1538156019169,"tddate":null,"forum":"S1xzyhR9Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Improving Sentence Representations with Multi-view Frameworks","abstract":"Multi-view learning can provide self-supervision when different views are available of the same data. Distributional hypothesis provides another form of useful self-supervision from adjacent sentences which are plentiful in large unlabelled corpora. Motivated by the asymmetry in the two hemispheres of the human brain as well as the observation that different learning architectures tend to emphasise different aspects of sentence meaning, we present two multi-view frameworks for learning sentence representations in an unsupervised fashion. One framework uses a generative objective and the other a discriminative one. In both frameworks, the final representation is an ensemble of two views, in which, one view encodes the input sentence with a Recurrent Neural Network (RNN), and the other view encodes it with a simple linear model. We show that, after learning, the vectors produced by our multi-view frameworks provide improved representations over their single-view learned counterparts, and the combination of different views gives representational improvement over each view and demonstrates solid transferability on standard downstream tasks.","keywords":["multi-view","learning","sentence","representation"],"authorids":["ICLR.cc/2019/Conference/Paper967/Authors"],"authors":["Anonymous"],"TL;DR":"Multi-view learning improves unsupervised sentence representation learning","pdf":"/pdf/11b3b05f54d864347047897926172e8091d4d75b.pdf","paperhash":"anonymous|improving_sentence_representations_with_multiview_frameworks","_bibtex":"@inproceedings{    \nanonymous2019improving,    \ntitle={Improving Sentence Representations with Multi-view Frameworks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1xzyhR9Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyxG13R9Km","original":"r1g77y0cY7","number":968,"cdate":1538087898327,"ddate":null,"tcdate":1538087898327,"tmdate":1538156018962,"tddate":null,"forum":"SyxG13R9Km","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"How Training Data Affect the Accuracy and Robustness of Neural Networks for Image Classification","abstract":"Recent work has demonstrated the lack of robustness of well-trained deep neural networks (DNNs) to adversarial examples.  For example, visually indistinguishable perturbations, when mixed with an original image, can easily lead deep learning models to misclassifications.  In light of a recent study on the mutual influence between robustness and accuracy over 18 different ImageNet models, this paper investigates how training data affect the accuracy and robustness of deep neural\nnetworks. We conduct extensive experiments on four different datasets, including CIFAR-10, MNIST, STL-10, and Tiny ImageNet, with several representative neural networks. Our results reveal previously unknown phenomena that exist between the size of training data and characteristics of the resulting models. In particular, besides confirming that the model accuracy improves as the amount of training data increases, we also observe that the model robustness improves initially, but there exists a turning point after which robustness starts to deteriorate.  How and when such turning points occur vary for different neural networks and different datasets.","keywords":["Adversarial attacks","Robustness","CW","I-FGSM"],"authorids":["ICLR.cc/2019/Conference/Paper968/Authors"],"authors":["Anonymous"],"pdf":"/pdf/c4a7bc22229085357d859b5f713f8ccb319fac28.pdf","paperhash":"anonymous|how_training_data_affect_the_accuracy_and_robustness_of_neural_networks_for_image_classification","_bibtex":"@inproceedings{    \nanonymous2019how,    \ntitle={How Training Data Affect the Accuracy and Robustness of Neural Networks for Image Classification},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxG13R9Km},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJxfJnC9YX","original":"HyexZ_h9FQ","number":969,"cdate":1538087898491,"ddate":null,"tcdate":1538087898491,"tmdate":1538156018762,"tddate":null,"forum":"BJxfJnC9YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Spatio-Temporal Representations Using Spike-Based Backpropagation","abstract":"Spiking neural networks (SNNs) offer a promising alternative to current artificial neural networks to enable low-power event-driven neuromorphic hardware. However, training SNNs remains a challenge primarily because of the complex non-differentiable neuronal behavior arising from their spike-based computation. In this paper, we propose an algorithm to train spiking autoencoders on regenerative learning tasks. A sigmoid approximation is used in place of the Leaky Integrate-and-Fire neuron's threshold based activation during backpropagation to enable differentiability. The loss is computed on the membrane potential of the output layer, which is then backpropagated through the network at each time step. These spiking autoencoders learn meaningful spatio-temporal representations of the data, across two modalities - audio and visual. We demonstrate audio to image synthesis in a spike-based environment by sharing these spatio-temporal representations between the two modalities. These models achieve very low reconstruction loss, comparable to ANNs, on MNIST and Fashion-MNIST datasets, and while converting TI-46 digits audio samples to MNIST images. ","keywords":["spiking neural networks","autoencoders","representation learning","backpropagation","multimodal"],"authorids":["ICLR.cc/2019/Conference/Paper969/Authors"],"authors":["Anonymous"],"pdf":"/pdf/820d782a1eb38bc17b02b942b7d13c7bdf1d6648.pdf","paperhash":"anonymous|learning_spatiotemporal_representations_using_spikebased_backpropagation","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Spatio-Temporal Representations Using Spike-Based Backpropagation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJxfJnC9YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rye7knCqK7","original":"SygohGe9KQ","number":970,"cdate":1538087898659,"ddate":null,"tcdate":1538087898659,"tmdate":1538156018554,"tddate":null,"forum":"rye7knCqK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Individualized Controlled Continuous Communication Model for Multiagent Cooperative and Competitive Tasks","abstract":"Learning when to communicate and doing that effectively is essential in multi-agent tasks. Recent works show that continuous communication allows efficient training with back-propagation in multi-agent scenarios, but have been restricted to fully-cooperative tasks. In this paper, we present Individualized Controlled Continuous Communication Model (IC3Net) which has better training efficiency than simple continuous communication model, and can be applied to semi-cooperative and competitive settings along with the cooperative settings. IC3Net controls continuous communication with a gating mechanism and uses individualized rewards foreach agent to gain better performance and scalability while fixing credit assignment issues. Using variety of tasks including StarCraft BroodWars explore and combat scenarios, we show that our network yields improved performance and convergence rates than the baselines as the scale increases. Our results convey that IC3Net agents learn when to communicate based on the scenario and profitability.","keywords":["multiagent","communication","competitive","cooperative","continuous","emergent"],"authorids":["ICLR.cc/2019/Conference/Paper970/Authors"],"authors":["Anonymous"],"TL;DR":"We introduce IC3Net, a single network which can be used to train agents in cooperative, competitive and mixed scenarios. We also show that agents can learn when to communicate using our model.","pdf":"/pdf/32d6830f4a88c46b5a39c8420234a038274b4df7.pdf","paperhash":"anonymous|individualized_controlled_continuous_communication_model_for_multiagent_cooperative_and_competitive_tasks","_bibtex":"@inproceedings{    \nanonymous2019individualized,    \ntitle={Individualized Controlled Continuous Communication Model for Multiagent Cooperative and Competitive Tasks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rye7knCqK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJxXynC9t7","original":"HkeICYi9FQ","number":971,"cdate":1538087898831,"ddate":null,"tcdate":1538087898831,"tmdate":1538156018348,"tddate":null,"forum":"HJxXynC9t7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Expressiveness in Deep Reinforcement Learning","abstract":"Representation learning in reinforcement learning (RL) algorithms focuses on extracting useful features for choosing good actions. Expressive representations are essential for learning well-performed policies. In this paper, we study the relationship between the state representation assigned by the state extractor and the performance of the RL agent. We observe that representations assigned by the better state extractor are more scattered than which assigned by the worse one. Moreover, RL agents achieving high performances always have high rank matrices which are composed by their representations. Based on our observations, we formally define expressiveness of the state extractor as the rank of the matrix composed by representations. Therefore, we propose to promote expressiveness so as to improve algorithm performances, and we call it Expressiveness Promoted DRL. We apply our method on both policy gradient and value-based algorithms, and experimental results on 55 Atari games show the superiority of our proposed method.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper971/Authors"],"authors":["Anonymous"],"pdf":"/pdf/87421afc848df50f51a0b546dafb8c2ef2703750.pdf","paperhash":"anonymous|expressiveness_in_deep_reinforcement_learning","_bibtex":"@inproceedings{    \nanonymous2019expressiveness,    \ntitle={Expressiveness in Deep Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxXynC9t7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1g7y2RqYX","original":"r1gXQxCYKm","number":972,"cdate":1538087899061,"ddate":null,"tcdate":1538087899061,"tmdate":1538156018141,"tddate":null,"forum":"r1g7y2RqYX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Label Propagation Networks","abstract":"Graph networks have recently attracted considerable interest, and in particular in the context of semi-supervised learning. These methods typically work by generating node representations that are propagated throughout a given weighted graph.\n\nHere we argue that for semi-supervised learning, it is more natural to consider propagating labels in the graph instead. Towards this end, we propose a differentiable neural version of the classic Label Propagation (LP) algorithm. This formulation can be used for learning edge weights, unlike other methods where weights are set heuristically. Starting from a layer implementing a single iteration of LP, we proceed by adding several important non-linear steps that significantly enhance the label-propagating mechanism.\n\nExperiments in two distinct settings demonstrate the utility of our approach.\n","keywords":["semi supervised learning","graph networks","deep learning architectures"],"authorids":["ICLR.cc/2019/Conference/Paper972/Authors"],"authors":["Anonymous"],"TL;DR":"Neural net for graph-based semi-supervised learning; revisits the classics and propagates *labels* rather than feature representations","pdf":"/pdf/2768addc12ba552c746bf9512007c16cea2465d1.pdf","paperhash":"anonymous|label_propagation_networks","_bibtex":"@inproceedings{    \nanonymous2019label,    \ntitle={Label Propagation Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1g7y2RqYX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Bylmkh05KX","original":"SyxCUa_cK7","number":973,"cdate":1538087899228,"ddate":null,"tcdate":1538087899228,"tmdate":1538156017929,"tddate":null,"forum":"Bylmkh05KX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Unsupervised Speech Recognition via Segmental Empirical Output Distribution Matching","abstract":"We consider the problem of training speech recognition systems without using any labeled data, under the assumption that the learner can only access to the input utterances and a phoneme language model estimated from a non-overlapping corpus. We propose a fully unsupervised learning algorithm that alternates between solving two sub-problems: (i) learn a phoneme classifier for a given set of phoneme segmentation boundaries, and (ii) refining the phoneme boundaries based on a given classifier. To solve the first sub-problem, we introduce a novel unsupervised cost function named Segmental Empirical Output Distribution Matching, which generalizes the work in (Liu et al., 2017) to segmental structures. For the second sub-problem, we develop an approximate MAP approach to refining the boundaries obtained from Wang et al. (2017). Experimental results on TIMIT dataset demonstrate the success of this first fully unsupervised phoneme recognition system, which achieves a phone error rate (PER) of 41.6%. Although it is still far away from the state-of-the-art supervised systems, we show that with oracle boundaries and matching language model, the PER could be improved to 32.5%. This performance approaches the supervised system of the same model architecture, demonstrating the great potential of the proposed method. ","keywords":["Unsupervised speech recognition","unsupervised learning","phoneme classification"],"authorids":["ICLR.cc/2019/Conference/Paper973/Authors"],"authors":["Anonymous"],"pdf":"/pdf/896dc3365c9b551c67b35458ccdc1103fe49e814.pdf","paperhash":"anonymous|unsupervised_speech_recognition_via_segmental_empirical_output_distribution_matching","_bibtex":"@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Speech Recognition via Segmental Empirical Output Distribution Matching},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bylmkh05KX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BkMXkhA5Fm","original":"r1l0zTTqKX","number":974,"cdate":1538087899398,"ddate":null,"tcdate":1538087899398,"tmdate":1538156017717,"tddate":null,"forum":"BkMXkhA5Fm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning State Representations in Complex Systems with Multimodal Data","abstract":"Representation learning becomes especially important for complex systems with multimodal data sources such as cameras or sensors. Recent advances in reinforcement learning and optimal control make it possible to design control algorithms on these latent representations, but the field still lacks a large-scale standard dataset for unified comparison. In this work, we present a large-scale dataset and evaluation framework for representation learning for the complex task of landing an airplane. We implement and compare several approaches to representation learning on this dataset in terms of the quality of simple supervised learning tasks and disentanglement scores. The resulting representations can be used for further tasks such as anomaly detection, optimal control, model-based reinforcement learning, and other applications.","keywords":["deep learning","representation learning","state representation","disentangled representation","dataset","autonomous system","temporal multimodal data"],"authorids":["ICLR.cc/2019/Conference/Paper974/Authors"],"authors":["Anonymous"],"TL;DR":"Multimodal synthetic dataset, collected from X-plane flight simulator, used for learning state representation and unified evaluation framework for representation learning","pdf":"/pdf/3b11013c10c7dc27e8badac5e92beddab407a397.pdf","paperhash":"anonymous|learning_state_representations_in_complex_systems_with_multimodal_data","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning State Representations in Complex Systems with Multimodal Data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkMXkhA5Fm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rke41hC5Km","original":"Hyx6Ct6qFQ","number":975,"cdate":1538087899570,"ddate":null,"tcdate":1538087899570,"tmdate":1538156017510,"tddate":null,"forum":"rke41hC5Km","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Generating Realistic Stock Market Order Streams","abstract":"We propose an approach to generate realistic and high-fidelity stock market data based on generative adversarial networks.\nWe model the order stream as a stochastic process with finite history dependence, and employ a conditional Wasserstein GAN to capture history dependence of orders in a stock market. \nWe test our approach with actual market and synthetic data on a number of different statistics, and find the generated data to be close to real data. ","keywords":["application in finance","stock markets","generative models"],"authorids":["ICLR.cc/2019/Conference/Paper975/Authors"],"authors":["Anonymous"],"TL;DR":"We propose an approach to generate realistic and high-fidelity stock market data based on generative adversarial networks.","pdf":"/pdf/b20e2bef7c68f57187170b2a6eba82b79191ab04.pdf","paperhash":"anonymous|generating_realistic_stock_market_order_streams","_bibtex":"@inproceedings{    \nanonymous2019generating,    \ntitle={Generating Realistic Stock Market Order Streams},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rke41hC5Km},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hyx4knR9Ym","original":"SygVFzS5Ym","number":976,"cdate":1538087899747,"ddate":null,"tcdate":1538087899747,"tmdate":1538156017296,"tddate":null,"forum":"Hyx4knR9Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Generalizable Adversarial Training via Spectral Normalization","abstract":"Deep neural networks (DNNs) have set benchmarks on a wide array of supervised learning tasks. Trained DNNs, however, often lack robustness to minor adversarial perturbations to the input, which undermines their true practicality. Recent works have increased the robustness of DNNs by fitting networks using adversarially-perturbed training samples, but the improved performance can still be far below the performance seen in non-adversarial settings. A significant portion of this gap can be attributed to the decrease in generalization performance due to adversarial training. In this work, we extend the notion of margin loss to adversarial settings and bound the generalization error for DNNs trained under several well-known gradient-based attack schemes, motivating an effective regularization scheme based on spectral normalization of the DNN's weight matrices. We also provide a computationally-efficient method for normalizing the spectral norm of convolutional layers with arbitrary stride and padding schemes in deep convolutional networks. We evaluate the power of spectral normalization extensively on combinations of datasets, network architectures, and adversarial training schemes.","keywords":["Adversarial attacks","adversarial training","spectral normalization","generalization guarantee"],"authorids":["ICLR.cc/2019/Conference/Paper976/Authors"],"authors":["Anonymous"],"pdf":"/pdf/59864086ec60f5706d162c04c75bf01abc8e9fcc.pdf","paperhash":"anonymous|generalizable_adversarial_training_via_spectral_normalization","_bibtex":"@inproceedings{    \nanonymous2019generalizable,    \ntitle={Generalizable Adversarial Training via Spectral Normalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyx4knR9Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1g4k309F7","original":"HJxyIyA9F7","number":977,"cdate":1538087899921,"ddate":null,"tcdate":1538087899921,"tmdate":1538156017085,"tddate":null,"forum":"H1g4k309F7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Wasserstein Barycenter Model Ensembling","abstract":"In this paper we propose to perform model ensembling in a multiclass or a multilabel learning setting using Wasserstein barycenters. Optimal transport metrics, such as the Wasserstein distance, allow incorporating semantic side information such as word embeddings. Using Wass. barycenters to find the consensus between models allows us to balance confidence and semantics in finding the agreement between the models. We show applications of Wasserstein ensembling in attribute-based classification, multilabel learning and image captioning generation. These results show that the Wass. ensembling is a viable alternative to the basic geometric or arithmetic mean ensembling.","keywords":["Wasserstein barycenter model ensembling"],"authorids":["ICLR.cc/2019/Conference/Paper977/Authors"],"authors":["Anonymous"],"TL;DR":"we propose to use Wasserstein barycenters for semantic model ensembling","pdf":"/pdf/25394fe54dcf908e115f6bafcefd46fbadefe2c0.pdf","paperhash":"anonymous|wasserstein_barycenter_model_ensembling","_bibtex":"@inproceedings{    \nanonymous2019wasserstein,    \ntitle={Wasserstein Barycenter Model Ensembling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1g4k309F7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJg4J3CqFm","original":"Skepida5tX","number":978,"cdate":1538087900096,"ddate":null,"tcdate":1538087900096,"tmdate":1538156016876,"tddate":null,"forum":"rJg4J3CqFm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Discrete Wasserstein Embeddings","abstract":"Despite their prevalence, Euclidean embeddings of data are fundamentally limited in their ability to capture latent semantic structures, which need not conform to Euclidean spatial assumptions. Here we consider an alternative, which embeds data as discrete probability distributions in a Wasserstein space, endowed with an optimal transport metric. Wasserstein spaces are much larger and more flexible than Euclidean spaces, in that they can successfully embed a wider variety of metric structures. We propose to exploit this flexibility by learning an embedding that captures the semantic information in the Wasserstein distance between embedded distributions. We examine empirically the representational capacity of such learned Wasserstein embeddings, showing that they can embed a wide variety of complex metric structures with smaller distortion than an equivalent Euclidean embedding. We also investigate an application to word embedding, demonstrating a unique advantage of Wasserstein embeddings: we can directly visualize the high-dimensional embedding, as it is a probability distribution on a low-dimensional space. This obviates the need for dimensionality reduction techniques such as t-SNE for visualization.","keywords":["Embedding","Wasserstein","Optimal Transport"],"authorids":["ICLR.cc/2019/Conference/Paper978/Authors"],"authors":["Anonymous"],"TL;DR":"We show that Wasserstein spaces are good targets for embedding data with complex semantic structure.","pdf":"/pdf/6e2db40f353e7064fc5aa12dade0c4940c623e3d.pdf","paperhash":"anonymous|learning_discrete_wasserstein_embeddings","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Discrete Wasserstein Embeddings},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJg4J3CqFm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1fNJhRqFX","original":"S1xcUkA9FQ","number":979,"cdate":1538087900277,"ddate":null,"tcdate":1538087900277,"tmdate":1538156016670,"tddate":null,"forum":"S1fNJhRqFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Exploration using Distributional RL and UCB","abstract":"    We establish the relation between Distributional RL and the Upper Confidence Bound (UCB) approach to exploration.\n    In this paper we show that the density of the Q function estimated by Distributional RL can be successfully used for the estimation of UCB. This approach does not require counting and, therefore, generalizes well to the Deep RL. We also point to the asymmetry of the empirical densities estimated by the Distributional RL algorithms like QR-DQN. This observation leads to the reexamination of the variance's performance in the UCB type approach to exploration. We introduce truncated variance as an alternative estimator of the UCB and a novel algorithm based on it. We empirically show that newly introduced algorithm achieves better performance in multi-armed bandits setting. Finally, we extend this approach to high-dimensional setting and test it on the Atari 2600 games. New approach achieves better performance compared to QR-DQN in 26 of games, 13 ties out of 49 games.","keywords":["Distributional RL","UCB","exploration","Atari 2600","multi-armed bandits"],"authorids":["ICLR.cc/2019/Conference/Paper979/Authors"],"authors":["Anonymous"],"TL;DR":"Exploration using Distributional RL and truncagted variance.","pdf":"/pdf/c848962619a0820a6a346f72a374a44d821def86.pdf","paperhash":"anonymous|exploration_using_distributional_rl_and_ucb","_bibtex":"@inproceedings{    \nanonymous2019exploration,    \ntitle={Exploration using Distributional RL and UCB},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1fNJhRqFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BylE1205Fm","original":"SJgV3JL5Km","number":980,"cdate":1538087900448,"ddate":null,"tcdate":1538087900448,"tmdate":1538156016455,"tddate":null,"forum":"BylE1205Fm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Emerging Disentanglement in Auto-Encoder Based Unsupervised Image Content Transfer","abstract":"We study the problem of learning to map, in an unsupervised way, between domains A and B, such that the samples b in B contain all the information that exists in samples $\\va\\in A$ and some additional information. For example, ignoring occlusions, B can be people with glasses, A people without, and the glasses, would be the added information. When mapping a sample a from the first domain to the other domain, the missing information is replicated from an independent reference sample b in B. Thus, in the above example, we can create, for every person without glasses a version with the glasses observed in any face image. \n\nOur solution employs a single two-pathway encoder and a single decoder for both domains. The common part of the two domains and the separate part are encoded as two vectors, and the separate part is fixed at zero for domain A. The loss terms are minimal and involve reconstruction losses for the two domains and a domain confusion term. Our analysis shows that under mild assumptions, this architecture, which is much simpler than the literature guided-translation methods, is enough to ensure disentanglement between the two domains. We present convincing results in a few visual domains, such as no-glasses to glasses, adding facial hair based on a reference image, etc.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper980/Authors"],"authors":["Anonymous"],"TL;DR":"An image to image translation method which adds to one image the content of another thereby creating a new image.","pdf":"/pdf/edc1369c74c7a385e3915835b6d4832ea1721691.pdf","paperhash":"anonymous|emerging_disentanglement_in_autoencoder_based_unsupervised_image_content_transfer","_bibtex":"@inproceedings{    \nanonymous2019emerging,    \ntitle={Emerging Disentanglement in Auto-Encoder Based Unsupervised Image Content Transfer},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BylE1205Fm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkgHk3RctX","original":"S1lLRz-9tX","number":981,"cdate":1538087900682,"ddate":null,"tcdate":1538087900682,"tmdate":1538156016247,"tddate":null,"forum":"HkgHk3RctX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Seq2Slate: Re-ranking and Slate Optimization with RNNs","abstract":"Ranking is a central task in machine learning and information retrieval. In this task, it is especially important to present the user with a slate of items that is appealing as a whole. This in turn requires taking into account interactions between items, since intuitively, placing an item on the slate affects the decision of which other items should be chosen alongside it.\nIn this work, we propose a sequence-to-sequence model for ranking called seq2slate. At each step, the model predicts the next item to place on the slate given the items already chosen. The recurrent nature of the model allows complex dependencies between items to be captured directly in a flexible and scalable way. We show how to learn the model end-to-end from weak supervision in the form of easily obtained click-through data. We further demonstrate the usefulness of our approach in experiments on standard ranking benchmarks as well as in a real-world recommendation system.","keywords":["Recurrent neural networks","learning to rank","pointer networks"],"authorids":["ICLR.cc/2019/Conference/Paper981/Authors"],"authors":["Anonymous"],"TL;DR":"A pointer network architecture for re-ranking items, learned from click-through logs.","pdf":"/pdf/dc4fd08c5eeb3146c32f551d9a2ac1622e25c4ba.pdf","paperhash":"anonymous|seq2slate_reranking_and_slate_optimization_with_rnns","_bibtex":"@inproceedings{    \nanonymous2019seq2slate:,    \ntitle={Seq2Slate: Re-ranking and Slate Optimization with RNNs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkgHk3RctX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HylSk205YQ","original":"BkxzYA6ctQ","number":982,"cdate":1538087900866,"ddate":null,"tcdate":1538087900866,"tmdate":1538156016040,"tddate":null,"forum":"HylSk205YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Multi-agent Deep Reinforcement Learning with Extremely Noisy Observations","abstract":"Multi-agent reinforcement learning systems aim to provide interacting agents with the ability to collaboratively learn and adapt to the behaviour of other agents. In many real-world applications, the agents can only acquire a partial view of the world. Here we consider a setting whereby most agents' observations are also extremely noisy, hence only weakly correlated to the true state of the environment. Under these circumstances, learning an optimal policy becomes particularly challenging, even in the unrealistic case that an agent's policy can be made conditional upon all other agents’ observations. To overcome these difficulties, we propose a multi-agent deep deterministic policy gradient algorithm enhanced by a communication medium (MADDPG-M), which implements a two-level, concurrent learning mechanism. An agent's policy depends on its own private observations as well as those explicitly shared by others through a communication medium. At any given point in time, an agent must decide whether its private observations are sufficiently informative to be shared with others. However, our environments provide no explicit feedback informing an agent whether a communication action is beneficial, rather the communication policies must also be learned through experience concurrently to the main policies. Our experimental results demonstrate that the algorithm performs well in six highly non-stationary environments of progressively higher complexity, and offers substantial performance gains compared to the baselines.","keywords":["Reinforcement learning","multi-agent","hierarchical","noisy observation","partial observability","deep learning"],"authorids":["ICLR.cc/2019/Conference/Paper982/Authors"],"authors":["Anonymous"],"pdf":"/pdf/14ebf091135f2701d77e64bfbf1a4ff860fee70d.pdf","paperhash":"anonymous|multiagent_deep_reinforcement_learning_with_extremely_noisy_observations","_bibtex":"@inproceedings{    \nanonymous2019multi-agent,    \ntitle={Multi-agent Deep Reinforcement Learning with Extremely Noisy Observations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HylSk205YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkgSk2A9Y7","original":"H1lriETcYX","number":983,"cdate":1538087901106,"ddate":null,"tcdate":1538087901106,"tmdate":1538156015837,"tddate":null,"forum":"HkgSk2A9Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Stochastic Gradient Push for Distributed Deep Learning","abstract":"Large mini-batch parallel SGD is commonly used for distributed training of deep\nnetworks. Approaches that use tightly-coupled exact distributed averaging based\non AllReduce are sensitive to slow nodes and high-latency communication. In\nthis work we show the applicability of Stochastic Gradient Push (SGP) for distributed\ntraining. SGP uses a gossip algorithm called PushSum for approximate\ndistributed averaging, allowing for much more loosely coupled communications\nwhich can be beneficial in high-latency or high-variability scenarios. The tradeoff\nis that approximate distributed averaging injects additional noise in the gradient\nwhich can affect the train and test accuracies. We prove that SGP converges to\na stationary point of smooth, non-convex objective functions. Furthermore, we\nvalidate empirically the potential of SGP. For example, using 32 nodes with 8\nGPUs per node to train ResNet-50 on ImageNet, where nodes communicate over\n10Gbps Ethernet, SGP completes 90 epochs in around 1.5 hours while AllReduce\nSGD takes over 5 hours, and the top-1 validation accuracy of SGP remains within\n1.2% of that obtained using AllReduce SGD.","keywords":["optimization","distributed","large scale","deep learning"],"authorids":["ICLR.cc/2019/Conference/Paper983/Authors"],"authors":["Anonymous"],"TL;DR":"For distributed training over high-latency networks, use gossip-based approximate distributed averaging instead of exact distribute averaging like AllReduce.","pdf":"/pdf/d0d33db85752bdd51a0a55a3be871f7c4384c3a1.pdf","paperhash":"anonymous|stochastic_gradient_push_for_distributed_deep_learning","_bibtex":"@inproceedings{    \nanonymous2019stochastic,    \ntitle={Stochastic Gradient Push for Distributed Deep Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkgSk2A9Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1GHJ3R9tQ","original":"rke2P-p5Fm","number":984,"cdate":1538087901277,"ddate":null,"tcdate":1538087901277,"tmdate":1538156015634,"tddate":null,"forum":"B1GHJ3R9tQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"HyperGAN:  Exploring the Manifold of Neural Networks","abstract":"We introduce HyperGAN, a generative adversarial network that learns to generate all the parameters of a deep  neural network. HyperGAN first transforms low dimensional noise into a latent space, which can be sampled from to obtain diverse, performant sets of parameters for a target architecture. We utilize an architecture that bears resemblance to adversarial autoencoders, but with the data term substituted to be classification loss, which is equivalent to minimizing the KL-divergence between the generated network parameter distribution with a unknown true parameter distribution. We apply HyperGAN to classification, showing that HyperGAN can learn to generate parameters which solve the MNIST and CIFAR-10 datasets with competitive performance to fully supervised learning, while learning a rich distribution of effective parameters. We also show that HyperGAN can also provide better uncertainty than standard ensembles. We show this by evaluating the robustness of HyperGAN-generated ensembles to domain-shift, testing with out of distribution data as well as adversarial examples. We see that in addition to being highly accurate on inlier data, HyperGAN can provide reasonable uncertainty estimates.","keywords":["hypernetworks","generative adversarial networks","anomaly detection"],"authorids":["ICLR.cc/2019/Conference/Paper984/Authors"],"authors":["Anonymous"],"TL;DR":"We use a GAN to generate parameters of a neural network in one forward pass.","pdf":"/pdf/877daff5129441f118a58ee345e6cf34585d5dce.pdf","paperhash":"anonymous|hypergan_exploring_the_manifold_of_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019hypergan:,    \ntitle={HyperGAN:  Exploring the Manifold of Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1GHJ3R9tQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hkxr1nCcFm","original":"HkeT8V9cFQ","number":985,"cdate":1538087901441,"ddate":null,"tcdate":1538087901441,"tmdate":1538156015419,"tddate":null,"forum":"Hkxr1nCcFm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"An investigation of model-free planning","abstract":"The field of reinforcement learning (RL) is facing increasingly challenging domains with combinatorial complexity. For an RL agent to address these challenges, it is essential that it can plan effectively. Prior work has typically utilized an explicit model of the environment, combined with a specific planning algorithm (such as tree search).  More recently, a new family of methods have been proposed that learn how to plan, by providing the structure for planning via an inductive bias in the function approximator (such as a tree structured neural network), trained end-to-end by a model-free RL algorithm. In this paper, we go even further, and suggest that an entirely model-free approach, without any special structure beyond standard neural network components such as convolutional networks and LSTMs, can learn to plan effectively.  We measure our agent's effectiveness at planning in terms of its ability to generalize across a combinatorial and irreversible state space, its data efficiency, and its ability to utilize additional thinking time.  We find that our agent has the characteristics that one might expect to find in a true planning algorithm. Furthermore, it exceeds the state-of-the-art in challenging combinatorial domains such as Sokoban and outperforms other model-free approaches that utilize strong inductive biases towards planning. ","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper985/Authors"],"authors":["Anonymous"],"pdf":"/pdf/d31da2f2899123cf4a29782ec18c5416d2bc0d80.pdf","paperhash":"anonymous|an_investigation_of_modelfree_planning","_bibtex":"@inproceedings{    \nanonymous2019an,    \ntitle={An investigation of model-free planning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hkxr1nCcFm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJl8J30qFX","original":"SkltIMwcKQ","number":986,"cdate":1538087901670,"ddate":null,"tcdate":1538087901670,"tmdate":1538156015207,"tddate":null,"forum":"SJl8J30qFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Global Additive Explanations for Neural Nets Using Model Distillation","abstract":"Interpretability has largely focused on local explanations, i.e. explaining why a model made a particular prediction for a sample. These explanations are appealing due to their simplicity and local fidelity. However, they do not provide information about the general behavior of the model. We propose to leverage model distillation to learn global additive explanations that describe the relationship between input features and model predictions. These global explanations take the form of feature shapes, which are more expressive than feature attributions. Through careful experimentation, we show qualitatively and quantitatively that global additive explanations are able to describe model behavior and yield insights about models such as neural nets. A visualization of our approach applied to a neural net as it is trained is available at https://youtu.be/ErQYwNqzEdc","keywords":["global interpretability","additive explanations","model distillation","neural nets","tabular data"],"authorids":["ICLR.cc/2019/Conference/Paper986/Authors"],"authors":["Anonymous"],"TL;DR":"We propose to leverage model distillation to learn global additive explanations in the form of feature shapes (that are more expressive than feature attributions) for models such as neural nets trained on tabular data.","pdf":"/pdf/e85b64d7325f3836eb4250782b5c18d3676def25.pdf","paperhash":"anonymous|learning_global_additive_explanations_for_neural_nets_using_model_distillation","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Global Additive Explanations for Neural Nets Using Model Distillation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJl8J30qFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rylIy3R9K7","original":"SygKkVaqtm","number":987,"cdate":1538087901840,"ddate":null,"tcdate":1538087901840,"tmdate":1538156015003,"tddate":null,"forum":"rylIy3R9K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Understand the dynamics of GANs via Primal-Dual Optimization","abstract":"Generative adversarial network (GAN) is one of the best known unsupervised learning techniques these days due to its superior ability to learn data distributions. In spite of its great success in applications, GAN is known to be notoriously hard to train. The tremendous amount of time it takes to run the training algorithm and its sensitivity to hyper-parameter tuning have been haunting researchers in this area. To resolve these issues, we need to first understand how GANs work. Herein, we take a step toward this direction by examining the dynamics of GANs. We relate a large class of GANs including the Wasserstein GANs to max-min optimization problems with the coupling term being linear over the discriminator. By developing new primal-dual optimization tools, we show that, with a proper stepsize choice, the widely used first-order iterative algorithm in training GANs would in fact converge to a stationary solution with a sublinear rate. The same framework also applies to multi-task learning and distributional robust learning problems. We verify our analysis on numerical examples with both synthetic and real data sets. We hope our analysis shed light on future studies on the theoretical properties of relevant machine learning problems.","keywords":["non-convex optimization","generative adversarial network","primal dual algorithm"],"authorids":["ICLR.cc/2019/Conference/Paper987/Authors"],"authors":["Anonymous"],"TL;DR":"We show that, with a proper stepsize choice, the widely used first-order iterative algorithm in training GANs would in fact converge to a stationary solution with a sublinear rate.","pdf":"/pdf/0c10c334a4755e423f65efbb1e200a2b59c86a37.pdf","paperhash":"anonymous|understand_the_dynamics_of_gans_via_primaldual_optimization","_bibtex":"@inproceedings{    \nanonymous2019understand,    \ntitle={Understand the dynamics of GANs via Primal-Dual Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylIy3R9K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyGLy2RqtQ","original":"rJeOCTicFX","number":988,"cdate":1538087902016,"ddate":null,"tcdate":1538087902016,"tmdate":1538156014802,"tddate":null,"forum":"HyGLy2RqtQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Over-parameterization Improves Generalization in the XOR Detection Problem","abstract":"Empirical evidence suggests that neural networks with ReLU activations generalize better with over-parameterization. However, there is currently no theoretical analysis that explains this observation. In this work, we study a simplified learning task with over-parameterized convolutional networks that empirically exhibits the same qualitative phenomenon.  For this setting, we provide a theoretical analysis of the optimization and generalization performance of gradient descent. Specifically, we prove data-dependent sample complexity bounds which show that over-parameterization improves the generalization performance of gradient descent.","keywords":["deep learning","theory","non convex optimization","over-parameterization"],"authorids":["ICLR.cc/2019/Conference/Paper988/Authors"],"authors":["Anonymous"],"TL;DR":"We show in a simplified learning task that over-parameterization improves generalization of a convnet that is trained with gradient descent.","pdf":"/pdf/bffe7960e0b37c129a2deb2dcffd1377ad380cd3.pdf","paperhash":"anonymous|overparameterization_improves_generalization_in_the_xor_detection_problem","_bibtex":"@inproceedings{    \nanonymous2019over-parameterization,    \ntitle={Over-parameterization Improves Generalization in the XOR Detection Problem},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyGLy2RqtQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJg8yhAqKm","original":"r1lw89YqKX","number":989,"cdate":1538087902183,"ddate":null,"tcdate":1538087902183,"tmdate":1538156014596,"tddate":null,"forum":"rJg8yhAqKm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Transfer and Exploration via the Information Bottleneck","abstract":"A central challenge in reinforcement learning is discovering effective policies for tasks where rewards are sparsely distributed. We postulate that in the absence of useful reward signals, an effective exploration strategy should seek out {\\it decision states}. These states lie at critical junctions in the state space from where the agent can transition to new, potentially unexplored regions. We propose to learn about decision states from prior experience. By training a goal-conditioned model with an information bottleneck, we can identify decision states by examining where the model accesses the goal state through the bottleneck. We find that this simple mechanism effectively identifies decision states, even in partially observed settings. In effect, the model learns the sensory cues that correlate with potential subgoals. In new environments, this model can then identify novel subgoals for further exploration, guiding the agent through a sequence of potential decision  states and through new regions of the state space.","keywords":["Information bottleneck","policy transfer","policy generalization","exploration"],"authorids":["ICLR.cc/2019/Conference/Paper989/Authors"],"authors":["Anonymous"],"TL;DR":"Training agents with goal-policy information bottlenecks promotes transfer and yields a powerful exploration bonus","pdf":"/pdf/55ba10561ce7b4ee308d202aca6d973e07a4b58d.pdf","paperhash":"anonymous|transfer_and_exploration_via_the_information_bottleneck","_bibtex":"@inproceedings{    \nanonymous2019transfer,    \ntitle={Transfer and Exploration via the Information Bottleneck},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJg8yhAqKm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyeU1hRcFX","original":"HJey_dT9FQ","number":990,"cdate":1538087902361,"ddate":null,"tcdate":1538087902361,"tmdate":1538156014387,"tddate":null,"forum":"HyeU1hRcFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Unsupervised Conditional Generation using noise engineered mode matching GAN","abstract":"Conditional generation refers to the process of sampling from an unknown distribution conditioned on semantics of the data. This can be achieved by augmenting the generative model with the desired semantic labels, albeit it is not straightforward in an unsupervised setting where the semantic label of every data sample is unknown. In this paper, we address this issue by proposing a method that can generate samples conditioned on the properties of a latent distribution engineered in accordance with a certain data prior. In particular, a latent space inversion network is trained in tandem with a generative adversarial network such that the modal properties of the latent space distribution are induced in the data generating distribution. We demonstrate that our model despite being fully unsupervised, is effective in learning meaningful representations through its mode matching property. We validate our method on multiple unsupervised tasks such as conditional generation, dataset attribute discovery and inference using three real world image datasets namely MNIST, CIFAR-10 and CELEB-A and show that the results are comparable to the state-of-the-art methods. ","keywords":["Noise engineered GAN","Latent space engineering","Mode matching","Unsupervised learning"],"authorids":["ICLR.cc/2019/Conference/Paper990/Authors"],"authors":["Anonymous"],"TL;DR":"A GAN model where an inversion mapping from the generated data space to an engineered latent space is learned such that properties of the data generating distribution are matched to those of the latent distribution.","pdf":"/pdf/c294dd9ba46eaa875abbaec9c7cfff39842d2300.pdf","paperhash":"anonymous|unsupervised_conditional_generation_using_noise_engineered_mode_matching_gan","_bibtex":"@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Conditional Generation using noise engineered mode matching GAN},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyeU1hRcFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJePy3RcF7","original":"SkgKg1pqFQ","number":991,"cdate":1538087902527,"ddate":null,"tcdate":1538087902527,"tmdate":1538156014183,"tddate":null,"forum":"HJePy3RcF7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Rethinking learning rate schedules for stochastic optimization","abstract":"There is a stark disparity between the learning rate schedules used in the practice of large scale machine learning and what are considered admissible learning rate schedules prescribed in the theory of stochastic approximation. Recent results, such as in the 'super-convergence' methods which use oscillating learning rates, serve to emphasize this point even more.\nOne plausible explanation is that non-convex neural network training procedures are better suited to the use of fundamentally different learning rate  schedules, such as the ``cut the learning rate every constant number of epochs'' method (which more closely resembles an exponentially decaying learning rate schedule); note that this widely used schedule is in stark contrast to the polynomial decay schemes prescribed in the stochastic approximation literature, which are indeed shown to be (worst case) optimal for classes of convex optimization problems.\n\nThe main contribution of this work shows that the picture is far more nuanced, where we do not even need to move to non-convex optimization to show other learning rate schemes can be far more effective. In fact, even for the simple case of stochastic linear regression with a fixed time horizon, the rate achieved by any polynomial decay scheme is sub-optimal compared to the statistical minimax rate (by a factor of condition number); in contrast the ```''cut the learning rate every constant number of epochs'' provides an exponential improvement (depending only logarithmically on the condition number) compared to any polynomial decay scheme.  Finally, it is important to ask if our theoretical insights are somehow fundamentally tied to quadratic loss minimization (where we have circumvented minimax lower bounds for more general convex optimization problems)? Here, we conjecture that recent results which make the gradient norm small at a near optimal rate, for both convex and non-convex optimization, may also provide more insights into learning rate schedules used in practice.\n","keywords":["SGD","learning rate","step size schedules","stochastic approximation","stochastic optimization","deep learning","non-convex optimization","stochastic gradient descent"],"authorids":["ICLR.cc/2019/Conference/Paper991/Authors"],"authors":["Anonymous"],"TL;DR":"This paper presents a rigorous study of why practically used learning rate schedules (for a given computational budget) offer significant advantages even though these schemes are not advocated by the classical theory of Stochastic Approximation.","pdf":"/pdf/cff24fbf0f01c04ba5f0b5b2d33e453deb2bda9d.pdf","paperhash":"anonymous|rethinking_learning_rate_schedules_for_stochastic_optimization","_bibtex":"@inproceedings{    \nanonymous2019rethinking,    \ntitle={Rethinking learning rate schedules for stochastic optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJePy3RcF7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJxPk2A9Km","original":"BkePw0hqYX","number":992,"cdate":1538087902706,"ddate":null,"tcdate":1538087902706,"tmdate":1538156013980,"tddate":null,"forum":"BJxPk2A9Km","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning What to Remember: Long-term Episodic Memory Networks for Learning from Streaming Data","abstract":"Current generation of memory-augmented neural networks has limited scalability as they cannot efficiently process data that are too large to fit in the external memory storage. One example of this is lifelong learning scenario where the model receives unlimited length of data stream as an input which contains vast majority of uninformative entries. We tackle this problem by proposing a memory network fit for long-term lifelong learning scenario, which we refer to as Long-term Episodic Memory Networks (LEMN), that features a RNN-based retention agent that learns to replace less important memory entries based on the retention probability generated on each entry that is learned to identify data instances of generic importance relative to other memory entries, as well as its historical importance. Such learning of retention agent allows our long-term episodic memory network to retain memory entries of generic importance for a given task. We validate our model on a path-finding task as well as synthetic and real question answering tasks, on which our model achieves significant improvements over the memory augmented networks with rule-based memory scheduling as well as an RL-based baseline that does not consider relative or historical importance of the memory.","keywords":["Memory Network","Lifelong Learning"],"authorids":["ICLR.cc/2019/Conference/Paper992/Authors"],"authors":["Anonymous"],"pdf":"/pdf/53e3fa3166fc7d49e5832f68d4c3216c5087ab61.pdf","paperhash":"anonymous|learning_what_to_remember_longterm_episodic_memory_networks_for_learning_from_streaming_data","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning What to Remember: Long-term Episodic Memory Networks for Learning from Streaming Data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJxPk2A9Km},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJfvknCqFQ","original":"ryxRiJAqFQ","number":993,"cdate":1538087902888,"ddate":null,"tcdate":1538087902888,"tmdate":1538156013777,"tddate":null,"forum":"BJfvknCqFQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A Rotation and a Translation Suffice: Fooling CNNs with Simple Transformations","abstract":"We show that simple spatial transformations, namely translations and rotations alone, suffice to fool neural networks on a significant fraction of their inputs in multiple image classification tasks. Our results are in sharp contrast to previous work in adversarial robustness that relied on more complicated optimization ap- proaches unlikely to appear outside a truly adversarial context. Moreover, the misclassifying rotations and translations are easy to find and require only a few black-box queries to the target model. Overall, our findings emphasize the need to design robust classifiers even for natural input transformations in benign settings.\n","keywords":["robustness","spatial transformations","invariance","rotations","data augmentation","robust optimization"],"authorids":["ICLR.cc/2019/Conference/Paper993/Authors"],"authors":["Anonymous"],"TL;DR":"We show that CNNs are not robust to simple rotations and translation and explore methods of improving this.","pdf":"/pdf/3a95ee20b9313f1ab539108bda763e4511ba6e2a.pdf","paperhash":"anonymous|a_rotation_and_a_translation_suffice_fooling_cnns_with_simple_transformations","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A Rotation and a Translation Suffice: Fooling CNNs with Simple Transformations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJfvknCqFQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJfwJ2A5KX","original":"S1x0h8gwY7","number":994,"cdate":1538087903067,"ddate":null,"tcdate":1538087903067,"tmdate":1538156013576,"tddate":null,"forum":"HJfwJ2A5KX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Data-Dependent Coresets for Compressing Neural Networks with Applications to Generalization Bounds","abstract":"We present an efficient coresets-based neural network compression algorithm that sparsifies the parameters of a trained fully-connected neural network in a manner that provably approximates the network's output. Our approach is based on an importance sampling scheme that judiciously defines a sampling distribution over the neural network parameters, and as a result, retains parameters of high importance while discarding redundant ones. We leverage a novel, empirical notion of sensitivity and extend traditional coreset constructions to the application of compressing parameters. Our theoretical analysis establishes guarantees on the size and accuracy of the resulting compressed network and gives rise to generalization bounds that may provide new insights into the generalization properties of neural networks. We demonstrate the practical effectiveness of our algorithm on a variety of neural network configurations and real-world data sets.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper994/Authors"],"authors":["Anonymous"],"pdf":"/pdf/1f92919b1004e4753965552d69cbc7b555fd07f5.pdf","paperhash":"anonymous|datadependent_coresets_for_compressing_neural_networks_with_applications_to_generalization_bounds","_bibtex":"@inproceedings{    \nanonymous2019data-dependent,    \ntitle={Data-Dependent Coresets for Compressing Neural Networks with Applications to Generalization Bounds},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJfwJ2A5KX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyNPk2R9K7","original":"BJgJakAqYQ","number":995,"cdate":1538087903233,"ddate":null,"tcdate":1538087903233,"tmdate":1538156013372,"tddate":null,"forum":"SyNPk2R9K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning to Describe Scenes with Programs","abstract":"Human scene perception goes beyond recognizing a collection of objects and their pairwise relations. We are able to understand the higher-level, abstract regularities within the scene such as symmetry and repetition. Current vision recognition modules and scene representations fall short in this dimension. In this paper, we present scene programs, representing a scene via a symbolic program for its objects and their attributes. We also propose a model that infers such scene programs by exploiting a hierarchical, object-based scene representation. Experiments demonstrate that our model works well on synthetic data and is able to transfer to real images with such compositional structure. The use of scene programs has enabled a number of applications, such as complex visual analogy-making and scene extrapolation.","keywords":["Structured scene representations","program synthesis"],"authorids":["ICLR.cc/2019/Conference/Paper995/Authors"],"authors":["Anonymous"],"TL;DR":"We present scene programs, a structured scene representation that captures both low-level object appearance and high-level regularity in the scene.","pdf":"/pdf/ae43464a56ea8c22db437f74149dca78ff561bc9.pdf","paperhash":"anonymous|learning_to_describe_scenes_with_programs","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Describe Scenes with Programs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyNPk2R9K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryxwJhC9YX","original":"B1eRB-V5tm","number":996,"cdate":1538087903397,"ddate":null,"tcdate":1538087903397,"tmdate":1538156013160,"tddate":null,"forum":"ryxwJhC9YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Instance-aware Image-to-Image Translation","abstract":"Unsupervised image-to-image translation has gained considerable attention due to the recent impressive progress based on generative adversarial networks (GANs). However, previous methods often fail in challenging cases, in particular, when an image has multiple target instances and a translation task involves significant changes in shape, e.g., translating pants to skirts in fashion images. To tackle the issues, we propose a novel method, coined instance-aware GAN (InstaGAN), that incorporates the instance information (e.g., object segmentation masks) and improves multi-instance transfiguration. The proposed method translates both an image and the corresponding set of instance attributes while maintaining the permutation invariance property of the instances. To this end, we introduce a context preserving loss that encourages the network to learn the identity function outside of target instances. We also propose a sequential mini-batch inference/training technique that handles multiple instances with a limited GPU memory and enhances the network to generalize better for multiple instances. Our comparative evaluation demonstrates the effectiveness of the proposed method on different image datasets, in particular, in the aforementioned challenging cases.","keywords":["Image-to-Image Translation","Generative Adversarial Networks"],"authorids":["ICLR.cc/2019/Conference/Paper996/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a novel method to incorporate the set of instance attributes for image-to-image translation.","pdf":"/pdf/feff040defedceab91af618cd603f04df16d3e52.pdf","paperhash":"anonymous|instanceaware_imagetoimage_translation","_bibtex":"@inproceedings{    \nanonymous2019instance-aware,    \ntitle={Instance-aware Image-to-Image Translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxwJhC9YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJgd1nAqFX","original":"Hyl76J0qF7","number":997,"cdate":1538087903625,"ddate":null,"tcdate":1538087903625,"tmdate":1538156012953,"tddate":null,"forum":"HJgd1nAqFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"DOM-Q-NET:  Grounded RL on Structured Language","abstract":"The World Wide Web is a rich repository of knowledge about the real world. The ability for agents to interact with the web would allow for significant improvements in knowledge understanding and representation learning. However, web navigation tasks are difficult for the current deep reinforcement learning (RL) models due to the large discrete action space and the varying number of actions between the states. In this work, we introduce DOM-Q-NET, a novel architecture for RL-based web navigation to address both of these problems. DOM-Q-NET utilizes a graph neural network to represent tree-structured HTML along with a shared state space across multiple tasks. We show 2x improvements in sample efficiency when training in the multi-task setting, allowing our model to transfer learned behaviours across tasks. Furthermore, we demonstrate the capabilities of our model on the WorldOfBits environments where we can match or outperform existing work without the use of expert demonstrations.","keywords":["Reinforcement Learning","Web Navigation","Graph Neural Networks"],"authorids":["ICLR.cc/2019/Conference/Paper997/Authors"],"authors":["Anonymous"],"pdf":"/pdf/c7474e607fd56756a50e69e545112f28059ddfe9.pdf","paperhash":"anonymous|domqnet_grounded_rl_on_structured_language","_bibtex":"@inproceedings{    \nanonymous2019dom-q-net:,    \ntitle={DOM-Q-NET:  Grounded RL on Structured Language},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJgd1nAqFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkluJ2R9KQ","original":"ryx19ra9Ym","number":998,"cdate":1538087903798,"ddate":null,"tcdate":1538087903798,"tmdate":1538156012749,"tddate":null,"forum":"rkluJ2R9KQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A new dog learns old tricks:  RL finds classic optimization algorithms","abstract":"This paper introduces a novel framework for learning algorithms to solve online combinatorial optimization problems. Towards this goal, we introduce a number of key ideas from traditional algorithms and complexity theory. First, we draw a new connection between primal-dual methods and reinforcement learning. Next, we introduce the concept of adversarial distributions (universal and high-entropy training sets), which are distributions that encourage the learner to find algorithms that work well in the worst case. We test our new ideas on a number of optimization problem such as the AdWords problem, the online knapsack problem, and the secretary problem. Our results indicate that the models have learned behaviours that are consistent with the traditional optimal algorithms for these problems.","keywords":["reinforcement learning","algorithms","adwords","knapsack","secretary"],"authorids":["ICLR.cc/2019/Conference/Paper998/Authors"],"authors":["Anonymous"],"TL;DR":"By combining ideas from traditional algorithms design and reinforcement learning, we introduce a novel framework for learning algorithms that solve online combinatorial optimization problems.","pdf":"/pdf/914f2d1373a70ffaaf6880f49f953c0f1b8cd144.pdf","paperhash":"anonymous|a_new_dog_learns_old_tricks_rl_finds_classic_optimization_algorithms","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A new dog learns old tricks:  RL finds classic optimization algorithms},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkluJ2R9KQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ByGuynAct7","original":"S1e7ZhpcKX","number":999,"cdate":1538087903978,"ddate":null,"tcdate":1538087903978,"tmdate":1538156012541,"tddate":null,"forum":"ByGuynAct7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Deep Weight Prior","abstract":"Bayesian inference is known to provide a general framework for incorporating prior knowledge or specific properties into machine learning models via carefully choosing a prior distribution. In this work, we propose a new type of prior distributions for convolutional neural networks, deep weight prior, that in contrast to previously published techniques, favors empirically estimated structure of convolutional filters e.g., spatial correlations of weights.  We define deep weight prior as an implicit distribution and propose a method for variational inference with such type of implicit priors.  In experiments, we show that deep weight priors can improve the performance of Bayesian neural networks on several problems when training data is limited.  Also, we found that initialization of weights of conventional convolutional networks with samples from deep weight prior leads to faster training.","keywords":["deep learning","variational inference","prior distributions"],"authorids":["ICLR.cc/2019/Conference/Paper999/Authors"],"authors":["Anonymous"],"TL;DR":"An empirical prior for convolutional layers in Bayesian neural networks that improves learning on small datasets.","pdf":"/pdf/8d7a1013259857862956d7247ddef4089900387f.pdf","paperhash":"anonymous|deep_weight_prior","_bibtex":"@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Weight Prior},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByGuynAct7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJluy2RcFm","original":"rJl2fBp5F7","number":1000,"cdate":1538087904322,"ddate":null,"tcdate":1538087904322,"tmdate":1538156012333,"tddate":null,"forum":"BJluy2RcFm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Janossy Pooling: Learning Deep Permutation-Invariant Functions for Variable-Size Inputs","abstract":"We consider a simple and overarching representation for permutation-invariant functions of sequences (or set functions). Our approach, which we call Janossy pooling, expresses a permutation-invariant function as the average of a permutation-sensitive function applied to all reorderings of the input sequence. This allows us to leverage the rich and mature literature on permutation-sensitive functions to construct novel and flexible permutation-invariant functions. If carried out naively, Janossy pooling can be computationally prohibitive. To allow computational tractability, we consider three kinds of approximations: canonical orderings of sequences, functions with k-order interactions, and stochastic optimization algorithms with random permutations. Our framework unifies a variety of existing work in the literature, and suggests possible modeling and algorithmic extensions. We explore a few in our experiments, which demonstrate improved performance over current state-of-the-art methods.","keywords":["representation learning","permutation invariance","set functions","feature pooling"],"authorids":["ICLR.cc/2019/Conference/Paper1000/Authors"],"authors":["Anonymous"],"TL;DR":"We propose Janossy pooling, a method for learning deep permutation invariant functions designed to exploit relationships within the input sequence and tractable inference strategies such as a stochastic optimization procedure we call piSGD","pdf":"/pdf/bc8ca4ef368a3d6ebf6e7102ce20f0f285e4ca45.pdf","paperhash":"anonymous|janossy_pooling_learning_deep_permutationinvariant_functions_for_variablesize_inputs","_bibtex":"@inproceedings{    \nanonymous2019janossy,    \ntitle={Janossy Pooling: Learning Deep Permutation-Invariant Functions for Variable-Size Inputs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJluy2RcFm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Skluy2RcK7","original":"S1xXQQFcFm","number":1001,"cdate":1538087904494,"ddate":null,"tcdate":1538087904494,"tmdate":1538156012100,"tddate":null,"forum":"Skluy2RcK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet","abstract":"Various methods of measuring unit selectivity have been developed in order to understand the representations learned by neural networks.  Here we undertake a comparison of four such measures on the well studied network AlexNet. In contrast to work on recurrent neural networks (RNNs), we fail to find any 100\\% selective `localist units' in the hidden layers of AlexNet, and demonstrate that previous assessments of selectivity suggest a higher level of selectivity than is warranted, with the most selective units only responding most strongly to a small minority of images from within a category. No difference in selectivity was found between layers \\layer{fc6} and \\layer{fc7}, and \\layer{fc8} was much more selective. Only the output \\layer{prob} layer contained any localist units. We also  generated images that maximally activated individual units and found that under (5\\%) of units in \\layer{fc6} and \\layer{conv5} produced images of interpretable objects that humans consistently labeled, whereas \\layer{fc8} produced over 50\\% interpretable images. We consider why different degrees of selectivity are observed with RNNs and AlexNet, and suggest visualizing activations with jitterplots, aside from being comparable to neuroscience techniques, are a good first step to assessing unit selectivity.","keywords":["AlexNet","neural networks","selectivity","localist","distributed","represenataion","precision","measures of selectivity","object detectors","single directions","network analysis"],"authorids":["ICLR.cc/2019/Conference/Paper1001/Authors"],"authors":["Anonymous"],"TL;DR":"Common selectivity metrics overestimate the selectivity of units, true object detectors and localist codes are extremely rare, but class selectivity does increase with depth. ","pdf":"/pdf/9984f73c24e0e894eab8587776c975fc1bdc3411.pdf","paperhash":"anonymous|selectivity_metrics_can_overestimate_the_selectivity_of_units_a_case_study_on_alexnet","_bibtex":"@inproceedings{    \nanonymous2019selectivity,    \ntitle={Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Skluy2RcK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1eKJ3R5KQ","original":"r1l_6Bh9tm","number":1002,"cdate":1538087904666,"ddate":null,"tcdate":1538087904666,"tmdate":1538156011896,"tddate":null,"forum":"S1eKJ3R5KQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Answer-based Adversarial Training for Generating Clarification Questions","abstract":"We propose a generative adversarial training approach for the problem of clarification question generation. Our approach generates clarification questions with the goal of eliciting new information that would make the given context more complete. We develop a Generative Adversarial Network (GAN) where the generator is a sequence-to-sequence model and the discriminator is a utility function that models the value of updating the context with the answer to the clarification question. We evaluate on two datasets, using both automatic metrics and human judgments of usefulness, specificity and relevance, showing that our approach outperforms both a retrieval-based model and ablations that exclude the utility model and the adversarial training.\n","keywords":["natural language processing","text generation","generative adversarial network"],"authorids":["ICLR.cc/2019/Conference/Paper1002/Authors"],"authors":["Anonymous"],"TL;DR":"We propose an adversarial training approach to the problem of clarification question generation which uses the answer to the question to model the reward. ","pdf":"/pdf/d5a432da55cdc0f50e0c6ec4e642e57ca3abda5e.pdf","paperhash":"anonymous|answerbased_adversarial_training_for_generating_clarification_questions","_bibtex":"@inproceedings{    \nanonymous2019answer-based,    \ntitle={Answer-based Adversarial Training for Generating Clarification Questions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1eKJ3R5KQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyxtJh0qYm","original":"rylrQ2T5KQ","number":1003,"cdate":1538087904831,"ddate":null,"tcdate":1538087904831,"tmdate":1538156011691,"tddate":null,"forum":"SyxtJh0qYm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Variational Autoencoder with Arbitrary Conditioning","abstract":"We propose a single neural probabilistic model based on variational autoencoder that can be conditioned on an arbitrary subset of observed features and then sample the remaining features in \"one shot\". The features may be both real-valued and categorical. Training of the model is performed by stochastic variational Bayes. The experimental evaluation on synthetic data, as well as feature imputation and image inpainting problems, shows the effectiveness of the proposed approach and diversity of the generated samples.","keywords":["unsupervised learning","generative models","conditional variational autoencoder","variational autoencoder","missing features multiple imputation","inpainting"],"authorids":["ICLR.cc/2019/Conference/Paper1003/Authors"],"authors":["Anonymous"],"TL;DR":"We propose an extension of conditional variational autoencoder that allows conditioning on an arbitrary subset of the features and sampling the remaining ones.","pdf":"/pdf/3ed0661941487d8bd34cd7a12d8741d74c79dd28.pdf","paperhash":"anonymous|variational_autoencoder_with_arbitrary_conditioning","_bibtex":"@inproceedings{    \nanonymous2019variational,    \ntitle={Variational Autoencoder with Arbitrary Conditioning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxtJh0qYm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HylKJhCcKm","original":"ByeeIy5cYX","number":1004,"cdate":1538087905012,"ddate":null,"tcdate":1538087905012,"tmdate":1538156011478,"tddate":null,"forum":"HylKJhCcKm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Generalized Capsule Networks with Trainable Routing Procedure","abstract":"CapsNet (Capsule Network) was first proposed by Sabour et al. (2017) and lateranother version of CapsNet was proposed by Hinton et al. (2018).  CapsNet hasbeen proved effective in modeling spatial features with much fewer parameters.However, the routing procedures (dynamic routing and EM routing) in both pa-pers are not well incorporated into the whole training process,  and the optimalnumber for the routing procedure has to be found manually.  We propose Gen-eralized GapsNet (G-CapsNet) to overcome this disadvantages by incorporatingthe routing procedure into the optimization.  We implement two versions of G-CapsNet (fully-connected and convolutional) on CAFFE (Jia et al. (2014)) andevaluate them by testing the accuracy on MNIST & CIFAR10, the robustness towhite-box & black-box attack, and the generalization ability on GAN-generatedsynthetic images.  We also explore the scalability of G-CapsNet by constructinga relatively deep G-CapsNet.   The experiment shows that G-CapsNet has goodgeneralization ability and scalability. ","keywords":["Capsule networks","generalization","scalability","adversarial robustness"],"authorids":["ICLR.cc/2019/Conference/Paper1004/Authors"],"authors":["Anonymous"],"TL;DR":"A scalable capsule network","pdf":"/pdf/879862ec204ec733901e0ac88e56a36e876b6c8a.pdf","paperhash":"anonymous|generalized_capsule_networks_with_trainable_routing_procedure","_bibtex":"@inproceedings{    \nanonymous2019generalized,    \ntitle={Generalized Capsule Networks with Trainable Routing Procedure},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HylKJhCcKm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1eKk2CcKm","original":"S1gr5TTqt7","number":1005,"cdate":1538087905186,"ddate":null,"tcdate":1538087905186,"tmdate":1538156011272,"tddate":null,"forum":"B1eKk2CcKm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Kmer2vec: Towards transcriptomic representations by learning kmer embeddings","abstract":"In this work we propose kmer2vec, a method to compute continuous embeddings for kmers from raw RNA-seq data, in a reference-free fashion. We report that our model captures information of both DNA sequence similarity as well as DNA sequence abundance in the embedding latent space. We confirm the quality of these vectors by comparing them to known gene sub-structures and report that the latent space recovers exon information from raw RNA-Seq data from acute myeloid leukemia patients. Furthermore we show that this latent space allows the detection of genomic abnormalities such as translocations as well as patient-specific mutations, making this representation space both useful for visualization as well as analysis.","keywords":["representation learning","RNA-Seq","gene expression","bioinformatics","computational biology","transcriptomics","deep learning","genomics"],"authorids":["ICLR.cc/2019/Conference/Paper1005/Authors"],"authors":["Anonymous"],"pdf":"/pdf/8801eda4683da9bebbab7a0718334aa8d4f1e4b9.pdf","paperhash":"anonymous|kmer2vec_towards_transcriptomic_representations_by_learning_kmer_embeddings","_bibtex":"@inproceedings{    \nanonymous2019kmer2vec:,    \ntitle={Kmer2vec: Towards transcriptomic representations by learning kmer embeddings},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1eKk2CcKm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HklY120cYm","original":"S1gBV3LFYX","number":1006,"cdate":1538087905357,"ddate":null,"tcdate":1538087905357,"tmdate":1538156011063,"tddate":null,"forum":"HklY120cYm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech","abstract":"In this work, we propose a new solution for parallel wave generation by WaveNet. In contrast to parallel WaveNet~ (Oord et al., 2018), we distill a Gaussian inverse autoregressive flow from the autoregressive WaveNet by minimizing a novel regularized KL divergence between their highly-peaked output distributions. Our method computes the KL divergence in closed-form, which simplifies the training algorithm and provides very efficient distillation.  In addition, we propose the first text-to-wave neural architecture for speech synthesis, which is fully convolutional and enables fast end-to-end training from scratch. It significantly outperforms the previous pipeline that connects a text-to-spectrogram model to a separately trained WaveNet~(Ping et al., 2018).  We also successfully distill a parallel waveform synthesizer conditioned on the hidden representation in this end-to-end model.","keywords":["text-to-speech","deep generative models","end-to-end","text to waveform"],"authorids":["ICLR.cc/2019/Conference/Paper1006/Authors"],"authors":["Anonymous"],"pdf":"/pdf/918a94700a40aa7b1a7bc457be9a9f57597c83df.pdf","paperhash":"anonymous|clarinet_parallel_wave_generation_in_endtoend_texttospeech","_bibtex":"@inproceedings{    \nanonymous2019clarinet:,    \ntitle={ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HklY120cYm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1lq1hRqYQ","original":"H1xgN6ncKQ","number":1007,"cdate":1538087905526,"ddate":null,"tcdate":1538087905526,"tmdate":1538156010852,"tddate":null,"forum":"r1lq1hRqYQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"From Language to Goals: Inverse Reinforcement Learning for Vision-Based Instruction Following","abstract":"Reinforcement learning is a promising framework for solving control problems, but its use in practical situations is hampered by the fact that reward functions are often difficult to engineer. Specifying goals and tasks for autonomous machines, such as robots, is a significant challenge: conventionally, reward functions and goal states have been used to communicate objectives. But people can communicate objectives to each other simply by describing or demonstrating them. How can we build learning algorithms that will allow us to tell machines what we want them to do? In this work, we investigate the problem of grounding language commands as reward functions using inverse reinforcement learning, and argue that language-conditioned rewards are more transferable than language-conditioned policies to new environments. We propose language-conditioned reward learning (LC-RL), which grounds language commands as a reward function represented by a deep neural network. We demonstrate that our model learns rewards that transfer to novel tasks and environments on realistic, high-dimensional visual environments with natural language commands, whereas directly learning a language-conditioned policy leads to poor performance.","keywords":["inverse reinforcement learning","language grounding","instruction following","language-based learning"],"authorids":["ICLR.cc/2019/Conference/Paper1007/Authors"],"authors":["Anonymous"],"TL;DR":"We ground language commands in a high-dimensional visual environment by learning language-conditioned rewards using inverse reinforcement learning.","pdf":"/pdf/00602547104676a31d155c0b1af82871d8f1e115.pdf","paperhash":"anonymous|from_language_to_goals_inverse_reinforcement_learning_for_visionbased_instruction_following","_bibtex":"@inproceedings{    \nanonymous2019from,    \ntitle={From Language to Goals: Inverse Reinforcement Learning for Vision-Based Instruction Following},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1lq1hRqYQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryl5khRcKm","original":"rkgDBzwcFQ","number":1008,"cdate":1538087905694,"ddate":null,"tcdate":1538087905694,"tmdate":1538156010635,"tddate":null,"forum":"ryl5khRcKm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Human-level Protein Localization with Convolutional Neural Networks","abstract":"Localizing a specific protein in a human cell is essential for understanding cellular functions and biological processes of underlying diseases. A promising, low-cost, and time-efficient biotechnology for localizing proteins is high-throughput fluorescence microscopy imaging (HTI). HTI stains the protein of interest in a cell with fluorescent antibodies and subsequently takes a microscopic image. Together with images of other stained proteins or cell organelles and the annotation by the Human Protein Atlas project, these images provide a rich source of information on the protein location which can be utilized by computational methods. It is yet unclear how precise such methods are and whether they can compete with human experts. We here focus on deep learning image analysis methods and, in particular, on Convolutional Neural Networks (CNNs) since they showed overwhelming success across different imaging tasks. We propose a novel CNN architecture “GapNet-PL” that has been designed to tackle the characteristics of HTI data and uses global averages of filters at different abstraction levels. We present the largest comparison of CNN architectures including GapNet-PL for protein localization in HTI images of human cells. GapNet-PL outperforms all other competing methods and reaches close to perfect localization in all 13 tasks with an average AUC of 98% and F1 score of 78%. On a separate test set the performance of GapNet-PL was compared with a human expert. GapNet-PL achieved an accuracy of 91%, significantly (p-value 2e-10) outperforming the human expert with an accuracy of 61%.","keywords":["Convolutional Neural Networks","High-resolution images","Multiple-Instance Learning","Microscopy Imaging","Protein Localization"],"authorids":["ICLR.cc/2019/Conference/Paper1008/Authors"],"authors":["Anonymous"],"pdf":"/pdf/b884b920a8511100f39659461e5570607dc1f4a8.pdf","paperhash":"anonymous|humanlevel_protein_localization_with_convolutional_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019human-level,    \ntitle={Human-level Protein Localization with Convolutional Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryl5khRcKm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJf9k305Fm","original":"HkgmxpKqKQ","number":1009,"cdate":1538087905864,"ddate":null,"tcdate":1538087905864,"tmdate":1538156010418,"tddate":null,"forum":"BJf9k305Fm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Visualizing and Discovering Behavioural Weaknesses in Deep Reinforcement Learning","abstract":"As deep reinforcement learning is being applied to more and more tasks, there is a growing need to better understand and probe the learned agents. Visualizing and understanding the decision making process can be very valuable to comprehend and identify problems in the learned behavior. However, this topic has been relatively under-explored in the reinforcement learning community. In this work we present a method for synthesizing states of interest for a trained agent. Such states could be situations (e.g. crashing or damaging a car) in which specific actions are necessary. Further, critical states in which a very high or a very low reward can be achieved (e.g. risky states) are often interesting to understand the situational awareness of the system. To this end, we learn a generative model over the state space of the environment and use its latent space to optimize a target function for the state of interest. In our experiments we show that this method can generate insightful visualizations for a variety of environments and reinforcement learning methods. We explore these issues in the standard Atari benchmark games as well as in an autonomous driving simulator. Based on the efficiency with which we have been able to identify significant decision scenarios with this technique, we believe this general approach could serve as an important tool for AI safety applications.","keywords":["Visualization","Deep Reinforcement Learning"],"authorids":["ICLR.cc/2019/Conference/Paper1009/Authors"],"authors":["Anonymous"],"TL;DR":"We present a method to synthesize states of interest for reinforcement learning agents in order to analyze their behavior. ","pdf":"/pdf/031b1e528623d3b1cb5273e2cef20bd448bb5e26.pdf","paperhash":"anonymous|visualizing_and_discovering_behavioural_weaknesses_in_deep_reinforcement_learning","_bibtex":"@inproceedings{    \nanonymous2019visualizing,    \ntitle={Visualizing and Discovering Behavioural Weaknesses in Deep Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJf9k305Fm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HygqJnCqtm","original":"rJl6K5u9Km","number":1010,"cdate":1538087906047,"ddate":null,"tcdate":1538087906047,"tmdate":1538156010206,"tddate":null,"forum":"HygqJnCqtm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Rating Continuous Actions in Spatial Multi-Agent Problems","abstract":"We study credit assignment problems in spatial multi-agent environments where agents pursue a joint objective. On the example of soccer, we rate the movements of individual players with respect to their potential for staging a successful attack. We propose a purely data-driven approach to simultaneously learn a model of agent movements as well as their ratings via an agent-centric deep reinforcement learning framework. Our model allows for efficient learning and sampling of ratings in the continuous action space. We empirically observe on historic soccer data that the model accurately rates agent movements w.r.t. their relative contribution to the collective goal.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1010/Authors"],"authors":["Anonymous"],"pdf":"/pdf/afefc9fc414499637017252357755e1853bbe3b3.pdf","paperhash":"anonymous|rating_continuous_actions_in_spatial_multiagent_problems","_bibtex":"@inproceedings{    \nanonymous2019rating,    \ntitle={Rating Continuous Actions in Spatial Multi-Agent Problems},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HygqJnCqtm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SklckhR5Ym","original":"rJgMziWcF7","number":1011,"cdate":1538087906218,"ddate":null,"tcdate":1538087906218,"tmdate":1538156009998,"tddate":null,"forum":"SklckhR5Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Improved Language Modeling by Decoding the Past","abstract":"Highly regularized LSTMs achieve impressive results on several benchmark datasets in language modeling. We propose a new regularization method based on decoding the last token in the context using the predicted distribution of the next token. This biases the model towards retaining more contextual information, in turn improving its ability to predict the next token. With negligible overhead in the number of parameters and training time, our past decode regularization (PDR) method achieves state-of-the-art word level perplexity on the Penn Treebank (55.6) and WikiText-2 (63.5) datasets and bits-per-character on the Penn Treebank Character (1.169)  dataset for character level language modeling. Using dynamic evaluation, we also achieve the first sub 50 perplexity of 49.3 on the Penn Treebank test set.","keywords":["language modeling","regularization","LSTM"],"authorids":["ICLR.cc/2019/Conference/Paper1011/Authors"],"authors":["Anonymous"],"TL;DR":"Decoding the last token in the context using the predicted next token distribution acts as a regularizer and improves language modeling.","pdf":"/pdf/2da76069b51609f240e74669fff8ce322d78e4bb.pdf","paperhash":"anonymous|improved_language_modeling_by_decoding_the_past","_bibtex":"@inproceedings{    \nanonymous2019improved,    \ntitle={Improved Language Modeling by Decoding the Past},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SklckhR5Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJx5kn0cK7","original":"BJecwMh5KQ","number":1012,"cdate":1538087906406,"ddate":null,"tcdate":1538087906406,"tmdate":1538156009789,"tddate":null,"forum":"SJx5kn0cK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"HAPPIER: Hierarchical Polyphonic Music Generative RNN","abstract":"Generating polyphonic music with coherent global structure is a major challenge for automatic composition algorithms. The primary difficulty arises due to the inefficiency of models to recognize underlying patterns beneath music notes across different levels of time scales and remain long-term consistency while composing. Hierarchical architectures can capture and represent learned patterns in different temporal scales and maintain consistency over long time spans, and this corresponds to the hierarchical structure in music. Motivated by this, focusing on leveraging the idea of hierarchical models and improve them to fit the sequence modeling problem, our paper proposes HAPPIER: a novel HierArchical PolyPhonic musIc gEnerative RNN. In HAPPIER, A higher `measure level' learns correlations across measures and patterns for chord progressions, and a lower `note level' learns a conditional distribution over the notes to generate within a measure. The two hierarchies operate at different clock rates: the higher one operates on a longer timescale and updates every measure, while the lower one operates on a shorter timescale and updates every unit duration. The two levels communicate with each other, and thus the entire architecture is trained jointly end-to-end by back-propagation. HAPPIER, profited from the strength of the hierarchical structure, generates polyphonic music with long-term dependencies compared to the state-of-the-art methods.","keywords":["hierarchical model","RNN","generative model","automatic composing"],"authorids":["ICLR.cc/2019/Conference/Paper1012/Authors"],"authors":["Anonymous"],"pdf":"/pdf/457475c9a969d80c693de2a0578cadadc97b92e3.pdf","paperhash":"anonymous|happier_hierarchical_polyphonic_music_generative_rnn","_bibtex":"@inproceedings{    \nanonymous2019happier:,    \ntitle={HAPPIER: Hierarchical Polyphonic Music Generative RNN},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJx5kn0cK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1xoy3CcYX","original":"H1lHEBj9Ym","number":1013,"cdate":1538087906575,"ddate":null,"tcdate":1538087906575,"tmdate":1538156009581,"tddate":null,"forum":"S1xoy3CcYX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Adversarial Examples Are a Natural Consequence of Test Error in Noise","abstract":"    Maliciously constructed inputs, or adversarial examples, can fool trained machine learning models. Over the last few years, adversarial examples have captured the attention of the research community, especially in the case where the adversary is restricted to making only small modifications of a correctly handled input. When it was first discovered that neural networks are sensitive to small perturbations, many researchers found this surprising and proposed several hypotheses to explain it. In this work, we show that this sensitivity and the poor performance of classification models (relative to humans) on noisy images are two manifestations of the same underlying phenomenon. Nearby errors simply lie on the boundary of a large set of errors whose volume can be measured using test error in additive noise. We present compelling new evidence in favor of this interpretation before discussing some preexisting results which also support our perspective. The relationship between nearby errors and failure to generalize in noise has implications for the adversarial defense literature, as it suggests that defenses which fail to reduce test error in noise will also fail to defend against small adversarial perturbations. This yields a computationally tractable evaluation metric for defenses to consider: test error in noisy image distributions.","keywords":["Adversarial examples","generalization"],"authorids":["ICLR.cc/2019/Conference/Paper1013/Authors"],"authors":["Anonymous"],"TL;DR":"Small adversarial perturbations should be expected given observed error rates of models outside the natural data distribution.","pdf":"/pdf/30d39e6b0a6badb1ab2401582c60df0d76f024ce.pdf","paperhash":"anonymous|adversarial_examples_are_a_natural_consequence_of_test_error_in_noise","_bibtex":"@inproceedings{    \nanonymous2019adversarial,    \ntitle={Adversarial Examples Are a Natural Consequence of Test Error in Noise},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1xoy3CcYX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ByloJ20qtm","original":"rJebmyAqt7","number":1014,"cdate":1538087906747,"ddate":null,"tcdate":1538087906747,"tmdate":1538156009373,"tddate":null,"forum":"ByloJ20qtm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Neural Program Repair by Jointly Learning to Localize and Repair","abstract":"Due to its potential to improve programmer productivity and software quality, automated program repair has been an active topic of research. Newer techniques harness neural networks to learn directly from examples of buggy programs and their fixes. In this work, we consider a recently identified class of bugs called variable-misuse bugs. The state-of-the-art solution for variable misuse enumerates potential fixes for all possible bug locations in a program, before selecting the best prediction. We show that it is beneficial to train a model that jointly and directly localizes and repairs variable-misuse bugs. We present multi-headed pointer networks for this purpose, with one head each for localization and repair. The experimental results show that the joint model significantly outperforms an enumerative solution that uses a pointer based model for repair alone.","keywords":["neural program repair","neural program embeddings","pointer networks"],"authorids":["ICLR.cc/2019/Conference/Paper1014/Authors"],"authors":["Anonymous"],"TL;DR":"Multi-headed Pointer Networks for jointly learning to localize and repair Variable Misuse bugs","pdf":"/pdf/7c5712a1bc9f82c4192f204d4eb6579912a169b3.pdf","paperhash":"anonymous|neural_program_repair_by_jointly_learning_to_localize_and_repair","_bibtex":"@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Program Repair by Jointly Learning to Localize and Repair},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByloJ20qtm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJgs1n05YQ","original":"S1gqgLhqFX","number":1015,"cdate":1538087906921,"ddate":null,"tcdate":1538087906921,"tmdate":1538156009164,"tddate":null,"forum":"SJgs1n05YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning and Planning with a Semantic Model","abstract":"Building deep reinforcement learning agents that can generalize and adapt to unseen environments remains a fundamental challenge for AI. This paper describes progresses on this challenge in the context of man-made environments, which are visually diverse but contain intrinsic semantic regularities. We propose a hybrid model-based and model-free approach, LEArning and Planning with Semantics (LEAPS), consisting of a multi-target sub-policy that acts on visual inputs, and a Bayesian model over semantic structures. When placed in an unseen environment, the agent plans with the semantic model to make high-level decisions, proposes the next sub-target for the sub-policy to execute, and updates the semantic model based on new observations. We perform experiments in visual navigation tasks using House3D, a 3D environment that contains diverse human-designed indoor scenes with real-world objects. LEAPS outperforms strong baselines that do not explicitly plan using the semantic content.","keywords":["deep reinforcement learning","generalization","semantic structure","model-based"],"authorids":["ICLR.cc/2019/Conference/Paper1015/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a hybrid model-based & model-free approach using semantic information to improve DRL generalization in man-made environments.","pdf":"/pdf/109813df773eec18675dc3825f22bfe8382bf44b.pdf","paperhash":"anonymous|learning_and_planning_with_a_semantic_model","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning and Planning with a Semantic Model},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJgs1n05YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkgoyn09KQ","original":"Skl37UhqKm","number":1016,"cdate":1538087907103,"ddate":null,"tcdate":1538087907103,"tmdate":1538156008961,"tddate":null,"forum":"rkgoyn09KQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"textTOvec: DEEP CONTEXTUALIZED NEURAL AUTOREGRESSIVE MODELS OF LANGUAGE WITH DISTRIBUTED COMPOSITIONAL PRIOR","abstract":"We address two challenges of probabilistic topic modelling in order to better estimate\nthe probability of a word in a given context, i.e., P(wordjcontext) : (1) No\nLanguage Structure in Context: Probabilistic topic models ignore word order by\nsummarizing a given context as a “bag-of-word” and consequently the semantics\nof words in the context is lost. In this work, we incorporate language structure\nby combining a neural autoregressive topic model (TM) with a LSTM based language\nmodel (LSTM-LM) in a single probabilistic framework. The LSTM-LM\nlearns a vector-space representation of each word by accounting for word order\nin local collocation patterns, while the TM simultaneously learns a latent representation\nfrom the entire document. In addition, the LSTM-LM models complex\ncharacteristics of language (e.g., syntax and semantics), while the TM discovers\nthe underlying thematic structure in a collection of documents. We unite two complementary\nparadigms of learning the meaning of word occurrences by combining\na topic model and a language model in a unified probabilistic framework, named\nas ctx-DocNADE. (2) Limited Context and/or Smaller training corpus of documents:\nIn settings with a small number of word occurrences (i.e., lack of context)\nin short text or data sparsity in a corpus of few documents, the application of TMs\nis challenging. We address this challenge by incorporating external knowledge\ninto neural autoregressive topic models via a language modelling approach: we\nuse word embeddings as input of a LSTM-LM with the aim to improve the wordtopic\nmapping on a smaller and/or short-text corpus. The proposed DocNADE\nextension is named as ctx-DocNADEe.\n\nWe present novel neural autoregressive topic model variants coupled with neural\nlanguage models and embeddings priors that consistently outperform state-of-theart\ngenerative topic models in terms of generalization (perplexity), interpretability\n(topic coherence) and applicability (retrieval and classification) over 6 long-text\nand 8 short-text datasets from diverse domains.","keywords":["neural topic model","natural language processing","text representation","language modeling","information retrieval","deep learning"],"authorids":["ICLR.cc/2019/Conference/Paper1016/Authors"],"authors":["Anonymous"],"TL;DR":"Unified neural model of topic and language modeling to introduce language structure  in topic models for contextualized topic vectors ","pdf":"/pdf/471731d1077d70db693906a59d580be21c7cea79.pdf","paperhash":"anonymous|texttovec_deep_contextualized_neural_autoregressive_models_of_language_with_distributed_compositional_prior","_bibtex":"@inproceedings{    \nanonymous2019texttovec:,    \ntitle={textTOvec: DEEP CONTEXTUALIZED NEURAL AUTOREGRESSIVE MODELS OF LANGUAGE WITH DISTRIBUTED COMPOSITIONAL PRIOR},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgoyn09KQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BkesJ3R9YX","original":"SkeUVTnqtm","number":1017,"cdate":1538087907278,"ddate":null,"tcdate":1538087907278,"tmdate":1538156008749,"tddate":null,"forum":"BkesJ3R9YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Where and when to look? Spatial-temporal attention for action recognition in videos","abstract":"Inspired by the observation that humans are able to process videos efficiently by only paying attention when and where it is needed, we propose a novel spatial-temporal attention mechanism for video-based action recognition. For spatial attention, we learn a saliency mask to allow the model to focus on the most salient parts of the feature maps. \nFor temporal attention, we employ a soft temporal attention mechanism to identify the most relevant frames from an input video. Further, we propose a set of regularizers that ensure that our attention mechanism attends to coherent regions in space and time. Our model is efficient, as it proposes a separable spatio-temporal mechanism for video attention, while being able to identify important parts of the video both spatially and temporally.  We demonstrate the efficacy of our approach on three public video action recognition datasets. The proposed approach leads to state-of-the-art performance on all of them, including the new large-scale Moments in Time dataset. Furthermore, we quantitatively and qualitatively evaluate our model's ability to accurately localize discriminative regions spatially and critical frames temporally. This is despite our model only being trained with per video classification labels. ","keywords":["visual attention","video action recognition","network interpretability"],"authorids":["ICLR.cc/2019/Conference/Paper1017/Authors"],"authors":["Anonymous"],"pdf":"/pdf/3b393fbc310b19ac84188071e80eddfe87081d4c.pdf","paperhash":"anonymous|where_and_when_to_look_spatialtemporal_attention_for_action_recognition_in_videos","_bibtex":"@inproceedings{    \nanonymous2019where,    \ntitle={Where and when to look? Spatial-temporal attention for action recognition in videos},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkesJ3R9YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1Gsk3R9Fm","original":"r1luhqp5Ym","number":1018,"cdate":1538087907448,"ddate":null,"tcdate":1538087907448,"tmdate":1538156008527,"tddate":null,"forum":"r1Gsk3R9Fm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Shallow Learning For Deep Networks","abstract":"Shallow supervised 1-hidden layer neural networks have a number of favorable properties that make them easier to interpret, analyze, and optimize than their deep counterparts, but lack their representational power.  Here we use 1-hiddenlayer learning problems to sequentially build deep networks layer by layer, which can inherit properties from shallow networks.  Contrary to previous approaches using shallow networks, we focus on problems where deep learning is reportedas critical for success. We thus study CNNs on two large-scale image recognition tasks:  ImageNet and CIFAR-10.   Using a simple set of ideas for architecture and training we find that solving sequential 1-hidden-layer auxiliary problemsleads to a CNN that exceeds AlexNet performance on ImageNet. Extending ourtraining methodology to construct individual layers by solving 2-and-3-hiddenlayer auxiliary problems, we obtain an 11-layer network that exceeds VGG-11 on ImageNet obtaining 89.8% top-5 single crop. To our knowledge, this is the first competitive alternative to end-to-end training of CNNs that can scale to ImageNet. We conduct a wide range of experiments to study the properties this induces on the intermediate layers.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1018/Authors"],"authors":["Anonymous"],"TL;DR":"We build CNNs layer by layer without end to end training and show that this kind of approach can scale to Imagenet, while having multiple favorable  properties.","pdf":"/pdf/e5596c81a12324f168710c01e25c5c12c10326b8.pdf","paperhash":"anonymous|shallow_learning_for_deep_networks","_bibtex":"@inproceedings{    \nanonymous2019shallow,    \ntitle={Shallow Learning For Deep Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1Gsk3R9Fm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hkg313AcFX","original":"ByltmgAqFm","number":1019,"cdate":1538087907618,"ddate":null,"tcdate":1538087907618,"tmdate":1538156008316,"tddate":null,"forum":"Hkg313AcFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Metropolis-Hastings view on variational inference and adversarial training","abstract":"In this paper we propose to view the acceptance rate of the Metropolis-Hastings algorithm as a universal objective for learning to sample from target distribution -- given either as a set of samples or in the form of unnormalized density. This point of view unifies the goals of such approaches as Markov Chain Monte Carlo (MCMC), Generative Adversarial Networks (GANs), variational inference. To reveal the connection we derive the lower bound on the acceptance rate and treat it as the objective for learning explicit and implicit samplers. The form of the lower bound allows for doubly stochastic gradient optimization in case the target distribution factorizes (i.e. over data points). We empirically validate our approach on Bayesian inference for neural networks and generative models for images.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1019/Authors"],"authors":["Anonymous"],"TL;DR":"Learning to sample via lower bounding the acceptance rate of the Metropolis-Hastings algorithm","pdf":"/pdf/26b07f5be5702648f240bfca4b52710896f4db6f.pdf","paperhash":"anonymous|metropolishastings_view_on_variational_inference_and_adversarial_training","_bibtex":"@inproceedings{    \nanonymous2019metropolis-hastings,    \ntitle={Metropolis-Hastings view on variational inference and adversarial training},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hkg313AcFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Byg3y3C9Km","original":"BJgcXg0cYQ","number":1020,"cdate":1538087907783,"ddate":null,"tcdate":1538087907783,"tmdate":1538156008105,"tddate":null,"forum":"Byg3y3C9Km","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Protein Structure with a Differentiable Simulator","abstract":"The Boltzmann distribution is a natural model for many systems, from brains to materials and biomolecules, but is often of limited utility for fitting data because Monte Carlo algorithms are unable simulate it in available time. This gap between the expressive capabilities and sampling practicalities of energy-based models is exemplified by the protein folding problem, since energy landscapes underlie contemporary knowledge of protein biophysics but computer simulations are still unable to fold all but the smallest proteins from first-principles. In this work we bridge the gap between the expressive capacity of energy functions and the practical capabilities of their simulators by using an unrolled Monte Carlo simulation as a model for data. We compose a neural energy function with a novel and efficient simulator based on Langevin dynamics to build an end-to-end-differentiable model of atomic protein structure given amino acid sequence information. We introduce techniques for stabilizing backpropagation under long roll-outs and demonstrate the model's capacity to make multimodal predictions and to generalize to unobserved protein fold types when trained on a large corpus of protein structures.","keywords":["generative modeling","simulators","molecular modeling","proteins","structured prediction"],"authorids":["ICLR.cc/2019/Conference/Paper1020/Authors"],"authors":["Anonymous"],"TL;DR":"We use an unrolled simulator of a neural energy function as an end-to-end differentiable model of protein structure and show it can hierarchically generalize to unseen fold types.","pdf":"/pdf/cbf8f35dfd2b0663dc75e7decf3dbafc2df0682b.pdf","paperhash":"anonymous|learning_protein_structure_with_a_differentiable_simulator","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Protein Structure with a Differentiable Simulator},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byg3y3C9Km},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1lnJ2Rqt7","original":"rkef6-j9Fm","number":1021,"cdate":1538087908013,"ddate":null,"tcdate":1538087908013,"tmdate":1538156007896,"tddate":null,"forum":"H1lnJ2Rqt7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"LARGE BATCH SIZE TRAINING OF NEURAL NETWORKS WITH ADVERSARIAL TRAINING AND SECOND-ORDER INFORMATION","abstract":"Stochastic Gradient Descent (SGD) methods using randomly selected batches are widely-used to train neural network (NN) models. Performing design exploration to find the best NN for a particular task often requires extensive training with different models on a large dataset,  which is very computationally expensive. The most straightforward method to accelerate this computation is to distribute the batch of SGD over multiple processors. However, large batch training often times leads to degradation in accuracy, poor generalization, and even poor robustness to adversarial attacks.  Existing solutions for large batch training either do not work or require massive hyper-parameter tuning. To address this issue, we propose a novel large batch training method which combines recent results in adversarial training (to regularize against ``sharp minima'') and second order optimization (to use curvature information to change batch size adaptively during training). We extensively evaluate our method on Cifar-10/100, SVHN, TinyImageNet, and ImageNet datasets, using multiple NNs, including residual networks as well as compressed networks such as SqueezeNext.  Our new approach exceeds the performance of the existing solutions in terms of both accuracy and the number of SGD iterations (up to 1\\% and $3\\times$, respectively). We emphasize that this is achieved without any additional hyper-parameter tuning to tailor our method to any of these experiments.\n","keywords":["adversarial training","large batch size","neural network"],"authorids":["ICLR.cc/2019/Conference/Paper1021/Authors"],"authors":["Anonymous"],"TL;DR":"Large batch size training using adversarial training and second order information","pdf":"/pdf/f066053d342a2bb0d52090e6458d8e53fd11d357.pdf","paperhash":"anonymous|large_batch_size_training_of_neural_networks_with_adversarial_training_and_secondorder_information","_bibtex":"@inproceedings{    \nanonymous2019large,    \ntitle={LARGE BATCH SIZE TRAINING OF NEURAL NETWORKS WITH ADVERSARIAL TRAINING AND SECOND-ORDER INFORMATION},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1lnJ2Rqt7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryxhynC9KX","original":"B1gS823qtm","number":1022,"cdate":1538087908198,"ddate":null,"tcdate":1538087908198,"tmdate":1538156007685,"tddate":null,"forum":"ryxhynC9KX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"CNNSAT: Fast, Accurate Boolean Satisfiability using Convolutional Neural Networks","abstract":"Boolean satisfiability (SAT) is one of the most well-known NP-complete\nproblems and has been extensively studied.  State-of-the-art solvers\nexist and have found a wide range of applications. However, they still\ndo not scale well to formulas with hundreds of variables. To tackle\nthis fundamental scalability challenge, we introduce CNNSAT, a fast\nand accurate statistical decision procedure for SAT based on\nconvolutional neural networks. CNNSAT's effectiveness is due to a\nprecise and compact representation of Boolean\nformulas. On both real and synthetic formulas, CNNSAT is highly\n  accurate and orders of magnitude faster than the\nstate-of-the-art solver Z3.  We also describe how to extend CNNSAT to\npredict satisfying assignments when it predicts a formula to be\nsatisfiable.","keywords":["Convolutional Neural Networks","Boolean satisfiability problem","Satisfiability modulo theories"],"authorids":["ICLR.cc/2019/Conference/Paper1022/Authors"],"authors":["Anonymous"],"TL;DR":"We introduce CNNSAT, a fast and accurate statistical decision procedure for SAT based on convolutional neural networks.","pdf":"/pdf/dde051adb37d8219abe8ddd1942657acef9d07b3.pdf","paperhash":"anonymous|cnnsat_fast_accurate_boolean_satisfiability_using_convolutional_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019cnnsat:,    \ntitle={CNNSAT: Fast, Accurate Boolean Satisfiability using Convolutional Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxhynC9KX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1g2JnRcFX","original":"S1gyc_25Fm","number":1023,"cdate":1538087908371,"ddate":null,"tcdate":1538087908371,"tmdate":1538156007456,"tddate":null,"forum":"S1g2JnRcFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Local SGD Converges Fast and Communicates Little","abstract":"Mini-batch stochastic gradient descent (SGD) is state of the art in large scale distributed training. The scheme can reach a linear speed-up with respect to the number of workers, but this is rarely seen in practice as the scheme often suffers from large network delays and bandwidth limits. To overcome this communication bottleneck recent works propose to reduce the communication frequency. An algorithm of this type is local SGD that runs SGD independently in parallel on different workers and averages the sequences only once in a while. This scheme shows promising results in practice, but eluded thorough theoretical analysis.\n    \nWe prove concise convergence rates for local SGD on convex problems and show that it converges at the same rate as mini-batch SGD in terms of number of evaluated gradients, that is, the scheme achieves linear speed-up in the number of workers and mini-batch size. The number of  communication rounds can be reduced up to a factor of T^{1/2}---where T denotes the number of total steps---compared to mini-batch SGD. This also holds for asynchronous implementations.\n\nLocal SGD can also be used for large scale training of deep learning models. The results shown here aim serving as a guideline to further explore the theoretical and practical aspects of local SGD in these applications.","keywords":["optimization","communication","theory","stochastic gradient descent","SGD","mini-batch","local SGD","parallel restart SGD","distributed training"],"authorids":["ICLR.cc/2019/Conference/Paper1023/Authors"],"authors":["Anonymous"],"TL;DR":"We prove that parallel local SGD achieves linear speedup with much lesser communication than parallel mini-batch SGD.","pdf":"/pdf/3b6b540869c7dd7e56b01009b63b367aaba7be24.pdf","paperhash":"anonymous|local_sgd_converges_fast_and_communicates_little","_bibtex":"@inproceedings{    \nanonymous2019local,    \ntitle={Local SGD Converges Fast and Communicates Little},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1g2JnRcFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkgpy3C5tX","original":"HkeTCro9F7","number":1024,"cdate":1538087908546,"ddate":null,"tcdate":1538087908546,"tmdate":1538156007241,"tddate":null,"forum":"rkgpy3C5tX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Amortized Bayesian Meta-Learning","abstract":"Meta-learning, or learning-to-learn, has proven to be a successful strategy in attacking problems in supervised learning and reinforcement learning that involve small amounts of data. State-of-the-art solutions involve learning an initialization and/or learning algorithm using a set of training episodes so that the meta learner can generalize to an evaluation episode quickly. These methods perform well but often lack good quantification of uncertainty, which can be vital to real-world applications when data is lacking. We propose a meta-learning method which efficiently amortizes hierarchical variational inference across tasks, learning a prior distribution over neural network weights so that a few steps of Bayes by Backprop will produce a good task-specific approximate posterior. We show that our method produces good uncertainty estimates on contextual bandit and few-shot learning benchmarks.","keywords":["variational inference","meta-learning","few-shot learning","uncertainty quantification"],"authorids":["ICLR.cc/2019/Conference/Paper1024/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a meta-learning method which efficiently amortizes hierarchical variational inference across training episodes.","pdf":"/pdf/60e72bd2f7bc02b08ce3982cb52f771738524f80.pdf","paperhash":"anonymous|amortized_bayesian_metalearning","_bibtex":"@inproceedings{    \nanonymous2019amortized,    \ntitle={Amortized Bayesian Meta-Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgpy3C5tX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hygp1nR9FQ","original":"H1gZrMa5tQ","number":1025,"cdate":1538087908724,"ddate":null,"tcdate":1538087908724,"tmdate":1538156007025,"tddate":null,"forum":"Hygp1nR9FQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Unifying Bilateral Filtering and Adversarial Training for Robust Neural Networks","abstract":"Recent analysis of deep neural networks has revealed their vulnerability to carefully structured adversarial examples. Many effective algorithms exist to craft these adversarial examples, but performant defenses seem to be far away. In this work,  we explore the use of edge-aware bilateral filtering as a projection back to the space of natural images. We show that bilateral filtering is an effective defense in multiple attack settings, where the strength of the adversary gradually increases. In the case of adversary who has no knowledge of the defense, bilateral filtering can remove more than 90% of adversarial examples from a variety of different attacks. To evaluate against an adversary with complete knowledge of our defense, we adapt the bilateral filter as a trainable layer in a neural network and show that adding this layer makes ImageNet images significantly more robust to attacks. When trained under a framework of adversarial training, we show that the resulting model is hard to fool with even the best attack methods. ","keywords":["Adversarial examples","Image denoising"],"authorids":["ICLR.cc/2019/Conference/Paper1025/Authors"],"authors":["Anonymous"],"TL;DR":"We adapt bilateral filtering as a layer in a neural network which improves robustness to adversarial examples using nonlocal filtering.","pdf":"/pdf/3b8d5c4a510af93ca0a74996fcb8aab8319bf4c9.pdf","paperhash":"anonymous|unifying_bilateral_filtering_and_adversarial_training_for_robust_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019unifying,    \ntitle={Unifying Bilateral Filtering and Adversarial Training for Robust Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hygp1nR9FQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1xaJn05FQ","original":"r1grrxA5tX","number":1026,"cdate":1538087908892,"ddate":null,"tcdate":1538087908892,"tmdate":1538156006817,"tddate":null,"forum":"H1xaJn05FQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Sliced Wasserstein Auto-Encoders","abstract":"In this paper we use the geometric properties of the optimal transport (OT) problem and the Wasserstein distances to define a prior distribution for the latent space of an auto-encoder. We introduce Sliced-Wasserstein Auto-Encoders (SWAE), that enable one to shape the distribution of the latent space into any samplable probability distribution without the need for training an adversarial network or having a likelihood function specified. In short, we regularize the auto-encoder loss with the sliced-Wasserstein distance between the distribution of the encoded training samples and a samplable prior distribution. We show that the proposed formulation has an efficient numerical solution that provides similar capabilities to Wasserstein Auto-Encoders (WAE) and Variational Auto-Encoders (VAE), while benefiting from an embarrassingly simple implementation. We provide extensive error analysis for our algorithm, and show its merits on three benchmark datasets.","keywords":["optimal transport","Wasserstein distances","auto-encoders","unsupervised learning"],"authorids":["ICLR.cc/2019/Conference/Paper1026/Authors"],"authors":["Anonymous"],"TL;DR":"In this paper we use the sliced-Wasserstein distance to shape the latent distribution of an auto-encoder into any samplable prior distribution. ","pdf":"/pdf/86f5eb47db6fbf842556e68b8b870bf10ecf1345.pdf","paperhash":"anonymous|sliced_wasserstein_autoencoders","_bibtex":"@inproceedings{    \nanonymous2019sliced,    \ntitle={Sliced Wasserstein Auto-Encoders},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1xaJn05FQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJepJh0qKX","original":"SkxFHlCqKX","number":1027,"cdate":1538087909067,"ddate":null,"tcdate":1538087909067,"tmdate":1538156006612,"tddate":null,"forum":"HJepJh0qKX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Empirical Study of Easy and Hard Examples in CNN Training","abstract":"Deep Neural Networks (DNNs) generalize well despite their massive size and capability of memorizing all examples.\nThere is a hypothesis that DNNs start learning from simple patterns based on the observations that are consistently well-classified at early epochs (i.e., easy examples) and examples misclassified (i.e., hard examples).\nHowever, despite the importance of understanding the learning dynamics of DNNs, properties of easy and hard examples are not fully investigated.\nIn this paper, we study the similarities of easy and hard examples respectively among different CNNs, assessing those examples’ contributions to generalization.\nOur results show that most easy examples are identical among different CNNs, as they share similar dataset-dependent patterns (e.g., colors, structures, and superficial cues in high-frequency).\nMoreover, while hard examples tend to contribute more to generalization than easy examples, removing a large number of easy examples leads to poor generalization, and we find that most misclassified examples in validation dataset are hard examples.\nBy analyzing intriguing properties of easy and hard examples, we discover that the reason why easy and hard examples have such properties can be explained by biases in a dataset and Stochastic Gradient Descent (SGD).","keywords":["easy examples","hard example","CNN"],"authorids":["ICLR.cc/2019/Conference/Paper1027/Authors"],"authors":["Anonymous"],"TL;DR":"Unknown properties of easy and hard examples are shown, and they come from biases in a dataset and SGD.","pdf":"/pdf/0d13fbbca368863487ad2966e5ed7bf200ca19ef.pdf","paperhash":"anonymous|empirical_study_of_easy_and_hard_examples_in_cnn_training","_bibtex":"@inproceedings{    \nanonymous2019empirical,    \ntitle={Empirical Study of Easy and Hard Examples in CNN Training},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJepJh0qKX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkgTkhRcKQ","original":"r1e-e-M5t7","number":1028,"cdate":1538087909254,"ddate":null,"tcdate":1538087909254,"tmdate":1538156006399,"tddate":null,"forum":"HkgTkhRcKQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"AdaShift: Decorrelation and Convergence of Adaptive Learning Rate Methods","abstract":"Adam is shown not being able to converge to the optimal solution in certain cases. Researchers recently propose several algorithms to avoid the issue of non-convergence of Adam, but their efficiency turns out to be unsatisfactory in practice. In this paper, we provide a new insight into the non-convergence issue of Adam as well as other adaptive learning rate methods. We argue that there exists an inappropriate correlation between gradient $g_t$ and the second moment term $v_t$ in Adam ($t$ is the timestep), which results in that a large gradient is likely to have small step size while a small gradient may have a large step size. We demonstrate that such unbalanced step sizes are the fundamental cause of non-convergence of Adam, and we further prove that decorrelating $v_t$ and $g_t$ will lead to unbiased step size for each gradient, thus solving the non-convergence problem of Adam. Finally, we propose AdaShift, a novel adaptive learning rate method that decorrelates $v_t$ and $g_t$ by temporal shifting, i.e., using temporally shifted gradient $g_{t-n}$ to calculate $v_t$. The experiment results demonstrate that AdaShift is able to address the non-convergence issue of Adam, while still maintaining a competitive performance with Adam in terms of both training speed and generalization. ","keywords":["optimizer","Adam","convergence","decorrelation"],"authorids":["ICLR.cc/2019/Conference/Paper1028/Authors"],"authors":["Anonymous"],"TL;DR":"We analysis and solve the non-convergence issue of Adam.","pdf":"/pdf/62a06f5b6f69b413ef9773705879b86e8d819dcb.pdf","paperhash":"anonymous|adashift_decorrelation_and_convergence_of_adaptive_learning_rate_methods","_bibtex":"@inproceedings{    \nanonymous2019adashift:,    \ntitle={AdaShift: Decorrelation and Convergence of Adaptive Learning Rate Methods},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkgTkhRcKQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Skl6k209Ym","original":"rkgYGO6tY7","number":1029,"cdate":1538087909426,"ddate":null,"tcdate":1538087909426,"tmdate":1538156006189,"tddate":null,"forum":"Skl6k209Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Alignment Based Mathching Networks for One-Shot Classification and Open-Set Recognition","abstract":"Deep learning for object classification relies heavily on convolutional models. While effective, CNNs are rarely interpretable after the fact. An attention mechanism can be used to highlight the area of the image that the model focuses on thus offering a narrow view into the mechanism of classification. We expand on this idea by forcing the method to explicitly align images to be classified to reference images representing the classes. The mechanism of alignment is learned and therefore does not require that the reference objects are anything like those being classified. Beyond explanation, our exemplar based cross-alignment method enables classification with only a single example per category (one-shot). Our model cuts the 5-way, 1-shot error rate in Omniglot from 2.1\\% to 1.4\\% and in MiniImageNet from 53.5\\% to 46.5\\% while simultaneously providing point-wise alignment information providing some understanding on what the network is capturing. This method of alignment also enables the recognition of an unsupported class (open-set) in the one-shot setting while maintaining an F1-score of above 0.5 for Omniglot even with 19 other distracting classes while baselines completely fail to separate the open-set class in the one-shot setting.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1029/Authors"],"authors":["Anonymous"],"pdf":"/pdf/b2aff749b17fb4801b3c2c8e8546b79f74c3b1d7.pdf","paperhash":"anonymous|alignment_based_mathching_networks_for_oneshot_classification_and_openset_recognition","_bibtex":"@inproceedings{    \nanonymous2019alignment,    \ntitle={Alignment Based Mathching Networks for One-Shot Classification and Open-Set Recognition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Skl6k209Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJg013C5KX","original":"HJxq9AHqYQ","number":1030,"cdate":1538087909596,"ddate":null,"tcdate":1538087909596,"tmdate":1538156005982,"tddate":null,"forum":"SJg013C5KX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Teaching to Teach by Structured Dark Knowledge","abstract":"To educate hyper deep learners, \\emph{Curriculum Learnings} (CLs) require either human heuristic participation or self-deciding the difficulties of training instances. These coaching manners are blind to the coherent structures among examples, categories, and tasks, which are pregnant with more knowledgeable curriculum-routed teachers. In this paper, we propose a general methodology \\emph{Teaching to Teach} (T2T). T2T is facilitated by \\emph{Structured Dark Knowledge} (SDK) that constitutes a communication protocol between structured knowledge prior and teaching strategies. On one hand, SDK adaptively extracts structured knowledge by selecting a training subset consistent with the previous teaching decisions. On the other hand, SDK teaches curriculum-agnostic teachers by transferring this knowledge to update their teaching policy. This virtuous cycle can be flexibly-deployed in most existing CL platforms and more importantly, very generic across various structured knowledge characteristics, e.g., diversity, complementarity, and causality. We evaluate T2T across different learners, teachers, and tasks, which significantly demonstrates that structured knowledge can be inherited by the teachers to further benefit learners' training.\n","keywords":["teaching to teach","dark knowledge","curriculum learning","teaching"],"authorids":["ICLR.cc/2019/Conference/Paper1030/Authors"],"authors":["Anonymous"],"TL;DR":"We newly proposed ``teaching to teach, to educate a better teacher to teach a better student by introducing structured dark knowledge.","pdf":"/pdf/21e866806c410c1732c62a1c88852f08587f2efd.pdf","paperhash":"anonymous|teaching_to_teach_by_structured_dark_knowledge","_bibtex":"@inproceedings{    \nanonymous2019teaching,    \ntitle={Teaching to Teach by Structured Dark Knowledge},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJg013C5KX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BklAyh05YQ","original":"B1ekjLsqFm","number":1031,"cdate":1538087909768,"ddate":null,"tcdate":1538087909768,"tmdate":1538156005762,"tddate":null,"forum":"BklAyh05YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Neural Network Bandit Learning by Last Layer Marginalization","abstract":"We propose a new method for training neural networks online in a bandit setting. Similar to prior work, we model the uncertainty only in the last layer of the network, treating the rest of the network as a feature extractor. This allows us to successfully balance between exploration and exploitation due to the efficient, closed-form uncertainty estimates available for linear models. To train the rest of the network, we take advantage of the posterior we have over the last layer, optimizing over all values in the last layer distribution weighted by probability. We derive a closed form, differential approximation to this objective and show empirically over various models and datasets that training the rest of the network in this fashion leads to both better online and offline performance when compared to other methods.","keywords":["Bandit learning","online learning","contextual bandits","neural network learning in online settings"],"authorids":["ICLR.cc/2019/Conference/Paper1031/Authors"],"authors":["Anonymous"],"TL;DR":"This paper proposes a new method for neural network learning in online bandit settings by marginalizing over the last layer","pdf":"/pdf/e76f30548510499f3efd68bfb420d907d15aa121.pdf","paperhash":"anonymous|neural_network_bandit_learning_by_last_layer_marginalization","_bibtex":"@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Network Bandit Learning by Last Layer Marginalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BklAyh05YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HylRk2A5FQ","original":"HkehXldcYQ","number":1032,"cdate":1538087909945,"ddate":null,"tcdate":1538087909945,"tmdate":1538156005553,"tddate":null,"forum":"HylRk2A5FQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Graph Learning Network: A Structure Learning Algorithm","abstract":"Graph prediction methods that work closely with the structure of the data, e.g., graph generation, commonly ignore the content of its nodes. On the other hand, the solutions that consider the node’s information, e.g., classification, ignore the structure of the whole. And some methods exist in between, e.g., link prediction, but predict the structure piece-wise instead of considering the graph as a whole. We hypothesize that by jointly predicting the structure of the graph and its nodes’ features, we can improve both tasks. We propose the Graph Learning Network (GLN), a simple yet effective process to learn node embeddings and structure prediction functions. Our model uses graph convolutions to propose expected node features, and predict the best structure based on them. We repeat these steps sequentially to enhance the prediction and the embeddings. In contrast to existing generation methods that rely only on the structure of the data, we use the feature on the nodes to predict better relations, similar to what link prediction methods do. However, we propose an holistic approach to process the whole graph for our predictions. Our experiments show that our method predicts consistent structures across a set of problems, while creating meaningful node embeddings.","keywords":["graph prediction","graph structure learning","graph neural network"],"authorids":["ICLR.cc/2019/Conference/Paper1032/Authors"],"authors":["Anonymous"],"TL;DR":"Methods for simultaneous prediction of nodes' feature embeddings and adjacency matrix, and how to learn this process.","pdf":"/pdf/13426a6ef41774e9acb65816704749f9d5b8f62e.pdf","paperhash":"anonymous|graph_learning_network_a_structure_learning_algorithm","_bibtex":"@inproceedings{    \nanonymous2019graph,    \ntitle={Graph Learning Network: A Structure Learning Algorithm},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HylRk2A5FQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJeRkh05Km","original":"r1x8gPpqF7","number":1033,"cdate":1538087910110,"ddate":null,"tcdate":1538087910110,"tmdate":1538156005348,"tddate":null,"forum":"HJeRkh05Km","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Visual Semantic Navigation using Scene Priors","abstract":"How do humans navigate to target objects in novel scenes? Do we use the semantic/functional priors we have built over years to efficiently search and navigate? For example, to search for mugs, we search cabinets near the coffee machine and for fruits we try the fridge. In this work, we focus on incorporating semantic priors in the task of semantic navigation. We propose to use Graph Convolutional Networks for incorporating the prior knowledge into a deep reinforcement learning framework. The agent uses the features from the knowledge graph to predict the actions. For evaluation, we use the AI2-THOR framework. Our experiments show how semantic knowledge improves the  performance significantly. More importantly, we show improvement in generalization to unseen scenes and/or objects.","keywords":["Visual Navigation","Scene Prior","Knowledge Graph","Graph Convolution Networks","Deep Reinforcement Learning"],"authorids":["ICLR.cc/2019/Conference/Paper1033/Authors"],"authors":["Anonymous"],"pdf":"/pdf/5dce0be37ab5cf6218a7fd07567058ccf47254b9.pdf","paperhash":"anonymous|visual_semantic_navigation_using_scene_priors","_bibtex":"@inproceedings{    \nanonymous2019visual,    \ntitle={Visual Semantic Navigation using Scene Priors},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJeRkh05Km},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryeAy3AqYm","original":"BJxO8gCctQ","number":1034,"cdate":1538087910306,"ddate":null,"tcdate":1538087910306,"tmdate":1538156005130,"tddate":null,"forum":"ryeAy3AqYm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Distilled Agent DQN for Provable Adversarial Robustness","abstract":"As deep neural networks have become the state of the art for solving complex reinforcement learning tasks, susceptibility to perceptual adversarial examples have become a concern. The transferability of adversarial examples for neural networks is known to enable attacks capable of tricking the agent into bad states or into not being able to learn at all. In this work we demonstrate a simple poisoning attack able to fool DQNs when trained with defense methods commonly used for classification tasks. We also propose an algorithm, called DadQN, which is based on deep Q-networks and enables the use of stronger defenses, including defenses increasing provability.","keywords":["reinforcement learning","dqn","adversarial examples","robustness analysis","adversarial defense","robust learning","robust rl"],"authorids":["ICLR.cc/2019/Conference/Paper1034/Authors"],"authors":["Anonymous"],"TL;DR":"We introduce a way of (provably) defending Deep-RL against adversarial perturbations, including a new poisoning attack.","pdf":"/pdf/25471815f879120e40bae7242601b400a74031f9.pdf","paperhash":"anonymous|distilled_agent_dqn_for_provable_adversarial_robustness","_bibtex":"@inproceedings{    \nanonymous2019distilled,    \ntitle={Distilled Agent DQN for Provable Adversarial Robustness},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryeAy3AqYm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1MAJhR5YX","original":"BJxrqUs9KX","number":1035,"cdate":1538087910475,"ddate":null,"tcdate":1538087910475,"tmdate":1538156004919,"tddate":null,"forum":"B1MAJhR5YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Empirical Bounds on Linear Regions of Deep Rectifier Networks","abstract":"One form of characterizing the expressiveness of a piecewise linear neural network is by the number of linear regions, or pieces, of the function modeled. We have observed substantial progress in this topic through lower and upper bounds on the maximum number of linear regions and a counting procedure. However, these bounds only account for the dimensions of the network and the exact counting may take a prohibitive amount of time, therefore making it infeasible to benchmark the expressiveness of networks. In this work, we approximate the number of linear regions of specific rectifier networks with an algorithm for probabilistic lower bounds of mixed-integer linear sets. In addition, we present a tighter upper bound that leverages network coefficients. We test both on trained networks. The algorithm for probabilistic lower bounds is several orders of magnitude faster than exact counting and the values reach similar orders of magnitude, hence making our approach a viable method to compare the expressiveness of such networks. The refined upper bound is particularly stronger on networks with narrow layers.  ","keywords":["linear regions","approximate model counting","mixed-integer linear programming"],"authorids":["ICLR.cc/2019/Conference/Paper1035/Authors"],"authors":["Anonymous"],"TL;DR":"We provide improved upper bounds for the number of linear regions used in network expressivity, and an highly efficient algorithm (w.r.t. exact counting) to obtain probabilistic lower bounds on the actual number of linear regions.","pdf":"/pdf/d9f58f980b435a26576cbac2081fa07d500cbcb2.pdf","paperhash":"anonymous|empirical_bounds_on_linear_regions_of_deep_rectifier_networks","_bibtex":"@inproceedings{    \nanonymous2019empirical,    \ntitle={Empirical Bounds on Linear Regions of Deep Rectifier Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1MAJhR5YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1xyx3R9tQ","original":"BylgM535F7","number":1036,"cdate":1538087910643,"ddate":null,"tcdate":1538087910643,"tmdate":1538156004712,"tddate":null,"forum":"r1xyx3R9tQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Prototypical Examples in Deep Learning: Metrics, Characteristics, and Utility","abstract":"Machine learning (ML) research has investigated prototypes: examples that are representative of the behavior to be learned. We systematically evaluate five methods for identifying prototypes, both ones previously introduced as well as new ones we propose, finding all of them to provide meaningful but different interpretations. Through a human study, we confirm that all five metrics are well matched to human intuition. Examining cases where the metrics disagree offers an informative perspective on the properties of data and algorithms used in learning, with implications for data-corpus construction, efficiency, adversarial robustness, interpretability, and other ML aspects. In particular, we confirm that the \"train on hard\" curriculum approach can improve accuracy on many datasets and tasks, but that it is strictly worse when there are many mislabeled or ambiguous examples.","keywords":["prototypes","curriculum learning","interpretability","differential privacy","adversarial robustness"],"authorids":["ICLR.cc/2019/Conference/Paper1036/Authors"],"authors":["Anonymous"],"TL;DR":"We can identify prototypical and outlier examples in machine learning that are quantifiably very different, and make use of them to improve many aspects of neural networks.","pdf":"/pdf/7e85ce76966ab102826ce0d9c2c1b860037bcc21.pdf","paperhash":"anonymous|prototypical_examples_in_deep_learning_metrics_characteristics_and_utility","_bibtex":"@inproceedings{    \nanonymous2019prototypical,    \ntitle={Prototypical Examples in Deep Learning: Metrics, Characteristics, and Utility},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xyx3R9tQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJgklhAcK7","original":"r1xllNtFYQ","number":1037,"cdate":1538087910817,"ddate":null,"tcdate":1538087910817,"tmdate":1538156004503,"tddate":null,"forum":"BJgklhAcK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Meta-Learning with Latent Embedding Optimization","abstract":"Gradient-based meta-learning techniques are both widely applicable and proficient at solving challenging few-shot learning and fast adaptation problems. However, they have practical difficulties when operating on high-dimensional parameter spaces in extreme low-data regimes. We show that it is possible to bypass these limitations by learning a data-dependent latent generative representation of model parameters, and performing gradient-based meta-learning in this low-dimensional latent space. The resulting approach, latent embedding optimization (LEO), decouples the gradient-based adaptation procedure from the underlying high-dimensional space of model parameters. Our evaluation shows that LEO can achieve state-of-the-art performance on the competitive miniImageNet and tieredImageNet few-shot classification tasks. Further analysis indicates LEO is able to capture uncertainty in the data and model parameters, and can perform adaptation more effectively by optimizing in latent space.","keywords":["meta-learning","few-shot","miniImageNet","tieredImageNet","hypernetworks","generative","latent embedding","optimization"],"authorids":["ICLR.cc/2019/Conference/Paper1037/Authors"],"authors":["Anonymous"],"TL;DR":"Latent Embedding Optimization (LEO) is a novel gradient-based meta-learner with state-of-the-art performance on the challenging 5-way 1-shot and 5-shot miniImageNet and tieredImageNet classification tasks.","pdf":"/pdf/a67a1130f5f694d578f45610321f8679b855e98e.pdf","paperhash":"anonymous|metalearning_with_latent_embedding_optimization","_bibtex":"@inproceedings{    \nanonymous2019meta-learning,    \ntitle={Meta-Learning with Latent Embedding Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgklhAcK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Skeke3C5Fm","original":"SylQnch5Ym","number":1038,"cdate":1538087910988,"ddate":null,"tcdate":1538087910988,"tmdate":1538156004299,"tddate":null,"forum":"Skeke3C5Fm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Multilingual Neural Machine Translation With Soft Decoupled Encoding","abstract":"Multilingual training of neural machine translation (NMT) systems has led to impressive accuracy improvements on low-resource languages. However, there are still significant challenges in efficiently learning word representations in the face of paucity of data. In this paper, we propose Soft Decoupled Encoding (SDE), a multilingual lexicon encoding framework specifically designed to share lexical-level information intelligently without requiring heuristic preprocessing such as pre-segmenting the data. SDE represents a word by its spelling through a character encoding, and its semantic meaning through a latent embedding space shared by all languages. Experiments on a standard dataset of four low-resource languages show consistent improvements over strong multilingual NMT baselines, with gains of up to 2 BLEU on one of the tested languages, achieving the new state-of-the-art on all four language pairs.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1038/Authors"],"authors":["Anonymous"],"pdf":"/pdf/f4bc08c9d532c7bd3762dca6704da2898fee6a56.pdf","paperhash":"anonymous|multilingual_neural_machine_translation_with_soft_decoupled_encoding","_bibtex":"@inproceedings{    \nanonymous2019multilingual,    \ntitle={Multilingual Neural Machine Translation With Soft Decoupled Encoding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Skeke3C5Fm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJgkx2Aqt7","original":"S1lePw35Y7","number":1039,"cdate":1538087911154,"ddate":null,"tcdate":1538087911154,"tmdate":1538156004082,"tddate":null,"forum":"HJgkx2Aqt7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning To Simulate","abstract":"Simulation is a useful tool in situations where training data for machine learning models is costly to annotate or even hard to acquire. In this work, we propose a reinforcement learning-based method for automatically adjusting the parameters of any (non-differentiable) simulator, thereby controlling the distribution of synthesized data in order to maximize the accuracy of a model trained on that data. In contrast to prior art that hand-crafts these simulation parameters or adjusts only parts of the available parameters, our approach fully controls the simulator with the actual underlying goal of maximizing accuracy, rather than mimicking the real data distribution or randomly generating a large volume of data. We find that our approach (i) quickly converges to the optimal simulation parameters in controlled experiments and (ii) can indeed discover good sets of parameters for an image rendering simulator in actual computer vision applications.","keywords":["Simulation in machine learning","reinforcement learning","policy gradients","image rendering"],"authorids":["ICLR.cc/2019/Conference/Paper1039/Authors"],"authors":["Anonymous"],"TL;DR":"We propose an algorithm that automatically adjusts parameters of a simulation engine to generate training data for a neural network such that validation accuracy is maximized.","pdf":"/pdf/0b6114da9ce132ba91c98d9cd6987cdf7581414a.pdf","paperhash":"anonymous|learning_to_simulate","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning To Simulate},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJgkx2Aqt7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJz1x20cFQ","original":"S1gfZVj9Km","number":1040,"cdate":1538087911348,"ddate":null,"tcdate":1538087911348,"tmdate":1538156003867,"tddate":null,"forum":"SJz1x20cFQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Hierarchical RL Using an Ensemble of Proprioceptive Periodic Policies","abstract":"In this paper we introduce a simple, robust approach to hierarchically training an agent in the setting of sparse reward tasks.\nThe agent is split into a low-level and a high-level policy. The low-level policy only accesses internal, proprioceptive dimensions of the state observation. The low-level policies are trained with a simple reward that encourages changing the values of the non-proprioceptive dimensions. Furthermore, it is induced to be periodic with the use a ``phase function.'' The high-level policy is trained using a sparse, task-dependent reward, and operates by choosing which of the low-level policies to run at any given time. Using this approach, we solve difficult maze and navigation tasks with sparse rewards using the Mujoco Ant and Humanoid agents and show improvement over recent hierarchical methods. ","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1040/Authors"],"authors":["Anonymous"],"pdf":"/pdf/0c425043dc4ff682322fa41eb4c7a0e6018936fb.pdf","paperhash":"anonymous|hierarchical_rl_using_an_ensemble_of_proprioceptive_periodic_policies","_bibtex":"@inproceedings{    \nanonymous2019hierarchical,    \ntitle={Hierarchical RL Using an Ensemble of Proprioceptive Periodic Policies},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJz1x20cFQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1glehC5tQ","original":"H1xf1loYYX","number":1041,"cdate":1538087911571,"ddate":null,"tcdate":1538087911571,"tmdate":1538156003658,"tddate":null,"forum":"r1glehC5tQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Distinguishability of Adversarial Examples","abstract":"Machine learning models including traditional models and neural networks can be easily fooled by adversarial examples which are generated from the natural examples with small perturbations.  This poses a critical challenge to machine learning security, and impedes the wide application of machine learning in many important domains such as computer vision and malware detection.  Unfortunately, even state-of-the-art defense approaches such as adversarial training and defensive distillation still suffer from major limitations and can be circumvented.  From a unique angle, we propose to investigate two important research questions in this paper: Are adversarial examples distinguishable from natural examples?  Are adversarial examples generated by different methods distinguishable from each other?  These two questions concern the distinguishability of adversarial examples.  Answering them will potentially lead to a simple yet effective approach, termed as defensive distinction in this paper under the formulation of multi-label classification, for protecting against adversarial examples.  We design and perform experiments using the MNIST dataset to investigate these two questions, and obtain highly positive results demonstrating the strong distinguishability of adversarial examples.  We recommend that this unique defensive distinction approach should be seriously considered to complement other defense approaches.","keywords":["Adversarial Examples","Machine Learning","Neural Networks","Distinguishability","Defense"],"authorids":["ICLR.cc/2019/Conference/Paper1041/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a defensive distinction protection approach and demonstrate the strong distinguishability of adversarial examples.","pdf":"/pdf/dc04eae63abcb4edcbe6a17b372b4fb03a501a31.pdf","paperhash":"anonymous|distinguishability_of_adversarial_examples","_bibtex":"@inproceedings{    \nanonymous2019distinguishability,    \ntitle={Distinguishability of Adversarial Examples},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1glehC5tQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJegl2C9K7","original":"S1eiGjCvYQ","number":1042,"cdate":1538087911742,"ddate":null,"tcdate":1538087911742,"tmdate":1538156003457,"tddate":null,"forum":"rJegl2C9K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Feature Matters: A Stage-by-Stage Approach for Task Independent Knowledge Transfer","abstract":"Convolutional Neural Networks (CNNs) become deeper and deeper in recent years, making the study of model acceleration imperative. It is a common practice to employ a shallow network, called student, to learn from a deep one, which is termed as teacher. Prior work made many attempts to transfer different types of knowledge from teacher to student, however, there are two problems remaining unsolved. Firstly, the knowledge used by existing methods is highly dependent on task and dataset, limiting their applications. Secondly, there lacks an effective training scheme for the transfer process, leading to degradation of performance. In this work, we argue that feature is the most important knowledge from teacher. It is sufficient for student to just learn good features regardless of the target task. From this discovery, we further present an efficient learning strategy to mimic features stage by stage. Extensive experiments demonstrate the importance of features and show that the proposed approach significantly narrows down the gap between student and teacher, outperforming the state-of-the-art methods.\n","keywords":["knowledge transfer","task independent","feature transfer","stage-by-stage"],"authorids":["ICLR.cc/2019/Conference/Paper1042/Authors"],"authors":["Anonymous"],"TL;DR":"This paper proposes to transfer knowledge from deep model to shallow one by mimicking features stage by stage.","pdf":"/pdf/06729f67091f583f6caef1c72f89e598b8f957cf.pdf","paperhash":"anonymous|feature_matters_a_stagebystage_approach_for_task_independent_knowledge_transfer","_bibtex":"@inproceedings{    \nanonymous2019feature,    \ntitle={Feature Matters: A Stage-by-Stage Approach for Task Independent Knowledge Transfer},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJegl2C9K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJflg30qKX","original":"r1lide0cKQ","number":1043,"cdate":1538087911980,"ddate":null,"tcdate":1538087911980,"tmdate":1538156003253,"tddate":null,"forum":"HJflg30qKX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Gradient descent aligns the layers of deep linear networks","abstract":"This paper establishes risk convergence and asymptotic weight matrix alignment --- a form of implicit regularization --- of gradient flow and gradient descent when applied to deep linear networks on linearly separable data. In more detail, for gradient flow applied to strictly decreasing loss functions (with similar results for gradient descent with particular decreasing step sizes):\n(1) the risk converges to 0;\n(ii) the normalized i-th weight matrix asymptotically equals its\nrank-1 approximation u_iv_i^T;\n(iii) these rank-1 matrices are aligned across layers, meaning |v_{i+1}^T u_i| -> 1.\nIn the case of the logistic loss (binary cross entropy), more can be said: the linear function induced by the network --- the product of its weight matrices --- converges to the same direction as the maximum margin solution. This last property was identified in prior work, but only under assumptions on gradient descent which here are implied by the alignment phenomenon.","keywords":["implicit regularization","alignment of layers","deep linear networks","gradient descent","separable data"],"authorids":["ICLR.cc/2019/Conference/Paper1043/Authors"],"authors":["Anonymous"],"pdf":"/pdf/2224784cbde9a73062efb352f877943c11557bcb.pdf","paperhash":"anonymous|gradient_descent_aligns_the_layers_of_deep_linear_networks","_bibtex":"@inproceedings{    \nanonymous2019gradient,    \ntitle={Gradient descent aligns the layers of deep linear networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJflg30qKX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJglg2A9FX","original":"HJeEh09qYm","number":1044,"cdate":1538087912150,"ddate":null,"tcdate":1538087912150,"tmdate":1538156003034,"tddate":null,"forum":"HJglg2A9FX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Iteratively Learning from the Best","abstract":"We study a simple generic framework to address the issue of bad training data; both bad labels in supervised problems, and bad samples in unsupervised ones. Our approach starts by fitting a model to the whole training dataset, but then iteratively improves it by alternating between (a) revisiting the training data to select samples with lowest current loss, and (b) re-training the model on only these selected samples. It can be applied to any existing model training setting which provides a loss measure for samples, and a way to refit on new ones. We show the merit of this approach in both theory and practice We first prove statistical consistency, and linear convergence to the ground truth and global optimum, for two simpler model settings: mixed linear regression, and gaussian mixture models.  We then demonstrate its success empirically in (a) saving the accuracy of existing deep image classifiers when there are errors in the labels of training images, and (b) improving the quality of samples generated by existing DC-GAN models, when it is given training data that contains a fraction of the images from a different and unintended dataset.  The experimental results show  significant improvement over the baseline methods that ignore the existence of bad labels/samples. ","keywords":["noisy samples","deep learning","generative adversarial network"],"authorids":["ICLR.cc/2019/Conference/Paper1044/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a simple framework that addresses the problem of spurious data in both supervised and unsupervised settings.","pdf":"/pdf/b3e77bf142d212666af4a2a4c655ed7d4dca3055.pdf","paperhash":"anonymous|iteratively_learning_from_the_best","_bibtex":"@inproceedings{    \nanonymous2019iteratively,    \ntitle={Iteratively Learning from the Best},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJglg2A9FX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rylxxhRctX","original":"rkeYFC65Km","number":1045,"cdate":1538087912338,"ddate":null,"tcdate":1538087912338,"tmdate":1538156002823,"tddate":null,"forum":"rylxxhRctX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Coverage and Quality Driven Training of Generative Image Models","abstract":"Generative modeling of natural images has been extensively studied in recent years, yielding remarkable progress. Current state-of-the-art methods are either based on maximum likelihood estimation or adversarial training. Both methods have their own drawbacks, which are complementary in nature. The first leads to over-generalization as the maximum likelihood criterion encourages models to cover the support of the training data by heavily penalizing small masses assigned to training data. Simplifying assumptions in such models limits their capacity and makes them spill mass on unrealistic samples. The second leads to mode-dropping since adversarial training encourages high quality samples from the model, but only indirectly enforces diversity among the samples. To overcome these drawbacks we make two contributions. First, we propose a model that extends variational autoencoders by using deterministic invertible transformation layers to map samples from the decoder to the image space. This induces correlations among the pixels given the latent variables, improving over factorial decoders commonly used in variational autoencoders. Second, we propose a unified training approach that leverages coverage and quality based criteria. Our models obtain likelihood scores competitive with state-of-the-art likelihood-based models, while achieving sample quality typical of adversarially trained networks. ","keywords":["deep learning","generative modeling","unsupervised learning","maximum likelihood","adversarial learning","gan","vae"],"authorids":["ICLR.cc/2019/Conference/Paper1045/Authors"],"authors":["Anonymous"],"TL;DR":"Generative models that yield Gan-like samples and achieve competitive likelihood on held-out data. ","pdf":"/pdf/6160ac7dd4bbfbe48ded782a7dd22ca403934541.pdf","paperhash":"anonymous|coverage_and_quality_driven_training_of_generative_image_models","_bibtex":"@inproceedings{    \nanonymous2019coverage,    \ntitle={Coverage and Quality Driven Training of Generative Image Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylxxhRctX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Skgge3R9FQ","original":"B1eUNq35YX","number":1046,"cdate":1538087912510,"ddate":null,"tcdate":1538087912510,"tmdate":1538156002620,"tddate":null,"forum":"Skgge3R9FQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Controlling Over-generalization and its Effect on Adversarial Examples Detection and Generation","abstract":"Convolutional Neural Networks (CNNs) significantly improve the state-of-the-art for many applications, especially in computer vision. However, CNNs still suffer from a tendency to confidently classify out-distribution samples from unknown classes into pre-defined known classes. Further, they are also vulnerable to adversarial examples. We are relating these two issues through the tendency of CNNs to over-generalize for areas of the input space not covered well by the training set. We show that a CNN augmented with an extra output class can act as a simple yet effective end-to-end model for controlling over-generalization. As an appropriate training set for the extra class, we introduce two resources that are computationally efficient to obtain: a representative natural out-distribution set and interpolated in-distribution samples. To help select a representative natural out-distribution set among available ones, we propose a simple measurement to assess an out-distribution set's fitness. We also demonstrate that training such an augmented CNN with representative out-distribution natural datasets and some interpolated samples allows it to better handle a wide range of unseen out-distribution samples and black-box adversarial examples without training it on any adversaries. Finally, we show that generation of white-box adversarial attacks using our proposed augmented CNN can become harder, as the attack algorithms have to get around the rejection regions when generating actual adversaries.","keywords":["Convolutional Neural Networks","Adversarial Instances","Out-distribution Samples","Rejection Option","Over-generalization"],"authorids":["ICLR.cc/2019/Conference/Paper1046/Authors"],"authors":["Anonymous"],"TL;DR":"Properly training CNNs with dustbin class increase their robustness to adversarial attacks and their capacity to deal with out-distribution samples.","pdf":"/pdf/90f0fd97d7e104314ea4596c1bffb7f2089968c2.pdf","paperhash":"anonymous|controlling_overgeneralization_and_its_effect_on_adversarial_examples_detection_and_generation","_bibtex":"@inproceedings{    \nanonymous2019controlling,    \ntitle={Controlling Over-generalization and its Effect on Adversarial Examples Detection and Generation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Skgge3R9FQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJgWl3A5YX","original":"rkgSDoccKm","number":1047,"cdate":1538087912673,"ddate":null,"tcdate":1538087912673,"tmdate":1538156002416,"tddate":null,"forum":"BJgWl3A5YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"The Body is not a Given: Joint Agent Policy Learning and Morphology Evolution","abstract":"Reinforcement learning (RL) has proven to be a powerful paradigm for deriving complex behaviors from simple reward signals in a wide range of environments. When applying RL to continuous control agents in simulated physics environments, the body is usually considered to be part of the environment. However, during evolution the physical body of biological organisms and their controlling brains are co-evolved, thus exploring a much larger space of actuator/controller configurations. Put differently, the intelligence does not reside only in the agent's mind, but also in the design of their body. \nWe propose a method for uncovering strong agents, consisting of a good combination of a body and policy, based on combining RL with an evolutionary procedure. Given the resulting agent, we also propose an approach for identifying the body changes that contributed the most to the agent performance. We use the Shapley value from cooperative game theory to find the fair contribution of individual components, taking into account synergies between components. \nWe evaluate our methods in an environment similar to the the recently proposed Robo-Sumo task, where agents in a 3D environment with simulated physics compete in tipping over their opponent or pushing them out of the arena. Our results show that the proposed methods are indeed capable of generating strong agents, significantly outperforming baselines that focus on optimizing the agent policy alone. \n\nA video is available at: www.youtube.com/watch?v=eei6Rgom3YY","keywords":["Reinforcement Learning","Continuous Control","Evolutionary Computation","Genetic Algorithms","Evolving Morphology","Baldwin Effect","Population Based Training"],"authorids":["ICLR.cc/2019/Conference/Paper1047/Authors"],"authors":["Anonymous"],"TL;DR":"Evolving the shape of the body in RL controlled agents improves their performance (and help learning)","pdf":"/pdf/e0cb762e4788adb7e795f442d9f3b13bc2a17768.pdf","paperhash":"anonymous|the_body_is_not_a_given_joint_agent_policy_learning_and_morphology_evolution","_bibtex":"@inproceedings{    \nanonymous2019the,    \ntitle={The Body is not a Given: Joint Agent Policy Learning and Morphology Evolution},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgWl3A5YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1x-x309tm","original":"BklbDgC5t7","number":1048,"cdate":1538087912844,"ddate":null,"tcdate":1538087912844,"tmdate":1538156002209,"tddate":null,"forum":"H1x-x309tm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"On the Convergence of A Class of Adam-Type Algorithms  for Non-Convex Optimization","abstract":"This paper studies a class of adaptive gradient based momentum algorithms that update the  search directions and learning rates simultaneously using past gradients. This class, which we refer to as the ''``Adam-type'', includes the popular algorithms such as Adam, AMSGrad, AdaGrad. Despite their popularity in training deep neural networks (DNNs), the convergence of these algorithms for solving  non-convex problems remains an open question. In this paper, we develop an analysis framework and a set of mild sufficient conditions that guarantee the convergence of the Adam-type methods, with a convergence rate of order   $O(\\log{T}/\\sqrt{T})$ for non-convex stochastic optimization. Our convergence analysis applies to a new algorithm called AdaFom (AdaGrad with First Order Momentum). We show that the conditions are essential, by identifying concrete examples in which violating the conditions makes an algorithm diverge. Besides providing one of the first comprehensive analysis for Adam-type methods in the non-convex setting, our results can also help the practitioners to easily  monitor the progress of algorithms and determine their convergence behavior. ","keywords":["nonconvex optimization","Adam","convergence analysis"],"authorids":["ICLR.cc/2019/Conference/Paper1048/Authors"],"authors":["Anonymous"],"TL;DR":"We analyze convergence of Adam-type algorithms and provide mild sufficient conditions to guarantee their convergence, we also show  violating the conditions can makes an algorithm diverge.","pdf":"/pdf/cc73a47ad3d96fce5885d96cc9ea30eb7c90a86e.pdf","paperhash":"anonymous|on_the_convergence_of_a_class_of_adamtype_algorithms_for_nonconvex_optimization","_bibtex":"@inproceedings{    \nanonymous2019on,    \ntitle={On the Convergence of A Class of Adam-Type Algorithms  for Non-Convex Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1x-x309tm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Syeben09FQ","original":"Hyl_lBT5YX","number":1049,"cdate":1538087913010,"ddate":null,"tcdate":1538087913010,"tmdate":1538156001994,"tddate":null,"forum":"Syeben09FQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Evaluating GANs via Duality","abstract":"Generative Adversarial Networks (GANs) have shown great results in accurately modeling complex distributions, but their training is known to be difficult due to instabilities caused by a challenging minimax optimization problem. This is especially troublesome given the lack of an evaluation metric that can reliably detect non-convergent behaviors. We leverage the notion of duality gap from game theory in order to propose a novel convergence metric for GANs that has low computational cost. We verify the validity of the proposed metric for various test scenarios commonly used in the literature. ","keywords":["Generative Adversarial Networks","GANs","game theory"],"authorids":["ICLR.cc/2019/Conference/Paper1049/Authors"],"authors":["Anonymous"],"pdf":"/pdf/b12d3cb7bbf2b817c682fe5502596d5122d8e9c5.pdf","paperhash":"anonymous|evaluating_gans_via_duality","_bibtex":"@inproceedings{    \nanonymous2019evaluating,    \ntitle={Evaluating GANs via Duality},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syeben09FQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BkMWx309FX","original":"BkepL4y5KX","number":1050,"cdate":1538087913186,"ddate":null,"tcdate":1538087913186,"tmdate":1538156001786,"tddate":null,"forum":"BkMWx309FX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Reinforcement Learning with Perturbed Rewards","abstract":"Recent studies have shown the vulnerability of reinforcement learning (RL) models in noisy settings. The sources of noises differ across scenarios. For instance, in practice, the observed reward channel is often subject to noise (e.g., when observed rewards are collected through sensors), and thus observed rewards may not be credible as a result. Also, in applications such as robotics, a deep reinforcement learning (DRL) algorithm can be manipulated to produce arbitrary errors. In this paper, we consider noisy RL problems where observed rewards by RL agents are generated with a reward confusion matrix. We call such observed rewards as perturbed rewards. We develop an unbiased reward estimator aided robust RL framework that enables RL agents to learn in noisy environments while observing only perturbed rewards. Our framework draws upon approaches for supervised learning with noisy data. The core ideas of our solution include estimating a reward confusion matrix and defining a set of unbiased surrogate rewards. We prove the convergence and sample complexity of our approach. Extensive experiments on different DRL platforms show that policies based on our estimated surrogate reward can achieve higher expected rewards, and converge faster than existing baselines. For instance, the state-of-the-art PPO algorithm is able to obtain 67.5% and 46.7% improvements in average on five Atari games, when the error rates are 10% and 30% respectively. ","keywords":["robust reinforcement learning","noisy reward","sample complexity"],"authorids":["ICLR.cc/2019/Conference/Paper1050/Authors"],"authors":["Anonymous"],"TL;DR":"A new approach for learning with noisy rewards in reinforcement learning","pdf":"/pdf/f89a709407274f9152ae7a03b513930c552c2774.pdf","paperhash":"anonymous|reinforcement_learning_with_perturbed_rewards","_bibtex":"@inproceedings{    \nanonymous2019reinforcement,    \ntitle={Reinforcement Learning with Perturbed Rewards},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkMWx309FX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1l-e3Cqtm","original":"SJg7cxA9F7","number":1051,"cdate":1538087913367,"ddate":null,"tcdate":1538087913367,"tmdate":1538156001582,"tddate":null,"forum":"r1l-e3Cqtm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Deep Probabilistic Video Compression","abstract":"We propose a variational inference approach to deep probabilistic video compression.  Our model uses advances in variational autoencoders (VAEs) for sequential data and combines it with recent work on neural image compression. The approach jointly learns to transform the original video into a  lower-dimensional representation as well as to entropy code this representation according to a temporally-conditioned probabilistic model. We split the latent space into local (per frame) and global (per segment) variables, and show that training the VAE to utilize both representations leads to an improved rate-distortion performance. Evaluation on small videos from public data sets with varying complexity and diversity show that our model yields competitive results when trained on generic video content. Extreme compression performance is achieved for videos with specialized content if the model is trained on similar videos.","keywords":["variational inference","video compression","deep generative models"],"authorids":["ICLR.cc/2019/Conference/Paper1051/Authors"],"authors":["Anonymous"],"TL;DR":"Deep Probabilistic Video Compression Via Sequential Variational Autoencoders","pdf":"/pdf/9459cd77e2547453b2b1fc9e85e7fefe1105debf.pdf","paperhash":"anonymous|deep_probabilistic_video_compression","_bibtex":"@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Probabilistic Video Compression},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1l-e3Cqtm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BygfghAcYX","original":"r1lWdia9K7","number":1052,"cdate":1538087913544,"ddate":null,"tcdate":1538087913544,"tmdate":1538156001374,"tddate":null,"forum":"BygfghAcYX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"The role of over-parametrization in generalization of neural networks","abstract":"Despite existing work on ensuring generalization of neural networks in terms of scale sensitive complexity measures, such as norms, margin and sharpness, these complexity measures do not offer an explanation of why neural networks generalize better with over-parametrization. In this work we suggest a novel complexity measure based on unit-wise capacities resulting in a tighter generalization bound for two layer ReLU networks. Our capacity bound correlates with the behavior of test error with increasing network sizes, and could potentially explain the improvement in generalization with over-parametrization. We further present a matching lower bound for the Rademacher complexity that improves over previous capacity lower bounds for neural networks.","keywords":["Generalization","Over-Parametrization","Neural Networks","Deep Learning"],"authorids":["ICLR.cc/2019/Conference/Paper1052/Authors"],"authors":["Anonymous"],"TL;DR":"We suggest a generalization bound that could potentially explain the improvement in generalization with over-parametrization.","pdf":"/pdf/19e6138f2e3dca240567dcc95dbc1d66801d7b39.pdf","paperhash":"anonymous|the_role_of_overparametrization_in_generalization_of_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019the,    \ntitle={The role of over-parametrization in generalization of neural networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BygfghAcYX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJgMlhRctm","original":"ryxWHqa9KX","number":1053,"cdate":1538087913713,"ddate":null,"tcdate":1538087913713,"tmdate":1538156001162,"tddate":null,"forum":"rJgMlhRctm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision","abstract":"We propose the Neuro-Symbolic Concept Learner (NS-CL), a model that learns visual concepts, words, and semantic parsing of sentences without explicit supervision on any of them; instead, our model learns by simply looking at images and reading paired questions and answers. Our model builds an object-based scene representation and translates sentences into executable, symbolic programs. To bridge the learning of two modules, we use a neural-symbolic reasoning module that executes these programs on the latent scene representation. Analog to the human concept learning, given the parsed program, the perception module learns visual concepts based on the language description of the object being referred to. Meanwhile, the learned visual concepts facilitate learning new words and parsing new sentences. We use curriculum learning to guide searching over the large compositional space of images and language. Extensive experiments demonstrate the accuracy and efficiency of our model on learning visual concepts, word representations, and semantic parsing of sentences. Further, our method allows easy generalization to new object attributes, compositions, language concepts, scenes and questions, and even new program domains. It also empowers applications including visual question answering and bidirectional image-text retrieval.","keywords":["Neuro-Symbolic Representations","Concept Learning","Visual Reasoning"],"authorids":["ICLR.cc/2019/Conference/Paper1053/Authors"],"authors":["Anonymous"],"TL;DR":"We present a Neuro-Symbolic Concept Learner to learn visual concepts, words, and semantic parsing of sentences without explicit annotations for any of them. ","pdf":"/pdf/51de63c42340eb59c36c6e63208765754c6e3fb8.pdf","paperhash":"anonymous|the_neurosymbolic_concept_learner_interpreting_scenes_words_and_sentences_from_natural_supervision","_bibtex":"@inproceedings{    \nanonymous2019the,    \ntitle={The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJgMlhRctm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyefgnCqFm","original":"B1esL46qYX","number":1054,"cdate":1538087913879,"ddate":null,"tcdate":1538087913879,"tmdate":1538156000946,"tddate":null,"forum":"HyefgnCqFm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning space time dynamics with PDE guided neural networks","abstract":"Spatio-Temporal processes bear a central importance in many applied scientific fields. Generally, differential equations are used to describe these processes. In this work, we address the problem of learning spatio-temporal dynamics with neural networks when only partial information on the system's state is available. Taking inspiration from the dynamical system approach, we outline a general framework in which complex dynamics generated by families of differential equations  can be learned in a principled way. Two models are derived from this framework. We demonstrate how they can be applied in practice by considering the problem of forecasting fluid flows. We show how the underlying equations fit into our formalism and evaluate our method by comparing with standard baselines.","keywords":["deep learning","spatio-temporal dynamics","physical processes","differential equations","dynamical systems"],"authorids":["ICLR.cc/2019/Conference/Paper1054/Authors"],"authors":["Anonymous"],"pdf":"/pdf/ab9bc51ce689069b58c29290ce63afcde8262419.pdf","paperhash":"anonymous|learning_space_time_dynamics_with_pde_guided_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning space time dynamics with PDE guided neural networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyefgnCqFm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1Gfx3Rqtm","original":"ryluIRcctm","number":1055,"cdate":1538087914054,"ddate":null,"tcdate":1538087914054,"tmdate":1538156000736,"tddate":null,"forum":"H1Gfx3Rqtm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"End-to-End Hierarchical Text Classification with Label Assignment Policy","abstract":"We present an end-to-end reinforcement learning approach to hierarchical text classification where documents are labeled by placing them at the right positions in a given hierarchy.\nWhile existing “global” methods construct hierarchical losses for model training, they either make “local” decisions at each hierarchy node or ignore the hierarchy structure during inference. To close the gap between training/inference and optimize holistic metrics in an end-to-end manner, we propose to learn a label assignment policy to determine where to place the documents and when to stop. The proposed method, HiLAP, optimizes holistic metrics over the hierarchy, makes inter-dependent decisions during inference, and can be combined with different text encoding models for end-to-end training.\nExperiments on three public datasets show that HiLAP yields an average improvement of 33.4% in Macro-F1 and 5.0% in Samples-F1, outperforming state-of-the-art methods by a large margin.","keywords":["Hierarchical Classification","Text Classification"],"authorids":["ICLR.cc/2019/Conference/Paper1055/Authors"],"authors":["Anonymous"],"pdf":"/pdf/a642601d8aec01aa0d1b8004103294f753aa238f.pdf","paperhash":"anonymous|endtoend_hierarchical_text_classification_with_label_assignment_policy","_bibtex":"@inproceedings{    \nanonymous2019end-to-end,    \ntitle={End-to-End Hierarchical Text Classification with Label Assignment Policy},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1Gfx3Rqtm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ByezgnA5tm","original":"H1ePxm8FKX","number":1056,"cdate":1538087914220,"ddate":null,"tcdate":1538087914220,"tmdate":1538156000522,"tddate":null,"forum":"ByezgnA5tm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Constraining Action Sequences with Formal Languages for Deep Reinforcement Learning","abstract":"We study the problem of deep reinforcement learning where the agent's action sequences are constrained, e.g., prohibition of dithering or overactuating action sequences that might damage a robot, drone, or other physical device.  Our model focuses on constraints that can be described by automata such as DFAs or PDAs. We then propose multiple approaches to augment the state descriptions of the Markov decision process (MDP) with summaries of recent action histories.  We empirically evaluate these methods applying DQN to three Atari games, training with reward shaping.  We found that our approaches are effective in significantly reducing, and even eliminating, constraint violations while maintaining high reward.  We  also observed that the total reward achieved by an agent can be highly sensitive to how much the constraints encourage or discourage exploration of potentially effective actions during training, and, in addition to helping ensure safe policies, the use of constraints can enhance exploration during training.","keywords":["reinforcement learning","constraints","finite state machines"],"authorids":["ICLR.cc/2019/Conference/Paper1056/Authors"],"authors":["Anonymous"],"TL;DR":"We constrain an agent's actions during reinforcement learning, for safety or to enhance exploration.","pdf":"/pdf/2aaa8ae079f15e81a450751cb05ac95498eb61c4.pdf","paperhash":"anonymous|constraining_action_sequences_with_formal_languages_for_deep_reinforcement_learning","_bibtex":"@inproceedings{    \nanonymous2019constraining,    \ntitle={Constraining Action Sequences with Formal Languages for Deep Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByezgnA5tm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJxfxnA9K7","original":"BklmigC9tm","number":1057,"cdate":1538087914387,"ddate":null,"tcdate":1538087914387,"tmdate":1538156000313,"tddate":null,"forum":"SJxfxnA9K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Structured Prediction using cGANs with Fusion Discriminator","abstract":"We propose a novel method for incorporating conditional information into a generative adversarial network (GAN) for structured prediction tasks. This method is based on fusing features from the generated and conditional information in feature space and allows the discriminator to better capture higher-order statistics from the data. This method also increases the strength of the signals passed through the network where the real or generated data and the conditional data agree. The proposed method is conceptually simpler than the joint convolutional neural network - conditional Markov random field (CNN-CRF) models and enforces higher-order consistency without being limited to a very specific class of high-order potentials. Experimental results demonstrate that this method leads to improvement on a variety of different structured prediction tasks including image synthesis, semantic segmentation, and depth estimation.","keywords":["Generative Adversarial Networks","GANs","conditional GANs","Discriminator","Fusion"],"authorids":["ICLR.cc/2019/Conference/Paper1057/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a novel way to incorporate conditional image information into the discriminator of GANs using feature fusion that can be used for structured prediction tasks.","pdf":"/pdf/acb4d17dbd0806deea009c6ff570731e88f83dab.pdf","paperhash":"anonymous|structured_prediction_using_cgans_with_fusion_discriminator","_bibtex":"@inproceedings{    \nanonymous2019structured,    \ntitle={Structured Prediction using cGANs with Fusion Discriminator},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJxfxnA9K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SkxXg2C5FX","original":"HJlltxn5YX","number":1058,"cdate":1538087914556,"ddate":null,"tcdate":1538087914556,"tmdate":1538156000107,"tddate":null,"forum":"SkxXg2C5FX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Don't Settle for Average, Go for the Max: Fuzzy Sets and Max-Pooled Word Vectors","abstract":"Recent literature suggests that averaged word vectors followed by simple post-processing outperform many deep learning methods on semantic textual similarity tasks. Furthermore, when averaged word vectors are trained supervised on large corpora of paraphrases, they achieve state-of-the-art results on standard STS benchmarks. Inspired by these revelations, we push the limits of word embeddings even further. We propose a novel fuzzy bag-of-word (FBoW) representation for text that contains all the words in the vocabulary simultaneously but with different degrees of membership, which are derived from similarities between word vectors. We show that max-pooled word vectors are only a special case of fuzzy BoW and should be compared via fuzzy Jaccard index rather than cosine similarity. Finally, we propose DynaMax, a completely unsupervised and non-parametric similarity measure that dynamically extracts and max-pools good features depending on the sentence pair. This method is both efficient and easy to implement, yet outperforms current baselines on STS tasks by a large margin when word vectors are trained unsupervised. When the word vectors are trained supervised to directly optimise cosine similarity, our measure is still comparable in performance despite being unrelated to the original objective.","keywords":["word vectors","sentence representations","distributed representations","fuzzy sets","bag-of-words","unsupervised learning","word vector compositionality","max-pooling","Jaccard index"],"authorids":["ICLR.cc/2019/Conference/Paper1058/Authors"],"authors":["Anonymous"],"TL;DR":"Max-pooled word vectors with fuzzy Jaccard set similarity are an extremely competitive baseline for semantic similarity; we propose a simple dynamic variant that performs even better.","pdf":"/pdf/679ce844e999ed4ffeaae9f748c31188ee88291d.pdf","paperhash":"anonymous|dont_settle_for_average_go_for_the_max_fuzzy_sets_and_maxpooled_word_vectors","_bibtex":"@inproceedings{    \nanonymous2019don't,    \ntitle={Don't Settle for Average, Go for the Max: Fuzzy Sets and Max-Pooled Word Vectors},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkxXg2C5FX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SkeXehR9t7","original":"HygBigC5tX","number":1059,"cdate":1538087914775,"ddate":null,"tcdate":1538087914775,"tmdate":1538155999893,"tddate":null,"forum":"SkeXehR9t7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Graph2Seq: Graph to Sequence Learning with Attention-Based Neural Networks","abstract":"The celebrated \\emph{Sequence to Sequence learning (Seq2Seq)} technique and its numerous variants achieve excellent performance on many tasks. However, many machine learning tasks have inputs naturally represented as graphs; existing Seq2Seq models face a significant challenge in achieving accurate conversion from graph form to the appropriate sequence. \nTo address this challenge, we introduce a general end-to-end graph-to-sequence neural encoder-decoder architecture that maps an input graph to a sequence of vectors and uses an attention-based LSTM method to decode the target sequence from these vectors. \nOur method first generates the node and graph embeddings using an improved graph-based neural network with a novel aggregation strategy to incorporate edge direction information in the node embeddings. \nWe further introduce a novel attention mechanism that aligns node embeddings and the decoding sequence to better cope with large graphs.\nExperimental results on bAbI, Shortest Path, and Natural Language Generation tasks demonstrate that our model achieves state-of-the-art performance and significantly outperforms existing Seq2Seq and Tree2Seq models; using the proposed aggregation strategy, the model can converge rapidly to the optimal performance.","keywords":["Graph Encoder","Graph Decoder","Graph2Seq","Graph Attention"],"authorids":["ICLR.cc/2019/Conference/Paper1059/Authors"],"authors":["Anonymous"],"TL;DR":"Graph to Sequence Learning with Attention-Based Neural Networks","pdf":"/pdf/8d4be7bc5d5c200554d901c9e21fb746757201e7.pdf","paperhash":"anonymous|graph2seq_graph_to_sequence_learning_with_attentionbased_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019graph2seq:,    \ntitle={Graph2Seq: Graph to Sequence Learning with Attention-Based Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkeXehR9t7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ByfXe2C5tm","original":"BJeEmm2qtQ","number":1060,"cdate":1538087914945,"ddate":null,"tcdate":1538087914945,"tmdate":1538155999683,"tddate":null,"forum":"ByfXe2C5tm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"NLProlog: Reasoning with Weak Unification for Natural Language Question Answering","abstract":"Symbolic logic allows practitioners to build systems that perform rule-based reasoning which is interpretable and which can easily be augmented with prior knowledge. However, such systems are traditionally difficult to apply to problems involving natural language due to the large linguistic variability of language. Currently, most work in natural language processing focuses on neural networks which learn distributed representations of words and their composition, thereby performing well in the presence of large linguistic variability. We propose to reap the benefits of both approaches by applying a combination of neural networks and logic programming to natural language question answering. We propose to employ an external, non-differentiable Prolog prover which utilizes a similarity function over pretrained sentence encoders. We fine-tune these representations via Evolution Strategies with the goal of multi-hop reasoning on natural language.  This allows us to create a system that can apply rule-based reasoning to natural language and induce domain-specific natural language rules from training data. We evaluate the proposed system on two different question answering tasks, showing that it complements two very strong baselines – BIDAF (Seo et al., 2016a) and FASTQA (Weissenborn et al.,2017) – and outperforms both when used in an ensemble.","keywords":["symbolic reasoning","neural networks","natural language processing","question answering","sentence embeddings","evolution strategies"],"authorids":["ICLR.cc/2019/Conference/Paper1060/Authors"],"authors":["Anonymous"],"TL;DR":"We introduce NLProlog, a system that performs rule-based reasoning on natural language by leveraging pretrained sentence embeddings and fine-tuning with Evolution Strategies, and apply it to two multi-hop Question Answering tasks.","pdf":"/pdf/439a8084e413bbd1728b1d8125849f66b9e8357d.pdf","paperhash":"anonymous|nlprolog_reasoning_with_weak_unification_for_natural_language_question_answering","_bibtex":"@inproceedings{    \nanonymous2019nlprolog:,    \ntitle={NLProlog: Reasoning with Weak Unification for Natural Language Question Answering},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByfXe2C5tm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HklQxnC5tX","original":"BketjhwYFm","number":1061,"cdate":1538087915114,"ddate":null,"tcdate":1538087915114,"tmdate":1538155999461,"tddate":null,"forum":"HklQxnC5tX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Overlapping Community Detection with Graph Neural Networks","abstract":"Community detection in graphs is of central importance in graph mining, machine learning and network science.  Detecting overlapping communities is especially challenging, and remains an open problem.  Motivated by the success of graph-based  deep  learning  in  other  graph-related  tasks,  we  study  the  applicability  of this framework for overlapping community detection. We propose a probabilistic model for overlapping community detection based on the graph neural network architecture.  Despite its simplicity, our model outperforms the existing approaches in the community recovery task by a large margin.  Moreover, due to the inductive formulation, the proposed model is able to perform out-of-sample community detection for nodes that were not present at training time","keywords":["community detection","deep learning for graphs"],"authorids":["ICLR.cc/2019/Conference/Paper1061/Authors"],"authors":["Anonymous"],"TL;DR":"Detecting overlapping communities in graphs using graph neural networks","pdf":"/pdf/f55876160fada78bec5fd7d9aac7846c59415775.pdf","paperhash":"anonymous|overlapping_community_detection_with_graph_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019overlapping,    \ntitle={Overlapping Community Detection with Graph Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HklQxnC5tX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJx7l309Fm","original":"BkeIiSa5Ym","number":1062,"cdate":1538087915281,"ddate":null,"tcdate":1538087915281,"tmdate":1538155999253,"tddate":null,"forum":"HJx7l309Fm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Actor-Attention-Critic for Multi-Agent Reinforcement Learning","abstract":"Reinforcement learning in multi-agent scenarios is important for real-world applications but presents challenges beyond those seen in single-agent settings. We present an actor-critic algorithm that trains decentralized policies in multi-agent settings, using centrally computed critics that share an attention mechanism which selects relevant information for each agent at every timestep. This attention mechanism enables more effective and scalable learning in complex multi-agent environments, when compared to recent approaches. Our approach is applicable not only to cooperative settings with shared rewards, but also individualized reward settings, including adversarial settings, and it makes no assumptions about the action spaces of the agents. As such, it is flexible enough to be applied to most multi-agent learning problems","keywords":["multi-agent","reinforcement learning","attention","actor-critic"],"authorids":["ICLR.cc/2019/Conference/Paper1062/Authors"],"authors":["Anonymous"],"TL;DR":"We propose an approach to learn decentralized policies in multi-agent settings using attention-based critics and demonstrate promising results in environments with complex interactions.","pdf":"/pdf/2ebfcebe70c8d3519933eadd9cd0021cd126b555.pdf","paperhash":"anonymous|actorattentioncritic_for_multiagent_reinforcement_learning","_bibtex":"@inproceedings{    \nanonymous2019actor-attention-critic,    \ntitle={Actor-Attention-Critic for Multi-Agent Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJx7l309Fm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SkMQg3C5K7","original":"Hyg4r_a5FQ","number":1063,"cdate":1538087915459,"ddate":null,"tcdate":1538087915459,"tmdate":1538155999042,"tddate":null,"forum":"SkMQg3C5K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A Convergence Analysis of Gradient Descent for Deep Linear Neural Networks","abstract":"We analyze speed of convergence to global optimum for gradient descent training a deep linear neural network by minimizing the L2 loss over whitened data.  Convergence at a linear rate is guaranteed when the following hold: (i) dimensions of hidden layers are at least the minimum of the input and output dimensions; (ii) weight matrices at initialization are approximately balanced; and (iii) the initial loss is smaller than the loss of any rank-deficient solution.  The assumptions on initialization (conditions (ii) and (iii)) are necessary, in the sense that violating any one of them may lead to convergence failure.  Moreover, in the important case of output dimension 1, i.e. scalar regression, they are met, and thus convergence to global optimum holds, with constant probability under a random initialization scheme.  Our results significantly extend previous analyses, e.g., of deep linear residual networks (Bartlett et al., 2018).","keywords":["Deep Learning","Learning Theory","Non-Convex Optimization"],"authorids":["ICLR.cc/2019/Conference/Paper1063/Authors"],"authors":["Anonymous"],"TL;DR":"We analyze gradient descent for deep linear neural networks, providing a guarantee of convergence to global optimum at a linear rate.","pdf":"/pdf/fc6794cc8c53de6a63eb60587e8ec8ad36dedb7e.pdf","paperhash":"anonymous|a_convergence_analysis_of_gradient_descent_for_deep_linear_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A Convergence Analysis of Gradient Descent for Deep Linear Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkMQg3C5K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hke4l2AcKQ","original":"HyxEZna9Y7","number":1064,"cdate":1538087915631,"ddate":null,"tcdate":1538087915631,"tmdate":1538155998830,"tddate":null,"forum":"Hke4l2AcKQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders","abstract":"Variational Autoencoder (VAE), a simple and effective deep generative model, has led to a number of impressive empirical successes and spawned many advanced variants and theoretical investigations. However, recent studies demonstrate that, when equipped with expressive generative distributions (aka. decoders), VAE suffers from learning uninformative latent representations with the observation called KL Varnishing, in which case VAE collapses into an unconditional generative model. In this work, we introduce mutual posterior-divergence regularization, a novel regularization that is able to control the geometry of the latent space to accomplish meaningful representation learning, while achieving comparable or superior capability of density estimation.Experiments on three image benchmark datasets demonstrate that, when equipped with powerful decoders, our model performs well both on density estimation and representation learning.","keywords":["VAE","regularization","auto-regressive"],"authorids":["ICLR.cc/2019/Conference/Paper1064/Authors"],"authors":["Anonymous"],"pdf":"/pdf/13103aac1ba6da07ca7fe2b62499e13179ded8a6.pdf","paperhash":"anonymous|mae_mutual_posteriordivergence_regularization_for_variational_autoencoders","_bibtex":"@inproceedings{    \nanonymous2019mae:,    \ntitle={MAE: Mutual Posterior-Divergence Regularization for Variational AutoEncoders},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hke4l2AcKQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJgEl3A5tm","original":"HylNL_sqtm","number":1065,"cdate":1538087915793,"ddate":null,"tcdate":1538087915793,"tmdate":1538155998617,"tddate":null,"forum":"SJgEl3A5tm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"CAMOU: Learning Physical Vehicle Camouflages to Adversarially Attack Detectors in the Wild","abstract":"In this paper, we conduct an interesting experimental study about the physical adversarial attack on object detectors in the wild. In particular, we learn  a camouflage pattern to hide vehicles from being detected by state-of-the-art convolutional neural network based detectors. Our approach alternates between two threads. In the first, we train a neural approximation function to imitate how a simulator applies camouflages to vehicles and how a vehicle detector performs given an image generated by the simulator. In the second, we minimize the approximated detection score by searching for the optimal camouflage. Experiments show that the learned camouflage can not only hide a vehicle from the image-based detectors under many cases, but also generalizes to different environments, vehicles, and object detectors. ","keywords":["Adversarial Attack","Object Detection","Synthetic Simulation"],"authorids":["ICLR.cc/2019/Conference/Paper1065/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a method to learn physical vehicle camouflage to adversarially attack object detectors in the wild. We find our camouflage effective and transferable.","pdf":"/pdf/428696911c2d60bf951f3f2072f3a8fabaec01e1.pdf","paperhash":"anonymous|camou_learning_physical_vehicle_camouflages_to_adversarially_attack_detectors_in_the_wild","_bibtex":"@inproceedings{    \nanonymous2019camou:,    \ntitle={CAMOU: Learning Physical Vehicle Camouflages to Adversarially Attack Detectors in the Wild},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJgEl3A5tm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rye4g3AqFm","original":"SylX2xAcFQ","number":1066,"cdate":1538087915957,"ddate":null,"tcdate":1538087915957,"tmdate":1538155998403,"tddate":null,"forum":"rye4g3AqFm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Deep learning generalizes because the parameter-function map is biased towards simple functions","abstract":"Deep neural networks generalize remarkably well without explicit regularization even in the strongly over-parametrized regime. This success suggests that some form of implicit regularization must be at work. In this paper we argue that a strong intrinsic bias in the parameter-function map helps explain the success of deep neural networks. We provide evidence that the parameter-function map results in a heavily biased prior over functions, if we assume that the training algorithm samples parameters close to uniformly within the zero-error region. The PAC-Bayes theorem then guarantees good expected generalization for target functions producing high-likelihood training sets.\nWe exploit connections between deep neural networks and Gaussian processes to estimate the marginal likelihood, finding remarkably good agreement between Gaussian processes and neural networks for small input sets.  Using approximate marginal likelihood calculations we produce nontrivial generalization PAC-Bayes error bounds which correlate well with the true error on realistic datasets such as MNIST and CIFAR and for architectures including convolutional and fully connected networks.\nAs predicted by recent arguments based on algorithmic information theory, we find that the prior probability drops exponentially with linear increases in several measures of descriptional complexity of the target function. As target functions in many real problems are expected to be highly structured, this simplicity bias offers an insight into why deep networks generalize well on real world problems, but badly on randomized data.","keywords":["generalization","deep learning theory","PAC-Bayes","Gaussian processes","parameter-function map","simplicity bias"],"authorids":["ICLR.cc/2019/Conference/Paper1066/Authors"],"authors":["Anonymous"],"TL;DR":"The parameter-function map of deep networks is hugely biased; this can explain why they generalize. We use PAC-Bayes and Gaussian processes to obtain nonvacuous bounds.","pdf":"/pdf/40f5dd65fc08ce4577d52189fa8b8a0961e7fc30.pdf","paperhash":"anonymous|deep_learning_generalizes_because_the_parameterfunction_map_is_biased_towards_simple_functions","_bibtex":"@inproceedings{    \nanonymous2019deep,    \ntitle={Deep learning generalizes because the parameter-function map is biased towards simple functions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rye4g3AqFm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1x4ghC9tQ","original":"BJef8Ln9Y7","number":1067,"cdate":1538087916133,"ddate":null,"tcdate":1538087916133,"tmdate":1538155998190,"tddate":null,"forum":"S1x4ghC9tQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Temporal Difference Variational Auto-Encoder","abstract":"To act and plan in complex environments, we posit that agents should have a mental simulator of the world with three characteristics: (a) it should build an abstract state representing the condition of the world; (b) it should form a belief which represents uncertainty on the world; (c) it should go beyond simple step-by-step simulation, and exhibit temporal abstraction. Motivated by the absence of a model satisfying all these requirements, we propose TD-VAE, a generative sequence model that learns representations containing explicit beliefs about states several steps into the future, and that can be rolled out directly without single-step transitions. TD-VAE is trained on pairs of temporally separated time points, using an analogue of temporal difference learning used in reinforcement learning.","keywords":["generative models","variational auto-encoders","state space models","temporal difference learning"],"authorids":["ICLR.cc/2019/Conference/Paper1067/Authors"],"authors":["Anonymous"],"TL;DR":"Generative model of temporal data, that builds online belief state, operates in latent space, does jumpy predictions and rollouts of states.","pdf":"/pdf/b717515b9441e50f0c7daf570e682e1813688dc8.pdf","paperhash":"anonymous|temporal_difference_variational_autoencoder","_bibtex":"@inproceedings{    \nanonymous2019temporal,    \ntitle={Temporal Difference Variational Auto-Encoder},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1x4ghC9tQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BkgVx3A9Km","original":"rkltHvn9FX","number":1068,"cdate":1538087916308,"ddate":null,"tcdate":1538087916308,"tmdate":1538155997979,"tddate":null,"forum":"BkgVx3A9Km","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A More Globally Accurate Dimensionality Reduction Method Using Triplets","abstract":"We first show that the commonly used dimensionality reduction (DR) methods such as t-SNE and LargeVis\npoorly capture the global structure of the data in the low dimensional embedding. We show this via a number of tests for the DR methods that can be easily applied by any practitioner to the dataset at hand. Surprisingly enough, t-SNE performs the best w.r.t. the commonly used measures that reward the local neighborhood accuracy such as precision-recall while having the worst performance in our tests for global structure. We then contrast the performance of these two DR method\nagainst our new method called TriMap. The main idea behind TriMap is to capture higher orders of structure with triplet information (instead of pairwise information used by t-SNE and LargeVis), and to minimize a robust loss function for satisfying the chosen triplets. We provide compelling experimental evidence on large natural datasets for the clear advantage of the TriMap DR results. As LargeVis, TriMap is fast and scales linearly with the number of data points.","keywords":["Dimensionality Reduction","Visualization","Triplets","t-SNE","LargeVis"],"authorids":["ICLR.cc/2019/Conference/Paper1068/Authors"],"authors":["Anonymous"],"TL;DR":"A new dimensionality reduction method using triplets which is significantly faster than t-SNE and provides more accurate results globally","pdf":"/pdf/ded77a65ddcb04e3fbe8c8fbf1a97f3a9c372ae4.pdf","paperhash":"anonymous|a_more_globally_accurate_dimensionality_reduction_method_using_triplets","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A More Globally Accurate Dimensionality Reduction Method Using Triplets},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkgVx3A9Km},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1eVe2AqKX","original":"SJlL4lA5tm","number":1069,"cdate":1538087916468,"ddate":null,"tcdate":1538087916468,"tmdate":1538155997767,"tddate":null,"forum":"S1eVe2AqKX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"PCNN: Environment Adaptive Model Without Finetuning","abstract":"Convolutional Neural Networks (CNNs) have achieved tremendous success for many computer vision tasks, which shows a promising perspective of deploying CNNs on mobile platforms. An obstacle to this promising perspective is the tension between intensive resource consumption of CNNs and limited resource budget on mobile platforms. Existing works generally utilize a simpler architecture with lower accuracy for a higher energy-efficiency, \\textit{i.e.}, trading accuracy for resource consumption. An emerging opportunity to both increasing accuracy and decreasing resource consumption is \\textbf{class skew}, \\textit{i.e.}, the strong temporal and spatial locality of the appearance of classes. However, it is challenging to efficiently utilize the class skew due to both the frequent switches and the huge number of class skews. Existing works use transfer learning to adapt the model towards the class skew during runtime, which consumes resource intensively. In this paper, we propose \\textbf{probability layer}, an \\textit{easily-implemented and highly flexible add-on module} to adapt the model efficiently during runtime \\textit{without any fine-tuning} and achieving an \\textit{equivalent or better} performance than transfer learning. Further, both \\textit{increasing accuracy} and \\textit{decreasing resource consumption} can be achieved during runtime through the combination of probability layer and pruning methods.","keywords":["Class skew","Runtime adaption"],"authorids":["ICLR.cc/2019/Conference/Paper1069/Authors"],"authors":["Anonymous"],"pdf":"/pdf/0433eaef5167e45b9043bdbdd544454d1fba6239.pdf","paperhash":"anonymous|pcnn_environment_adaptive_model_without_finetuning","_bibtex":"@inproceedings{    \nanonymous2019pcnn:,    \ntitle={PCNN: Environment Adaptive Model Without Finetuning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1eVe2AqKX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1gBgnR9Y7","original":"BklI_1ccYm","number":1070,"cdate":1538087916639,"ddate":null,"tcdate":1538087916639,"tmdate":1538155997558,"tddate":null,"forum":"S1gBgnR9Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"End-to-end learning of pharmacological assays from high-resolution microscopy images","abstract":"Predicting the outcome of pharmacological assays based on high-resolution microscopy\nimages of treated cells is a crucial task in drug discovery which tremendously\nincreases discovery rates. However, end-to-end learning on these images\nwith convolutional neural networks (CNNs) has not been ventured for this task\nbecause it has been considered infeasible and overly complex. On the largest\navailable public dataset, we compare several state-of-the-art CNNs trained in an\nend-to-end fashion with models based on a cell-centric approach involving segmentation.\nWe found that CNNs operating on full images containing hundreds\nof cells perform significantly better at assay prediction than networks operating\non a single-cell level. Surprisingly, we could predict 29% of the 209 pharmacological\nassays at high predictive performance (AUC > 0.9). We compared a\nnovel CNN architecture called “GapNet” against four competing CNN architectures\nand found that it performs on par with the best methods and at the same time\nhas the lowest training time. Our results demonstrate that end-to-end learning on\nhigh-resolution imaging data is not only possible but even outperforms cell-centric\nand segmentation-dependent approaches. Hence, the costly cell segmentation and\nfeature extraction steps are not necessary, in fact they even hamper predictive performance.\nOur work further suggests that many pharmacological assays could\nbe replaced by high-resolution microscopy imaging together with convolutional\nneural networks.","keywords":["Convolutional Neural Networks","High-resolution images","Multiple-Instance Learning","Drug Discovery","Molecular Biology"],"authorids":["ICLR.cc/2019/Conference/Paper1070/Authors"],"authors":["Anonymous"],"pdf":"/pdf/38186950e7fe170b684f76f2355b2e60da84b050.pdf","paperhash":"anonymous|endtoend_learning_of_pharmacological_assays_from_highresolution_microscopy_images","_bibtex":"@inproceedings{    \nanonymous2019end-to-end,    \ntitle={End-to-end learning of pharmacological assays from high-resolution microscopy images},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1gBgnR9Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1eSg3C9Ym","original":"B1esaA55t7","number":1071,"cdate":1538087916806,"ddate":null,"tcdate":1538087916806,"tmdate":1538155997353,"tddate":null,"forum":"B1eSg3C9Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"MEAN-FIELD ANALYSIS OF BATCH NORMALIZATION","abstract":"Batch Normalization (BatchNorm) is an extremely useful component of modern neural network architectures, enabling optimization using higher learning rates and achieving faster convergence. In this paper, we use mean-field theory to analytically quantify the impact of BatchNorm on the geometry of the loss landscape for multi-layer networks consisting of fully-connected and convolutional layers. We show that it has a flattening effect on the loss landscape, as quantified by the maximum eigenvalue of the Fisher Information Matrix. These findings are then used to justify the use of larger learning rates for networks that use BatchNorm, and we provide quantitative characterization of the maximal allowable learning rate to ensure convergence. Experiments support our theoretically predicted maximum learning rate, and furthermore suggest that networks with smaller values of the BatchNorm parameter achieve lower loss after the same number of epochs of training.","keywords":["neural networks","optimization","batch normalization","mean field theory","Fisher information"],"authorids":["ICLR.cc/2019/Conference/Paper1071/Authors"],"authors":["Anonymous"],"pdf":"/pdf/21d067f9263e397a49f392c9822d7e4e706613f7.pdf","paperhash":"anonymous|meanfield_analysis_of_batch_normalization","_bibtex":"@inproceedings{    \nanonymous2019mean-field,    \ntitle={MEAN-FIELD ANALYSIS OF BATCH NORMALIZATION},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1eSg3C9Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Bygre3R9Fm","original":"r1ltVLT9t7","number":1072,"cdate":1538087916972,"ddate":null,"tcdate":1538087916972,"tmdate":1538155997144,"tddate":null,"forum":"Bygre3R9Fm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"DEFactor: Differentiable Edge Factorization-based Probabilistic Graph Generation","abstract":"Generating novel molecules with optimal properties is a crucial step in many industries such as drug discovery. Recently, deep generative models have shown a promising way of performing de-novo molecular design.  Although graph generative models are currently available they are either computationally expensive, limiting their use to only small graphs or are formulated as a sequence of discrete actions needed to construct a graph, making the output graph non-differentiable w.r.t the model parameters, therefore preventing them to be used in scenarios such as conditional graph generation. In this work we propose a model for conditional graph generation that is computationally cheap, scalable, directly optimises properties of the graph, and generates a probabilistic graph, making the process differentiable, thus enabling end-to-end training with stochastic gradient descent. We demonstrate favourable performance of our model on prototype-based molecular graph conditional generation tasks.","keywords":["molecular graphs","conditional autoencoder","graph autoencoder"],"authorids":["ICLR.cc/2019/Conference/Paper1072/Authors"],"authors":["Anonymous"],"TL;DR":"New scalable graph decoding scheme that allows to perform direct molecular graph conditional generation.","pdf":"/pdf/3efa5eccc28cdb86ce18e9edefdf71398dcf206c.pdf","paperhash":"anonymous|defactor_differentiable_edge_factorizationbased_probabilistic_graph_generation","_bibtex":"@inproceedings{    \nanonymous2019defactor:,    \ntitle={DEFactor: Differentiable Edge Factorization-based Probabilistic Graph Generation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bygre3R9Fm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJzSgnRcKX","original":"S1g4wRncYX","number":1073,"cdate":1538087917134,"ddate":null,"tcdate":1538087917134,"tmdate":1538155996933,"tddate":null,"forum":"SJzSgnRcKX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"What do you learn from context? Probing for sentence structure in contextualized word representations","abstract":"Contextualized representation models such as CoVe (McCann et al., 2017) and\nELMo (Peters et al., 2018a) have recently achieved state-of-the-art results on a\ndiverse array of downstream NLP tasks. Building on recent token-level probing\nwork, we introduce a novel edge probing task design and construct a broad suite of\nsub-sentence tasks derived from the traditional structured NLP pipeline. We probe\nword-level contextual representations from three recent models and investigate\nhow they encode sentence structure across a range of syntactic, semantic, local,\nand long-range phenomena. We find that ELMo encodes linguistic structure at the\nword level better than other comparable models, and that existing models trained\non language modeling and translation produce strong representations for syntactic\nphenomena, but only offer small improvements on semantic tasks over a noncontextual\nbaseline.","keywords":["natural language processing","word embeddings","transfer learning","interpretability"],"authorids":["ICLR.cc/2019/Conference/Paper1073/Authors"],"authors":["Anonymous"],"TL;DR":"We probe for sentence structure in ELMo and related contextual embedding models. We find existing models efficiently encode syntax and show evidence of long-range dependencies, but only offer small improvements on semantic tasks.","pdf":"/pdf/35761ae4ea30b9110fdc2db7537f6a9d1ecc2937.pdf","paperhash":"anonymous|what_do_you_learn_from_context_probing_for_sentence_structure_in_contextualized_word_representations","_bibtex":"@inproceedings{    \nanonymous2019what,    \ntitle={What do you learn from context? Probing for sentence structure in contextualized word representations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJzSgnRcKX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJfHg2A5tQ","original":"rJlHTlR5YX","number":1074,"cdate":1538087917301,"ddate":null,"tcdate":1538087917301,"tmdate":1538155996721,"tddate":null,"forum":"SJfHg2A5tQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"BNN+: Improved Binary Network Training","abstract":"Deep neural networks (DNN) are widely used in many applications. However, their deployment on edge devices has been difficult because they are resource hungry. Binary networks (BNN) help to alleviate the prohibitive resource requirements of DNN; where both activations and weights are limited to one bit. We propose an improved binary training method (BNN+), an improvement to the popular BNN training scheme, which helps to reduce accuracy degradation compared to the full-precision counterpart.  Our method is based on linear operations that are easily implementable into the binary training framework and we show experimental results on CIFAR-10 obtaining an accuracy of 86.5%, on AlexNet and 91.6% with VGG network. On ImageNet, our method also outperforms the traditional BNN and XNOR-net, by a margin of 4% and 2% respectively. ","keywords":["Binary Network","Binary Training","Model Compression","Quantization"],"authorids":["ICLR.cc/2019/Conference/Paper1074/Authors"],"authors":["Anonymous"],"TL;DR":"The paper presents an improved training mechanism for obtaining binary networks with smaller accuracy drop compared that helps close the gap with it's full precision counterpart","pdf":"/pdf/e20ebacde5c4438d872e8b89418945b4e5ceb63b.pdf","paperhash":"anonymous|bnn_improved_binary_network_training","_bibtex":"@inproceedings{    \nanonymous2019bnn+:,    \ntitle={BNN+: Improved Binary Network Training},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJfHg2A5tQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SkNSehA9FQ","original":"S1eIqMn9t7","number":1075,"cdate":1538087917466,"ddate":null,"tcdate":1538087917466,"tmdate":1538155996508,"tddate":null,"forum":"SkNSehA9FQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Open Vocabulary Learning on Source Code with a Graph-Structured Cache","abstract":"Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names.  Reasoning over such a vocabulary is not something for which most NLP methods are designed.  We introduce a Graph-Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code.  We find that combining this graph-structured cache strategy with recent Graph-Neural-Network-based models for supervised learning on code improves the models' performance on a code completion task and a variable naming task --- with over 100\\% relative improvement on the latter --- at the cost of a moderate increase in computation time.","keywords":["deep learning","graph neural network","open vocabulary","natural language processing","source code","abstract syntax tree","code completion","variable naming"],"authorids":["ICLR.cc/2019/Conference/Paper1075/Authors"],"authors":["Anonymous"],"TL;DR":"We show that caching out-of-vocabulary words in a graph, with edges connecting them to their usages, and processing it with a graph neural network improves performance on supervised learning tasks on computer source code.","pdf":"/pdf/8234196380aff2e27c76bfdd893de383a1f23370.pdf","paperhash":"anonymous|open_vocabulary_learning_on_source_code_with_a_graphstructured_cache","_bibtex":"@inproceedings{    \nanonymous2019open,    \ntitle={Open Vocabulary Learning on Source Code with a Graph-Structured Cache},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkNSehA9FQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkx8l3Cctm","original":"rygv5JeFKX","number":1076,"cdate":1538087917651,"ddate":null,"tcdate":1538087917651,"tmdate":1538155996299,"tddate":null,"forum":"rkx8l3Cctm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Safe Policy Learning from Observations","abstract":"In this paper, we consider the problem of learning a policy by observing numerous non-expert agents. Our goal is to extract a policy that, with high-confidence, acts better than the agents' average performance. Such a setting is important for real-world problems where expert data is scarce but non-expert data can easily be obtained, e.g. by crowdsourcing. Our approach is to pose this problem as safe policy improvement in reinforcement learning. First, we evaluate an average behavior policy and approximate its value function. Then, we develop a stochastic policy improvement algorithm that safely improves the average behavior. The primary advantages of our approach, termed Rerouted Behavior Improvement (RBI), over other safe learning methods are its stability in the presence of value estimation errors and the elimination of a policy search process.  We demonstrate these advantages in the Taxi grid-world domain and in four games from the Atari learning environment.","keywords":["learning from observations","safe reinforcement learning","deep reinforcement learning"],"authorids":["ICLR.cc/2019/Conference/Paper1076/Authors"],"authors":["Anonymous"],"TL;DR":"An algorithm for learning to improve upon the behavior demonstrated by multiple unknown policies, by combining imitation learning and a novel safe policy improvement step that is resilient to value estimation errors.","pdf":"/pdf/f367ad02843dafcc859c695433f2f091ec2c8d3f.pdf","paperhash":"anonymous|safe_policy_learning_from_observations","_bibtex":"@inproceedings{    \nanonymous2019safe,    \ntitle={Safe Policy Learning from Observations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkx8l3Cctm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ByxLl309Ym","original":"HkgomVn5tQ","number":1077,"cdate":1538087917817,"ddate":null,"tcdate":1538087917817,"tmdate":1538155996088,"tddate":null,"forum":"ByxLl309Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Conditional Inference in Pre-trained Variational Autoencoders via Cross-coding","abstract":"Variational Autoencoders (VAEs) are a popular generative model, but one in which conditional inference can be challenging. If the decomposition into query and evidence variables is fixed, conditional VAEs provide an attractive solution. To support arbitrary queries, one is generally reduced to Markov Chain Monte Carlo sampling methods that  can suffer from long mixing times.  In this paper, we propose an idea we term cross-coding to approximate the distribution over the latent variables after conditioning on an evidence assignment to some subset of the variables. This allows generating query samples without retraining the full VAE.  We experimentally evaluate three variations of cross-coding showing that (i) can be quickly optimized for different decompositions of evidence and query and (ii) they quantitatively and qualitatively outperform Hamiltonian Monte Carlo.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1077/Authors"],"authors":["Anonymous"],"pdf":"/pdf/2acbda5f3f5a9ca4de0b727c8e5892acaea113cd.pdf","paperhash":"anonymous|conditional_inference_in_pretrained_variational_autoencoders_via_crosscoding","_bibtex":"@inproceedings{    \nanonymous2019conditional,    \ntitle={Conditional Inference in Pre-trained Variational Autoencoders via Cross-coding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByxLl309Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SygLehCqtm","original":"ryxRA6n5FQ","number":1078,"cdate":1538087917980,"ddate":null,"tcdate":1538087917980,"tmdate":1538155995879,"tddate":null,"forum":"SygLehCqtm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning protein sequence embeddings using information from structure","abstract":"Inferring structural properties of a protein given only its amino acid sequence is a challenging problem. Existing approaches based solely on sequence are unable to recognize and exploit structural patterns when sequences have diverged too far. We introduce a novel framework for infusing structural information into position-specific representations of protein sequences. We train bidirectional long short-term memory (LSTM) models on protein sequences with a two-part feedback mechanism to incorporate (i) pairwise residue contact maps for individual proteins and (ii) co-membership in structural categories based on a curated database (SCOPe). For co-membership, we introduce soft symmetric alignment (SSA) between sequences of vector embeddings. We show empirically that our approach outperforms existing direct sequence alignment methods and also a structure-based alignment method when predicting structural similarity. SSA also enables learning informative position-specific embeddings even when no residue level supervision is available. Finally, we demonstrate that the learned embeddings can be transferred to other protein sequence problems, improving state-of-the-art in transmembrane domain prediction.","keywords":["sequence embedding","sequence alignment","RNN","LSTM","protein structure","amino acid sequence","contextual embeddings","transmembrane prediction"],"authorids":["ICLR.cc/2019/Conference/Paper1078/Authors"],"authors":["Anonymous"],"TL;DR":"We present a method for learning protein sequence embedding models using structural information in the form of global structural similarity between proteins and within protein residue-residue contacts.","pdf":"/pdf/807475e1b3357b96b8c16a8122b84d25a75bee9d.pdf","paperhash":"anonymous|learning_protein_sequence_embeddings_using_information_from_structure","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning protein sequence embeddings using information from structure},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SygLehCqtm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyGLg2C9K7","original":"SylrRxActm","number":1079,"cdate":1538087918155,"ddate":null,"tcdate":1538087918155,"tmdate":1538155995637,"tddate":null,"forum":"HyGLg2C9K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"How Training Data Affect the Accuracy and Robustness of Neural Networks for Image Classification","abstract":"Recent work has demonstrated the lack of robustness of well-trained deep neural networks (DNNs) to adversarial examples.  For example, visually indistinguishable perturbations, when mixed with an original image, can easily lead deep learning models to misclassifications.  In light of a recent study on the mutual influence between robustness and accuracy over 18 different ImageNet models, this paper investigates how training data affect the accuracy and robustness of deep neural\nnetworks. We conduct extensive experiments on four different datasets, including CIFAR-10, MNIST, STL-10, and Tiny ImageNet, with several representative neural networks. Our results reveal previously unknown phenomena that exist between the size of training data and characteristics of the resulting models. In particular, besides confirming that the model accuracy improves as the amount of training data increases, we also observe that the model robustness improves initially, but there exists a turning point after which robustness starts to deteriorate.  How and when such turning points occur vary for different neural networks and different datasets.","keywords":["Adversarial attacks","Robustness","CW","I-FGSM"],"authorids":["ICLR.cc/2019/Conference/Paper1079/Authors"],"authors":["Anonymous"],"pdf":"/pdf/afbc083efb9253ee20f25651950c74d87d78c52f.pdf","paperhash":"anonymous|how_training_data_affect_the_accuracy_and_robustness_of_neural_networks_for_image_classification","_bibtex":"@inproceedings{    \nanonymous2019how,    \ntitle={How Training Data Affect the Accuracy and Robustness of Neural Networks for Image Classification},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyGLg2C9K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJgLg3R9KQ","original":"HJemiu39K7","number":1080,"cdate":1538087918315,"ddate":null,"tcdate":1538087918315,"tmdate":1538155995439,"tddate":null,"forum":"BJgLg3R9KQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning what and where to attend with humans in the loop","abstract":" Most recent gains in visual recognition have originated from the incorporation of attention mechanisms in deep convolutional networks (DCNs). Because these networks are optimized for object recognition, they learn where to attend using only a weak form of supervision derived from image class labels. Here, we demonstrate the benefit of using stronger supervisory signals by teaching DCNs to attend to image regions that humans deem important for object recognition. We first describe a large-scale online experiment (ClickMe) used to supplement ImageNet with nearly half a million human-derived \"top-down\" attention maps. Using human psychophysics, we confirm that the identified \"top-down\" features from ClickMe are more diagnostic than \"bottom-up\" features for rapid image categorization. As a proof of concept, we extend a state-of-the-art attention network and demonstrate that adding humans-in-the-loop with ClickMe supervision significantly improves its accuracy, while also yielding visual features that are more interpretable and more similar to those used by human observers.","keywords":["Attention models","human feature importance","object recognition","cognitive science"],"authorids":["ICLR.cc/2019/Conference/Paper1080/Authors"],"authors":["Anonymous"],"TL;DR":"A large-scale dataset for training attention models for object recognition leads to more accurate, interpretable, and human-like object recognition.","pdf":"/pdf/67ab40eb7162e341d7ee1d1ec2079d9fc0d89bda.pdf","paperhash":"anonymous|learning_what_and_where_to_attend_with_humans_in_the_loop","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning what and where to attend with humans in the loop},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgLg3R9KQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJl8gnAqtX","original":"SkeKwpQuKX","number":1081,"cdate":1538087918482,"ddate":null,"tcdate":1538087918482,"tmdate":1538155995241,"tddate":null,"forum":"SJl8gnAqtX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring","abstract":"We propose a new application of embedding techniques to problem retrieval in adaptive tutoring. The objective is to retrieve problems similar in mathematical concepts. There are two challenges: First, like sentences, problems helpful to tutoring are never exactly the same in terms of the underlying concepts. Instead, good problems mix concepts in innovative ways, while still displaying continuity in their relationships. Second, it is difficult for humans to determine a similarity score consistent across a large enough training set. We propose a hierarchical problem embedding algorithm, called Prob2Vec, that consists of an abstraction and an embedding step. Prob2Vec achieves 96.88\\% accuracy on a problem similarity test, in contrast to 75\\% from directly applying state-of-the-art sentence embedding methods. It is surprising that Prob2Vec is able to distinguish very fine-grained differences among problems, an ability humans need time and effort to acquire. In addition, the sub-problem of concept labeling with imbalanced training data set is interesting in its own right. It is a multi-label problem suffering from dimensionality explosion, which we propose ways to ameliorate. We propose the novel negative pre-training algorithm that dramatically reduces false negative and positive ratios for classification, using an imbalanced training data set.","keywords":["personalized learning","e-learning","text embedding","Skip-gram","imbalanced data set","data level classification methods"],"authorids":["ICLR.cc/2019/Conference/Paper1081/Authors"],"authors":["Anonymous"],"TL;DR":"We propose the Prob2Vec method for problem embedding used in a personalized e-learning tool in addition to a data level classification method, called negative pre-training, for cases where the training data set is imbalanced.","pdf":"/pdf/94550a8d889861f60e4f5d79a43db74c8cb7ba7a.pdf","paperhash":"anonymous|prob2vec_mathematical_semantic_embedding_for_problem_retrieval_in_adaptive_tutoring","_bibtex":"@inproceedings{    \nanonymous2019prob2vec:,    \ntitle={Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJl8gnAqtX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJgvg30ctX","original":"HJxeyZRqKQ","number":1082,"cdate":1538087918653,"ddate":null,"tcdate":1538087918653,"tmdate":1538155995039,"tddate":null,"forum":"BJgvg30ctX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Information Regularized Neural Networks","abstract":"We formulate an information-based optimization problem for supervised classification. For invertible neural networks, the control of these information terms is passed down to the latent features and parameter matrix in the last fully connected layer, given that mutual information is invariant under invertible map.  We propose an objective function and prove that it solves the optimization problem. Our framework allows us to learn latent features in an more interpretable form while improving the classification performance. We perform extensive quantitative and qualitative experiments in comparison with the existing state-of-the-art classification models.","keywords":["supervised classification","information theory","deep learning","regularization"],"authorids":["ICLR.cc/2019/Conference/Paper1082/Authors"],"authors":["Anonymous"],"TL;DR":"we propose a regularizer that improves the classification performance of neural networks","pdf":"/pdf/c2467c3a358b3cca4accfb1dca86d3459c62b0d7.pdf","paperhash":"anonymous|information_regularized_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019information,    \ntitle={Information Regularized Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgvg30ctX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyxPx3R9tm","original":"rkgyNUnct7","number":1083,"cdate":1538087918820,"ddate":null,"tcdate":1538087918820,"tmdate":1538155994829,"tddate":null,"forum":"HyxPx3R9tm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow","abstract":"Adversarial learning methods have been proposed for a wide range of applications, but the training of adversarial models can be notoriously unstable. Effectively balancing the performance of the generator and discriminator is critical, since a discriminator that achieves very high accuracy will produce relatively uninformative gradients. In this work, we propose a simple and general technique to constrain information flow in the discriminator by means of an information bottleneck. By enforcing a constraint on the mutual information between the observations and the discriminator's internal representation, we can effectively modulate the discriminator's accuracy and maintain useful and informative gradients. We demonstrate that our proposed variational discriminator bottleneck (VDB) leads to significant improvements across three distinct application areas for adversarial learning algorithms. Our primary evaluation studies the applicability of the VDB to imitation learning of dynamic continuous control skills, such as running. We show that our method can learn such skills directly from raw video demonstrations, substantially outperforming prior adversarial imitation learning methods. The VDB can also be combined with adversarial inverse reinforcement learning to learn parsimonious reward functions that can be transferred and re-optimized in new settings. Finally, we demonstrate that VDB can train GANs more effectively for image generation, improving upon a number of prior stabilization methods.","keywords":["reinforcement learning","generative adversarial networks","imitation learning","inverse reinforcement learning","information bottleneck"],"authorids":["ICLR.cc/2019/Conference/Paper1083/Authors"],"authors":["Anonymous"],"TL;DR":"Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.","pdf":"/pdf/7e0649b2d8ac29a50096f52c599802f0ab209a77.pdf","paperhash":"anonymous|variational_discriminator_bottleneck_improving_imitation_learning_inverse_rl_and_gans_by_constraining_information_flow","_bibtex":"@inproceedings{    \nanonymous2019variational,    \ntitle={Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyxPx3R9tm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1gDgn0qY7","original":"BylPJZCcYm","number":1084,"cdate":1538087918995,"ddate":null,"tcdate":1538087918995,"tmdate":1538155994625,"tddate":null,"forum":"H1gDgn0qY7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A Study of Robustness of Neural Nets Using Approximate Feature Collisions","abstract":"In recent years, various studies have focused on the robustness of neural nets. While it is known that neural nets are not robust to examples with adversarially chosen perturbations as a result of linear operations on the input data, we show in this paper there could be a convex polytope within which all examples are misclassified by neural nets due to the properties of ReLU activation functions. We propose a way to finding such polytopes empirically and demonstrate that such polytopes exist in practice. Furthermore, we show that such polytopes exist even after constraining the examples to be a composition of image patches, resulting in perceptibly different examples at different locations in the polytope that are all misclassified. ","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1084/Authors"],"authors":["Anonymous"],"pdf":"/pdf/64fdaeefbe67621486b1f237e7fb5c315e1ee661.pdf","paperhash":"anonymous|a_study_of_robustness_of_neural_nets_using_approximate_feature_collisions","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A Study of Robustness of Neural Nets Using Approximate Feature Collisions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1gDgn0qY7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hygvln09K7","original":"SygkcCs9FQ","number":1085,"cdate":1538087919159,"ddate":null,"tcdate":1538087919159,"tmdate":1538155994423,"tddate":null,"forum":"Hygvln09K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Meta Learning with Fast/Slow Learners","abstract":"Meta-learning has recently achieved success in many optimization problems. In general, a meta learner g(.) could be learned for a base model f(.) on a variety of tasks, such that it can be more efficient on a new task. In this paper, we make some key modifications to enhance the performance of meta-learning models. (1) we leverage different meta-strategies for different modules to optimize them separately: we use conservative “slow learners” on low-level basic feature representation layers and “fast learners” on high-level task-specific layers; (2) Furthermore, we provide theoretical analysis on why the proposed approach works, based on a case study on a two-layer MLP. We evaluate our model on synthetic MLP regression, as well as low-shot learning tasks on Omniglot and ImageNet benchmarks. We demonstrate that our approach is able to achieve state-of-the-art performance.","keywords":["computer vision","meta learning"],"authorids":["ICLR.cc/2019/Conference/Paper1085/Authors"],"authors":["Anonymous"],"TL;DR":"We applied multiple meta-strategy to improve meta-learning performance on base CNNs. ","pdf":"/pdf/50464de80c7928c82c356173530565720a58249a.pdf","paperhash":"anonymous|meta_learning_with_fastslow_learners","_bibtex":"@inproceedings{    \nanonymous2019meta,    \ntitle={Meta Learning with Fast/Slow Learners},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hygvln09K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJGven05Y7","original":"ByeDzz65Ym","number":1086,"cdate":1538087919328,"ddate":null,"tcdate":1538087919328,"tmdate":1538155994212,"tddate":null,"forum":"HJGven05Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"How to train your MAML","abstract":"The field of few-shot learning has recently seen substantial advancements. Most of these advancements came from casting few-shot learning as a meta-learning problem.Model Agnostic Meta Learning or MAML is currently one of the best approaches for few-shot learning via meta-learning. MAML is simple, elegant and very powerful, however, it has a variety of issues, such as being very sensitive to neural network architectures, often leading to instability during training, requiring arduous hyperparameter searches to stabilize training and achieve high generalization and being very computationally expensive at both training and inference times. In this paper, we propose various modifications to MAML that not only stabilize the system, but also substantially improve the generalization performance, convergence speed and computational overhead of MAML, which we call MAML++.","keywords":["meta-learning","deep-learning","few-shot learning","supervised learning","neural-networks","stochastic optimization"],"authorids":["ICLR.cc/2019/Conference/Paper1086/Authors"],"authors":["Anonymous"],"TL;DR":"MAML is great, but it has many problems, we solve many of those problems and as a result we learn most hyper parameters end to end, speed-up training and inference and set a new SOTA in few-shot learning","pdf":"/pdf/ab52191bdf94a242efadfff20f589a99a3898563.pdf","paperhash":"anonymous|how_to_train_your_maml","_bibtex":"@inproceedings{    \nanonymous2019how,    \ntitle={How to train your MAML},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJGven05Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJ4vlh0qtm","original":"S1g_FofFOX","number":1087,"cdate":1538087919491,"ddate":null,"tcdate":1538087919491,"tmdate":1538155994002,"tddate":null,"forum":"rJ4vlh0qtm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"SSoC: Learning Spontaneous and Self-Organizing Communication for Multi-Agent Collaboration","abstract":"Multi-agent collaboration is required by numerous real-world problems. Although distributed setting is usually adopted by practical systems, local range communication and information aggregation still matter in fulfilling complex tasks. For multi-agent reinforcement learning, many previous studies have been dedicated to design an effective communication architecture. However, existing models usually suffer from an ossified communication structure, e.g., most of them predefine a particular communication mode by specifying a fixed time frequency and spatial scope for agents to communicate regardless of necessity. Such design is incapable of dealing with multi-agent scenarios that are capricious and complicated, especially when only partial information is available. Motivated by this, we argue that the solution is to build a spontaneous and self-organizing communication (SSoC) learning scheme. By treating the communication behaviour as an explicit action, SSoC learns to organize communication in an effective and efficient way. Particularly, it enables each agent to spontaneously decide when and who to send messages based on its observed states. In this way, a dynamic inter-agent communication channel is established in an online and self-organizing manner. The agents also learn how to adaptively aggregate the received messages and its own hidden states to execute actions. Various experiments have been conducted to demonstrate that SSoC really learns intelligent message passing among agents located far apart. With such agile communications, we observe that effective collaboration tactics emerge which have not been mastered by the compared baselines.","keywords":["reinforcement learning","multi-agent learning","multi-agent communication","deep learning"],"authorids":["ICLR.cc/2019/Conference/Paper1087/Authors"],"authors":["Anonymous"],"TL;DR":"This paper proposes a spontaneous and self-organizing communication (SSoC) learning scheme for multi-agent RL tasks.","pdf":"/pdf/1099efbf8c05d5cb6ce83ac0a5bd18c5211a097c.pdf","paperhash":"anonymous|ssoc_learning_spontaneous_and_selforganizing_communication_for_multiagent_collaboration","_bibtex":"@inproceedings{    \nanonymous2019ssoc:,    \ntitle={SSoC: Learning Spontaneous and Self-Organizing Communication for Multi-Agent Collaboration},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJ4vlh0qtm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJgOl3AqY7","original":"SJgu0df_F7","number":1088,"cdate":1538087919664,"ddate":null,"tcdate":1538087919664,"tmdate":1538155993781,"tddate":null,"forum":"HJgOl3AqY7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Modulated Variational Auto-Encoders for Many-to-Many Musical Timbre Transfer","abstract":"Generative models have been successfully applied to image style transfer and domain translation. However, there is still a wide gap in the quality of results when learning such tasks on musical audio. Furthermore, most translation models only enable one-to-one or one-to-many transfer by relying on separate encoders or decoders and complex, computationally-heavy models. In this paper, we introduce the Modulated Variational auto-Encoders (MoVE) to perform musical timbre transfer. First, we define timbre transfer as applying parts of the auditory properties of a musical instrument onto another. We show that we can achieve and improve this task by conditioning existing domain translation techniques with Feature-wise Linear Modulation (FiLM). Then, by replacing the usual adversarial translation criterion by a Maximum Mean Discrepancy (MMD) objective, we alleviate the need for an auxiliary pair of discriminative networks. This allows a faster and more stable training, along with a controllable latent space encoder. By further conditioning our system on several different instruments, we can generalize to many-to-many transfer within a single variational architecture able to perform multi-domain transfers. Our models map inputs to 3-dimensional representations, successfully translating timbre from one instrument to another and supporting sound synthesis on a reduced set of control parameters. We evaluate our method in reconstruction and generation tasks while analyzing the auditory descriptor distributions across transferred domains. We show that this architecture incorporates generative controls in multi-domain transfer, yet remaining rather light, fast to train and effective on small datasets.","keywords":["Musical Timbre","Instrument Translation","Domain Translation","Style Transfer","Sound Synthesis","Musical Information","Deep Learning","Variational Auto-Encoder","Generative Models","Network Conditioning"],"authorids":["ICLR.cc/2019/Conference/Paper1088/Authors"],"authors":["Anonymous"],"TL;DR":"The paper uses Variational Auto-Encoding and network conditioning for Musical Timbre Transfer, we develop and generalize our architecture for many-to-many instrument transfers together with visualizations and evaluations.","pdf":"/pdf/8d84da61b7a7ccea762a0eb61988ad6f1e2f079c.pdf","paperhash":"anonymous|modulated_variational_autoencoders_for_manytomany_musical_timbre_transfer","_bibtex":"@inproceedings{    \nanonymous2019modulated,    \ntitle={Modulated Variational Auto-Encoders for Many-to-Many Musical Timbre Transfer},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJgOl3AqY7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ByldlhAqYQ","original":"rkxTMWt9Fm","number":1089,"cdate":1538087919839,"ddate":null,"tcdate":1538087919839,"tmdate":1538155993566,"tddate":null,"forum":"ByldlhAqYQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Transfer Learning for Sequences via Learning to Collocate","abstract":"Transfer learning aims to solve the data sparsity for a specific domain by applying information of another domain. Given a sequence (e.g. a natural language sentence), the transfer learning, usually enabled by recurrent neural network (RNN), represent the sequential information transfer. RNN uses a chain of repeating cells to model the sequence data. However, previous studies of neural network based transfer learning simply transfer the information across the whole layers, which are unfeasible for seq2seq and sequence labeling. Meanwhile, such layer-wise transfer learning mechanisms also lose the fine-grained cell-level information from the source domain.\n\nIn this paper, we proposed the aligned recurrent transfer, ART, to achieve cell-level information transfer. ART is in a recurrent manner that different cells share the same parameters. Besides transferring the corresponding information at the same position, ART transfers information from all collocated words in the source domain. This strategy enables ART to capture the word collocation across domains in a more flexible way. We conducted extensive experiments on both sequence labeling tasks (POS tagging, NER) and sentence classification (sentiment analysis). ART outperforms the state-of-the-arts over all experiments.\n","keywords":["transfer learning","recurrent neural network","attention","natural language processing"],"authorids":["ICLR.cc/2019/Conference/Paper1089/Authors"],"authors":["Anonymous"],"TL;DR":"Transfer learning for sequence via learning to align cell-level information across domains.","pdf":"/pdf/8ebc6ad01a3da3b39892a9df71721b4e4916a44c.pdf","paperhash":"anonymous|transfer_learning_for_sequences_via_learning_to_collocate","_bibtex":"@inproceedings{    \nanonymous2019transfer,    \ntitle={Transfer Learning for Sequences via Learning to Collocate},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByldlhAqYQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1lug3R5FX","original":"Byx40kC9tX","number":1090,"cdate":1538087920007,"ddate":null,"tcdate":1538087920007,"tmdate":1538155993357,"tddate":null,"forum":"H1lug3R5FX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"On the Geometry of Adversarial Examples","abstract":"Adversarial examples are a pervasive phenomenon of machine learning models where seemingly imperceptible perturbations to the input lead to misclassifications for otherwise statistically accurate models. We propose a geometric framework, drawing on tools from the manifold reconstruction literature, to analyze the high-dimensional geometry of adversarial examples. In particular, we highlight the importance of codimension: for low-dimensional data manifolds embedded in high-dimensional space there are many directions off the manifold in which to construct adversarial examples. Adversarial examples are a natural consequence of learning a decision boundary that classifies the low-dimensional data manifold well, but classifies points near the manifold incorrectly. Using our geometric framework we prove (1) a tradeoff between robustness under different norms, (2) that adversarial training in balls around the data is sample inefficient, and (3) sufficient sampling conditions under which nearest neighbor classifiers and ball-based adversarial training are robust.","keywords":["adversarial examples","high-dimensional geometry"],"authorids":["ICLR.cc/2019/Conference/Paper1090/Authors"],"authors":["Anonymous"],"TL;DR":"We present a geometric framework for proving robustness guarantees and highlight the importance of codimension in adversarial examples. ","pdf":"/pdf/28aa43ab133f6fe6178ae0cf2cf50d0c5e1fa92c.pdf","paperhash":"anonymous|on_the_geometry_of_adversarial_examples","_bibtex":"@inproceedings{    \nanonymous2019on,    \ntitle={On the Geometry of Adversarial Examples},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1lug3R5FX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1zOg309tX","original":"B1gDbVM5KX","number":1091,"cdate":1538087920167,"ddate":null,"tcdate":1538087920167,"tmdate":1538155993148,"tddate":null,"forum":"r1zOg309tX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Understanding the Effectiveness of Lipschitz-Continuity in Generative Adversarial Nets","abstract":"In this paper, we investigate the underlying factor that leads to the failure and success in training of GANs. Specifically, we study the property of the optimal discriminative function $\\ff(x)$ and show that $\\ff(x)$ in most GANs can only reflect the local densities at $x$, which means the value of $\\ff(x)$ for points in the fake distribution ($P_g$) does not contain any information useful about the location of other points in the real distribution ($P_r$). Given that the supports of the real and fake distributions are usually disjoint, we argue that such a $\\ff(x)$ and its gradient tell nothing about ``how to pull $P_g$ to $P_r$'', which turns out to be the fundamental cause of failure in training of GANs. We further demonstrate that a well-defined distance metric (including Wasserstein distance) does not necessarily ensure the convergence of GANs. Finally, we propose Lipschitz-continuity condition as a general solution and show that in a large family of GAN objectives, Lipschitz condition is capable of connecting $P_g$ and $P_r$ through $\\ff(x)$ such that the gradient $\\nabla_{\\!x}\\ff(x)$ at each sample $x \\tsim P_g$ points towards some real sample $y \\tsim P_r$. ","keywords":["GANs","Lipschitz-continuity","convergence"],"authorids":["ICLR.cc/2019/Conference/Paper1091/Authors"],"authors":["Anonymous"],"TL;DR":"We disclose the fundamental cause of failure in training of GANs, and demonstrate that Lipschitz-continuity is a general solution to this issue.","pdf":"/pdf/a12fe616b152d8dbc13c399dbbeaa06aa5c93692.pdf","paperhash":"anonymous|understanding_the_effectiveness_of_lipschitzcontinuity_in_generative_adversarial_nets","_bibtex":"@inproceedings{    \nanonymous2019understanding,    \ntitle={Understanding the Effectiveness of Lipschitz-Continuity in Generative Adversarial Nets},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1zOg309tX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1gOe209t7","original":"HJeOZ-CcFQ","number":1092,"cdate":1538087920335,"ddate":null,"tcdate":1538087920335,"tmdate":1538155992929,"tddate":null,"forum":"r1gOe209t7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Reconciling Feature-Reuse and Overfitting in DenseNet with Specialized Dropout","abstract":"Recently convolutional neural networks (CNNs) achieve great accuracy in visual recognition tasks. DenseNet becomes one of the most popular CNN models due to its effectiveness in feature-reuse. However, like other CNN models, DenseNets also face overfitting problem if not severer. Existing dropout method can be applied but not as effective due to the introduced nonlinear connections. In particular, the property of feature-reuse in DenseNet will be impeded, and the dropout effect will be weakened by the spatial correlation inside feature maps. To address these problems, we craft the design of a specialized dropout method from three aspects, dropout location, dropout granularity, and dropout probability. The insights attained here could potentially be applied as a general approach for boosting the accuracy of other CNN models with similar nonlinear connections. Experimental results show that DenseNets with our specialized dropout method yield better accuracy compared to vanilla DenseNet and state-of-the-art CNN models, and such accuracy boost increases with the model depth.","keywords":["Specialized dropout","computer vision"],"authorids":["ICLR.cc/2019/Conference/Paper1092/Authors"],"authors":["Anonymous"],"TL;DR":"Realizing the drawbacks when applying original dropout on DenseNet, we craft the design of dropout method from three aspects, the idea of which could also be applied on other CNN models.","pdf":"/pdf/2939c75d31519701b96f705bb886e29725429b45.pdf","paperhash":"anonymous|reconciling_featurereuse_and_overfitting_in_densenet_with_specialized_dropout","_bibtex":"@inproceedings{    \nanonymous2019reconciling,    \ntitle={Reconciling Feature-Reuse and Overfitting in DenseNet with Specialized Dropout},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1gOe209t7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJxug2R9Km","original":"SJxeuxT-YX","number":1093,"cdate":1538087920497,"ddate":null,"tcdate":1538087920497,"tmdate":1538155992718,"tddate":null,"forum":"rJxug2R9Km","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Meta-Learning for Contextual Bandit Exploration","abstract":"We describe MÊLÉE, a meta-learning algorithm for learning a good exploration policy in the interactive contextual bandit setting. Here, an algorithm must take actions based on contexts, and learn based only on a reward signal from the action taken, thereby generating an exploration/exploitation trade-off. MÊLÉE addresses this trade-off by learning a good exploration strategy based on offline synthetic tasks, on which it can simulate the contextual bandit setting. Based on these simulations, MÊLÉE uses an imitation learning strategy to learn a good exploration policy that can then be applied to true contextual bandit tasks at test time. We compare MÊLÉE to seven strong baseline contextual bandit algorithms on a set of three hundred real-world datasets, on which it outperforms alternatives in most settings, especially when differences in rewards are large. Finally, we demonstrate the importance of having a rich feature representation for learning how to explore.\n","keywords":["meta-learning","bandits","exploration","imitation learning"],"authorids":["ICLR.cc/2019/Conference/Paper1093/Authors"],"authors":["Anonymous"],"TL;DR":"We present a meta-learning algorithm, MÊLÉE, for learning a good exploration function in the interactive contextual bandit setting.","pdf":"/pdf/dc2298039804e0454caff65a4df83e29da6cd652.pdf","paperhash":"anonymous|metalearning_for_contextual_bandit_exploration","_bibtex":"@inproceedings{    \nanonymous2019meta-learning,    \ntitle={Meta-Learning for Contextual Bandit Exploration},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJxug2R9Km},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1xFxh0cKX","original":"SklPRGh5tm","number":1094,"cdate":1538087920665,"ddate":null,"tcdate":1538087920665,"tmdate":1538155992508,"tddate":null,"forum":"B1xFxh0cKX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Guided Evolutionary Strategies: Escaping the curse of dimensionality in random search","abstract":"Many applications in machine learning require optimizing a function whose true gradient is unknown, but where surrogate gradient information (directions that may be correlated with, but not necessarily identical to, the true gradient) is available instead. This arises when an approximate gradient is easier to compute than the full gradient (e.g. in meta-learning or unrolled optimization), or when a true gradient is intractable and is replaced with a surrogate (e.g. in certain reinforcement learning applications or training networks with discrete variables). We propose Guided Evolutionary Strategies, a method for optimally using surrogate gradient directions along with random search. We define a search distribution for evolutionary strategies that is elongated along a subspace spanned by the surrogate gradients. This allows us to estimate a descent direction which can then be passed to a first-order optimizer. We analytically and numerically characterize the tradeoffs that result from tuning how strongly the search distribution is stretched along the guiding subspace, and use this to derive a setting of the hyperparameters that works well across problems. Finally, we apply our method to example problems including truncated unrolled optimization and training neural networks with discrete variables, demonstrating improvement over both standard evolutionary strategies and first-order methods (that directly follow the surrogate gradient). We provide a demo of Guided ES at: redacted URL","keywords":["evolutionary strategies","optimization","gradient estimators","biased gradients"],"authorids":["ICLR.cc/2019/Conference/Paper1094/Authors"],"authors":["Anonymous"],"TL;DR":"We propose an optimization method for when only biased gradients are available--we define a new gradient estimator for this scenario, derive the bias and variance of this estimator, and apply it to example problems.","pdf":"/pdf/0b14c36140480f115b0847908574fc08e2bfb320.pdf","paperhash":"anonymous|guided_evolutionary_strategies_escaping_the_curse_of_dimensionality_in_random_search","_bibtex":"@inproceedings{    \nanonymous2019guided,    \ntitle={Guided Evolutionary Strategies: Escaping the curse of dimensionality in random search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1xFxh0cKX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJgYl205tQ","original":"Skl34l7qYQ","number":1095,"cdate":1538087920851,"ddate":null,"tcdate":1538087920851,"tmdate":1538155992296,"tddate":null,"forum":"BJgYl205tQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality","abstract":"Generative Adversarial Networks (GANs) are an elegant mechanism for data generation.  However, a key challenge when using GANs is how to best measure their ability to generate realistic data. In this paper, we demonstrate that an intrinsic dimensional characterization of the data space learned by a GAN model leads to an effective evaluation metric for GAN quality.  In particular, we propose a new evaluation measure, CrossLID, that assesses the local intrinsic dimensionality (LID) of input data with respect to neighborhoods within GAN-generated samples.  In experiments on 3 benchmark image datasets, we compare our proposed measure to several state-of-the-art evaluation metrics. Our experiments show that CrossLID is strongly correlated with sample quality, is sensitive to mode collapse, is robust to small-scale noise and image transformations, and can be applied in a model-free  manner.  Furthermore, we show how CrossLID can be used within the GAN training process to improve generation quality.\n","keywords":["Generative Adversarial Networks","Evaluation Metric","Local Intrinsic Dimensionality"],"authorids":["ICLR.cc/2019/Conference/Paper1095/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a new metric for evaluating GAN models.","pdf":"/pdf/e6ccd2320fffed60dd5c99d1f8ff72e4fde4b5af.pdf","paperhash":"anonymous|quality_evaluation_of_gans_using_cross_local_intrinsic_dimensionality","_bibtex":"@inproceedings{    \nanonymous2019quality,    \ntitle={Quality Evaluation of GANs Using Cross Local Intrinsic Dimensionality},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgYl205tQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkxtl3C5YX","original":"B1gAb099YQ","number":1097,"cdate":1538087921188,"ddate":null,"tcdate":1538087921188,"tmdate":1538155991871,"tddate":null,"forum":"rkxtl3C5YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Understanding & Generalizing AlphaGo Zero","abstract":"AlphaGo Zero (AGZ) introduced a new {\\em tabula rasa} reinforcement learning algorithm that has achieved superhuman performance in the games of Go, Chess, and Shogi with no prior knowledge other than the rules of the game. This success naturally begs the question whether it is possible to develop similar high-performance reinforcement learning algorithms for generic sequential decision-making problems (beyond two-player games), using only the constraints of the environment as the ``rules.'' To address this challenge, we start by taking steps towards developing a formal understanding of AGZ.  AGZ includes two key innovations: (1) it learns a policy (represented as a neural network) using {\\em supervised learning} with cross-entropy loss from samples generated via Monte-Carlo Tree Search (MCTS); (2) it uses {\\em self-play} to learn without training data. \n\nWe argue that the self-play in AGZ corresponds to learning a Nash equilibrium for the two-player game; and the supervised learning with MCTS is attempting to learn the policy corresponding to the Nash equilibrium, by establishing a novel bound on the difference between the expected return achieved by two policies in terms of the expected KL divergence (cross-entropy) of their induced distributions. To extend AGZ to generic sequential decision-making problems, we introduce a {\\em robust MDP} framework, in which the agent and nature effectively play a zero-sum game: the agent aims to take actions to maximize reward while nature seeks state transitions, subject to the constraints of that environment, that minimize the agent's reward. For a challenging network scheduling domain, we find that AGZ within the robust MDP framework provides near-optimal performance, matching one of the best known scheduling policies that has taken the networking community three decades of intensive research to develop.\n","keywords":["reinforcement learning","AlphaGo Zero"],"authorids":["ICLR.cc/2019/Conference/Paper1097/Authors"],"authors":["Anonymous"],"pdf":"/pdf/cf9c4ba3d4036b7f8cb7126bf1bfd8dc1ce647d8.pdf","paperhash":"anonymous|understanding_generalizing_alphago_zero","_bibtex":"@inproceedings{    \nanonymous2019understanding,    \ntitle={Understanding & Generalizing AlphaGo Zero},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxtl3C5YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJgYxn09Fm","original":"ryxvKh3qFQ","number":1098,"cdate":1538087921362,"ddate":null,"tcdate":1538087921362,"tmdate":1538155991664,"tddate":null,"forum":"rJgYxn09Fm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Implicitly Recurrent CNNs Through Parameter Sharing","abstract":"We introduce a parameter sharing scheme, in which different layers of a convolutional neural network (CNN) are defined by a learned linear combination of parameter tensors from a global bank of templates.  Restricting the number of templates yields a flexible hybridization of traditional CNNs and recurrent networks.  Compared to traditional CNNs, we demonstrate substantial parameter savings on standard image classification tasks, while maintaining accuracy.\n\nOur simple parameter sharing scheme, though defined via soft weights, in practice yields trained networks with near strict recurrent structure; with negligible side effects, they convert into networks with actual recurrent loops.  Training these networks thus implicitly involves discovery of suitable recurrent architectures.  As a consequence, our hybrid networks are not only more parameter efficient, but also learn some tasks faster.  Specifically, on synthetic tasks which are algorithmic in nature, our hybrid networks both train faster and extrapolate better on test examples outside the span of the training set.","keywords":["deep learning","architecture search","computer vision"],"authorids":["ICLR.cc/2019/Conference/Paper1098/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a method that enables CNN folding to create recurrent connections","pdf":"/pdf/1abfcbe4c16d8d3ac7bb17798366ce6b404967be.pdf","paperhash":"anonymous|learning_implicitly_recurrent_cnns_through_parameter_sharing","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Implicitly Recurrent CNNs Through Parameter Sharing},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJgYxn09Fm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hye9lnCct7","original":"B1gCvwTqtm","number":1099,"cdate":1538087921525,"ddate":null,"tcdate":1538087921525,"tmdate":1538155991457,"tddate":null,"forum":"Hye9lnCct7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Actionable Representations with Goal Conditioned Policies","abstract":"Representation learning is a central challenge across a range of machine learning areas. In reinforcement learning, effective and functional representations have the potential to tremendously accelerate learning progress and solve more challenging problems. Most prior work on representation learning has focused on generative approaches, learning representations that capture all the underlying factors of variation in the observation space in a more disentangled or well-ordered manner. In this paper, we instead aim to learn functionally salient representations: representations that are not necessarily complete in terms of capturing all factors of variation in the observation space, but rather aim to capture those factors of variation that are important for decision making -- that are \"actionable\". These representations are aware of the dynamics of the environment, and capture only the elements of the observation that are necessary for decision making rather than all factors of variation, eliminating the need for explicit reconstruction. We show how these learned representations can be useful to improve exploration for sparse reward problems, to enable long horizon hierarchical reinforcement learning, and as a state representation for learning policies for downstream tasks. We evaluate our method on a number of simulated environments, and compare it to prior methods for representation learning, exploration, and hierarchical reinforcement learning.","keywords":["Representation Learning","Reinforcement Learning"],"authorids":["ICLR.cc/2019/Conference/Paper1099/Authors"],"authors":["Anonymous"],"TL;DR":"Learning state representations which capture factors necessary for control","pdf":"/pdf/0e121bbb1b6cf5ddeb4869becc185a819d037e8b.pdf","paperhash":"anonymous|learning_actionable_representations_with_goal_conditioned_policies","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Actionable Representations with Goal Conditioned Policies},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hye9lnCct7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1xce3ActX","original":"HJxztehcYm","number":1100,"cdate":1538087921693,"ddate":null,"tcdate":1538087921693,"tmdate":1538155991252,"tddate":null,"forum":"r1xce3ActX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Deep Embeddings in Krein Spaces","abstract":"The non-linear embedding achieved by a Siamese network is indeed a realization of a Hilbert space, \\ie, a metric space with a positive definite inner product.  Krein spaces generalize the notion of Hilbert spaces to geometrical structures with indefinite inner products. As a result, distances and norms in a Krein space can become negative. The negative spectral of an inner product is usually attributed to observation noise, though such a claim has never been fully studied, nor proved. Seeking how Krein spaces can be constructed from data, we propose a simple and innocent-looking modification to Siamese networks, equipping them with the power to realize indefinite inner-products. This provides a data-driven technique to decide whether the negative spectrum of an inner-product is helpful or not. We empirically show that our Krein embeddings outperform Hilbert space embeddings on recognition tasks. ","keywords":["Krein spaces","Deep embedding learning"],"authorids":["ICLR.cc/2019/Conference/Paper1100/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a solution that realizes deep embeddings in Krein spaces.","pdf":"/pdf/55885ecd3ac372ab7a6b939d1e8d079153d9275a.pdf","paperhash":"anonymous|learning_deep_embeddings_in_krein_spaces","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Deep Embeddings in Krein Spaces},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xce3ActX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1xcx3C5FX","original":"ByxoV8n5KX","number":1101,"cdate":1538087921863,"ddate":null,"tcdate":1538087921863,"tmdate":1538155991045,"tddate":null,"forum":"S1xcx3C5FX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Statistical Verification of Neural Networks","abstract":"We present a new approach to neural network verification based on estimating the proportion of inputs for which a property is violated. Specifically, we estimate the probability of the event that the property is violated under an input model. This permits classic verification as a special case, for which one considers only the question of whether this expectation is exactly zero or not. When the property can be violated, our approach provides an informative notion of how robust the network is, rather than just the conventional assertion that the network is not verifiable. Furthermore, it provides an ability to scale to larger networks than classical formal verification approaches. Key to achieving this is an adaptation of multi-level splitting, a Monte Carlo approach for estimating the probability of rare events, to our statistical verification framework. We demonstrate that our approach is able to emulate existing verification procedures on benchmark problems, while scaling to larger networks and providing reliable additional information in the form of accurate estimates of the violation probability.","keywords":["neural network verification","multi-level splitting","formal verification"],"authorids":["ICLR.cc/2019/Conference/Paper1101/Authors"],"authors":["Anonymous"],"TL;DR":"We introduce a statistical approach to neural network verification that provides an informative notion of how robust a network is, rather than just the conventional binary assertion of whether or not of property is violated.","pdf":"/pdf/eed0681e96bb21558f7510d6ac9f1bdf1d14d004.pdf","paperhash":"anonymous|statistical_verification_of_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019statistical,    \ntitle={Statistical Verification of Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1xcx3C5FX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1z9ehAqYX","original":"HJex_Ja5KQ","number":1102,"cdate":1538087922026,"ddate":null,"tcdate":1538087922026,"tmdate":1538155990834,"tddate":null,"forum":"S1z9ehAqYX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Shrinkage-based Bias-Variance Trade-off for Deep Reinforcement Learning","abstract":"Deep reinforcement learning has achieved remarkable successes in solving various challenging artificial intelligence tasks. A variety of different algorithms have been introduced and improved towards human-level performance. Although technical advances have been developed for each individual algorithms, there has been strong evidence showing that further substantial improvements can be achieved by properly combining multiple approaches with difference biases and variances. In this work, we propose to use the James-Stein (JS) shrinkage estimator to combine on-policy policy gradient estimators which have low bias but high variance, with low-variance high-bias gradient estimates such as those constructed based on model-based methods or temporally smoothed averaging of historical gradients. Empirical results show that our simple shrinkage approach is very effective in practice and substantially improve the sample efficiency of the state-of-the-art on-policy methods on various continuous control tasks.\n","keywords":["bias-variance trade-off","James-stein estimator","reinforcement learning"],"authorids":["ICLR.cc/2019/Conference/Paper1102/Authors"],"authors":["Anonymous"],"pdf":"/pdf/0669c9494e7e1ad3a35b87edb358a4af9aeb09d1.pdf","paperhash":"anonymous|shrinkagebased_biasvariance_tradeoff_for_deep_reinforcement_learning","_bibtex":"@inproceedings{    \nanonymous2019shrinkage-based,    \ntitle={Shrinkage-based Bias-Variance Trade-off for Deep Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1z9ehAqYX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyGcghRct7","original":"HJeFZPJ9Ym","number":1103,"cdate":1538087922194,"ddate":null,"tcdate":1538087922194,"tmdate":1538155990628,"tddate":null,"forum":"HyGcghRct7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Random mesh projectors for inverse problems","abstract":" We propose a new learning-based approach to solve ill-posed inverse problems in imaging. We address the case where ground truth training samples are rare and the problem is severely ill-posed---both because of the underlying physics and because we can only get few measurements. This setting is common in geophysical imaging and remote sensing.We show that in this case the common approach to directly learn the mapping from the measured data to the reconstruction becomes unstable. Instead, we propose to first learn an ensemble of simpler mappings from the data to projections of the unknown image into random piecewise-constant subspaces. We then combine the projections to form a final reconstruction by solving a deconvolution-like problem. We show experimentally the proposed method is more robust to measurement noise and corruptions not seen during training than a directly learned inverse.","keywords":["imaging","inverse problems","subspace projections","random Delaunay triangulations","CNN","geophysics","regularization"],"authorids":["ICLR.cc/2019/Conference/Paper1103/Authors"],"authors":["Anonymous"],"TL;DR":"We solve ill-posed inverse problems with scarce ground truth examples by estimating an ensemble of random projections of the model instead of the model itself.","pdf":"/pdf/bf500146eda22305eddbeb62d868737d33f3ab09.pdf","paperhash":"anonymous|random_mesh_projectors_for_inverse_problems","_bibtex":"@inproceedings{    \nanonymous2019random,    \ntitle={Random mesh projectors for inverse problems},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyGcghRct7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJNceh0cFX","original":"HJle4WC5Km","number":1104,"cdate":1538087922355,"ddate":null,"tcdate":1538087922355,"tmdate":1538155990420,"tddate":null,"forum":"SJNceh0cFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A   RECURRENT NEURAL CASCADE-BASED MODEL FOR CONTINUOUS-TIME DIFFUSION PROCESS","abstract":"Many works have been proposed in the literature to capture the dynamics of diffusion in networks. While some of them define graphical markovian models to extract temporal relationships between node infections in networks, others consider diffusion episodes as sequences of infections via recurrent neural models. In this paper we propose a model at the crossroads of these two extremes, which embeds the history of diffusion in infected nodes as hidden continuous states. Depending on the trajectory followed by the content before reaching a given node, the distribution of influence probabilities may vary. However, content trajectories  are usually hidden in the data, which induces challenging learning problems. We propose a topological recurrent neural model which exhibits good experimental performances for diffusion modelling and prediction. ","keywords":["Information Diffusion","Recurrent Neural Network","Black Box Inference"],"authorids":["ICLR.cc/2019/Conference/Paper1104/Authors"],"authors":["Anonymous"],"pdf":"/pdf/f09c2a275267cebf093074f40762ff3e56f1e833.pdf","paperhash":"anonymous|a_recurrent_neural_cascadebased_model_for_continuoustime_diffusion_process","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A   RECURRENT NEURAL CASCADE-BASED MODEL FOR CONTINUOUS-TIME DIFFUSION PROCESS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJNceh0cFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hyxsl2AqKm","original":"rylWVZRctQ","number":1105,"cdate":1538087922518,"ddate":null,"tcdate":1538087922518,"tmdate":1538155990212,"tddate":null,"forum":"Hyxsl2AqKm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"ON THE EFFECTIVENESS OF TASK GRANULARITY FOR TRANSFER LEARNING","abstract":"We describe a DNN for video classification and captioning, trained end-to-end,\nwith shared features, to solve tasks at different levels of granularity, exploring the\nlink between granularity in a source task and the quality of learned features for\ntransfer learning. For solving the new task domain in transfer learning, we freeze\nthe trained encoder and fine-tune an MLP on the target domain. We train on the\nSomething-Something dataset with over 220, 000 videos, and multiple levels of\ntarget granularity, including 50 action groups, 174 fine-grained action categories\nand captions. Classification and captioning with Something-Something are challenging\nbecause of the subtle differences between actions, applied to thousands\nof different object classes, and the diversity of captions penned by crowd actors.\nOur model performs better than existing classification baselines for SomethingSomething,\nwith impressive fine-grained results. And it yields a strong baseline on\nthe new Something-Something captioning task. Experiments reveal that training\nwith more fine-grained tasks tends to produce better features for transfer learning.","keywords":["Transfer Learning","Video Understanding","Fine-grained Video Classification","Video Captioning","Common Sense","Something-Something Dataset."],"authorids":["ICLR.cc/2019/Conference/Paper1105/Authors"],"authors":["Anonymous"],"TL;DR":"If the model architecture is fixed, how would the complexity and granularity of task, effect the quality of learned features for transferring to a new task.","pdf":"/pdf/59be2f74b76794a3b5e5b2d439bd3d5f00e28e49.pdf","paperhash":"anonymous|on_the_effectiveness_of_task_granularity_for_transfer_learning","_bibtex":"@inproceedings{    \nanonymous2019on,    \ntitle={ON THE EFFECTIVENESS OF TASK GRANULARITY FOR TRANSFER LEARNING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyxsl2AqKm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryeoxnRqKQ","original":"HJgxQic9F7","number":1106,"cdate":1538087922682,"ddate":null,"tcdate":1538087922682,"tmdate":1538155989995,"tddate":null,"forum":"ryeoxnRqKQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"NATTACK: A STRONG AND UNIVERSAL GAUSSIAN BLACK-BOX ADVERSARIAL ATTACK","abstract":"Recent works find that DNNs are  vulnerable to adversarial examples, whose changes from the benign ones are imperceptible and yet lead DNNs to make wrong predictions. One can find various adversarial examples for the same input to a DNN using different attack methods. In other words, there is a population of adversarial examples, instead of only one, for any input to a DNN. By explicitly modeling this adversarial population with a Gaussian distribution, we propose a new black-box attack called NATTACK. The adversarial attack is hence formalized as an optimization problem, which searches the mean of the Gaussian under the guidance of increasing the target DNN's prediction error. NATTACK achieves 100%  attack success rate  on six out of ten recently published defense methods (and greater than 90% for the other four), all using the same algorithm. Such results are on par with or better than  powerful state-of-the-art white-box attacks. While the white-box attacks are often model-specific or defense-specific, the proposed black-box NATTACK is universally applicable to different defenses. ","keywords":["adversarial attack","black-box","evolutional strategy","policy gradient"],"authorids":["ICLR.cc/2019/Conference/Paper1106/Authors"],"authors":["Anonymous"],"pdf":"/pdf/7af762761b27dd8b502607e74b9ed0c8ec76f16a.pdf","paperhash":"anonymous|nattack_a_strong_and_universal_gaussian_blackbox_adversarial_attack","_bibtex":"@inproceedings{    \nanonymous2019nattack:,    \ntitle={NATTACK: A STRONG AND UNIVERSAL GAUSSIAN BLACK-BOX ADVERSARIAL ATTACK},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryeoxnRqKQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1ejxnCctX","original":"Hkl9eOnctm","number":1107,"cdate":1538087922854,"ddate":null,"tcdate":1538087922854,"tmdate":1538155989784,"tddate":null,"forum":"r1ejxnCctX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Representation Flow for Action Recognition","abstract":"In this paper, we propose a convolutional layer inspired by optical flow algorithms to learn motion representations. Our representation flow layer is a fully-differentiable layer designed to optimally capture the '`flow' of any representation channel within a convolutional neural network. Its parameters for iterative flow optimization are learned in an end-to-end fashion together with the other model parameters, maximizing the action recognition performance. Furthermore, we newly introduce the concept of learning '`flow of flow' representations by stacking multiple representation flow layers. We conducted extensive experimental evaluations, confirming its advantages over previous recognition models using traditional optical flows in both computational speed and performance.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1107/Authors"],"authors":["Anonymous"],"pdf":"/pdf/d8f411319fbba96c0aea29ffad4d045ae0de88ca.pdf","paperhash":"anonymous|representation_flow_for_action_recognition","_bibtex":"@inproceedings{    \nanonymous2019representation,    \ntitle={Representation Flow for Action Recognition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1ejxnCctX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Syeil309tX","original":"HylNneAcK7","number":1108,"cdate":1538087923022,"ddate":null,"tcdate":1538087923022,"tmdate":1538155989577,"tddate":null,"forum":"Syeil309tX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Optimized Gated Deep Learning Architectures for Sensor Fusion","abstract":"Sensor fusion is a key technology that integrates various sensory inputs to allow for robust decision making in many applications such as autonomous driving and robot control. Deep neural networks have been adopted for sensor fusion in a body of recent studies. Among these, the so-called netgated architecture was proposed, which has demonstrated improved performances over the conventional convolu- tional neural networks (CNN). In this paper, we address several limitations of the baseline negated architecture by proposing two further optimized architectures: a coarser-grained gated architecture employing (feature) group-level fusion weights and a two-stage gated architectures leveraging both the group-level and feature- level fusion weights. Using driving mode prediction and human activity recogni- tion datasets, we demonstrate the significant performance improvements brought by the proposed gated architectures and also their robustness in the presence of sensor noise and failures.\n","keywords":["deep learning","convolutional neural network","sensor fusion","activity recognition"],"authorids":["ICLR.cc/2019/Conference/Paper1108/Authors"],"authors":["Anonymous"],"TL;DR":"Optimized gated deep learning architectures for sensor fusion is proposed.","pdf":"/pdf/81dec7e6b7a567cbb7cd27f10bfa56c813204143.pdf","paperhash":"anonymous|optimized_gated_deep_learning_architectures_for_sensor_fusion","_bibtex":"@inproceedings{    \nanonymous2019optimized,    \ntitle={Optimized Gated Deep Learning Architectures for Sensor Fusion},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syeil309tX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJgolhR9Km","original":"HklwKej9K7","number":1109,"cdate":1538087923197,"ddate":null,"tcdate":1538087923197,"tmdate":1538155989367,"tddate":null,"forum":"BJgolhR9Km","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Neural Networks with Structural Resistance to Adversarial Attacks","abstract":"In adversarial attacks to machine-learning classifiers, small perturbations are added to input that is correctly classified. The perturbations yield adversarial examples, which are virtually indistinguishable from the unperturbed input, and yet are misclassified. In standard neural networks used for deep learning, attackers can craft adversarial examples from most input to cause a misclassification of their choice. \n\nWe introduce a new type of network units, called RBFI units, whose non-linear structure makes them inherently resistant to adversarial attacks. On permutation-invariant MNIST, in absence of adversarial attacks, networks using RBFI units match the performance of networks using sigmoid units, and are slightly below the accuracy of networks with ReLU units. When subjected to adversarial attacks, networks with RBFI units retain accuracies above 93% for projected gradient descent (PGD) attacks that degrade the accuracy of networks with ReLU or sigmoid units to below 70%.Considering a variety of attack mechanisms, RBFI networks trained on regular input either exceed or closely match the accuracy of sigmoid and ReLU network trained with the help of adversarial examples.\n\nThe non-linear structure of RBFI units makes them difficult to train using standard gradient descent. We show that RBFI networks of RBFI units can be efficiently trained to high accuracies using pseudogradients, computed using functions especially crafted to facilitate learning instead of their true derivatives.","keywords":["machine learning","adversarial attacks"],"authorids":["ICLR.cc/2019/Conference/Paper1109/Authors"],"authors":["Anonymous"],"TL;DR":"We introduce a type of neural network that is structurally resistant to adversarial attacks, even when trained on unaugmented training sets.  The resistance is due to the stability of network units wrt input perturbations.","pdf":"/pdf/f4bc9a28cb214e50f09abaaeea0677cf2e722b0c.pdf","paperhash":"anonymous|neural_networks_with_structural_resistance_to_adversarial_attacks","_bibtex":"@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Networks with Structural Resistance to Adversarial Attacks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgolhR9Km},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HylsgnCcFQ","original":"HJg-np25K7","number":1110,"cdate":1538087923362,"ddate":null,"tcdate":1538087923362,"tmdate":1538155989160,"tddate":null,"forum":"HylsgnCcFQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Dynamic Graph Representation Learning via Self-Attention Networks","abstract":"Learning latent representations of nodes in graphs is an important and ubiquitous task with widespread applications such as link prediction, node classification, and graph visualization. Previous methods on graph representation learning mainly focus on static graphs, however, many real-world graphs are dynamic and evolve over time. In this paper, we present Dynamic Self-Attention Network (DySAT), a novel neural architecture that operates on dynamic graphs and learns node representations that capture both structural properties and temporal evolutionary patterns. Specifically, DySAT computes node representations by jointly employing self-attention layers along two dimensions: structural neighborhood and temporal dynamics. We conduct link prediction experiments on two classes of graphs: communication networks and bipartite rating networks. Our experimental results show that DySAT has a significant performance gain over several different state-of-the-art graph embedding baselines.","keywords":["Graph Representation Learning","Dynamic Graphs","Attention","Self-Attention","Deep Learning"],"authorids":["ICLR.cc/2019/Conference/Paper1110/Authors"],"authors":["Anonymous"],"TL;DR":"A novel neural architecture named DySAT to learn node representations on dynamic graphs by employing self-attention along two dimensions: structural neighborhood and temporal dynamics, achieves state-of-the-art results in dynamic link prediction.","pdf":"/pdf/39b6aa54f2df048fda97ee088362aec4e8774aa8.pdf","paperhash":"anonymous|dynamic_graph_representation_learning_via_selfattention_networks","_bibtex":"@inproceedings{    \nanonymous2019dynamic,    \ntitle={Dynamic Graph Representation Learning via Self-Attention Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HylsgnCcFQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Bkg3g2R9FX","original":"B1lUTmp9YX","number":1111,"cdate":1538087923529,"ddate":null,"tcdate":1538087923529,"tmdate":1538155988945,"tddate":null,"forum":"Bkg3g2R9FX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Adaptive Gradient Methods with Dynamic Bound of Learning Rate","abstract":"Adaptive optimization methods such as AdaGrad, RMSProp and Adam have been proposed to achieve a rapid training process with an element-wise scaling term on learning rates. \nThough prevailing, they are observed to generalize poorly compared with SGD or even fail to converge due to unstable and extreme learning rates. \nRecent work has put forward some algorithms such as AMSGrad to tackle this issue but they failed to achieve considerable improvement over existing methods. \nIn our paper, we demonstrate that extreme learning rates can lead to poor performance.\nWe provide new variants of Adam and AMSGrad, called AdaBound and AMSBound respectively, which employ dynamic bounds on learning rates to achieve a gradual and smooth transition from adaptive methods to SGD and give a theoretical proof of convergence.\nWe further conduct experiments on various popular tasks and models, which is often insufficient in previous work.\nExperimental results show that new variants can eliminate the generalization gap between adaptive methods and SGD and maintain higher learning speed early in training at the same time.\nMoreover, they can bring significant improvement over their prototypes, especially on complex deep networks.","keywords":["Optimization","Adam","Generalization"],"authorids":["ICLR.cc/2019/Conference/Paper1111/Authors"],"authors":["Anonymous"],"TL;DR":"Novel variants of optimization methods that combine the benefits of both adaptive and non-adaptive methods.","pdf":"/pdf/98546fa95f55bda5b05d16d19c15cfe7ebcdeabe.pdf","paperhash":"anonymous|adaptive_gradient_methods_with_dynamic_bound_of_learning_rate","_bibtex":"@inproceedings{    \nanonymous2019adaptive,    \ntitle={Adaptive Gradient Methods with Dynamic Bound of Learning Rate},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkg3g2R9FX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Bylnx209YX","original":"BJxDjehqKm","number":1112,"cdate":1538087923688,"ddate":null,"tcdate":1538087923688,"tmdate":1538155988734,"tddate":null,"forum":"Bylnx209YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Adversarial Attacks on Graph Neural Networks via Meta Learning","abstract":"Deep learning models for graphs have advanced the state of the art on many tasks. Despite their recent success, little is known about their robustness. We investigate training time attacks on graph neural networks for node classification that perturb the discrete graph structure.  Our core principle is to use meta-gradients to solve the bilevel problem underlying training-time attacks, essentially treating the graph as a hyperparameter to optimize. Our experiments show that small graph perturbations consistently lead to a strong decrease in performance for graph convolutional networks, and even transfer to unsupervised embeddings. Remarkably, the perturbations created by our algorithm misguide the graph neural networks such that they perform worse than a simple baseline that ignores all relational information. Our attacks do not assume any knowledge about or access to the target classifiers.","keywords":["graph mining","adversarial attacks","meta learning","graph neural networks","node classification"],"authorids":["ICLR.cc/2019/Conference/Paper1112/Authors"],"authors":["Anonymous"],"TL;DR":"We use meta-gradients to attack the training procedure of deep neural networks for graphs.","pdf":"/pdf/dcf4e228c1f2a341bbee726d4e39fa322092e8b9.pdf","paperhash":"anonymous|adversarial_attacks_on_graph_neural_networks_via_meta_learning","_bibtex":"@inproceedings{    \nanonymous2019adversarial,    \ntitle={Adversarial Attacks on Graph Neural Networks via Meta Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bylnx209YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1Gnx2CqKQ","original":"H1l3Oxn5F7","number":1113,"cdate":1538087923848,"ddate":null,"tcdate":1538087923848,"tmdate":1538155988529,"tddate":null,"forum":"H1Gnx2CqKQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Hiding Objects from Detectors: Exploring Transferrable Adversarial Patterns","abstract":"Adversaries in neural networks have drawn much attention since their first debut. \nWhile most existing methods aim at deceiving image classification models into misclassification or crafting attacks for specific object instances in the object setection tasks, we focus on creating universal adversaries to fool object detectors and hide objects from the detectors. \nThe adversaries we examine are universal in three ways: \n(1) They are not specific for specific object instances; \n(2) They are image-independent; \n(3) They can further transfer to different unknown models. \nTo achieve this, we propose two novel techniques to improve the transferability of the adversaries: \\textit{piling-up} and \\textit{monochromatization}. \nBoth techniques prove to simplify the patterns of generated adversaries, and ultimately result in higher transferability. ","keywords":["adversarial","object detection"],"authorids":["ICLR.cc/2019/Conference/Paper1113/Authors"],"authors":["Anonymous"],"TL;DR":"We focus on creating universal adversaries to fool object detectors and hide objects from the detectors. ","pdf":"/pdf/149f561d0eefc9662e0400f8b3dbb345c6cab4e3.pdf","paperhash":"anonymous|hiding_objects_from_detectors_exploring_transferrable_adversarial_patterns","_bibtex":"@inproceedings{    \nanonymous2019hiding,    \ntitle={Hiding Objects from Detectors: Exploring Transferrable Adversarial Patterns},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1Gnx2CqKQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkG3e205K7","original":"HyxmiuYYY7","number":1114,"cdate":1538087924006,"ddate":null,"tcdate":1538087924006,"tmdate":1538155988322,"tddate":null,"forum":"HkG3e205K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Doubly Reparameterized Gradient Estimators for Monte Carlo Objectives","abstract":"Deep latent variable models have become a popular model choice due to the scalable learning algorithms introduced by (Kingma & Welling 2013, Rezende et al. 2014). These approaches maximize a variational lower bound on the intractable log likelihood of the observed data. Burda et al. (2015) introduced a multi-sample variational bound, IWAE, that is at least as tight as the standard variational lower bound and becomes increasingly tight as the number of samples increases. Counterintuitively, the typical inference network gradient estimator for the IWAE bound performs poorly as the number of samples increases (Rainforth et al. 2018, Le et al. 2018). Roeder et a. (2017) propose an improved gradient estimator, however, are unable to show it is unbiased. We show that it is in fact biased and that the bias can be estimated efficiently with a second application of the reparameterization trick. The doubly reparameterized gradient (DReG) estimator does not suffer as the number of samples increases, resolving the previously raised issues. The same idea can be used to improve many recently introduced training techniques for latent variable models. In particular, we show that this estimator reduces the variance of the IWAE gradient, the reweighted wake-sleep update (RWS) (Bornschein & Bengio 2014), and the jackknife variational inference (JVI) gradient (Nowozin 2018). Finally, we show that this computationally efficient, drop-in estimator translates to improved performance for all three objectives on several modeling tasks.","keywords":["variational autoencoder","reparameterization trick","IWAE","VAE","RWS","JVI"],"authorids":["ICLR.cc/2019/Conference/Paper1114/Authors"],"authors":["Anonymous"],"TL;DR":"Doubly reparameterized gradient estimators provide unbiased variance reduction which leads to improved performance.","pdf":"/pdf/afdaa9f8a72487e7277315f124ad36fed77b5ac3.pdf","paperhash":"anonymous|doubly_reparameterized_gradient_estimators_for_monte_carlo_objectives","_bibtex":"@inproceedings{    \nanonymous2019doubly,    \ntitle={Doubly Reparameterized Gradient Estimators for Monte Carlo Objectives},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkG3e205K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SkVhlh09tX","original":"BkxV9H65tm","number":1115,"cdate":1538087924174,"ddate":null,"tcdate":1538087924174,"tmdate":1538155988115,"tddate":null,"forum":"SkVhlh09tX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Pay Less Attention with Lightweight and Dynamic Convolutions","abstract":"Self-attention is a useful mechanism to build generative models for language and images. It determines the importance of context elements by comparing each element to the current time step. In this paper, we show that a very lightweight convolution can perform competitively to the best reported self-attention results. Next, we introduce dynamic convolutions which are simpler and more efficient than self-attention. We predict separate convolution kernels based solely on the current time-step in order to determine the importance of context elements. The number of operations required by this approach scales linearly in the input length, whereas self-attention is quadratic. Experiments on large-scale machine translation, language modeling and abstractive summarization show that dynamic convolutions improve over strong self-attention models. On the WMT'14 English-German test set dynamic convolutions achieve a new state of the art of 29.7 BLEU.","keywords":["Deep learning","sequence to sequence learning","convolutional neural networks","generative models"],"authorids":["ICLR.cc/2019/Conference/Paper1115/Authors"],"authors":["Anonymous"],"TL;DR":"Dynamic lightweight convolutions are competitive to self-attention on language tasks.","pdf":"/pdf/1cd147e51e2b223efa01aeba772ee4e35632dfbe.pdf","paperhash":"anonymous|pay_less_attention_with_lightweight_and_dynamic_convolutions","_bibtex":"@inproceedings{    \nanonymous2019pay,    \ntitle={Pay Less Attention with Lightweight and Dynamic Convolutions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkVhlh09tX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyVhg20cK7","original":"S1e0Tnnctm","number":1116,"cdate":1538087924334,"ddate":null,"tcdate":1538087924334,"tmdate":1538155987906,"tddate":null,"forum":"SyVhg20cK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Inducing Cooperation via Learning to reshape rewards in semi-cooperative multi-agent reinforcement learning","abstract":"We propose a deep reinforcement learning algorithm for semi-cooperative multi-agent tasks, where agents are equipped with their separate reward functions, yet with willingness to cooperate. Under these semi-cooperative scenarios, popular methods of centralized training with decentralized execution for inducing cooperation and removing the non-stationarity problem do not work well due to lack of a common shared reward as well as inscalability in centralized training. Our algorithm, called Peer-Evaluation based Dual DQN (PED-DQN), proposes to give peer evaluation signals to observed agents, which quantifies how they feel about a certain transition. This exchange of peer evaluation over time turns out to render agents to gradually reshape their reward functions so that their action choices from the myopic best-response tend to result in the good joint action with high cooperation. This evaluation-based method also allows flexible and scalable training by not assuming knowledge of the number of other agents and their observation and action spaces. We provide the performance evaluation of PED-DQN for the scenarios ranging from a simple two-person prisoner's dilemma to more complex semi-cooperative multi-agent tasks. In special cases where agents share a common reward function as in the centralized training methods, we show that inter-agent evaluation allows faster convergence. \n","keywords":["multiagent reinforcement learning","deep reinforcement learning","multiagent systems"],"authorids":["ICLR.cc/2019/Conference/Paper1116/Authors"],"authors":["Anonymous"],"TL;DR":"We use an peer evaluation mechanism to make semi-cooperative agents learn collaborative strategies in multiagent reinforcement learning settings","pdf":"/pdf/ac02f5dfab961642b24e16f2603849f146d5aafb.pdf","paperhash":"anonymous|inducing_cooperation_via_learning_to_reshape_rewards_in_semicooperative_multiagent_reinforcement_learning","_bibtex":"@inproceedings{    \nanonymous2019inducing,    \ntitle={Inducing Cooperation via Learning to reshape rewards in semi-cooperative multi-agent reinforcement learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyVhg20cK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJLhxnRqFQ","original":"HJxyE_6qKX","number":1117,"cdate":1538087924503,"ddate":null,"tcdate":1538087924503,"tmdate":1538155987695,"tddate":null,"forum":"SJLhxnRqFQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Adversarially Learned Mixture Model","abstract":"The Adversarially Learned Mixture Model (AMM) is a generative model for unsupervised or semi-supervised data clustering. The AMM is the first adversarially optimized method to model the conditional dependence between inferred continuous and categorical latent variables. Experiments on the MNIST and SVHN datasets show that the AMM allows for semantic separation of complex data when little or no labeled data is available. The AMM achieves unsupervised clustering error rates of 3.32% and 20.4% on the MNIST and SVHN datasets, respectively.  A semi-supervised extension of the AMM achieves a classification error rate of 5.60% on the SVHN dataset.","keywords":["Unsupervised","Semi-supervised","Generative","Adversarial","Clustering"],"authorids":["ICLR.cc/2019/Conference/Paper1117/Authors"],"authors":["Anonymous"],"TL;DR":"The AMM is the first fully adversarially optimized method to model the conditional dependence between categorical and continuous latent variables.","pdf":"/pdf/a9c763e04547d54f26eb22dd6be464853364e81e.pdf","paperhash":"anonymous|adversarially_learned_mixture_model","_bibtex":"@inproceedings{    \nanonymous2019adversarially,    \ntitle={Adversarially Learned Mixture Model},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJLhxnRqFQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJg6e2CcK7","original":"rJxyLCaqYQ","number":1118,"cdate":1538087924661,"ddate":null,"tcdate":1538087924661,"tmdate":1538155987481,"tddate":null,"forum":"HJg6e2CcK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Clean-Label Backdoor Attacks","abstract":"Deep neural networks have been recently demonstrated to be vulnerable to backdoor attacks. Specifically, by altering a small set of training examples, an adversary can install a backdoor that is able to be used during inference to fully control the model's behavior. While the attack is very powerful, it crucially relies on the adversary being able to introduce arbitrary, often clearly mislabeled, inputs to the training set and can thus be foiled even by fairly rudimentary data sanitization. In this paper, we introduce a new approach to executing backdoor attacks. This approach utilizes adversarial examples and GAN-generated data. The key feature is that the resulting poisoned inputs appear to be consistent with their label and thus seem benign even upon human inspection.","keywords":["data poisoning","backdoor attacks","clean labels","adversarial examples","generative adversarial networks"],"authorids":["ICLR.cc/2019/Conference/Paper1118/Authors"],"authors":["Anonymous"],"TL;DR":"We show how to successfully perform backdoor attacks without changing training labels.","pdf":"/pdf/e177d8f391b53031c7de05d76ffd80c49ac33068.pdf","paperhash":"anonymous|cleanlabel_backdoor_attacks","_bibtex":"@inproceedings{    \nanonymous2019clean-label,    \ntitle={Clean-Label Backdoor Attacks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJg6e2CcK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1lTg3RqYQ","original":"H1e0SGsctX","number":1119,"cdate":1538087924820,"ddate":null,"tcdate":1538087924820,"tmdate":1538155987260,"tddate":null,"forum":"S1lTg3RqYQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Exemplar Guided Unsupervised Image-to-Image Translation with Semantic Consistency","abstract":"Image-to-image translation has recently received significant attention due to advances in deep learning. Most works focus on learning either a one-to-one mapping in an unsupervised way or a many-to-many mapping in a supervised way. However, a more practical setting is many-to-many mapping in an unsupervised way, which is harder due to the lack of supervision and the complex inner- and cross-domain variations. To alleviate these issues, we propose the Exemplar Guided & Semantically Consistent Image-to-image Translation (EGSC-IT) network which conditions the translation process on an exemplar image in the target domain. We assume that an image comprises of a content component which is shared across domains, and a style component specific to each domain. Under the guidance of an exemplar from the target domain we apply Adaptive Instance Normalization to the shared content component, which allows us to transfer the style information of the target domain to the source domain. To avoid semantic inconsistencies during translation that naturally appear due to the large inner- and cross-domain variations, we introduce the concept of feature masks that provide coarse semantic guidance without requiring the use of any semantic labels. Experimental results on various datasets show that EGSC-IT does not only translate the source image to diverse instances in the target domain, but also preserves the semantic consistency during the process. ","keywords":["image-to-image translation","image generation","domain adaptation"],"authorids":["ICLR.cc/2019/Conference/Paper1119/Authors"],"authors":["Anonymous"],"TL;DR":"We propose the Exemplar Guided & Semantically Consistent Image-to-image Translation (EGSC-IT) network which conditions the translation process on an exemplar image in the target domain.","pdf":"/pdf/8a8302ddc810a625058707e8fc14179432869a80.pdf","paperhash":"anonymous|exemplar_guided_unsupervised_imagetoimage_translation_with_semantic_consistency","_bibtex":"@inproceedings{    \nanonymous2019exemplar,    \ntitle={Exemplar Guided Unsupervised Image-to-Image Translation with Semantic Consistency},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lTg3RqYQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1lpx3A9K7","original":"SJlfQAp9t7","number":1120,"cdate":1538087924994,"ddate":null,"tcdate":1538087924994,"tmdate":1538155987052,"tddate":null,"forum":"r1lpx3A9K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference","abstract":"Deep neural networks have been demonstrated to be vulnerable to adversarial attacks, where small perturbations intentionally added to the original inputs can fool the classifier. In this paper, we propose a defense method, Featurized Bidirectional Generative Adversarial Networks (FBGAN), to extract the semantic features of the input and filter the non-semantic perturbation. FBGAN is pre-trained on the clean dataset in an unsupervised manner, adversarially learning a bidirectional mapping between a high-dimensional data space and a low-dimensional semantic space; also mutual information is applied to disentangle the semantically meaningful features. After the bidirectional mapping, the adversarial data can be reconstructed to denoised data, which could be fed into any pre-trained classifier. We empirically show the quality of reconstruction images and the effectiveness of defense.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1120/Authors"],"authors":["Anonymous"],"pdf":"/pdf/9738a275f7113bead3ff53fb05b6e5620a9f6e1b.pdf","paperhash":"anonymous|featurized_bidirectional_gan_adversarial_defense_via_adversarially_learned_semantic_inference","_bibtex":"@inproceedings{    \nanonymous2019featurized,    \ntitle={Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1lpx3A9K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1lTg3RcFm","original":"S1xzkZC9FQ","number":1121,"cdate":1538087925159,"ddate":null,"tcdate":1538087925159,"tmdate":1538155986841,"tddate":null,"forum":"S1lTg3RcFm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Perception-Aware Point-Based Value Iteration for Partially Observable Markov Decision Processes","abstract":"Partially observable Markov decision processes (POMDPs) are a widely-used framework to model decision-making with uncertainty about the environment and under stochastic outcome. In conventional POMDP models, the observations that the agent receives originate from fixed known distribution. However, in a variety of real-world scenarios the agent has an active role in its perception by selecting which observations to receive. Due to combinatorial nature of such selection process, it is computationally intractable to integrate the perception decision with the planning decision. To prevent such expansion of the action space, we propose a greedy strategy for observation selection. \nWe develop a novel point-based value iteration algorithm that incorporates the greedy strategy to find near-optimal selection decision for sampled belief points. This in turn enables the solver to efficiently approximate the reachable subspace of belief simplex by essentially separating computations related to perception from planning.\nLastly, we implement the proposed solver and demonstrate its performance and computational advantage in a range of robotic scenarios where the robot simultaneously performs active perception and planning.","keywords":["partially observable Markov decision processes","active perception","submodular optimization","point-based value iteration","reinforcement learning"],"authorids":["ICLR.cc/2019/Conference/Paper1121/Authors"],"authors":["Anonymous"],"TL;DR":"We develop a point-based value iteration solver for POMDPs with active perception and planning tasks.","pdf":"/pdf/c7c9a0fa3662d32839a8077a7af3f909b54bb826.pdf","paperhash":"anonymous|perceptionaware_pointbased_value_iteration_for_partially_observable_markov_decision_processes","_bibtex":"@inproceedings{    \nanonymous2019perception-aware,    \ntitle={Perception-Aware Point-Based Value Iteration for Partially Observable Markov Decision Processes},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lTg3RcFm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1l6e3RcF7","original":"SJgwzJRcFm","number":1122,"cdate":1538087925320,"ddate":null,"tcdate":1538087925320,"tmdate":1538155986632,"tddate":null,"forum":"B1l6e3RcF7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A Walk with SGD: How SGD Explores Regions of Deep Network Loss?","abstract":"The non-convex nature of the loss landscape of deep neural networks (DNN) lends them the intuition that over the course of training, stochastic optimization algorithms explore different regions of the loss surface by entering and escaping many local minima due to the noise induced by mini-batches. But is this really the case? This question couples the geometry of the DNN loss landscape with how stochastic optimization algorithms like SGD interact with it during training. Answering this question may help us qualitatively understand the dynamics of deep neural network optimization. We show evidence through qualitative and quantitative experiments that mini-batch SGD rarely crosses barriers during DNN optimization. As we show, the mini-batch induced noise helps SGD explore different regions of the loss surface using a seemingly different mechanism. To complement this finding, we also investigate the qualitative reason behind the slowing down of this exploration when using larger batch-sizes. We show this happens because gradients from larger batch-sizes align more with the top eigenvectors of the Hessian, which makes SGD oscillate in the proximity of the parameter initialization, thus preventing exploration.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1122/Authors"],"authors":["Anonymous"],"pdf":"/pdf/f47da99158df06a898f20d9f1e18c0175bb96ef2.pdf","paperhash":"anonymous|a_walk_with_sgd_how_sgd_explores_regions_of_deep_network_loss","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A Walk with SGD: How SGD Explores Regions of Deep Network Loss?},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1l6e3RcF7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1xpe2C5Km","original":"rkg6w-CcKX","number":1123,"cdate":1538087925478,"ddate":null,"tcdate":1538087925478,"tmdate":1538155986418,"tddate":null,"forum":"H1xpe2C5Km","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Trace-back along capsules and its application on semantic segmentation  \t\t","abstract":"In this paper, we propose a capsule-based neural network model to solve the semantic segmentation problem. By taking advantage of the extractable part-whole dependencies available in capsule layers, we derive the probabilities of the class labels for individual capsules through a layer-by-layer recursive procedure. We model this procedure as a traceback layer, and take it as a central piece to build an end-to-end segmentation network. In addition to object boundaries, image-level class labels are also explicitly sought in our model, which poses a significant advantage over the state-of-the-art fully convolutional network (FCN) solutions. Experiments conducted on modified MNIST and neuroimages demonstrate that our model considerably enhance the segmentation performance compared to the leading FCN variant.\n","keywords":["capsule","capsule network","semantic segmentation","FCN"],"authorids":["ICLR.cc/2019/Conference/Paper1123/Authors"],"authors":["Anonymous"],"TL;DR":"A capsule-based semantic segmentation, which the probabilities of the class labels are traced back through capsule layers. ","pdf":"/pdf/4ac43f6305cf3652abc7d1f79b64afabe86b167c.pdf","paperhash":"anonymous|traceback_along_capsules_and_its_application_on_semantic_segmentation","_bibtex":"@inproceedings{    \nanonymous2019trace-back,    \ntitle={Trace-back along capsules and its application on semantic segmentation  \t\t},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1xpe2C5Km},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkxCenR5F7","original":"HklxOh35KQ","number":1124,"cdate":1538087925639,"ddate":null,"tcdate":1538087925639,"tmdate":1538155986211,"tddate":null,"forum":"HkxCenR5F7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Variational recurrent models for representation learning","abstract":"We study the problem of learning representations of sequence data. Recent work has built on variational autoencoders to develop variational recurrent models for generation. Our main goal is not generation but rather representation learning for downstream prediction tasks. Existing variational recurrent models typically use stochastic recurrent connections to model the dependence among neighboring latent variables, while generation assumes independence of generated data per time step given the latent sequence. In contrast, our models assume independence among all latent variables given non-stochastic hidden states, which speeds up inference, while assuming dependence of observations at each time step on all latent variables, which improves representation quality.  In addition, we propose and study extensions for improving downstream performance, including hierarchical auxiliary latent variables and prior updating during training. Experiments show improved performance on several speech and language tasks with different levels of supervision, as well as in a multi-view learning setting.","keywords":["Representation learning","variational model"],"authorids":["ICLR.cc/2019/Conference/Paper1124/Authors"],"authors":["Anonymous"],"pdf":"/pdf/dc11b8a1ae602fbe146f7f105be5aa5aa62d6218.pdf","paperhash":"anonymous|variational_recurrent_models_for_representation_learning","_bibtex":"@inproceedings{    \nanonymous2019variational,    \ntitle={Variational recurrent models for representation learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkxCenR5F7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyxCxhRcY7","original":"H1eYYyAcKX","number":1125,"cdate":1538087925806,"ddate":null,"tcdate":1538087925806,"tmdate":1538155986000,"tddate":null,"forum":"HyxCxhRcY7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Deep Anomaly Detection with Outlier Exposure","abstract":"It is important to detect and handle anomalous inputs when deploying machine learning systems. The use of larger and more complex inputs in deep learning magnifies the difficulty of distinguishing between anomalous and in-distribution examples. At the same time, diverse image and text data commonly used by deep learning systems are available in enormous quantities. We propose leveraging these data to improve deep anomaly detection by training anomaly detectors against an auxiliary dataset of outliers, an approach we call Outlier Exposure (OE). In extensive experiments in vision and natural language processing settings, we find that Outlier Exposure significantly improves the performance of existing anomaly detectors, including detectors based on density estimation, and that OE improves classifier calibration in the presence of anomalous inputs.  We also analyze the flexibility and robustness of Outlier Exposure, and identify characteristics of the auxiliary dataset that improve performance.","keywords":["confidence","uncertainty","anomaly","robustness"],"authorids":["ICLR.cc/2019/Conference/Paper1125/Authors"],"authors":["Anonymous"],"TL;DR":"We teach anomaly detection methods to learn heuristics for spotting new anomalies; experiments are in NLP and vision settings","pdf":"/pdf/8dc286ba2a228c39bc67a621df3a3f6bb6642928.pdf","paperhash":"anonymous|deep_anomaly_detection_with_outlier_exposure","_bibtex":"@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Anomaly Detection with Outlier Exposure},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyxCxhRcY7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1x0enCcK7","original":"SJxcZCp9tX","number":1126,"cdate":1538087925985,"ddate":null,"tcdate":1538087925985,"tmdate":1538155985782,"tddate":null,"forum":"B1x0enCcK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Automatic generation of object shapes with desired functionalities","abstract":"3D objects (artefacts) are made to fulfill functions. Designing an object often starts with defining a list of functionalities that it should provide, also known as functional requirements. Today, the design of 3D object models is still a slow and largely artisanal activity, with few CAD tools existing to aid the exploration of the design solution space. To accelerate the design process, we introduce an algorithm for generating object shapes with desired functionalities.  Following the concept of form follows function, we assume that existing object shapes were rationally chosen to provide desired functionalities. First, we use an artificial neural network to learn a function-to-form mapping by analysing a dataset of objects labeled with their functionalities. Then, we combine forms providing one or more desired functions, generating an object shape that is expected to provide all of them. Finally, we verify in simulation whether the generated object possesses the desired functionalities, by defining and executing functionality tests on it.\n","keywords":["automated design","affordance learning"],"authorids":["ICLR.cc/2019/Conference/Paper1126/Authors"],"authors":["Anonymous"],"TL;DR":"It's difficult to make objects with desired affordances. We propose an automated method for generating object shapes with desired affordances, based on neural networks.","pdf":"/pdf/9f63d5eb812e36a4ffd4a27675d9a68ed7288ed1.pdf","paperhash":"anonymous|automatic_generation_of_object_shapes_with_desired_functionalities","_bibtex":"@inproceedings{    \nanonymous2019automatic,    \ntitle={Automatic generation of object shapes with desired functionalities},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1x0enCcK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkx0g3R5tX","original":"Bklz782qK7","number":1127,"cdate":1538087926153,"ddate":null,"tcdate":1538087926153,"tmdate":1538155985572,"tddate":null,"forum":"rkx0g3R5tX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Partially Mutual Exclusive Softmax for Positive and Unlabeled data","abstract":"In recent years, softmax together with its fast approximations has become the de-facto loss function for deep neural networks with multiclass predictions. However, softmax is used in many problems that do not fully fit the multiclass framework and where the softmax assumption of mutually exclusive outcomes can lead to biased results. This is often the case for applications such as language modeling, next event prediction and matrix factorization, where many of the potential outcomes are not mutually exclusive, but are more likely to be independent conditionally on the state. To this end, for the set of problems with positive and unlabeled data, we propose a relaxation of the original softmax formulation, where, given the observed state, each of the outcomes are conditionally independent but share a common set of negatives. Since we operate in a regime where explicit negatives are missing, we create an adversarially-trained model of negatives and derive a new negative sampling and weighting scheme which we denote as Cooperative Importance Sampling (CIS). We show empirically the advantages of our newly introduced negative sampling scheme by pluging it in the Word2Vec algorithm and benching it extensively against other negative sampling schemes on both language modeling and matrix factorization tasks and show large lifts in performance.","keywords":["Negative Sampling","Sampled Softmax","Word embeddings","Adversarial Networks"],"authorids":["ICLR.cc/2019/Conference/Paper1127/Authors"],"authors":["Anonymous"],"TL;DR":"Defining a partially mutual exclusive softmax loss for postive data and implementing a cooperative based sampling scheme","pdf":"/pdf/e15329822a8671eb6c7cfde053e9a9f9eba6ba12.pdf","paperhash":"anonymous|partially_mutual_exclusive_softmax_for_positive_and_unlabeled_data","_bibtex":"@inproceedings{    \nanonymous2019partially,    \ntitle={Partially Mutual Exclusive Softmax for Positive and Unlabeled data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkx0g3R5tX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rylRgh0qK7","original":"rJgCTJA4FQ","number":1128,"cdate":1538087926320,"ddate":null,"tcdate":1538087926320,"tmdate":1538155985360,"tddate":null,"forum":"rylRgh0qK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Deterministic Policy Gradients with General State Transitions","abstract":"We study a reinforcement learning setting, where the state transition function is a convex combination of a stochastic continuous function and a deterministic function. Such a setting generalizes the widely-studied stochastic state transition setting, namely the setting of deterministic policy gradient (DPG).\n\nWe firstly give a simple example to illustrate that the deterministic policy gradient may be infinite under deterministic state transitions, and introduce a theoretical technique to prove the existence of the policy gradient in this generalized setting. Using this technique, we prove that the deterministic policy gradient indeed exists for a certain set of discount factors, and further prove two conditions that guarantee the existence for all discount factors. We then derive a closed form of the policy gradient whenever exists. Furthermore, to overcome the challenge of high sample complexity of DPG in this setting, we propose the Generalized Deterministic Policy Gradient (GDPG) algorithm. The main innovation of the algorithm is a new method of applying model-based techniques to the model-free algorithm, the deep deterministic policy gradient algorithm (DDPG). GDPG optimize the long-term rewards of the model-based augmented MDP subject to a constraint that the long-rewards of the MDP is less than the original one.\n\nWe finally conduct extensive experiments comparing GDPG with state-of-the-art methods and the direct model-based extension method of DDPG on several standard continuous control benchmarks. Results demonstrate that GDPG substantially outperforms DDPG, the model-based extension of DDPG and other baselines in terms of both convergence and long-term rewards in most environments.","keywords":["Reinforcement Learning","Deterministic Policy Gradients","Model-based"],"authorids":["ICLR.cc/2019/Conference/Paper1128/Authors"],"authors":["Anonymous"],"pdf":"/pdf/39c31f52844c80d9625b533a93af3594bf8d0fe7.pdf","paperhash":"anonymous|deterministic_policy_gradients_with_general_state_transitions","_bibtex":"@inproceedings{    \nanonymous2019deterministic,    \ntitle={Deterministic Policy Gradients with General State Transitions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylRgh0qK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJeRg205Fm","original":"HJeJL44PKQ","number":1129,"cdate":1538087926482,"ddate":null,"tcdate":1538087926482,"tmdate":1538155985149,"tddate":null,"forum":"BJeRg205Fm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Neural Network Regression with Beta, Dirichlet, and Dirichlet-Multinomial Outputs","abstract":"We propose a method for quantifying uncertainty in neural network regression models when the targets are real values on a $d$-dimensional simplex, such as probabilities. We show that each target can be modeled as a sample from a Dirichlet distribution, where the parameters of the Dirichlet are provided by the output of a neural network, and that the combined model can be trained using the gradient of the data likelihood. This approach provides interpretable predictions in the form of multidimensional distributions, rather than point estimates, from which one can obtain confidence intervals or quantify risk in decision making. Furthermore, we show that the same approach can be used to model targets in the form of empirical counts as samples from the Dirichlet-multinomial compound distribution. In experiments, we verify that our approach provides these benefits without harming the performance of the point estimate predictions on two diverse applications: (1) distilling deep convolutional networks trained on CIFAR-100, and (2) predicting the location of particle collisions in the XENON1T Dark Matter detector.","keywords":["regression","uncertainty","deep learning"],"authorids":["ICLR.cc/2019/Conference/Paper1129/Authors"],"authors":["Anonymous"],"TL;DR":"Neural network regression should use Dirichlet output distribution when targets are probabilities in order to quantify uncertainty of predictions.","pdf":"/pdf/307f854d16a91d35691110152d1995c9dfb8a767.pdf","paperhash":"anonymous|neural_network_regression_with_beta_dirichlet_and_dirichletmultinomial_outputs","_bibtex":"@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Network Regression with Beta, Dirichlet, and Dirichlet-Multinomial Outputs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJeRg205Fm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Ske1-209Y7","original":"rkxiIx65YX","number":1130,"cdate":1538087926661,"ddate":null,"tcdate":1538087926661,"tmdate":1538155984939,"tddate":null,"forum":"Ske1-209Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Probabilistic Model-Based Dynamic Architecture Search","abstract":"The architecture search methods for convolutional neural networks (CNNs) have shown promising results. These methods require significant computational resources, as they repeat the neural network training many times to evaluate and search the architectures. Developing the computationally efficient architecture search method is an important research topic. In this paper, we assume that the structure parameters of CNNs are categorical variables, such as types and connectivities of layers, and they are regarded as the learnable parameters. Introducing the multivariate categorical distribution as the underlying distribution for the structure parameters, we formulate a differentiable loss for the training task, where the training of the weights and the optimization of the parameters of the distribution for the structure parameters are coupled. They are trained using the stochastic gradient descent, leading to the optimization of the structure parameters within a single training. We apply the proposed method to search the architecture for two computer vision tasks: image classification and inpainting. The experimental results show that the proposed architecture search method is fast and can achieve comparable performance to the existing methods.","keywords":["architecture search","stochastic natural gradient","convolutional neural networks"],"authorids":["ICLR.cc/2019/Conference/Paper1130/Authors"],"authors":["Anonymous"],"TL;DR":"We present an efficient neural network architecture search method based on stochastic natural gradient method via probabilistic modeling.","pdf":"/pdf/8045cadcb6c967a6a029b65375a700bb61e45ffb.pdf","paperhash":"anonymous|probabilistic_modelbased_dynamic_architecture_search","_bibtex":"@inproceedings{    \nanonymous2019probabilistic,    \ntitle={Probabilistic Model-Based Dynamic Architecture Search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Ske1-209Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SkxJ-309FQ","original":"H1xgIIpqtm","number":1131,"cdate":1538087926826,"ddate":null,"tcdate":1538087926826,"tmdate":1538155984738,"tddate":null,"forum":"SkxJ-309FQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Hallucinations in Neural Machine Translation","abstract":"Neural machine translation (NMT) systems have reached state of the art performance in translating text and are in wide deployment.  Yet little is understood about how these systems function or break.  Here we show that NMT systems are susceptible to producing highly pathological translations that are completely untethered from the source material, which we term hallucinations.  Such pathological translations are problematic because they are are deeply disturbing of user trust and easy to find with a simple search.  We describe a method to generate hallucinations and show that many common variations of the NMT architecture are susceptible to them. We study a variety of approaches to reduce the frequency of hallucinations, including data augmentation, dynamical systems and regularization techniques, showing that data augmentation significantly reduces hallucination frequency. Finally, we analyze networks that produce hallucinations and show that there are signatures in the attention matrix as well as in the stability measures of the decoder.","keywords":["nmt","translate","dynamics","rnn"],"authorids":["ICLR.cc/2019/Conference/Paper1131/Authors"],"authors":["Anonymous"],"TL;DR":"We introduce and analyze the phenomenon of \"hallucinations\" in NMT, or spurious translations unrelated to source text, and propose methods to reduce its frequency.","pdf":"/pdf/5670d12cb8d5a89de116dbabaab9d109aeae60d6.pdf","paperhash":"anonymous|hallucinations_in_neural_machine_translation","_bibtex":"@inproceedings{    \nanonymous2019hallucinations,    \ntitle={Hallucinations in Neural Machine Translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkxJ-309FQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1l1b205KX","original":"HJxST2XqY7","number":1132,"cdate":1538087926992,"ddate":null,"tcdate":1538087926992,"tmdate":1538155984528,"tddate":null,"forum":"B1l1b205KX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Unsupervised Disentangling Structure and Appearance","abstract":"It is challenging to disentangle an object into two orthogonal spaces of structure and appearance since each can influence the visual observation in a different and unpredictable way. It is rare for one to have access to a large number of data to help separate the influences. In this paper, we present a novel framework to learn this disentangled representation in a completely unsupervised manner. We address this problem in a two-branch Variational Autoencoder framework. For the structure branch, we project the latent factor into a soft structured point tensor and constrain it with losses derived from prior knowledge. This encourages the branch to distill geometry information. Another branch learns the complementary appearance information. The two branches form an effective framework that can disentangle object's structure-appearance representation without any human annotation. We evaluate our approach on four image datasets, on which we demonstrate the superior disentanglement and visual analogy quality both in synthesis and real-world data. We are able to generate photo-realistic images with 256*256 resolution that are clearly disentangled in structure and appearance.","keywords":["disentangled representations","VAE","generative models","unsupervised learning"],"authorids":["ICLR.cc/2019/Conference/Paper1132/Authors"],"authors":["Anonymous"],"TL;DR":"We present a novel framework to learn the disentangled representation of structure and appearance in a completely unsupervised manner. ","pdf":"/pdf/e4e29d156e204dca1bf7c15a20486b2687fa4fa8.pdf","paperhash":"anonymous|unsupervised_disentangling_structure_and_appearance","_bibtex":"@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Disentangling Structure and Appearance},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1l1b205KX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkeyZhC9F7","original":"rJx_Yj15KQ","number":1133,"cdate":1538087927163,"ddate":null,"tcdate":1538087927163,"tmdate":1538155984320,"tddate":null,"forum":"HkeyZhC9F7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Heuristics for Automated Reasoning through Reinforcement Learning","abstract":"We demonstrate how to learn efficient heuristics for automated reasoning algorithms through deep reinforcement learning. We focus on backtracking search algorithms for quantified Boolean logics, which already can solve formulas of impressive size - up to 100s of thousands of variables. The main challenge is to find a representation of these formulas that lends itself to making predictions in a scalable way. For challenging problems, the heuristic learned through our approach reduces execution time by >=90% compared to the existing handwritten heuristics.","keywords":["reinforcement learning","deep learning","logics","formal methods","automated reasoning","backtracking search","satisfiability","quantified Boolean formulas"],"authorids":["ICLR.cc/2019/Conference/Paper1133/Authors"],"authors":["Anonymous"],"TL;DR":"RL finds better heuristics for automated reasoning algorithms.","pdf":"/pdf/f8c0b0d641707dab695ceaf0046e0f0c3c6c63a5.pdf","paperhash":"anonymous|learning_heuristics_for_automated_reasoning_through_reinforcement_learning","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Heuristics for Automated Reasoning through Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkeyZhC9F7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJlJ-2CqtX","original":"B1eHgWA5tX","number":1134,"cdate":1538087927329,"ddate":null,"tcdate":1538087927329,"tmdate":1538155984116,"tddate":null,"forum":"rJlJ-2CqtX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Success at any cost: value constrained model-free continuous control","abstract":"Applying Reinforcement Learning algorithms to continuous control problems -- such as locomotion and robot control -- often results in policies which rely on high-amplitude, high-frequency control signals, known colloquially as bang-bang control. While such policies can implement the optimal solution, particularly in simulated systems, they are often not desirable for real world systems since bang-bang control can lead to increased wear and tear and energy consumption and tends to excite undesired second-order dynamics.  To counteract this issue, multi-objective optimization can be used to simultaneously optimize both the reward and some auxiliary cost that discourages undesired (e.g. high-amplitude) control. In principle, such an approach can yield the sought after, smooth, control policies. It can, however, be hard to find the correct trade-off between cost and return that results in the desired behavior. In this paper we propose a new constraint-based approach which defines a lower bound on the return while minimizing one or more costs (such as control effort). We employ Lagrangian relaxation to learn both (a) the parameters of a control policy that satisfies the desired constraints and (b) the Lagrangian multipliers for the optimization. Moreover, we demonstrate policy optimization which satisfies constraints either in expectation or in a per-step fashion, and we learn a single conditional policy that is able to dynamically change the trade-off between return and cost. We demonstrate the efficiency of our approach using both the cart-pole swing-up task as well as a realistic, energy-optimized quadruped locomotion task.","keywords":["reinforcement learning","continuous control","robotics","constrained optimization","multi-objective optimization"],"authorids":["ICLR.cc/2019/Conference/Paper1134/Authors"],"authors":["Anonymous"],"TL;DR":"We apply constrained optimization to continuous control tasks subject to a penalty to ensure a lower bound on the return, and learn the resulting conditional Lagrangian multipliers simultaneously with the policy.","pdf":"/pdf/cbb0a12e9a7f63ff0819ceea61cb7326661bb07f.pdf","paperhash":"anonymous|success_at_any_cost_value_constrained_modelfree_continuous_control","_bibtex":"@inproceedings{    \nanonymous2019success,    \ntitle={Success at any cost: value constrained model-free continuous control},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJlJ-2CqtX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJgy-n0cK7","original":"Hkgn6AhqFX","number":1135,"cdate":1538087927496,"ddate":null,"tcdate":1538087927496,"tmdate":1538155983910,"tddate":null,"forum":"BJgy-n0cK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Inter-BMV: Interpolation with Block Motion Vectors for Fast Semantic Segmentation on Video","abstract":"Models optimized for accuracy on single images are often prohibitively slow to\nrun on each frame in a video, especially on challenging dense prediction tasks,\nsuch as semantic segmentation. Recent work exploits the use of optical flow to\nwarp image features forward from select keyframes, as a means to conserve computation\non video. This approach, however, achieves only limited speedup, even\nwhen optimized, due to the accuracy degradation introduced by repeated forward\nwarping, and the inference cost of optical flow estimation. To address these problems,\nwe propose a new scheme that propagates features using the block motion\nvectors (BMV) present in compressed video (e.g. H.264 codecs), instead of optical\nflow, and bi-directionally warps and fuses features from enclosing keyframes\nto capture scene context on each video frame. Our technique, interpolation-BMV,\nenables us to accurately estimate the features of intermediate frames, while keeping\ninference costs low. We evaluate our system on the CamVid and Cityscapes\ndatasets, comparing to both a strong single-frame baseline and related work. We\nfind that we are able to substantially accelerate segmentation on video, achieving\nnear real-time frame rates (20+ frames per second) on large images (e.g. 960 x \u0002720\npixels), while maintaining competitive accuracy. This represents an improvement\nof almost 6\u0002x over the single-frame baseline and 2.5x\u0002 over the fastest prior work.","keywords":["semantic segmentation","video","efficient inference","video segmentation","video compression"],"authorids":["ICLR.cc/2019/Conference/Paper1135/Authors"],"authors":["Anonymous"],"TL;DR":"We exploit video compression techniques (in particular, the block motion vectors in H.264 video) and feature similarity across frames to accelerate a classical image recognition task, semantic segmentation, on video.","pdf":"/pdf/ac549c52c3095d3757bfe623cbb4f7a37e32d359.pdf","paperhash":"anonymous|interbmv_interpolation_with_block_motion_vectors_for_fast_semantic_segmentation_on_video","_bibtex":"@inproceedings{    \nanonymous2019inter-bmv:,    \ntitle={Inter-BMV: Interpolation with Block Motion Vectors for Fast Semantic Segmentation on Video},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgy-n0cK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hygxb2CqKm","original":"H1xtrh-cYm","number":1136,"cdate":1538087927658,"ddate":null,"tcdate":1538087927658,"tmdate":1538155983696,"tddate":null,"forum":"Hygxb2CqKm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Stable Recurrent Models","abstract":"Stability is a fundamental property of dynamical systems, yet to this date it has had little bearing on the practice of recurrent neural networks. In this work, we conduct a thorough investigation of stable recurrent models. Theoretically, we prove stable recurrent neural networks are well approximated by feed-forward networks for the purpose of both inference and training by gradient descent. Empirically, we demonstrate stable recurrent models often perform as well as their unstable counterparts on benchmark sequence tasks. Taken together, these findings shed light on the effective power of recurrent networks and suggest much of sequence learning happens, or can be made to happen, in the stable regime. Moreover, our results help to explain why in many cases practitioners succeed in replacing recurrent models by feed-forward models.\n","keywords":["stability","gradient descent","non-convex optimization","recurrent neural networks"],"authorids":["ICLR.cc/2019/Conference/Paper1136/Authors"],"authors":["Anonymous"],"TL;DR":"Stable recurrent models can be approximated by feed-forward networks and empirically perform as well as unstable models on benchmark tasks.","pdf":"/pdf/c256e5a891fe9a4a2b998f660da98c510b640ef1.pdf","paperhash":"anonymous|stable_recurrent_models","_bibtex":"@inproceedings{    \nanonymous2019stable,    \ntitle={Stable Recurrent Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hygxb2CqKm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BkxgbhCqtQ","original":"BkgsvM6cF7","number":1137,"cdate":1538087927814,"ddate":null,"tcdate":1538087927814,"tmdate":1538155983483,"tddate":null,"forum":"BkxgbhCqtQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Predictive Uncertainty through Quantization","abstract":"High-risk domains require reliable confidence estimates from predictive models. \nDeep latent variable models provide these, but suffer from the rigid variational distributions used for tractable inference, which err on the side of overconfidence.\nWe propose Stochastic Quantized Activation Distributions (SQUAD), which imposes a flexible yet tractable distribution over discretized latent variables.\nThe proposed method is scalable, self-normalizing and sample efficient. We demonstrate that the model fully utilizes the flexible distribution, learns interesting non-linearities, and provides predictive uncertainty of competitive quality.\n","keywords":["variational inference","information bottleneck","bayesian deep learning","latent variable models","amortized variational inference","uncertainty","learning non-linearities"],"authorids":["ICLR.cc/2019/Conference/Paper1137/Authors"],"authors":["Anonymous"],"TL;DR":"A novel tractable and flexible variational distribution through quantization of latent variables, applied to the deep variational information bottleneck objective for improved uncertainty.","pdf":"/pdf/40076519eac44b8b67cb5c4cddfb7b6b07a3fb11.pdf","paperhash":"anonymous|predictive_uncertainty_through_quantization","_bibtex":"@inproceedings{    \nanonymous2019predictive,    \ntitle={Predictive Uncertainty through Quantization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkxgbhCqtQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Syxgbh05tQ","original":"rkg9z-AqYm","number":1138,"cdate":1538087927976,"ddate":null,"tcdate":1538087927976,"tmdate":1538155983271,"tddate":null,"forum":"Syxgbh05tQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Lyapunov-based Safe Policy Optimization","abstract":"In many reinforcement learning applications, it is crucial that the agent interacts with the environment only through safe policies, i.e.,~policies that do not take the agent to certain undesirable situations. These problems are often formulated as a constrained Markov decision process (CMDP) in which the agent's goal is to optimize its main objective while not violating a number of safety constraints. In this paper, we propose safe policy optimization algorithms that are based on the Lyapunov approach to CMDPs, an approach that has well-established theoretical guarantees in control engineering. We first show how to generate a set of state-dependent Lyapunov constraints from the original CMDP safety constraints. We then propose safe policy gradient algorithms that train a neural network policy using DDPG or PPO, while guaranteeing near-constraint satisfaction at every policy update by projecting either the policy parameter or the action onto the set of feasible solutions induced by the linearized Lyapunov constraints. Unlike the existing (safe) constrained PG algorithms, ours are more data efficient as they are able to utilize both on-policy and off-policy data. Furthermore, the action-projection version of our algorithms often leads to less conservative policy updates and allows for natural integration into an end-to-end PG training pipeline. We evaluate our algorithms and compare them with CPO and the Lagrangian method on several high-dimensional continuous state and action simulated robot locomotion tasks, in which the agent must satisfy certain safety constraints while minimizing its expected cumulative cost. ","keywords":["Reinforcement Learning","Safe Learning","Lyapunov Functions","Constrained Markov Decision Problems"],"authorids":["ICLR.cc/2019/Conference/Paper1138/Authors"],"authors":["Anonymous"],"TL;DR":"Safe Reinforcement Learning Algorithms for Continuous Control","pdf":"/pdf/e1b5a891dd1876cf6c8f99dc7ee5970d7ca1b65d.pdf","paperhash":"anonymous|lyapunovbased_safe_policy_optimization","_bibtex":"@inproceedings{    \nanonymous2019lyapunov-based,    \ntitle={Lyapunov-based Safe Policy Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syxgbh05tQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJxeWnCcF7","original":"SJlrSiN9KQ","number":1139,"cdate":1538087928159,"ddate":null,"tcdate":1538087928159,"tmdate":1538155983063,"tddate":null,"forum":"HJxeWnCcF7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Mixed-Curvature Representations in Product Spaces","abstract":"The quality of the representations achieved by embeddings is determined by how well the geometry of the embedding space matches the structure of the data. Euclidean space has been the workhorse space for embeddings; recently hyperbolic and spherical spaces are gaining popularity due to their ability to better embed new types of structured data---such as hierarchical data---but most data is not structured so uniformly. We address this problem by proposing embedding into a product manifold combining multiple copies of spherical, hyperbolic, and Euclidean spaces, providing a space of heterogeneous curvature suitable for a wide variety of structures. We introduce a heuristic to estimate the sectional curvature of graph data and directly determine the signature---the number of component spaces and their dimensions---of the product manifold. Empirically, we jointly learn the curvature and the embedding in the product space via Riemannian optimization. We discuss how to define and compute intrinsic quantities such as means---a challenging notion for product manifolds---and provably learnable optimization functions. On a range of datasets and reconstruction tasks, our product space embeddings outperform single Euclidean or hyperbolic spaces used in previous works, reducing distortion by 32.55% on a Facebook social network dataset. We learn word embeddings and find that a product of hyperbolic spaces in 50 dimensions consistently improves on baseline Euclidean and hyperbolic embeddings by 2.6 points in Spearman rank correlation on similarity tasks and 3.4 points on analogy accuracy.","keywords":["embeddings","non-Euclidean geometry","manifolds","geometry of data"],"authorids":["ICLR.cc/2019/Conference/Paper1139/Authors"],"authors":["Anonymous"],"TL;DR":"Product manifold embedding spaces with heterogenous curvature yield improved representations compared to traditional embedding spaces for a variety of structures.","pdf":"/pdf/853036bd64b6cd560e7e8208344589531b7f4227.pdf","paperhash":"anonymous|learning_mixedcurvature_representations_in_product_spaces","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Mixed-Curvature Representations in Product Spaces},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxeWnCcF7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJfxbhR9KQ","original":"HkxDoqa5YQ","number":1140,"cdate":1538087928331,"ddate":null,"tcdate":1538087928331,"tmdate":1538155982850,"tddate":null,"forum":"HJfxbhR9KQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Mimicking actions is a good strategy for beginners: Fast Reinforcement Learning with Expert Action Sequences","abstract":"Imitation Learning is the task of mimicking the behavior of an expert player in a Reinforcement Learning(RL) Environment to enhance the training of a fresh agent (called novice) beginning from scratch. Most of the Reinforcement Learning environments are stochastic in nature, i.e., the state sequences that an agent may encounter usually follow a Markov Decision Process (MDP). This makes the task of mimicking difficult as it is very unlikely that a new agent may encounter same or similar state sequences as an expert. Prior research in Imitation Learning proposes various ways to learn a mapping between the states encountered and the respective actions taken by the expert while mostly being agnostic to the order in which these were performed. Most of these methods need considerable number of states-action pairs to achieve good results. We propose a simple alternative to Imitation Learning by appending the novice’s action space with the frequent short action sequences that the expert has taken. This simple modification, surprisingly improves the exploration and significantly outperforms alternative approaches like Dataset Aggregation. We experiment with several popular Atari games and show significant and consistent growth in the score that the new agents achieve using just a few expert action sequences.","keywords":["Reinforcement Learning","Imitation Learning","Atari","A3C","GA3C"],"authorids":["ICLR.cc/2019/Conference/Paper1140/Authors"],"authors":["Anonymous"],"TL;DR":"Appending most frequent action pairs from an expert player to a novice RL agent's action space improves the scores by huge margin.","pdf":"/pdf/260f1cb5afb61580445e2a9bf67a7c2b62782857.pdf","paperhash":"anonymous|mimicking_actions_is_a_good_strategy_for_beginners_fast_reinforcement_learning_with_expert_action_sequences","_bibtex":"@inproceedings{    \nanonymous2019mimicking,    \ntitle={Mimicking actions is a good strategy for beginners: Fast Reinforcement Learning with Expert Action Sequences},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJfxbhR9KQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJggZnRcFQ","original":"B1eVpJO9YQ","number":1141,"cdate":1538087928499,"ddate":null,"tcdate":1538087928499,"tmdate":1538155982640,"tddate":null,"forum":"SJggZnRcFQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Programmatically Structured Representations with Perceptor Gradients","abstract":"We present the perceptor gradients algorithm -- a novel approach to learning symbolic representations based on the idea of decomposing an agent's policy into i) a perceptor network extracting symbols from raw observation data and ii) a task encoding program which maps the input symbols to output actions. We show that the proposed algorithm is able to learn representations that can be directly fed into a Linear-Quadratic Regulator (LQR) or a general purpose A* planner. Our experimental results confirm that the perceptor gradients algorithm is able to efficiently learn transferable symbolic representations as well as generate new observations according to a semantically meaningful specification.\n","keywords":["representation learning","structured representations","symbols","programs"],"authorids":["ICLR.cc/2019/Conference/Paper1141/Authors"],"authors":["Anonymous"],"pdf":"/pdf/fcc826dc1c1edbfe6c8fda6813cb5854b9428e1e.pdf","paperhash":"anonymous|learning_programmatically_structured_representations_with_perceptor_gradients","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Programmatically Structured Representations with Perceptor Gradients},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJggZnRcFQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1eWW2RqFX","original":"r1gC5b09Fm","number":1142,"cdate":1538087928663,"ddate":null,"tcdate":1538087928663,"tmdate":1538155982428,"tddate":null,"forum":"r1eWW2RqFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"PointGrow: Autoregressively Learned Point Cloud Generation with Self-Attention","abstract":"A point cloud is an agile 3D representation, efficiently modeling an object's surface geometry. However, these surface-centric properties also pose challenges on designing tools to recognize and synthesize point clouds. This work presents a novel autoregressive model, PointGrow, which generates realistic point cloud samples from scratch or conditioned from given semantic contexts. Our model operates recurrently, with each point sampled according to a conditional distribution given its previously-generated points. Since point cloud object shapes are typically encoded by long-range interpoint dependencies, we augment our model with dedicated self-attention modules to capture these relations. Extensive evaluation demonstrates that PointGrow achieves satisfying performance on both unconditional and conditional point cloud generation tasks, with respect to fidelity, diversity and semantic preservation. Further, conditional PointGrow learns a smooth manifold of given images where 3D shape interpolation and arithmetic calculation can be performed inside.","keywords":["point cloud generation","autoregressive models","self-attention"],"authorids":["ICLR.cc/2019/Conference/Paper1142/Authors"],"authors":["Anonymous"],"TL;DR":"An autoregressive deep learning model for generating diverse point clouds.","pdf":"/pdf/462e50728f340bfda0a678c6c987050199c82f4e.pdf","paperhash":"anonymous|pointgrow_autoregressively_learned_point_cloud_generation_with_selfattention","_bibtex":"@inproceedings{    \nanonymous2019pointgrow:,    \ntitle={PointGrow: Autoregressively Learned Point Cloud Generation with Self-Attention},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1eWW2RqFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rylbWhC5Ym","original":"SJg2EHictm","number":1143,"cdate":1538087928838,"ddate":null,"tcdate":1538087928838,"tmdate":1538155982220,"tddate":null,"forum":"rylbWhC5Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"HR-TD: A Regularized TD Method to Avoid Over-Generalization","abstract":"Temporal Difference learning with function approximation has been widely used recently and has led to several successful results.  However, compared with the original tabular-based methods, one major drawback of temporal difference learning with neural networks and other function approximators is that they tend to over-generalize across temporally successive states, resulting in slow convergence and even instability. In this work, we propose a novel TD learning method, Hadamard product Regularized TD (HR-TD), that reduces over-generalization and thus leads to faster convergence. This approach can be easily applied to both linear and nonlinear function approximators. \nHR-TD is evaluated on several linear and nonlinear benchmark domains, where we show improvement in learning behavior and performance.","keywords":["Reinforcement Learning","TD Learning","Deep Learning"],"authorids":["ICLR.cc/2019/Conference/Paper1143/Authors"],"authors":["Anonymous"],"TL;DR":"A regularization technique for TD learning that avoids temporal over-generalization, especially in Deep Networks","pdf":"/pdf/7c8f69e154640f8fa0e114300691784da51551aa.pdf","paperhash":"anonymous|hrtd_a_regularized_td_method_to_avoid_overgeneralization","_bibtex":"@inproceedings{    \nanonymous2019hr-td:,    \ntitle={HR-TD: A Regularized TD Method to Avoid Over-Generalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylbWhC5Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkGb-3C5t7","original":"r1lGgStcFm","number":1144,"cdate":1538087929006,"ddate":null,"tcdate":1538087929006,"tmdate":1538155982010,"tddate":null,"forum":"HkGb-3C5t7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"IMPROVING ADVERSARIAL DISCRIMINATIVE DOMAIN ADAPTATION","abstract":"Adversarial discriminative domain adaptation (ADDA) is an efficient framework for unsupervised domain adaptation, where the source and target domains are assumed to have the same classes, but no labels are available for the target domain. While ADDA has already achieved better training efficiency and competitive accuracy in comparison to other adversarial based methods, we investigate whether we can improve performance by incorporating task knowledge into the adversarial loss functions. We achieve this by extending the discriminator output over the source classes and leverage on the distribution over the source encoder posteriors, which is fixed during adversarial training, in order to align a shared encoder distribution to the source domain. The shared encoder receives a proportion of examples from both the source and target datasets, in order to smooth the learned distribution and improve its convergence properties during adversarial training. We additionally consider how the extended discriminator can be regularized in order to further improve performance, by treating the discriminator as a denoising autoencoder and corrupting its input. Our final design employs maximum mean discrepancy and reconstruction-based loss functions for adversarial training. We validate our framework on standard datasets like MNIST, USPS, SVHN, MNISTM and Office-31. Our results on all datasets show that our proposal is both simple and efficient, as it competes or outperforms the state-of-the-art in unsupervised domain adaptation, whilst offering lower complexity than other recent adversarial methods such as DIFA and CoGAN.","keywords":["domain adaptation","unsupervised learning","adversarial methods"],"authorids":["ICLR.cc/2019/Conference/Paper1144/Authors"],"authors":["Anonymous"],"TL;DR":"We improve the performance of ADDA by incorporating task knowledge into the adversarial loss functions and treating the discriminator as a denoising autoencoder.","pdf":"/pdf/ea22bd3a19a32ff4fee174b6239e40fa71b8882d.pdf","paperhash":"anonymous|improving_adversarial_discriminative_domain_adaptation","_bibtex":"@inproceedings{    \nanonymous2019improving,    \ntitle={IMPROVING ADVERSARIAL DISCRIMINATIVE DOMAIN ADAPTATION},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkGb-3C5t7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1gWWh05Y7","original":"SyxAOwa9KQ","number":1145,"cdate":1538087929185,"ddate":null,"tcdate":1538087929185,"tmdate":1538155981798,"tddate":null,"forum":"B1gWWh05Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Exploration in Policy Mirror Descent","abstract":"Policy optimization is a core problem in reinforcement learning. In this paper, we investigate Reversed Entropy Policy Mirror Descent (REPMD), an on-line policy optimization strategy that improves exploration behavior while assuring monotonic progress in a principled objective. REPMD conducts a form of maximum entropy exploration within a mirror descent framework, but uses an alternative policy update with a reversed KL projection. This modified formulation bypasses undesirable mode seeking behavior and avoids premature convergence to sub-optimal policies, while still supporting strong theoretical properties such as guaranteed policy improvement. An experimental evaluation demonstrates that this approach significantly improves practical exploration and surpasses the empirical performance of state-of-the art policy optimization methods in a set of benchmark tasks.","keywords":["Reinforcement Learning","Exploration","Policy Optimization"],"authorids":["ICLR.cc/2019/Conference/Paper1145/Authors"],"authors":["Anonymous"],"pdf":"/pdf/ec568121b7663f6ad015f33c0be2cea2562db6bc.pdf","paperhash":"anonymous|exploration_in_policy_mirror_descent","_bibtex":"@inproceedings{    \nanonymous2019exploration,    \ntitle={Exploration in Policy Mirror Descent},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1gWWh05Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJl-b3RcF7","original":"rklNr_YqKX","number":1146,"cdate":1538087929352,"ddate":null,"tcdate":1538087929352,"tmdate":1538155981592,"tddate":null,"forum":"rJl-b3RcF7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks","abstract":"Neural network pruning techniques can reduce the parameter counts of trained networks by over 90%, decreasing storage requirements and improving computational performance of inference without compromising accuracy. However, contemporary experience is that the sparse architectures produced by pruning are difficult to train from the start, which would similarly improve training performance.\n\nWe find that a standard technique for pruning weights naturally uncovers subnetworks whose initializations made them capable of training effectively. Based on these results, we articulate the \"lottery ticket hypothesis:\" unpruned, randomly-initialized feed-forward networks contain subnetworks (\"winning tickets\") that---when trained in isolation---converge in a comparable number of iterations to comparable generalization accuracy. The winning tickets we find have won the initialization lottery: their connections have initial weights that make training particularly effective.\n\nWe present an algorithm to identify winning tickets and a series of experiments that support the lottery ticket hypothesis and the importance of these fortuitous initializations.  We consistently find winning tickets that are less than 10\\% of the size of several fully-connected and convolutional feed-forward architectures for MNIST and CIFAR10. Furthermore, the winning tickets we find above that size converge faster than the original network and exhibit higher test accuracy.","keywords":["Neural networks","sparsity","pruning","compression","performance","architecture search"],"authorids":["ICLR.cc/2019/Conference/Paper1146/Authors"],"authors":["Anonymous"],"TL;DR":"Feedforward neural networks that can have weights pruned after training could have had the same weights pruned before training","pdf":"/pdf/c6e3b4bf4713f581b29e70a2f81e1bce35da86f6.pdf","paperhash":"anonymous|the_lottery_ticket_hypothesis_finding_sparse_trainable_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019the,    \ntitle={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJl-b3RcF7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyMWn05F7","original":"r1era9T5F7","number":1147,"cdate":1538087929517,"ddate":null,"tcdate":1538087929517,"tmdate":1538155981378,"tddate":null,"forum":"SyMWn05F7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Exploration Policies for Navigation","abstract":"Numerous past works have tackled the problem of task-driven navigation. But, how to effectively explore a new environment to enable a variety of down-stream tasks has received much less attention. In this work, we study how agents can autonomously explore realistic and complex 3D environments without the context of task-rewards. We propose a learning-based approach and investigate different policy architectures, reward functions, and training paradigms. We find that use of policies with spatial memory that are bootstrapped with imitation learning and finally finetuned with coverage rewards derived purely from on-board sensors can be effective at exploring novel environments. We show that our learned exploration policies can explore better than classical approaches based on geometry alone and generic learning-based exploration techniques. Finally, we also show how such task-agnostic exploration can be used for down-stream tasks. Videos are available at https://sites.google.com/view/exploration-for-nav/.","keywords":["Exploration","navigation","reinforcement learning"],"authorids":["ICLR.cc/2019/Conference/Paper1147/Authors"],"authors":["Anonymous"],"pdf":"/pdf/ece554567e11c4d86e1c0821dfaa8f0167c6303d.pdf","paperhash":"anonymous|learning_exploration_policies_for_navigation","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Exploration Policies for Navigation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyMWn05F7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyxMWh09KX","original":"r1gYibA5YQ","number":1148,"cdate":1538087929686,"ddate":null,"tcdate":1538087929686,"tmdate":1538155981167,"tddate":null,"forum":"SyxMWh09KX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Attentive Task-Agnostic Meta-Learning for Few-Shot Text Classification","abstract":"Current deep learning based text classification methods are limited by their ability to achieve fast learning and generalization when the data is scarce. We address this problem by integrating a meta-learning procedure that uses the knowledge learned across many tasks as an inductive bias towards better natural language understanding. Inspired by the Model-Agnostic Meta-Learning framework (MAML), we introduce the Attentive Task-Agnostic Meta-Learning (ATAML) algorithm for text classification. The proposed ATAML is designed to encourage task-agnostic representation learning by way of task-agnostic parameterization and facilitate task-specific adaptation via attention mechanisms. We provide evidence to show that the attention mechanism in ATAML has a synergistic effect on learning performance. Our experimental results reveal that, for few-shot text classification tasks, gradient-based meta-learning approaches ourperform popular transfer learning methods. In comparisons with models trained from random initialization, pretrained models and meta trained MAML, our proposed ATAML method generalizes better on single-label and multi-label classification tasks in miniRCV1 and miniReuters-21578 datasets.","keywords":["meta-learning","learning to learn","few-shot learning"],"authorids":["ICLR.cc/2019/Conference/Paper1148/Authors"],"authors":["Anonymous"],"TL;DR":"Meta-learning task-agnostic representations with attention.","pdf":"/pdf/b2e1422643e66521ec17675ea6c013fc7d58c0c0.pdf","paperhash":"anonymous|attentive_taskagnostic_metalearning_for_fewshot_text_classification","_bibtex":"@inproceedings{    \nanonymous2019attentive,    \ntitle={Attentive Task-Agnostic Meta-Learning for Few-Shot Text Classification},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxMWh09KX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJWfW2C9Y7","original":"HJxVTDqYtm","number":1149,"cdate":1538087929850,"ddate":null,"tcdate":1538087929850,"tmdate":1538155980962,"tddate":null,"forum":"BJWfW2C9Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Predictive Local Smoothness for Stochastic Gradient Methods","abstract":"Stochastic gradient methods are dominant in nonconvex optimization especially for deep models but have low asymptotical convergence due to the fixed smoothness. To address this problem, we propose a simple yet effective method for improving stochastic gradient methods named predictive local smoothness (PLS). First, we create a convergence condition to build a learning rate varied adaptively with local smoothness. Second, the local smoothness can be predicted by the latest gradients. Third, we use the adaptive learning rate to update the stochastic gradients for exploring linear convergence rates. By applying the PLS method, we implement new variants of three popular algorithms: PLS-stochastic gradient descent (PLS-SGD), PLS-accelerated SGD (PLS-AccSGD), and PLS-AMSGrad. Moreover, we provide much simpler proofs to ensure their linear convergence. Empirical results show that our variants have better performance gains than the popular algorithms, such as, faster convergence and alleviating explosion and vanish of gradients.","keywords":["stochastic gradient method","local smoothness","linear system","AMSGrad"],"authorids":["ICLR.cc/2019/Conference/Paper1149/Authors"],"authors":["Anonymous"],"pdf":"/pdf/ddb07bb24b7bf0524af557f7195870382d60e310.pdf","paperhash":"anonymous|predictive_local_smoothness_for_stochastic_gradient_methods","_bibtex":"@inproceedings{    \nanonymous2019predictive,    \ntitle={Predictive Local Smoothness for Stochastic Gradient Methods},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJWfW2C9Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SkfMWhAqYQ","original":"HkgToZ05Ym","number":1150,"cdate":1538087930011,"ddate":null,"tcdate":1538087930011,"tmdate":1538155980756,"tddate":null,"forum":"SkfMWhAqYQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet","abstract":"Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x32 px features and Alexnet performance for 16 x 16 px features). The constraint on local features makes it straight-forward to analyse how exactly each feature of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts, suggesting that modern DNNs approximately follow a similar bag-of-feature strategy.","keywords":["interpretability","representation learning","bag of features","deep learning","object recognition"],"authorids":["ICLR.cc/2019/Conference/Paper1150/Authors"],"authors":["Anonymous"],"TL;DR":"Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.","pdf":"/pdf/4d4950f80a0ef84e60db6e69dc64e020b3d0bda8.pdf","paperhash":"anonymous|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet","_bibtex":"@inproceedings{    \nanonymous2019approximating,    \ntitle={Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkfMWhAqYQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkgfWh0qKX","original":"r1xoJSWcY7","number":1151,"cdate":1538087930189,"ddate":null,"tcdate":1538087930189,"tmdate":1538155980541,"tddate":null,"forum":"rkgfWh0qKX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Do Language Models Have Common Sense?","abstract":"It has been argued that current machine learning models do not have commonsense, and therefore must be hard-coded with prior knowledge (Marcus, 2018). Here we show surprising evidence that language models can already learn to capture certain common sense knowledge. Our key observation is that a language model can compute the probability of any statement, and this probability can be used to evaluate the truthfulness of that statement.  On the Winograd Schema Challenge (Levesque et al., 2011), language models are 11% higher in accuracy than previous state-of-the-art supervised methods. Language models can also be fine-tuned for the task of Mining Commonsense Knowledge on ConceptNet to achieve an F1 score of 0.912 and 0.824, outperforming previous best results (Jastrzebskiet al., 2018).  Further analysis demonstrates that language models can discover unique features of Winograd Schema contexts that decide the correct answers without explicit supervision.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1151/Authors"],"authors":["Anonymous"],"TL;DR":"We present evidence that LMs do capture common sense with state-of-the-art results on both Winograd Schema Challenge and Commonsense Knowledge Mining.","pdf":"/pdf/66733cd0185bdc64077133178135d382c35f8ae2.pdf","paperhash":"anonymous|do_language_models_have_common_sense","_bibtex":"@inproceedings{    \nanonymous2019do,    \ntitle={Do Language Models Have Common Sense?},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkgfWh0qKX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1lz-3Rct7","original":"S1lVbDa9Y7","number":1152,"cdate":1538087930358,"ddate":null,"tcdate":1538087930358,"tmdate":1538155980331,"tddate":null,"forum":"B1lz-3Rct7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Three Mechanisms of Weight Decay Regularization","abstract":"Weight decay is one of the standard tricks in the neural network toolbox, but the reasons for its regularization effect are poorly understood, and recent results have cast doubt on the traditional interpretation in terms of L2 regularization. Literal weight decay has been shown to outperform L2 regularization for optimizers for which they differ.  We empirically investigate weight decay for three optimization algorithms (SGD, Adam, and KFAC) and a variety of network architectures. We identify three distinct mechanisms by which weight decay exerts a regularization effect, depending on the particular optimization algorithm and architecture: (1) increasing the effective learning rate, (2) regularizing approximated input-output Jacobian norm, and (3) reducing the effective damping coefficient for second-order optimization. Our results provide insight into how to improve the regularization of neural networks.","keywords":["Generalization","Regularization","Optimization"],"authorids":["ICLR.cc/2019/Conference/Paper1152/Authors"],"authors":["Anonymous"],"TL;DR":"We investigate weight decay regularization for different optimizers and identify three distinct mechanisms by which weight decay improves generalization.","pdf":"/pdf/7d20958ff96fb67d0bb69e3ef41caae5deebf255.pdf","paperhash":"anonymous|three_mechanisms_of_weight_decay_regularization","_bibtex":"@inproceedings{    \nanonymous2019three,    \ntitle={Three Mechanisms of Weight Decay Regularization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1lz-3Rct7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkxQ-nA9FX","original":"H1eaMjpqYQ","number":1153,"cdate":1538087930522,"ddate":null,"tcdate":1538087930522,"tmdate":1538155980131,"tddate":null,"forum":"rkxQ-nA9FX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Theoretical Analysis of Auto Rate-Tuning by Batch Normalization","abstract":"Batch Normalization (BN) has become a cornerstone of deep learning across diverse architectures, appearing to help optimization as well as generalization. While the idea makes intuitive sense, theoretical analysis of its effectiveness has been lacking. Here theoretical support is provided for one of its conjectured properties, namely, the ability to allow gradient descent to succeed with less tuning of learning rates. It is shown that even if we fix the learning rate of scale-invariant parameters (e.g., weights of each layer with BN) to a constant (say, 0.3), gradient descent still approaches a stationary point (i.e., a solution where gradient is zero) in the rate of T^{−1/2} in T iterations, asymptotically matching the best bound for gradient descent with well-tuned learning rates. A similar result with convergence rate T^{−1/4} is also shown for stochastic gradient descent.","keywords":["batch normalization","scale invariance","learning rate","stationary point"],"authorids":["ICLR.cc/2019/Conference/Paper1153/Authors"],"authors":["Anonymous"],"TL;DR":"We give a theoretical analysis of the ability of batch normalization to automatically tune learning rates, in the context of finding stationary points for a deep learning objective.","pdf":"/pdf/49b97f2150e7a169e44117319034e589e2fb06aa.pdf","paperhash":"anonymous|theoretical_analysis_of_auto_ratetuning_by_batch_normalization","_bibtex":"@inproceedings{    \nanonymous2019theoretical,    \ntitle={Theoretical Analysis of Auto Rate-Tuning by Batch Normalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxQ-nA9FX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1eX-nA5KX","original":"ByxIugT9F7","number":1154,"cdate":1538087930686,"ddate":null,"tcdate":1538087930686,"tmdate":1538155979918,"tddate":null,"forum":"S1eX-nA5KX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"VHEGAN: Variational Hetero-Encoder Randomized GAN for Zero-Short Learning","abstract":"To extract and relate visual and linguistic concepts from images and textual descriptions for text-based zero-shot learning (ZSL), we develop variational hetero-encoder (VHE) that decodes text via a deep probabilisitic topic model, the variational posterior of whose local latent variables is encoded from an image via a Weibull distribution based inference network. To further improve VHE and add an image generator, we propose VHE randomized generative adversarial net (VHEGAN) that exploits the synergy between VHE and GAN through their shared latent space. After training with a hybrid stochastic-gradient MCMC/variational inference/stochastic gradient descent inference algorithm, VHEGAN can be used in a variety of settings, such as text generation/retrieval conditioning on an image, image generation/retrieval conditioning on a document/image, and generation of text-image pairs. The efficacy of VHEGAN is demonstrated quantitatively with experiments on both conventional and generalized ZSL tasks, and qualitatively on (conditional) image and/or text generation/retrieval.","keywords":["Deep generative models","deep topic modeling","generative adversarial learning","variational encoder","zero-short learning"],"authorids":["ICLR.cc/2019/Conference/Paper1154/Authors"],"authors":["Anonymous"],"pdf":"/pdf/288b8ddfaa1d57e7a1159641af52b8b83c186c33.pdf","paperhash":"anonymous|vhegan_variational_heteroencoder_randomized_gan_for_zeroshort_learning","_bibtex":"@inproceedings{    \nanonymous2019vhegan:,    \ntitle={VHEGAN: Variational Hetero-Encoder Randomized GAN for Zero-Short Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1eX-nA5KX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryeX-nC9YQ","original":"SyeljTpcKX","number":1155,"cdate":1538087930846,"ddate":null,"tcdate":1538087930846,"tmdate":1538155979711,"tddate":null,"forum":"ryeX-nC9YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Dimension-Free Bounds for Low-Precision Training","abstract":"Low-precision training is a promising way of decreasing the time and energy cost of training machine learning models.\nPrevious work has analyzed low-precision training algorithms, such as low-precision stochastic gradient descent, and derived theoretical bounds on their convergence rates.\nThese bounds tend to depend on the dimension of the model $d$ in that the number of bits needed to achieve a particular error bound increases as $d$ increases.\nThis is undesirable because a motivating application for low-precision training is large-scale models, such as deep learning, where $d$ can be huge.\nIn this paper, we prove dimension-independent bounds for low-precision training algorithms that use fixed-point arithmetic, which lets us better understand what affects the convergence of these algorithms as parameters scale.\nOur methods also generalize naturally to let us prove new convergence bounds on low-precision training with other quantization schemes, such as low-precision floating-point computation and logarithmic quantization.","keywords":["low precision","stochastic gradient descent"],"authorids":["ICLR.cc/2019/Conference/Paper1155/Authors"],"authors":["Anonymous"],"TL;DR":"we proved dimension-independent bounds for low-precision training algorithms","pdf":"/pdf/dbad092cf35d187ba7689a7a36a2d85ed6ebdc2d.pdf","paperhash":"anonymous|dimensionfree_bounds_for_lowprecision_training","_bibtex":"@inproceedings{    \nanonymous2019dimension-free,    \ntitle={Dimension-Free Bounds for Low-Precision Training},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryeX-nC9YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkeX-3Rqtm","original":"HJx82b05Km","number":1156,"cdate":1538087931009,"ddate":null,"tcdate":1538087931009,"tmdate":1538155979501,"tddate":null,"forum":"rkeX-3Rqtm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Training Hard-Threshold Networks with Combinatorial Search in a Discrete Target Propagation Setting","abstract":"Learning deep neural networks with hard-threshold activation has recently become an important problem due to the proliferation of resource-constrained computing devices. In order to circumvent the inability to train with backpropagation in the present of hard-threshold activations, \\cite{friesen2017} introduced a discrete target propagation framework for training hard-threshold networks in a layer-by-layer fashion. Rather than using a gradient-based target heuristic, we explore the use of search methods for solving the target setting problem. Building on both traditional combinatorial optimization algorithms and gradient-based techniques, we develop a novel search algorithm Guided Random Local Search (GRLS). We demonstrate the effectiveness of our algorithm in training small networks on several datasets and evaluate our target-setting algorithm compared to simpler search methods and gradient-based techniques. Our results indicate that combinatorial optimization is a viable method for training hard-threshold networks that may have the potential to eventually surpass gradient-based methods in many settings. ","keywords":["hard-threshold network","combinatorial optimization","search","target propagation"],"authorids":["ICLR.cc/2019/Conference/Paper1156/Authors"],"authors":["Anonymous"],"pdf":"/pdf/79de3bbc5cbd1165f3632d65918edc0e158681fa.pdf","paperhash":"anonymous|training_hardthreshold_networks_with_combinatorial_search_in_a_discrete_target_propagation_setting","_bibtex":"@inproceedings{    \nanonymous2019training,    \ntitle={Training Hard-Threshold Networks with Combinatorial Search in a Discrete Target Propagation Setting},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkeX-3Rqtm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1eXbn05t7","original":"SyeZ2x39tm","number":1157,"cdate":1538087931171,"ddate":null,"tcdate":1538087931171,"tmdate":1538155979294,"tddate":null,"forum":"B1eXbn05t7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Open-Ended Content-Style Recombination Via Leakage Filtering","abstract":"We consider visual domains in which a class label specifies the content of an image, and class-irrelevant properties that differentiate instances constitute the style.  We present a domain-independent method that permits the open-ended recombination of style of one image with the content of another. Open ended simply means that the method generalizes to style and content not present in the training data. The method starts by constructing a content embedding using an existing deep metric-learning technique. This trained content encoder is incorporated into a variational autoencoder (VAE), paired with a to-be-trained style encoder. The VAE reconstruction loss alone is inadequate to ensure a decomposition of the latent representation into style and content. Our method thus includes an auxiliary loss, leakage filtering, which ensures that no style information remaining in the content representation is used for reconstruction and vice versa. We synthesize novel images by decoding the style representation obtained from one image with the content representation from another. Using this method for data-set augmentation, we obtain state-of-the-art performance on few-shot learning tasks.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1157/Authors"],"authors":["Anonymous"],"pdf":"/pdf/cd65307b830c64e683a59dfbcefb64b7eaee98db.pdf","paperhash":"anonymous|openended_contentstyle_recombination_via_leakage_filtering","_bibtex":"@inproceedings{    \nanonymous2019open-ended,    \ntitle={Open-Ended Content-Style Recombination Via Leakage Filtering},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1eXbn05t7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJeQbnA5tm","original":"HylfABpcY7","number":1158,"cdate":1538087931335,"ddate":null,"tcdate":1538087931335,"tmdate":1538155979086,"tddate":null,"forum":"HJeQbnA5tm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Noisy Information Bottlenecks for Generalization","abstract":"We propose Noisy Information Bottlenecks (NIB) to limit mutual information between learned parameters and the data through noise. We show why this benefits generalization and allows mitigation of model overfitting both for supervised and unsupervised learning, even for arbitrarily complex architectures. We reinterpret methods including the Variational Autoencoder, beta-VAE, network weight uncertainty and a variant of dropout combined with weight decay as special cases of our approach, explaining and quantifying regularizing properties and vulnerabilities within information theory.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1158/Authors"],"authors":["Anonymous"],"pdf":"/pdf/dc27771dff37a33481399992b77f1a04b654bb0d.pdf","paperhash":"anonymous|noisy_information_bottlenecks_for_generalization","_bibtex":"@inproceedings{    \nanonymous2019noisy,    \ntitle={Noisy Information Bottlenecks for Generalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJeQbnA5tm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1l7bnR5Ym","original":"rklDf85cKQ","number":1159,"cdate":1538087931499,"ddate":null,"tcdate":1538087931499,"tmdate":1538155978876,"tddate":null,"forum":"H1l7bnR5Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Bayesian Modelling and Monte Carlo Inference for GAN","abstract":"Bayesian modelling is a principal framework to perform model aggregation, which has been a primary mechanism to combat mode collapsing in the context of Generative Adversarial Networks (GANs). In this paper, we propose a novel Bayesian modelling framework for GANs, which iteratively learns a distribution over generators with a carefully crafted prior.  Learning is efficiently triggered by a tailored stochastic gradient Hamiltonian Monte Carlo with novel gradient approximation to perform Bayesian inference. Our theoretical analysis further reveals that our treatment is the first Bayesian modelling framework that yields an equilibrium where generator distributions are faithful to the data distribution. Empirical evidence on synthetic high-dimensional multi-modal data and the natural image database CIFAR-10 demonstrates the superiority of our method over both start-of-the-art multi-generator GANs and other Bayesian treatment for GANs.","keywords":["Generative Adversarial Networks","Bayesian Deep Learning","Mode Collapse","Inception Score","Generator","Discriminator","CIFAR-10"],"authorids":["ICLR.cc/2019/Conference/Paper1159/Authors"],"authors":["Anonymous"],"TL;DR":"A novel Bayesian treatment for GAN with theoretical guarantee.","pdf":"/pdf/9fd8eac65456798ca5a6436dd58486f6b93cc2fc.pdf","paperhash":"anonymous|bayesian_modelling_and_monte_carlo_inference_for_gan","_bibtex":"@inproceedings{    \nanonymous2019bayesian,    \ntitle={Bayesian Modelling and Monte Carlo Inference for GAN},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1l7bnR5Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hkg4W2AcFm","original":"SylwzBnqFm","number":1160,"cdate":1538087931666,"ddate":null,"tcdate":1538087931666,"tmdate":1538155978661,"tddate":null,"forum":"Hkg4W2AcFm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Overcoming the Disentanglement vs Reconstruction Trade-off via Jacobian Supervision","abstract":"Learning image representations where the factors of variation are disentangled\nis typically achieved with an encoder-decoder architecture where a subset of the\nlatent variables is constrained to correspond to specific factors, and the rest\nof them are considered nuisance variables. This widely used approach has an\nimportant drawback: as the dimension of the nuisance variables is increased,\nbetter image reconstruction is achieved, but the decoder has the flexibility to\nignore the specified factors, thus losing the ability to condition the output on\nthose factors.\nIn this work, we propose to overcome this trade-off by progressively growing the\ndimension of the latent code, while constraining the Jacobian of the output\nimage with respect to the disentangled variables to remain the same.  As a\nresult, the obtained models are effective at both disentangling and reconstruction.\nWe demonstrate the aplicability of this method in both unsupervised and\nsupervised scenarios for learning disentangled representations. In a facial\nattribute manipulation task, we obtain high quality image generation while\nsmoothly controlling dozens of attributes with a single model. This is an order\nof magnitude more disentangled factors than state-of-the-art methods, while\nobtaining visually similar or superior results, and avoiding adversarial\ntraining","keywords":["disentangling","autoencoders","jacobian","face manipulation"],"authorids":["ICLR.cc/2019/Conference/Paper1160/Authors"],"authors":["Anonymous"],"TL;DR":"A method to learn image representations that are good at both disentangling factors of variation and obtaining faithful reconstructions.","pdf":"/pdf/597486417d482cde34c9e1b6fdfdface1a300cf8.pdf","paperhash":"anonymous|overcoming_the_disentanglement_vs_reconstruction_tradeoff_via_jacobian_supervision","_bibtex":"@inproceedings{    \nanonymous2019overcoming,    \ntitle={Overcoming the Disentanglement vs Reconstruction Trade-off via Jacobian Supervision},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hkg4W2AcFm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1xNb2A9YX","original":"HJgDw6icFQ","number":1161,"cdate":1538087931828,"ddate":null,"tcdate":1538087931828,"tmdate":1538155978459,"tddate":null,"forum":"S1xNb2A9YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Minimal Images in Deep Neural Networks: Fragile Object Recognition in Natural Images","abstract":"The human ability to recognize objects is impaired when the object is not shown in full. \"Minimal images\" are the smallest regions of an image that remain recognizable for humans. Ullman et al. (2016) show that a slight modification of the location and size of the visible region of the minimal image produces a sharp drop in human recognition accuracy. In this paper, we demonstrate that such drops in accuracy due to changes of the visible region are a common phenomenon between humans and existing state-of-the-art deep neural networks (DNNs), and are much more prominent in DNNs. We found many cases where DNNs classified one region correctly and the other incorrectly, though they only differed by one row or column of pixels, and were often bigger than the average human minimal image size. We show that this phenomenon is independent from previous works that have reported lack of invariance to minor modifications in object location in DNNs. Our results thus reveal a new failure mode of DNNs that also affects humans to a much lesser degree. They expose how fragile DNN recognition ability is in natural images even without adversarial patterns being introduced. Bringing the robustness of DNNs in natural images to the human level remains an open challenge for the community. ","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1161/Authors"],"authors":["Anonymous"],"pdf":"/pdf/20cb85d674f05301452d5fc91519668b7c85c51d.pdf","paperhash":"anonymous|minimal_images_in_deep_neural_networks_fragile_object_recognition_in_natural_images","_bibtex":"@inproceedings{    \nanonymous2019minimal,    \ntitle={Minimal Images in Deep Neural Networks: Fragile Object Recognition in Natural Images},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1xNb2A9YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rylV-2C9KQ","original":"H1xCn-AcFm","number":1162,"cdate":1538087931988,"ddate":null,"tcdate":1538087931988,"tmdate":1538155978242,"tddate":null,"forum":"rylV-2C9KQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks","abstract":"Deep neural networks, in particular convolutional neural networks, have become highly effective tools for compressing images and solving inverse problems including denoising, inpainting, and reconstruction from few and noisy measurements. \nThis success can be attributed in part to their ability to represent and generate natural images well. \nContrary to classical tools such as wavelets, image-generating deep neural networks have a large number of parameters---typically a multiple of their output dimension---and need to be trained on large datasets.\nIn this paper, we propose an untrained simple image model, called the deep decoder, which is a deep neural network that can generate natural images from very few parameters.  As a consequence, we demonstrate that this network enables efficient image compression and state-of-the-art performance for inverse problems like denoising. \nContrary to previous deep image generators (trained or not) the network is under-parameterized, and thus conforms with the classical perspective that an efficient model maps a low-dimensional parameter space to a high-dimensional image space. \nIn addition, the deep decoder is simple in the sense that each layer has an identical structure that consists of only one upsampling unit, pixel-wise linear combination of channels, ReLU nonlinearity, and channelwise normalization.  This simplicity makes the program amenable to theoretical analysis.  Notably, the deep decoder does not involve convolutional layers.","keywords":["natural image model","image prior","under-determined neural networks","untrained network","non-convolutional network","denoising","inverse problem"],"authorids":["ICLR.cc/2019/Conference/Paper1162/Authors"],"authors":["Anonymous"],"TL;DR":"We introduce an underparameterized, nonconvolutional, and simple deep neural network that can, without training, effectively represent natural images and solve image processing tasks like compression and denoising competitively.","pdf":"/pdf/f60c0db0cf104dde28678704f3184cde322ec5bc.pdf","paperhash":"anonymous|deep_decoder_concise_image_representations_from_untrained_nonconvolutional_networks","_bibtex":"@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylV-2C9KQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJg4Z3RqF7","original":"H1ekHTp5t7","number":1163,"cdate":1538087932159,"ddate":null,"tcdate":1538087932159,"tmdate":1538155978039,"tddate":null,"forum":"BJg4Z3RqF7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Unsupervised Adversarial Image Reconstruction","abstract":"We address the problem of recovering an underlying signal from lossy and inaccurate measurements in an unsupervised fashion. Typically, we consider situations where there is no background knowledge on the structure of the unknown signal and where we do not have access to signal-measurement pairs, nor even unpaired signal data. We introduce a general framework, where a neural network is trained to recover plausible signals from the measurements in the data, by introducing an adversarial and a reconstruction loss. We evaluate our framework on different noise instances, and show that our approach yields comparable results to model variants trained with stronger supervision.","keywords":["Deep Learning","Adversarial","MAP","GAN","neural networks"],"authorids":["ICLR.cc/2019/Conference/Paper1163/Authors"],"authors":["Anonymous"],"pdf":"/pdf/75ee3664f65092c145619b203d3188530b521492.pdf","paperhash":"anonymous|unsupervised_adversarial_image_reconstruction","_bibtex":"@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Adversarial Image Reconstruction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJg4Z3RqF7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJeEWnR9F7","original":"HygFmHfYtm","number":1164,"cdate":1538087932329,"ddate":null,"tcdate":1538087932329,"tmdate":1538155977828,"tddate":null,"forum":"HJeEWnR9F7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Scaling up Deep Learning for PDE-based Models","abstract":"Across numerous applications, forecasting relies on numerical solvers for partial differential equations (PDEs). Although the use of deep-learning techniques has been proposed, the uses have been restricted by the fact the training data are obtained using PDE solvers. Thereby, the uses were limited to domains, where the PDE solver was applicable, but no further. \n\nWe present methods for training on small domains, while applying the trained models on larger domains, with consistency constraints ensuring the solutions are physically meaningful even at the boundary of the small domains. We demonstrate the results on an air-pollution forecasting model for Dublin, Ireland.","keywords":["recurrent neural networks","partial differential equation","domain decomposition","consistency constraints","advection","diffusion"],"authorids":["ICLR.cc/2019/Conference/Paper1164/Authors"],"authors":["Anonymous"],"TL;DR":"We present RNNs for training surrogate models of PDEs, wherein consistency constraints ensure the solutions are physically meaningful, even when the training uses much smaller domains than the trained model is applied to.","pdf":"/pdf/8701bc2d7a61b4324c361822b5ec940be4b02706.pdf","paperhash":"anonymous|scaling_up_deep_learning_for_pdebased_models","_bibtex":"@inproceedings{    \nanonymous2019scaling,    \ntitle={Scaling up Deep Learning for PDE-based Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJeEWnR9F7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyzVb3CcFX","original":"S1lgKxsKtQ","number":1165,"cdate":1538087932495,"ddate":null,"tcdate":1538087932495,"tmdate":1538155977617,"tddate":null,"forum":"SyzVb3CcFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Time-Agnostic Prediction: Predicting Predictable Video Frames","abstract":"Prediction is arguably one of the most basic functions of an intelligent system. In general, the problem of predicting events in the future or between two waypoints is exceedingly difficult. However, most phenomena naturally pass through relatively predictable bottlenecks---while we cannot predict the precise trajectory of a robot arm between being at rest and holding an object up, we can be certain that it must have picked the object up. To exploit this, we decouple visual prediction from a rigid notion of time. While conventional approaches predict frames at regularly spaced temporal intervals, our time-agnostic predictors (TAP) are not tied to specific times so that they may instead discover predictable \"bottleneck\" frames no matter when they occur. We evaluate our approach for future and intermediate frame prediction across three robotic manipulation tasks. Our predictions are not only of higher visual quality, but also correspond to coherent semantic subgoals in temporally extended tasks.","keywords":["visual prediction","subgoal generation","bottleneck states","time-agnostic"],"authorids":["ICLR.cc/2019/Conference/Paper1165/Authors"],"authors":["Anonymous"],"TL;DR":"In visual prediction tasks, letting your predictive model choose which times to predict does two things: (i) improves prediction quality, and (ii) leads to semantically coherent \"bottleneck state\" predictions, which are useful for planning.","pdf":"/pdf/15a26f973927f3ea37d6c5a3fc5fefa8273389f6.pdf","paperhash":"anonymous|timeagnostic_prediction_predicting_predictable_video_frames","_bibtex":"@inproceedings{    \nanonymous2019time-agnostic,    \ntitle={Time-Agnostic Prediction: Predicting Predictable Video Frames},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyzVb3CcFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1xrb3CqtQ","original":"BygjthpqKX","number":1166,"cdate":1538087932665,"ddate":null,"tcdate":1538087932665,"tmdate":1538155977406,"tddate":null,"forum":"r1xrb3CqtQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Latent Domain Transfer: Crossing modalities with Bridging Autoencoders","abstract":"Domain transfer is a exciting and challenging branch of machine learning because models must learn to smoothly transfer between domains, preserving local variations and capturing many aspects of variation without labels. \nHowever, most successful applications to date require the two domains to be closely related (ex. image-to-image, video-video), \nutilizing similar or shared networks to transform domain specific properties like texture, coloring, and line shapes. \nHere, we demonstrate that it is possible to transfer across modalities (ex. image-to-audio) by first abstracting the data with latent generative models and then learning transformations between latent spaces. \nWe find that a simple variational autoencoder is able to learn a shared latent space to bridge between two generative models in an unsupervised fashion, and even between different types of models (ex. variational autoencoder and a generative adversarial network). \nWe can further impose desired semantic alignment of attributes with a linear classifier in the shared latent space. \nThe proposed variation autoencoder enables preserving both locality and semantic alignment through the transfer process, as shown in the qualitative and quantitative evaluations.\nFinally, the hierarchical structure decouples the cost of training the base generative models and semantic alignments, enabling computationally efficient and data efficient retraining of personalized mapping functions. ","keywords":["Generative Model","Latent Space","Domain Transfer"],"authorids":["ICLR.cc/2019/Conference/Paper1166/Authors"],"authors":["Anonymous"],"TL;DR":"Conditional VAE on top of latent spaces of pre-trained generative models that enables  transfer between drastically different domains while preserving locality and semantic alignment.","pdf":"/pdf/1a9b2b5cdf92d52d8b5e725150332340cf2d135f.pdf","paperhash":"anonymous|latent_domain_transfer_crossing_modalities_with_bridging_autoencoders","_bibtex":"@inproceedings{    \nanonymous2019latent,    \ntitle={Latent Domain Transfer: Crossing modalities with Bridging Autoencoders},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xrb3CqtQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rylBZ305KQ","original":"rJx8nCp9Y7","number":1167,"cdate":1538087932829,"ddate":null,"tcdate":1538087932829,"tmdate":1538155977195,"tddate":null,"forum":"rylBZ305KQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Dynamic Recurrent Language Model","abstract":"Language evolves over time with trends and shifts in technological, political, or cultural contexts. Capturing these variations is important to develop better language models. While recent works tackle temporal drifts by learning diachronic embeddings, we instead propose to integrate a temporal component into a recurrent language model. It takes the form of global latent variables, which are structured in time by a learned non-linear transition function. We perform experiments on three time annotated corpora. Experimental results on language modeling and classification tasks show that our model performs consistently better than temporal word embedding methods in two temporal evaluation settings: prediction and modeling. Moreover, we empirically show that the system is able to predict informative latent states in the future.","keywords":["language modeling","variational inference","dynamic model","temporal data","deep learning"],"authorids":["ICLR.cc/2019/Conference/Paper1167/Authors"],"authors":["Anonymous"],"pdf":"/pdf/4c1d76e7b19b1ddaa81d859cb8b0120a2622ccab.pdf","paperhash":"anonymous|dynamic_recurrent_language_model","_bibtex":"@inproceedings{    \nanonymous2019dynamic,    \ntitle={Dynamic Recurrent Language Model},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylBZ305KQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HygBZnRctX","original":"BklG1p6cKQ","number":1168,"cdate":1538087932989,"ddate":null,"tcdate":1538087932989,"tmdate":1538155976987,"tddate":null,"forum":"HygBZnRctX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Transferring Knowledge across Learning Processes","abstract":"In complex transfer learning scenarios new tasks might not be tightly linked to previous tasks. Approaches that transfer information contained only in the final parameters of a source model will therefore struggle. Instead, transfer learning at a higher level of abstraction is needed. We propose Leap, a framework that achieves this by transferring knowledge across learning processes. We associate each task with a manifold on which the training process travels from initialization to final parameters and construct a meta learning objective that minimizes the expected length of this path. Our framework leverages only information obtained during training and can be computed on the fly at negligible cost. We demonstrate that our framework outperforms competing methods, both in meta learning and transfer learning, on a set of computer vision tasks. Finally, we demonstrate that Leap can transfer knowledge across learning processes in demanding Reinforcement learning environments (Atari) that involve millions of gradient steps.","keywords":["Meta Learning","Transfer Learning"],"authorids":["ICLR.cc/2019/Conference/Paper1168/Authors"],"authors":["Anonymous"],"TL;DR":"We propose Leap, a framework that transfers knowledge across learning processes by  minimizing the expected distance the training process travels on a task's loss surface.","pdf":"/pdf/9394cbc889c123d2fe4a4b103f7c9fc71fda711c.pdf","paperhash":"anonymous|transferring_knowledge_across_learning_processes","_bibtex":"@inproceedings{    \nanonymous2019transferring,    \ntitle={Transferring Knowledge across Learning Processes},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HygBZnRctX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ByxHb3R5tX","original":"Skx5zsTqF7","number":1169,"cdate":1538087933163,"ddate":null,"tcdate":1538087933163,"tmdate":1538155976779,"tddate":null,"forum":"ByxHb3R5tX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Universal Successor Features for Transfer Reinforcement Learning","abstract":"Transfer in Reinforcement Learning (RL) refers to the idea of applying knowledge gained from previous tasks to solving related tasks. Learning a universal value function (Schaul et al., 2015), which generalizes over goals and states, has previously been shown to be useful for transfer. However, successor features are believed to be more suitable than values for transfer (Dayan, 1993; Barreto et al.,2017), even though they cannot directly generalize to new goals. In this paper, we propose (1) Universal Successor Features (USFs) to capture the underlying dynamics of the environment while allowing generalization to unseen goals and (2) a flexible end-to-end model of USFs that can be trained by interacting with the environment. We show that learning USFs is compatible with any RL algorithm that learns state values using a temporal difference method. Our experiments in a simple gridworld and with two MuJoCo environments show that USFs can greatly accelerate training when learning multiple tasks and can effectively transfer knowledge to new tasks.","keywords":["Reinforcement Learning","Successor Features","Successor Representations","Transfer Learning","Representation Learning"],"authorids":["ICLR.cc/2019/Conference/Paper1169/Authors"],"authors":["Anonymous"],"pdf":"/pdf/2f9bb92ba68349ca11c3bf9d5a2512866192e527.pdf","paperhash":"anonymous|universal_successor_features_for_transfer_reinforcement_learning","_bibtex":"@inproceedings{    \nanonymous2019universal,    \ntitle={Universal Successor Features for Transfer Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByxHb3R5tX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1GHb2RqYX","original":"BklmACpqt7","number":1170,"cdate":1538087933346,"ddate":null,"tcdate":1538087933346,"tmdate":1538155976574,"tddate":null,"forum":"B1GHb2RqYX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"PolyCNN: Learning Seed Convolutional Filters","abstract":"In this work, we propose the polynomial convolutional neural network (PolyCNN), as a new design of a weight-learning efficient variant of the traditional CNN. The biggest advantage of the PolyCNN is that at each convolutional layer, only one convolutional filter is needed for learning the weights, which we call the seed filter, and all the other convolutional filters are the polynomial transformations of the seed filter, which is termed as an early fan-out. Alternatively, we can also perform late fan-out on the seed filter response to create the number of response maps needed to be input into the next layer. Both early and late fan-out allow the PolyCNN to learn only one convolutional filter at each layer, which can dramatically reduce the model complexity by saving 10x to 50x parameters during learning. While being efficient during both training and testing, the PolyCNN does not suffer performance due to the non-linear polynomial expansion which translates to richer representational power within the convolutional layers. By allowing direct control over model complexity, PolyCNN provides a flexible trade-off between performance and efficiency. We have verified the on-par performance between the proposed PolyCNN and the standard CNN on several visual datasets, such as MNIST, CIFAR-10, SVHN, and ImageNet.","keywords":["Efficient CNN","Seed convolutional filter"],"authorids":["ICLR.cc/2019/Conference/Paper1170/Authors"],"authors":["Anonymous"],"TL;DR":"PolyCNN only needs to learn one seed convolutional filter at each layer. This is an efficient variant of traditional CNN, with on-par performance.","pdf":"/pdf/eab96709ff84ca55714b348bfcb4a9b1c82060b8.pdf","paperhash":"anonymous|polycnn_learning_seed_convolutional_filters","_bibtex":"@inproceedings{    \nanonymous2019polycnn:,    \ntitle={PolyCNN: Learning Seed Convolutional Filters},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1GHb2RqYX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1MB-3RcF7","original":"SkgWzDccYX","number":1171,"cdate":1538087933507,"ddate":null,"tcdate":1538087933507,"tmdate":1538155976364,"tddate":null,"forum":"S1MB-3RcF7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Multi-objective training of Generative Adversarial Networks with multiple discriminators","abstract":"Recent literature has demonstrated promising results on the training of Generative Adversarial Networks by employing a set of discriminators, as opposed to the traditional game involving one generator against a single adversary. Those methods perform single-objective optimization on some simple consolidation of the losses, e.g. an average. In this work, we revisit the multiple-discriminator approach by framing the simultaneous minimization of losses provided by different models as a multi-objective optimization problem. Specifically, we evaluate the performance of multiple gradient descent and the hypervolume maximization algorithm on a number of different datasets. Moreover, we argue that the previously proposed methods and hypervolume maximization can all be seen as variations of multiple gradient descent in which the update direction computation can be done efficiently. Our results indicate that hypervolume maximization presents a better compromise between sample quality and diversity, and computational cost than previous methods.","keywords":["Generative Adversarial Networks","Multi-objective optimization","Generative models"],"authorids":["ICLR.cc/2019/Conference/Paper1171/Authors"],"authors":["Anonymous"],"TL;DR":"We introduce hypervolume maximization for training GANs with multiple discriminators, showing performance improvements in terms of sample quality and diversity. ","pdf":"/pdf/d2467496e1ae521e5b1dc7c604199499f030d8e5.pdf","paperhash":"anonymous|multiobjective_training_of_generative_adversarial_networks_with_multiple_discriminators","_bibtex":"@inproceedings{    \nanonymous2019multi-objective,    \ntitle={Multi-objective training of Generative Adversarial Networks with multiple discriminators},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1MB-3RcF7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1xLZ2R5KQ","original":"Skgp6bC9tm","number":1172,"cdate":1538087933682,"ddate":null,"tcdate":1538087933682,"tmdate":1538155976157,"tddate":null,"forum":"S1xLZ2R5KQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Maximum a Posteriori on a Submanifold: a General Image Restoration Method with GAN","abstract":"We propose a general method for various image restoration problems, such as denoising, deblurring, super-resolution and inpainting. The problem is formulated as a constrained optimization problem. Its objective is to maximize a posteriori probability of latent variables, and its constraint is that the image generated by these latent variables must be the same as the degraded image. We use a Generative Adversarial Network (GAN) as our density estimation model. Convincing results are obtained on MNIST dataset.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1172/Authors"],"authors":["Anonymous"],"pdf":"/pdf/c37f6720ae7ff4c9e85a0534c3c2fa54c5246703.pdf","paperhash":"anonymous|maximum_a_posteriori_on_a_submanifold_a_general_image_restoration_method_with_gan","_bibtex":"@inproceedings{    \nanonymous2019maximum,    \ntitle={Maximum a Posteriori on a Submanifold: a General Image Restoration Method with GAN},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1xLZ2R5KQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1x8WnA5Ym","original":"HkeIOXlKYX","number":1173,"cdate":1538087933839,"ddate":null,"tcdate":1538087933839,"tmdate":1538155975950,"tddate":null,"forum":"S1x8WnA5Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Diverse Generations using Determinantal Point Processes","abstract":"Generative models have proven to be an outstanding tool for representing high-\ndimensional probability distributions and generating realistic looking images. A\nfundamental characteristic of generative models is their ability to produce multi-\nmodal outputs. However while training, they are often susceptible to mode col-\nlapse, which means that the model is limited in mapping the input noise to only\na few modes of the true data distribution. In this paper, we draw inspiration from\nDeterminantal Point Process (DPP) to devise a generative model that alleviates\nmode collapse problem while producing higher quality samples. DPP is an ele-\ngant probabilistic measure used to model negative correlations within a subset, and\nhence quantify its diversity. We propose a generation penalty term that encourages\nthe generator to behave as a Determinantal Point Process sampler and hence learns\nto generates diverse data. In contrast to previous state-of-the-art generative mod-\nels that tend to use additional trainable parameters or complex training paradigms,\nour method does not change the original training scheme. Embedded in an ad-\nversarial strategy, our Generative DPP approach shows a consistent resistance to\nmode-collapse on a wide-variety of synthetic data and natural image datasets in-\ncluding MNIST and CIFAR10, while outperforming state-of-the-art methods for\ndata-efficiency, convergence-time, and generation quality. Our code will be made\npublicly available.","keywords":["Generative Adversarial Networks"],"authorids":["ICLR.cc/2019/Conference/Paper1173/Authors"],"authors":["Anonymous"],"TL;DR":"The addition of a diversity criterion inspired from DPP in the GAN objective avoids mode collapse and leads to better generations. ","pdf":"/pdf/60132625ef67cae51719bf67868c1abf4c942483.pdf","paperhash":"anonymous|learning_diverse_generations_using_determinantal_point_processes","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Diverse Generations using Determinantal Point Processes},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1x8WnA5Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryl8-3AcFX","original":"BklubSuqYX","number":1174,"cdate":1538087934000,"ddate":null,"tcdate":1538087934000,"tmdate":1538155975743,"tddate":null,"forum":"ryl8-3AcFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Environment Probing Interaction Policies","abstract":"A key challenge in reinforcement learning (RL) is environment generalization: a policy trained to solve a task in one environment often fails to solve the same task in a slightly different test environment. A common approach to improve inter-environment transfer is to learn policies that are invariant to the distribution of testing environments. However, we argue that instead of being invariant, the policy should identify the specific nuances of an environment and exploit them to achieve better performance. In this work, we propose the “Environment-Probing” Interaction (EPI) policy, a policy that probes a new environment to extract an implicit understanding of that environment’s behavior. Once this environment-specific information is obtained, it is used as an additional input to a task-specific policy that can now perform environment-conditioned actions to solve a task. To learn these EPI-policies, we present a reward function based on transition predictability. Specifically, a higher reward is given if the trajectory generated by the EPI-policy can be used to better predict transitions. We experimentally show that EPI-conditioned task-specific policies significantly outperform commonly used policy generalization methods on novel testing environments.","keywords":["Reinforcement Learning"],"authorids":["ICLR.cc/2019/Conference/Paper1174/Authors"],"authors":["Anonymous"],"pdf":"/pdf/5729f47bb76ca61354373bfcc6212f07860c773c.pdf","paperhash":"anonymous|environment_probing_interaction_policies","_bibtex":"@inproceedings{    \nanonymous2019environment,    \ntitle={Environment Probing Interaction Policies},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryl8-3AcFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1gL-2A9Ym","original":"H1lMzvScFX","number":1175,"cdate":1538087934169,"ddate":null,"tcdate":1538087934169,"tmdate":1538155975538,"tddate":null,"forum":"H1gL-2A9Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Personalized Embedding Propagation: Combining Neural Networks on Graphs with Personalized PageRank","abstract":"Neural message passing algorithms for semi-supervised classification on graphs have recently achieved great success. However, these methods only consider nodes that are a few propagation steps away and the size of this utilized neighborhood cannot be easily extended. In this paper, we use the relationship between graph convolutional networks (GCN) and PageRank to derive an improved propagation scheme based on personalized PageRank. We utilize this propagation procedure to construct personalized embedding propagation (PEP) and its approximation, PEP$_\\text{A}$. Our model's training time is on par or faster and its number of parameters on par or lower than previous models. It leverages a large, adjustable neighborhood for classification and can be combined with any neural network. We show that this model outperforms several recently proposed methods for semi-supervised classification on multiple graphs in the most thorough study done so far for GCN-like models.","keywords":["Graph","GCN","Neural network","Semi-supervised classification","Semi-supervised learning","PageRank","Personalized PageRank"],"authorids":["ICLR.cc/2019/Conference/Paper1175/Authors"],"authors":["Anonymous"],"TL;DR":"Personalized embedding propagation combines neural networks with personalized PageRank for semi-supervised classification on graphs.","pdf":"/pdf/3801d305bb6ead1f2ad2dee16365e1dbc8b2b1e1.pdf","paperhash":"anonymous|personalized_embedding_propagation_combining_neural_networks_on_graphs_with_personalized_pagerank","_bibtex":"@inproceedings{    \nanonymous2019personalized,    \ntitle={Personalized Embedding Propagation: Combining Neural Networks on Graphs with Personalized PageRank},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1gL-2A9Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rke8ZhCcFQ","original":"HkxFt_5qKX","number":1176,"cdate":1538087934347,"ddate":null,"tcdate":1538087934347,"tmdate":1538155975329,"tddate":null,"forum":"rke8ZhCcFQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"ATTACK GRAPH CONVOLUTIONAL NETWORKS BY ADDING FAKE NODES","abstract":"Graph convolutional networks (GCNs) have been widely used for classifying graph nodes in the semi-supervised setting.\nPrevious works have shown that GCNs are vulnerable to the perturbation on adjacency and feature matrices of existing nodes. However, it is unrealistic to change the connections of  existing nodes in many applications, such as existing users in social networks. In this paper, we investigate methods attacking GCNs by adding fake nodes. A greedy algorithm is proposed to generate adjacency and feature matrices of fake nodes, aiming to minimize the classification accuracy on the existing ones. In additional, we introduce a discriminator to classify fake nodes from real nodes, and propose a Greedy-GAN algorithm to simultaneously update the discriminator and the attacker, to make fake nodes indistinguishable to the real ones.  Our non-targeted attack decreases the accuracy of GCN down to 0.10, and our targeted attack reaches a success rate of 0.99 for attacking the whole datasets, and 0.94 on average for attacking a single node.","keywords":["Graph Convolutional Network","adversarial attack","node classification"],"authorids":["ICLR.cc/2019/Conference/Paper1176/Authors"],"authors":["Anonymous"],"TL;DR":"non-targeted and targeted attack on GCN by adding fake nodes","pdf":"/pdf/599c2e723f3adbb416da281cc68db4a7b0841082.pdf","paperhash":"anonymous|attack_graph_convolutional_networks_by_adding_fake_nodes","_bibtex":"@inproceedings{    \nanonymous2019attack,    \ntitle={ATTACK GRAPH CONVOLUTIONAL NETWORKS BY ADDING FAKE NODES},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rke8ZhCcFQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyxwW2A5Km","original":"SJlNZOp9Fm","number":1177,"cdate":1538087934519,"ddate":null,"tcdate":1538087934519,"tmdate":1538155975121,"tddate":null,"forum":"SyxwW2A5Km","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Representations of Categorical Feature Combinations via Self-Attention","abstract":"Self-attention has been widely used to model the sequential data and achieved remarkable results in many applications. Although it can be used to model dependencies without regard to positions of sequences, self-attention is seldom applied to non-sequential data. In this work, we propose to learn representations of multi-field categorical data in prediction tasks via self-attention mechanism, where features are orderless but have intrinsic relations over different fields. In most current DNN based models, feature embeddings are simply concatenated for further processing by networks. Instead, by applying self-attention to transform the embeddings, we are able to relate features in different fields and automatically learn representations of their combinations, which are known as the factors of many prevailing linear models. To further improve the effect of feature combination mining, we modify the original self-attention structure by restricting the similarity weight to have at most k non-zero values, which additionally regularizes the model. We experimentally evaluate the effectiveness of our self-attention model on non-sequential data. Across two click through rate prediction benchmark datasets, i.e., Cretio and Avazu, our model with top-k restricted self-attention achieves the state-of-the-art performance. Compared with the vanilla MLP, the gain by adding self-attention is significantly larger than that by modifying the network structures, which most current works focus on.","keywords":["Learning Representations","Feature Combinations","Self-Attention"],"authorids":["ICLR.cc/2019/Conference/Paper1177/Authors"],"authors":["Anonymous"],"pdf":"/pdf/97ef18bccd200f6f3d2f03a765365e49f7a692bb.pdf","paperhash":"anonymous|learning_representations_of_categorical_feature_combinations_via_selfattention","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Representations of Categorical Feature Combinations via Self-Attention},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxwW2A5Km},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkxw-hAcFQ","original":"rJeXVyCqFX","number":1178,"cdate":1538087934682,"ddate":null,"tcdate":1538087934682,"tmdate":1538155974903,"tddate":null,"forum":"rkxw-hAcFQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Generating Multi-Agent Trajectories using Programmatic Weak Supervision","abstract":"We study the problem of training sequential generative models for capturing coordinated multi-agent trajectory behavior, such as  offensive basketball gameplay.  When modeling such settings, it is often beneficial to design hierarchical models that can capture long-term coordination using intermediate variables.  Furthermore, these intermediate variables should capture interesting high-level behavioral semantics in an interpretable and manipulable way. We present a hierarchical framework that can effectively learn such sequential generative models.  Our approach is inspired by recent work on leveraging programmatically produced weak labels, which we extend to the spatiotemporal regime. In addition to synthetic settings, we show how to instantiate our framework to effectively model complex interactions between basketball players and generate realistic multi-agent trajectories of basketball gameplay over long time periods. We validate our approach using both quantitative and qualitative evaluations, including a user study comparison conducted with professional sports analysts.","keywords":["deep learning","generative models","imitation learning","hierarchical methods","data programming","weak supervision","spatiotemporal"],"authorids":["ICLR.cc/2019/Conference/Paper1178/Authors"],"authors":["Anonymous"],"TL;DR":"We blend deep generative models with programmatic weak supervision to generate coordinated multi-agent trajectories of significantly higher quality than previous baselines.","pdf":"/pdf/b08aeb8f004b70ef1e4be5a84481acb2f5bee2a1.pdf","paperhash":"anonymous|generating_multiagent_trajectories_using_programmatic_weak_supervision","_bibtex":"@inproceedings{    \nanonymous2019generating,    \ntitle={Generating Multi-Agent Trajectories using Programmatic Weak Supervision},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxw-hAcFQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rygvZ2RcYm","original":"Hklztd6ctQ","number":1179,"cdate":1538087934850,"ddate":null,"tcdate":1538087934850,"tmdate":1538155974699,"tddate":null,"forum":"rygvZ2RcYm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Knowledge Representation for Reinforcement Learning using General Value Functions","abstract":"Reinforcement learning (RL) is a very powerful approach for learning good control strategies from data. Value functions are a key concept for reinforcement learning, as they guide the search for good policies. A lot of effort has been devoted to designing and improving algorithms for learning value functions. In this paper, we argue that value functions are also a very natural way of providing a framework for knowledge representation for reinforcement learning agents. We show that generalized value functions provide a unifying lens for many algorithms, including policy gradient, successor features, option models and policies, and other forms of hierarchical reinforcement learning. We also demonstrate the potential of this representation to provide new, useful algorithms.","keywords":["Reinforcement Learning","General Value Functions","Policy Gradient","Hierarchical Reinforcement Learning","Successor Features"],"authorids":["ICLR.cc/2019/Conference/Paper1179/Authors"],"authors":["Anonymous"],"pdf":"/pdf/9160fb57c502bf6b206e5a51cf96dc060cb4bdba.pdf","paperhash":"anonymous|knowledge_representation_for_reinforcement_learning_using_general_value_functions","_bibtex":"@inproceedings{    \nanonymous2019knowledge,    \ntitle={Knowledge Representation for Reinforcement Learning using General Value Functions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rygvZ2RcYm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SygvZ209F7","original":"H1xxraS9Y7","number":1180,"cdate":1538087935020,"ddate":null,"tcdate":1538087935020,"tmdate":1538155974494,"tddate":null,"forum":"SygvZ209F7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Biologically-Plausible Learning Algorithms Can Scale to Large Datasets","abstract":"The backpropagation (BP) algorithm is often thought to be biologically implausible in the brain. One of the main reasons is that BP requires symmetric weight matrices in the feedforward and feedback pathways. To address this “weight transport problem” (Grossberg, 1987), two more biologically plausible algorithms, proposed by Liao et al. (2016) and Lillicrap et al. (2016), relax BP’s weight symmetry requirements and demonstrate comparable learning capabilities to that of BP on small datasets. However, a recent study by Bartunov et al. (2018) finds that although feedback alignment (FA) and some variants of target-propagation (TP) perform well on MNIST and CIFAR, they perform significantly worse than BP on ImageNet. Here, we additionally evaluate the sign-symmetry algorithm (Liao et al., 2016), which differs from both BP and FA in that the feedback and feedforward weights do not share magnitudes but share signs. We examine the performance of sign-symmetry and feedback alignment on ImageNet and MS COCO datasets using different network architectures (ResNet-18 and AlexNet for ImageNet, RetinaNet for MS COCO). Surprisingly, networks trained with sign-symmetry can attain classification performance approaching that of BP-trained networks. These results complement the study by Bartunov et al. (2018), and establish a new benchmark for future biologically plausible learning algorithms on more difficult datasets and more complex architectures.","keywords":["biologically plausible learning algorithm","ImageNet","sign-symmetry","feedback alignment"],"authorids":["ICLR.cc/2019/Conference/Paper1180/Authors"],"authors":["Anonymous"],"TL;DR":"Biologically plausible learning algorithms, particularly sign-symmetry, works well on ImageNet","pdf":"/pdf/49645e2ee26700066b2c0823874be6f6007b6482.pdf","paperhash":"anonymous|biologicallyplausible_learning_algorithms_can_scale_to_large_datasets","_bibtex":"@inproceedings{    \nanonymous2019biologically-plausible,    \ntitle={Biologically-Plausible Learning Algorithms Can Scale to Large Datasets},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SygvZ209F7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SygD-hCcF7","original":"SkxhYeAqKX","number":1181,"cdate":1538087935187,"ddate":null,"tcdate":1538087935187,"tmdate":1538155974267,"tddate":null,"forum":"SygD-hCcF7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Dimensionality Reduction for Representing the Knowledge of Probabilistic Models","abstract":"Most deep learning models rely on expressive high-dimensional representations to achieve good performance on tasks such as classification. However, the high dimensionality of these representations makes them difficult to interpret and prone to over-fitting. We propose a simple, intuitive and scalable dimension reduction framework that takes into account the soft probabilistic interpretation of standard deep models for classification. When applying our framework to visualization, our representations more accurately reflect inter-class distances than standard visualization techniques such as t-SNE. We show experimentally that our framework improves generalization performance to unseen categories in zero-shot learning. We also provide a finite sample error upper bound guarantee for the method.","keywords":["metric learning","distance learning","dimensionality reduction","bound guarantees"],"authorids":["ICLR.cc/2019/Conference/Paper1181/Authors"],"authors":["Anonymous"],"TL;DR":"dimensionality reduction for cases where examples can be represented as soft probability distributions","pdf":"/pdf/78ee4440d6553b1509c260917f88a2b66dce3b2a.pdf","paperhash":"anonymous|dimensionality_reduction_for_representing_the_knowledge_of_probabilistic_models","_bibtex":"@inproceedings{    \nanonymous2019dimensionality,    \ntitle={Dimensionality Reduction for Representing the Knowledge of Probabilistic Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SygD-hCcF7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJzwb2RcK7","original":"Bkgp0Ca9Km","number":1182,"cdate":1538087935363,"ddate":null,"tcdate":1538087935363,"tmdate":1538155974051,"tddate":null,"forum":"SJzwb2RcK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Adversarial Decomposition of Text Representation","abstract":"In this paper, we present a method for adversarial decomposition of text representation. This method can be used to decompose a representation of an input sentence into several independent vectors, where each vector is responsible for a specific aspect of the input sentence. We evaluate the proposed method on two case studies: the conversion between different social registers and diachronic language change. We show that the proposed method is capable of fine-grained con- trolled change of these aspects of the input sentence. For example, our model is capable of learning a continuous (rather than categorical) representation of the style of the sentence, in line with the reality of language use. The model uses adversarial-motivational training and includes a special motivational loss, which acts opposite to the discriminator and encourages a better decomposition. Finally, we evaluate the obtained meaning embeddings on a downstream task of para- phrase detection and show that they are significantly better than embeddings of a regular autoencoder.","keywords":["learning representation","decomposition","adversarial training","style transfer"],"authorids":["ICLR.cc/2019/Conference/Paper1182/Authors"],"authors":["Anonymous"],"TL;DR":"A method which learns separate representations for the meaning and the form of a sentence","pdf":"/pdf/43f023160f6e01b5aa08d7a24336bfb8197abff4.pdf","paperhash":"anonymous|adversarial_decomposition_of_text_representation","_bibtex":"@inproceedings{    \nanonymous2019adversarial,    \ntitle={Adversarial Decomposition of Text Representation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJzwb2RcK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyxdbnR9YQ","original":"SJgq1z05KQ","number":1183,"cdate":1538087935529,"ddate":null,"tcdate":1538087935529,"tmdate":1538155973842,"tddate":null,"forum":"SyxdbnR9YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"HANDLING CONCEPT DRIFT  IN WIFI-BASED INDOOR LOCALIZATION USING REPRESENTATION LEARNING","abstract":"We outline the problem of concept drifts for time series data. In this work, we analyze the temporal inconsistency of streaming wireless signals in the context of device-free passive indoor localization. We show that data obtained from WiFi channel state information (CSI) can be used to train a robust system capable of performing room level localization. One of the most challenging issues for such a system is the movement of input data distribution to an unexplored space over time, which leads to an unwanted shift in the learned boundaries of the output space. In this work, we propose a phase and magnitude augmented feature space along with a standardization technique that is little affected by drifts. We show that this robust representation of the data yields better learning accuracy and requires less number of retraining. ","keywords":["concept drift","wifi localization","feature representation."],"authorids":["ICLR.cc/2019/Conference/Paper1183/Authors"],"authors":["Anonymous"],"TL;DR":"We introduce an augmented robust feature space for streaming wifi data that is capable of tackling concept drift for indoor localization","pdf":"/pdf/e2484cedf687793b77242d6d4f6545dc488d5741.pdf","paperhash":"anonymous|handling_concept_drift_in_wifibased_indoor_localization_using_representation_learning","_bibtex":"@inproceedings{    \nanonymous2019handling,    \ntitle={HANDLING CONCEPT DRIFT  IN WIFI-BASED INDOOR LOCALIZATION USING REPRESENTATION LEARNING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxdbnR9YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJx_b3RqY7","original":"Ske0kMA9YQ","number":1184,"cdate":1538087935704,"ddate":null,"tcdate":1538087935704,"tmdate":1538155973636,"tddate":null,"forum":"rJx_b3RqY7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"AIM: Adversarial Inference by Matching Priors and Conditionals","abstract":"Effective inference for a generative adversarial model remains an important and challenging problem. We propose a novel approach, Adversarial Inference by Matching priors and conditionals (AIM), which explicitly matches prior and conditional distributions in both data and code spaces, and puts a direct constraint on the dependency structure of the generative model. We derive an equivalent form of the prior and conditional matching objective that can be optimized efficiently without any parametric assumption on the data. We validate the effectiveness of AIM on the MNIST, CIFAR-10, and CelebA datasets by conducting quantitative and qualitative evaluations. Results demonstrate that AIM significantly improves both reconstruction and generation as compared to other adversarial inference models.","keywords":["Generative adversarial network","inference","generative model"],"authorids":["ICLR.cc/2019/Conference/Paper1184/Authors"],"authors":["Anonymous"],"pdf":"/pdf/5d09610ae695e1e26f9c1087777409a3973bb82c.pdf","paperhash":"anonymous|aim_adversarial_inference_by_matching_priors_and_conditionals","_bibtex":"@inproceedings{    \nanonymous2019aim:,    \ntitle={AIM: Adversarial Inference by Matching Priors and Conditionals},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJx_b3RqY7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1z_Z2A5tX","original":"H1ghPeRqK7","number":1185,"cdate":1538087935874,"ddate":null,"tcdate":1538087935874,"tmdate":1538155973429,"tddate":null,"forum":"H1z_Z2A5tX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"DON’T JUDGE A BOOK BY ITS COVER - ON THE DYNAMICS OF RECURRENT NEURAL NETWORKS","abstract":"To be effective in sequential data processing, Recurrent Neural Networks (RNNs)\nare required to perform data processing as well as to keep track of past events\nby creating memories. Consequently RNNs are harder to train than their not recurrent\ncounterparts. In this paper, we investigate the representation of memories\nformed in trained RNN internal state under various training protocols. It is not\nclear whether there is a trade-off between learning discriminative task, learning\nactions and learning to memorize. Having observed the RNN’s apparently consistent\nperformance regardless of training protocol, we expected the internal dynamics\nto be similar as well. Instead we were surprised to discover substantial\ndifferences, leading to differences in the ability to generalize for unforeseen tasks\nor conditions. In an attempt to understand these differences we proposed a method\nfor tracking the formation of memories along the course of training, and indeed\nresults on memory shaping process were obtained.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1185/Authors"],"authors":["Anonymous"],"pdf":"/pdf/366a9255429aa0bfd2f1993acade7114423ddabf.pdf","paperhash":"anonymous|dont_judge_a_book_by_its_cover_on_the_dynamics_of_recurrent_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019don’t,    \ntitle={DON’T JUDGE A BOOK BY ITS COVER - ON THE DYNAMICS OF RECURRENT NEURAL NETWORKS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1z_Z2A5tX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkzOWnActX","original":"S1liZgDndm","number":1186,"cdate":1538087936038,"ddate":null,"tcdate":1538087936038,"tmdate":1538155973219,"tddate":null,"forum":"HkzOWnActX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"MuMoMAML: Model-Agnostic Meta-Learning for Multimodal Task Distributions","abstract":"Gradient-based meta-learners such as MAML (Finn et al., 2017) are able to learn a meta-prior from similar tasks to adapt to novel tasks from the same distribution with few gradient updates. However, such frameworks seek a common initialization shared across the entire task distribution, substantially limiting the diversity of the task distributions that they are able to learn from. In this paper, we aim to augment existing gradient-based meta-learners with the capability to identify the modes of a task distribution and adapt quickly through gradient updates given tasks sampled from a multimodal task distribution. Specifically, we propose a multimodal MAML algorithm (MuMoMAML), which is able to modulate its meta-learned prior according to the identified task modes, allowing further fast adaptation. We evaluate the proposed algorithm on a diverse set of problems including regression, few-shot image classification, and reinforcement learning. The results demonstrate the effectiveness of our model in efficiently acquiring a meta-learned prior under a multimodal task distribution.","keywords":["Meta-learning","gradient-based meta-learning","model-based meta-learning"],"authorids":["ICLR.cc/2019/Conference/Paper1186/Authors"],"authors":["Anonymous"],"TL;DR":"We proposed a meta-learner that generalizes across a multimodal task distribution by identifying the modes of the distribution and modulating its meta-learned prior accordingly, allowing further efficient adaptation through gradient updates.","pdf":"/pdf/8d7e09c4b0518c895a17bb971674f0102a95e988.pdf","paperhash":"anonymous|mumomaml_modelagnostic_metalearning_for_multimodal_task_distributions","_bibtex":"@inproceedings{    \nanonymous2019mumomaml:,    \ntitle={MuMoMAML: Model-Agnostic Meta-Learning for Multimodal Task Distributions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkzOWnActX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJedbn0ctQ","original":"S1es565tY7","number":1187,"cdate":1538087936196,"ddate":null,"tcdate":1538087936196,"tmdate":1538155973008,"tddate":null,"forum":"rJedbn0ctQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Zero-training Sentence Embedding via Orthogonal Basis","abstract":"We propose a simple and robust training-free approach for building sentence representations. Inspired by the Gram-Schmidt Process in geometric theory, we build an orthogonal basis of the subspace spanned by a word and its surrounding context in a sentence. We model the semantic meaning of a word in a sentence based on two aspects. One is its relatedness to the word vector subspace already spanned by its contextual words. The other is its novel semantic meaning which shall be introduced as a new basis vector perpendicular to this existing subspace.  Following this motivation, we develop an innovative method based on orthogonal basis to combine pre-trained word embeddings into sentence representation. This approach requires zero training and zero parameters, along with efficient inference performance. We evaluate our approach on 11 downstream NLP tasks. Experimental results show that our model outperforms all existing zero-training alternatives in all the tasks and it is competitive to other approaches relying on either large amounts of labelled data or prolonged training time.","keywords":["Natural Language Processing","Sentence Embeddings"],"authorids":["ICLR.cc/2019/Conference/Paper1187/Authors"],"authors":["Anonymous"],"TL;DR":"A simple and training-free approach for sentence embeddings with competitive performance compared with sophisticated models requiring either large amount of training data or prolonged training time.","pdf":"/pdf/e7566e8791b2eee17b383e8bf353c445bca39153.pdf","paperhash":"anonymous|zerotraining_sentence_embedding_via_orthogonal_basis","_bibtex":"@inproceedings{    \nanonymous2019zero-training,    \ntitle={Zero-training Sentence Embedding via Orthogonal Basis},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJedbn0ctQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJldZ2RqFX","original":"r1e7XbAcKm","number":1188,"cdate":1538087936356,"ddate":null,"tcdate":1538087936356,"tmdate":1538155972794,"tddate":null,"forum":"SJldZ2RqFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"D-GAN: Divergent generative adversarial network for positive unlabeled learning and counter-examples generation","abstract":"Positive Unlabeled learning task remains an interesting challenge in the context of image analysis. Recent approaches suggest to exploit the GANs abilities to answer this problem. In this paper, we propose a new approach named Divergent-GAN (D-GAN). It keeps the light adversarial architecture of the PGAN method, with a better robustness counter the varying images complexity, while simultaneously allowing the same functionalities as the GenPU method, like the generation of relevant counter-examples. However, this is achieved without the need of prior knowledge, nor an onerous architecture and framework. Its functionning is based on the combination between the behaviour principles of Positive Unlabeled learning classification and the adversarial GAN training. Experimental results show that this divergent adversarial framework outperforms the state of the art PU learning in terms of prediction accuracy, training robustness, and its ability to work on both simple and complex real images. Combined with an additional generator, the proposed approach even allows to accomplish noisy labeled learning, and thus opening new application perspectives for GANs architectures.","keywords":["Representation learning. Positive Unlabeled learning. Image classification"],"authorids":["ICLR.cc/2019/Conference/Paper1188/Authors"],"authors":["Anonymous"],"TL;DR":"A new two-stage positive unlabeled learning approach with GAN","pdf":"/pdf/cde41813ba28b4a9eaf38538888b232fe3d1f5f9.pdf","paperhash":"anonymous|dgan_divergent_generative_adversarial_network_for_positive_unlabeled_learning_and_counterexamples_generation","_bibtex":"@inproceedings{    \nanonymous2019d-gan:,    \ntitle={D-GAN: Divergent generative adversarial network for positive unlabeled learning and counter-examples generation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJldZ2RqFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryetZ20ctX","original":"HyeUeZaqYm","number":1189,"cdate":1538087936527,"ddate":null,"tcdate":1538087936527,"tmdate":1538155972592,"tddate":null,"forum":"ryetZ20ctX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Defensive Quantization: When Efficiency Meets Robustness","abstract":"Neural network quantization is becoming an industry standard to efficiently deploy deep learning models on hardware platforms, such as CPU, GPU, TPU, and FPGAs. However, we observe that the conventional quantization approaches are vulnerable to adversarial attacks. This paper aims to raise people's awareness about the security of the quantized models, and we designed a novel quantization methodology to jointly optimize the efficiency and robustness of deep learning models. We first conduct an empirical study to show that vanilla quantization suffers more from adversarial attacks. We observe that the inferior robustness comes from the error amplification effect, where the quantization operation further enlarges the distance caused by amplified noise. Then we propose a novel Defensive Quantization (DQ) method by controlling the Lipschitz constant of the network during quantization, such that the magnitude of the adversarial noise remains non-expansive during inference. Extensive experiments on CIFAR-10 and SVHN datasets demonstrate that our new quantization method can defend neural networks against adversarial examples, and even achieves superior robustness than their full-precision counterparts, while maintaining the same hardware efficiency as vanilla quantization approaches. As a by-product, DQ can also improve the accuracy of quantized models without adversarial attack. ","keywords":["defensive quantization","model quantization","adversarial attack","efficiency","robustness"],"authorids":["ICLR.cc/2019/Conference/Paper1189/Authors"],"authors":["Anonymous"],"TL;DR":"We designed a novel quantization methodology to jointly optimize the efficiency and robustness of deep learning models.","pdf":"/pdf/85f3ce4e3912f7d2521c01b5fa0430818fcf9287.pdf","paperhash":"anonymous|defensive_quantization_when_efficiency_meets_robustness","_bibtex":"@inproceedings{    \nanonymous2019defensive,    \ntitle={Defensive Quantization: When Efficiency Meets Robustness},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryetZ20ctX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HklKWhC5F7","original":"r1lOxz0qYQ","number":1190,"cdate":1538087936698,"ddate":null,"tcdate":1538087936698,"tmdate":1538155972380,"tddate":null,"forum":"HklKWhC5F7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"How Training Data Affect the Accuracy and Robustness of Neural Networks for Image Classification","abstract":"Recent work has demonstrated the lack of robustness of well-trained deep neural networks (DNNs) to adversarial examples.  For example, visually indistinguishable perturbations, when mixed with an original image, can easily lead deep learning models to misclassifications.  In light of a recent study on the mutual influence between robustness and accuracy over 18 different ImageNet models, this paper investigates how training data affect the accuracy and robustness of deep neural\nnetworks. We conduct extensive experiments on four different datasets, including CIFAR-10, MNIST, STL-10, and Tiny ImageNet, with several representative neural networks. Our results reveal previously unknown phenomena that exist between the size of training data and characteristics of the resulting models. In particular, besides confirming that the model accuracy improves as the amount of training data increases, we also observe that the model robustness improves initially, but there exists a turning point after which robustness starts to decrease.  How and when such turning points occur vary for different neural networks and different datasets.","keywords":["Adversarial attacks","Robustness","CW","I-FGSM"],"authorids":["ICLR.cc/2019/Conference/Paper1190/Authors"],"authors":["Anonymous"],"pdf":"/pdf/d9ebb0c0090f54f0871b450f142e10df4b292f2b.pdf","paperhash":"anonymous|how_training_data_affect_the_accuracy_and_robustness_of_neural_networks_for_image_classification","_bibtex":"@inproceedings{    \nanonymous2019how,    \ntitle={How Training Data Affect the Accuracy and Robustness of Neural Networks for Image Classification},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HklKWhC5F7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ByxF-nAqYX","original":"HyllAkA9F7","number":1191,"cdate":1538087936865,"ddate":null,"tcdate":1538087936865,"tmdate":1538155972168,"tddate":null,"forum":"ByxF-nAqYX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Locally Linear Unsupervised Feature Selection","abstract":"The paper, interested in unsupervised feature selection, aims to retain the features best accounting for the local patterns in the data. The proposed approach, called Locally Linear Unsupervised Feature Selection, relies on a dimensionality reduction method to characterize such patterns; each feature is thereafter assessed according to its compliance w.r.t. the local patterns, taking inspiration from Locally Linear Embedding (Roweis and Saul, 2000). The experimental validation of the approach on the scikit-feature benchmark suite demonstrates its effectiveness compared to the state of the art.","keywords":["Unsupervised Learning","Feature Selection","Dimension Reduction"],"authorids":["ICLR.cc/2019/Conference/Paper1191/Authors"],"authors":["Anonymous"],"TL;DR":"Unsupervised feature selection through capturing the local linear structure of the data","pdf":"/pdf/71c88ca9f4594ce9510419fc3b789f1955611b39.pdf","paperhash":"anonymous|locally_linear_unsupervised_feature_selection","_bibtex":"@inproceedings{    \nanonymous2019locally,    \ntitle={Locally Linear Unsupervised Feature Selection},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByxF-nAqYX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1lFZnR5YX","original":"rJgR_bA8KQ","number":1192,"cdate":1538087937031,"ddate":null,"tcdate":1538087937031,"tmdate":1538155971951,"tddate":null,"forum":"H1lFZnR5YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Neural Regression Tree","abstract":"Regression-via-Classification (RvC) is the process of converting a regression problem to a classification one. Current approaches for RvC use ad-hoc discretization strategies and are suboptimal. We propose a neural regression tree model for RvC. In this model, we employ a joint optimization framework where we learn optimal discretization thresholds while simultaneously optimizing the features for each node in the tree. We empirically show the validity of our model by testing it on two challenging regression tasks where we establish the state of the art.","keywords":["regression-via-classification","discretization","regression tree","neural model","optimization"],"authorids":["ICLR.cc/2019/Conference/Paper1192/Authors"],"authors":["Anonymous"],"TL;DR":"A novel neural regression tree for optimal discretization in regression-via-classification problems.","pdf":"/pdf/d060cb1461012aa0f7ff57425acf6a4c0cbed223.pdf","paperhash":"anonymous|neural_regression_tree","_bibtex":"@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Regression Tree},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1lFZnR5YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1xY-hRctX","original":"BJlh-os5K7","number":1193,"cdate":1538087937197,"ddate":null,"tcdate":1538087937197,"tmdate":1538155971744,"tddate":null,"forum":"B1xY-hRctX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Neural Logic Machines","abstract":"We propose Neural Logic Machines (NLMs), a neural-symbolic architecture for both inductive learning and logic reasoning. NLMs exploit the power of both neural networks—as function approximators for probabilistic distributions, and logic programming—as symbolic processor for objects with properties, relations, logic connectives, and quantifiers. After being trained on small-scale tasks (such as sorting short arrays), NLMs can learn the underlying logic rules, and generalize to arbitrarily large-scale tasks (such as sorting arbitrarily long arrays). In our experiments, NLMs achieve perfect generalization in a number of tasks, from relational reasoning tasks on family tree and general graphs, to decision making tasks including sorting, finding shortest paths, and the blocks world. Most of these tasks are hard to accomplish for neural networks or logical programming alone.","keywords":["Neural-symbolic","first-order logic","perfect generalization"],"authorids":["ICLR.cc/2019/Conference/Paper1193/Authors"],"authors":["Anonymous"],"TL;DR":"A fully differentiable neural-symbolic architecture to conduct first-order logic reasoning","pdf":"/pdf/d1928699780b4edc1aa0cbc4d61f07f2f43af976.pdf","paperhash":"anonymous|neural_logic_machines","_bibtex":"@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Logic Machines},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1xY-hRctX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BkeK-nRcFX","original":"BkxXlBn9Fm","number":1194,"cdate":1538087937365,"ddate":null,"tcdate":1538087937365,"tmdate":1538155971539,"tddate":null,"forum":"BkeK-nRcFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"The Nonlinearity Coefficient - Predicting Generalization in Deep Neural Networks","abstract":"For a long time, designing neural architectures that exhibit high performance was considered a dark art that required expert hand-tuning. One of the few well-known guidelines for architecture design is the avoidance of exploding or vanishing gradients. However, even this guideline has remained relatively vague and circumstantial, because there exists no well-defined, gradient-based metric that can be computed {\\it before} training begins and can robustly predict the performance of the network {\\it after} training is complete.\n\nWe introduce what is, to the best of our knowledge, the first such metric: the nonlinearity coefficient (NLC). Via an extensive empirical study, we show that the NLC, computed in the network's randomly initialized state, is a powerful predictor of test error and that attaining a right-sized NLC is essential for attaining an optimal test error, at least in fully-connected feedforward networks. The NLC is also conceptually simple, cheap to compute, and is robust to a range of confounders and architectural design choices that comparable metrics are not necessarily robust to. Hence, we argue the NLC is an important tool for architecture search and design, as it can robustly predict poor training outcomes before training even begins.","keywords":["deep learning","neural networks","nonlinearity","activation functions","exploding gradients","vanishing gradients","neural architecture search"],"authorids":["ICLR.cc/2019/Conference/Paper1194/Authors"],"authors":["Anonymous"],"TL;DR":"We introduce the NLC, a metric that is cheap to compute in the networks randomly initialized state and is highly predictive of generalization, at least in fully-connected networks.","pdf":"/pdf/dc9b613ffbc3bff15f05169e6affddedc3bffd82.pdf","paperhash":"anonymous|the_nonlinearity_coefficient_predicting_generalization_in_deep_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019the,    \ntitle={The Nonlinearity Coefficient - Predicting Generalization in Deep Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkeK-nRcFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Byl9bhA5F7","original":"H1e0lGA9Fm","number":1195,"cdate":1538087937532,"ddate":null,"tcdate":1538087937532,"tmdate":1538155971325,"tddate":null,"forum":"Byl9bhA5F7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Found by NEMO: Unsupervised Object Detection from Negative Examples and Motion","abstract":"This paper introduces NEMO, an approach to unsupervised object detection that uses motion---instead of image labels---as a cue to learn object detection. To discriminate between motion of the target object and other changes in the image, it relies on negative examples that show the scene without the object. The required data can be collected very easily by recording two short videos, a positive one showing the object in motion and a negative one showing the scene without the object. Without any additional form of pretraining or supervision and despite of occlusions, distractions, camera motion, and adverse lighting, those videos are sufficient to learn object detectors that can be applied to new videos and even generalize to unseen scenes and camera angles. In a baseline comparison, unsupervised object detection outperforms off-the shelf template matching and tracking approaches that are given an initial bounding box of the object. The learned object representations are also shown to be accurate enough to capture the relevant information from manipulation task demonstrations, which makes them applicable to learning from demonstration in robotics. An example of object detection that was learned from 3 minutes of video can be found here: http://y2u.be/u_jyz9_ETz4","keywords":["unsupervised learning","computer vision","object detection"],"authorids":["ICLR.cc/2019/Conference/Paper1195/Authors"],"authors":["Anonymous"],"TL;DR":"Learning to detect objects without image labels from 3 minutes of video","pdf":"/pdf/dc309db3eb610e78d83e4f3603a0edc894269939.pdf","paperhash":"anonymous|found_by_nemo_unsupervised_object_detection_from_negative_examples_and_motion","_bibtex":"@inproceedings{    \nanonymous2019found,    \ntitle={Found by NEMO: Unsupervised Object Detection from Negative Examples and Motion},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byl9bhA5F7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1g5b2RcKm","original":"HylKVmpcKQ","number":1196,"cdate":1538087937698,"ddate":null,"tcdate":1538087937698,"tmdate":1538155971114,"tddate":null,"forum":"r1g5b2RcKm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"MLPrune: Multi-Layer Pruning for Automated Neural Network Compression","abstract":"Model compression can significantly reduce the computation and memory footprint of large neural networks. To achieve a good trade-off between model size and accuracy, popular compression techniques usually rely on hand-crafted heuristics and\nrequire manually setting the compression ratio of each layer. This process is typically costly and suboptimal. In this paper, we propose a Multi-Layer Pruning method (MLPrune), which is theoretically sound, and can automatically decide appropriate compression ratios for all layers. Towards this goal, we use an efficient approximation of the Hessian as our pruning criterion, based on a Kronecker-factored Approximate Curvature method. We demonstrate the effectiveness of our method on several datasets and architectures, outperforming previous state-of-the-art by a large margin. Our experiments show that we can compress AlexNet and VGG16 by 25x without loss in accuracy on ImageNet. Furthermore, our method has much fewer hyper-parameters and requires no expert knowledge.","keywords":["Automated Model Compression","Neural Network Pruning"],"authorids":["ICLR.cc/2019/Conference/Paper1196/Authors"],"authors":["Anonymous"],"TL;DR":"MLPrune: an automated pruning method that doesn't require any tuning for per-layer compression ratio, achieves state-of-the-art pruning results on AlexNet and VGG16.","pdf":"/pdf/4efefe3d17702e4b5703d91ee93576371f2bdbc3.pdf","paperhash":"anonymous|mlprune_multilayer_pruning_for_automated_neural_network_compression","_bibtex":"@inproceedings{    \nanonymous2019mlprune:,    \ntitle={MLPrune: Multi-Layer Pruning for Automated Neural Network Compression},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1g5b2RcKm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1e9W3AqFX","original":"SylX-1TqFm","number":1197,"cdate":1538087937863,"ddate":null,"tcdate":1538087937863,"tmdate":1538155970907,"tddate":null,"forum":"B1e9W3AqFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Multi-task Learning with Gradient Communication","abstract":"  In this paper, we describe a general framework to systematically analyze current neural models for multi-task learning, in which we find that existing models expect to disentangle features into different spaces while features learned in practice are still entangled in shared space,  leaving potential hazards for other training or unseen tasks. We propose to alleviate this problem by incorporating a new inductive bias into the process of multi-task learning, that different tasks can communicate with each other not only by passing hidden variables but gradients explicitly. Experimentally, we evaluate proposed methods on three groups of tasks and two types of settings (\\textsc{in-task} and \\textsc{out-of-task}). Quantitative and qualitative results show their effectiveness.","keywords":["Pretend to share","Gradient Communication"],"authorids":["ICLR.cc/2019/Conference/Paper1197/Authors"],"authors":["Anonymous"],"TL;DR":"We introduce an inductive bias for multi-task learning, allowing different tasks to communicate by gradient passing.","pdf":"/pdf/8478230b29614f80aff59b693ef929fd7b77a547.pdf","paperhash":"anonymous|multitask_learning_with_gradient_communication","_bibtex":"@inproceedings{    \nanonymous2019multi-task,    \ntitle={Multi-task Learning with Gradient Communication},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1e9W3AqFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1lqZhRcFm","original":"S1gDB8ocF7","number":1198,"cdate":1538087938037,"ddate":null,"tcdate":1538087938037,"tmdate":1538155970689,"tddate":null,"forum":"H1lqZhRcFm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Unsupervised Learning of the Set of Local Maxima","abstract":"This paper describes a new form of unsupervised learning, whose input is a set of unlabeled points that are assumed to be local maxima of an unknown value function in an unknown subset of the vector space. Two functions are learned: (i) a set indicator c, which is a binary classifier, and (ii) a comparator function h that given two nearby samples, predicts which sample has the higher value. Loss terms are used to ensure that all training samples x are a local maxima, according to h and satisfy c(x)=1. Therefore, c and h provide training signals to each other: a point x' in the vicinity of x satisfies c(x)=-1 or is deemed by h to be lower in value than x. We present an algorithm, show an example where it is more efficient to use local maxima as an indicator function than to employ conventional classification, and derive a suitable generalization bound. Our experiments show that the method is able to outperform one-class classification algorithms in the task of anomaly detection and also provide an additional signal that is extracted in a completely unsupervised way.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1198/Authors"],"authors":["Anonymous"],"pdf":"/pdf/17dcde260180e9b7d9344ec145782e1fa60e2859.pdf","paperhash":"anonymous|unsupervised_learning_of_the_set_of_local_maxima","_bibtex":"@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Learning of the Set of Local Maxima},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1lqZhRcFm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJf9ZhC9FX","original":"rkgx2_pcYX","number":1199,"cdate":1538087938212,"ddate":null,"tcdate":1538087938212,"tmdate":1538155970477,"tddate":null,"forum":"HJf9ZhC9FX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Stochastic Gradient/Mirror Descent: Minimax Optimality and Implicit Regularization","abstract":"Stochastic descent methods (of the gradient and mirror varieties) have become increasingly popular in optimization. In fact, it is now widely recognized that the success of deep learning is not only due to the special deep architecture of the models, but also due to the behavior of the stochastic descent methods used, which play a key role in reaching \"good\" solutions that generalize well to unseen data. In an attempt to shed some light on why this is the case, we revisit some minimax properties of stochastic gradient descent (SGD) for the square loss of linear models---originally developed in the 1990's---and extend them to \\emph{general} stochastic mirror descent (SMD) algorithms for \\emph{general} loss functions and \\emph{nonlinear} models. \nIn particular, we show that there is a fundamental identity which holds for SMD (and SGD) under very general conditions, and which implies the minimax optimality of SMD (and SGD) for sufficiently small step size, and for a general class of loss functions and general nonlinear models.\nWe further show that this identity can be used to naturally establish other properties of SMD (and SGD), namely convergence and \\emph{implicit regularization} for over-parameterized linear models (in what is now being called the \"interpolating regime\"), some of which have been shown in certain cases in prior literature. We also argue how this identity can be used in the so-called \"highly over-parameterized\" nonlinear setting (where the number of parameters far exceeds the number of data points) to provide insights into why SMD (and SGD) may have similar convergence and implicit regularization properties for deep learning. ","keywords":["optimization","stochastic gradient descent","mirror descent","implicit regularization","deep learning theory"],"authorids":["ICLR.cc/2019/Conference/Paper1199/Authors"],"authors":["Anonymous"],"pdf":"/pdf/5f3d914d6acdc1c80430ab33ad92a06577aa9a55.pdf","paperhash":"anonymous|stochastic_gradientmirror_descent_minimax_optimality_and_implicit_regularization","_bibtex":"@inproceedings{    \nanonymous2019stochastic,    \ntitle={Stochastic Gradient/Mirror Descent: Minimax Optimality and Implicit Regularization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJf9ZhC9FX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Byf5-30qFX","original":"HkxI2fjct7","number":1200,"cdate":1538087938376,"ddate":null,"tcdate":1538087938376,"tmdate":1538155970265,"tddate":null,"forum":"Byf5-30qFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"DHER: Hindsight Experience Replay for Dynamic Goals","abstract":"Dealing with sparse rewards is one of the most important challenges in reinforcement learning (RL), especially when a goal is dynamic (e.g., to grasp a moving object). Hindsight experience replay (HER) has been shown an effective solution to handling  sparse rewards with fixed goals. However, it does not account for dynamic goals in its vanilla form and, as a result, even degrades the performance of existing off-policy RL algorithms when the goal is changing over time. \n\nIn this paper, we present Dynamic Hindsight Experience Replay (DHER), a novel approach for tasks with dynamic goals and sparse rewards. DHER automatically assembles successful experiences from two relevant failures and learns a reliable policy to achieve the dynamic goals. We evaluate DHER on tasks of robotic manipulation and moving object tracking, and transfer the polices from simulation to physical robots. Extensive comparison and ablation studies demonstrate  the superiority of our approach, showing that DHER is a crucial ingredient to enable RL to solve tasks with dynamic goals.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1200/Authors"],"authors":["Anonymous"],"pdf":"/pdf/b63ed34061b6887a5471e776815fde01d65ca056.pdf","paperhash":"anonymous|dher_hindsight_experience_replay_for_dynamic_goals","_bibtex":"@inproceedings{    \nanonymous2019dher:,    \ntitle={DHER: Hindsight Experience Replay for Dynamic Goals},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byf5-30qFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJei-2RcK7","original":"SJlCT10cYQ","number":1201,"cdate":1538087938543,"ddate":null,"tcdate":1538087938543,"tmdate":1538155970050,"tddate":null,"forum":"HJei-2RcK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Graph Transformer ","abstract":"Graph neural networks (GNN) have gained increasing research interests as a mean to the challenging goal of robust and universal graph learning. Previous GNNs have assumed single pre-fixed graph structure and permitted only local context encoding. This paper proposes a novel Graph Transformer (GTR) architecture that captures long-range dependency with global attention, and enables dynamic graph structures. In particular, GTR propagates features within the same graph structure via an intra-graph message passing, and transforms dynamic semantics across multi-domain graph-structured data (e.g. images, sequences, knowledge graphs) for multi-modal learning via an inter-graph message passing. Furthermore, GTR enables effective incorporation of any prior graph structure by weighted averaging of the prior and learned edges, which can be crucially useful for scenarios where prior knowledge is desired. The proposed GTR achieves new state-of-the-arts across three benchmark tasks, including few-shot learning, medical abnormality and disease classification, and graph classification. Experiments show that GTR is superior in learning robust graph representations, transforming high-level semantics across domains, and bridging between prior graph structure with automatic structure learning.  ","keywords":["Graph neural networks","transformer","attention"],"authorids":["ICLR.cc/2019/Conference/Paper1201/Authors"],"authors":["Anonymous"],"pdf":"/pdf/3a7848ff8d3363d0cd1fe59c2c7d9fdb9c1a688e.pdf","paperhash":"anonymous|graph_transformer","_bibtex":"@inproceedings{    \nanonymous2019graph,    \ntitle={Graph Transformer },    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJei-2RcK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyesW2C9YQ","original":"ryg45Aa5F7","number":1202,"cdate":1538087938724,"ddate":null,"tcdate":1538087938724,"tmdate":1538155969839,"tddate":null,"forum":"HyesW2C9YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"I Know the Feeling: Learning to Converse with Empathy","abstract":"Beyond understanding what is being discussed, human communication requires an awareness of what someone is feeling. One challenge for dialogue agents is being able to recognize feelings in the conversation partner and reply accordingly, a key communicative skill that is trivial for humans. Research in this area is made difficult by the paucity of large-scale publicly available datasets both for emotion and relevant dialogues. This work proposes a new task for empathetic dialogue generation and EmpatheticDialogues, a dataset of 25k conversations grounded in emotional contexts to facilitate training and evaluating dialogue systems. Our experiments indicate that models explicitly leveraging emotion predictions from previous utterances are perceived to be more empathetic by human evaluators, while improving on other metrics as well (e.g. perceived relevance of responses, BLEU scores).","keywords":["dialogue generation","nlp applications","grounded text  generation","contextual representation learning"],"authorids":["ICLR.cc/2019/Conference/Paper1202/Authors"],"authors":["Anonymous"],"TL;DR":"We improve existing dialogue systems for responding to people sharing personal stories, incorporating emotion prediction representations and also release a new benchmark and dataset of empathetic dialogues.","pdf":"/pdf/52b062707a776ca2357e1997e2b84f119f5f1e54.pdf","paperhash":"anonymous|i_know_the_feeling_learning_to_converse_with_empathy","_bibtex":"@inproceedings{    \nanonymous2019i,    \ntitle={I Know the Feeling: Learning to Converse with Empathy},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyesW2C9YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1eiZnAqKm","original":"SklIyVT5Ym","number":1203,"cdate":1538087938890,"ddate":null,"tcdate":1538087938890,"tmdate":1538155969628,"tddate":null,"forum":"H1eiZnAqKm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"The Expressive Power of Gated Recurrent Units as a Continuous Dynamical System","abstract":"Gated recurrent units (GRUs) were inspired by the common gated recurrent unit, long short-term\nmemory (LSTM), as a means of capturing temporal structure with less complex memory unit architecture.\nDespite their incredible success in tasks such as natural and artificial language processing,\nspeech, video, and polyphonic music, very little is understood about the specific dynamic features\nrepresentable in a GRU network. As a result, it is difficult to know a priori how successful a GRU-RNN\nwill perform on a given data set. In this paper, we develop a new theoretical framework to\nanalyze one and two dimensional GRUs as a continuous dynamical system, and classify the dynamic\nfeatures obtainable with such system. In addition, we show that a two dimensional GRU\ncannot mimic the dynamics of a ring attractor, or more generally, any line attractor without near\nzero constant curvature in phase space. These results were then experimentally verified by means of\ntime series prediction.","keywords":["Gated Recurrent Units","Recurrent Neural Network","Time Series Predictions","interpretable","Nonlinear Dynamics","Dynamical Systems"],"authorids":["ICLR.cc/2019/Conference/Paper1203/Authors"],"authors":["Anonymous"],"TL;DR":"We classify the the dynamical features one and two GRU cells can and cannot capture in continuous time, and verify our findings experimentally with k-step time series prediction.","pdf":"/pdf/42a57050f5e2349e781bbfef4ad9fdfc694f309a.pdf","paperhash":"anonymous|the_expressive_power_of_gated_recurrent_units_as_a_continuous_dynamical_system","_bibtex":"@inproceedings{    \nanonymous2019the,    \ntitle={The Expressive Power of Gated Recurrent Units as a Continuous Dynamical System},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1eiZnAqKm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1liWh09F7","original":"B1lKC-j9KX","number":1204,"cdate":1538087939058,"ddate":null,"tcdate":1538087939058,"tmdate":1538155969413,"tddate":null,"forum":"B1liWh09F7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"SALSA-TEXT : SELF ATTENTIVE LATENT SPACE BASED ADVERSARIAL TEXT GENERATION","abstract":"Inspired by the success of self attention mechanism and Transformer architecture\nin sequence transduction and image generation applications, we propose novel self\nattention-based architectures to improve the performance of adversarial latent code-\nbased schemes in text generation. Adversarial latent code-based text generation\nhas recently gained a lot of attention due to their promising results. In this paper,\nwe take a step to fortify the architectures used in these setups, specifically AAE\nand ARAE. We benchmark two latent code-based methods (AAE and ARAE)\ndesigned based on adversarial setups. In our experiments, the Google sentence\ncompression dataset is utilized to compare our method with these methods using\nvarious objective and subjective measures. The experiments demonstrate the\nproposed (self) attention-based models outperform the state-of-the-art in adversarial\ncode-based text generation.","keywords":["Self-attention","Transformer","generative adversarial networks","GAN","neural text generation","NTG","generative models"],"authorids":["ICLR.cc/2019/Conference/Paper1204/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a self-attention based GAN architecture for unconditional text generation and improve on previous adversarial code-based results.","pdf":"/pdf/6fa73c4491eb49700d676f0b93ffb13957ac9f6d.pdf","paperhash":"anonymous|salsatext_self_attentive_latent_space_based_adversarial_text_generation","_bibtex":"@inproceedings{    \nanonymous2019salsa-text,    \ntitle={SALSA-TEXT : SELF ATTENTIVE LATENT SPACE BASED ADVERSARIAL TEXT GENERATION},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1liWh09F7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJMjW3RqtX","original":"r1eNyHhcFX","number":1205,"cdate":1538087939221,"ddate":null,"tcdate":1538087939221,"tmdate":1538155969207,"tddate":null,"forum":"HJMjW3RqtX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"One-Shot High-Fidelity Imitation: Training Large-Scale Deep Nets with RL","abstract":"Humans are experts at high-fidelity imitation -- closely mimicking a demonstration, often in one attempt. Humans use this ability to quickly solve a  task instance, and to bootstrap learning of new tasks. Achieving these abilities in autonomous agents is an open problem. In this paper, we introduce an off-policy RL algorithm (MetaMimic) to narrow this gap. MetaMimic can learn both (i) policies for high-fidelity one-shot imitation of diverse novel skills, and (ii) policies that enable the agent to solve tasks more efficiently than the demonstrators. MetaMimic relies on the principle of storing all experiences in a memory and replaying these to learn massive deep neural network policies by off-policy RL. This paper introduces, to the best of our knowledge, the largest existing neural networks for deep RL and shows that larger networks with normalization are needed to achieve one-shot high-fidelity imitation on a challenging manipulation task.\nThe results also show that both types of policy can be learned from vision, in spite of the task rewards being sparse, and without access to demonstrator actions. ","keywords":["Imitation Learning","Deep Learning"],"authorids":["ICLR.cc/2019/Conference/Paper1205/Authors"],"authors":["Anonymous"],"TL;DR":"We present MetaMimic, an algorithm that takes as input a demonstration dataset and outputs (i) a one-shot high-fidelity imitation policy (ii) an unconditional task policy.","pdf":"/pdf/34848bbbdaf97736acefe815555df81d55db8d2b.pdf","paperhash":"anonymous|oneshot_highfidelity_imitation_training_largescale_deep_nets_with_rl","_bibtex":"@inproceedings{    \nanonymous2019one-shot,    \ntitle={One-Shot High-Fidelity Imitation: Training Large-Scale Deep Nets with RL},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJMjW3RqtX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BkMiWhR5K7","original":"S1xPwZ2YYQ","number":1206,"cdate":1538087939394,"ddate":null,"tcdate":1538087939394,"tmdate":1538155968989,"tddate":null,"forum":"BkMiWhR5K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Prior Convictions: Black-box Adversarial Attacks with Bandits and Priors","abstract":"We study the problem of generating adversarial examples in a black-box setting in which only loss-oracle access to a model is available. We introduce a framework that conceptually unifies much of the existing work on black-box attacks, and demonstrate that the current state-of-the-art methods are optimal in a natural sense. Despite this optimality, we show how to improve black-box attacks by bringing a new element into the problem: gradient priors. We give a bandit optimization-based algorithm that allows us to seamlessly integrate any such priors, and we explicitly identify and incorporate two examples. The resulting methods use two to four times fewer queries and fail two to six times less than the current state-of-the-art. The code for reproducing our work is available at https://git.io/fAjOJ.","keywords":["adversarial examples","gradient estimation","black-box attacks","model-based optimization","bandit optimization"],"authorids":["ICLR.cc/2019/Conference/Paper1206/Authors"],"authors":["Anonymous"],"TL;DR":"We present a unifying view on black-box adversarial attacks as a gradient estimation problem, and then present a framework (based on bandits optimization) to integrate priors into gradient estimation, leading to significantly increased performance.","pdf":"/pdf/915a3f23ece0af08b7755c64ca5dd1ebbee44aab.pdf","paperhash":"anonymous|prior_convictions_blackbox_adversarial_attacks_with_bandits_and_priors","_bibtex":"@inproceedings{    \nanonymous2019prior,    \ntitle={Prior Convictions: Black-box Adversarial Attacks with Bandits and Priors},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkMiWhR5K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1lhbnRqF7","original":"rJxsM4TqKX","number":1207,"cdate":1538087939566,"ddate":null,"tcdate":1538087939566,"tmdate":1538155968769,"tddate":null,"forum":"S1lhbnRqF7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension","abstract":"We propose a neural machine-reading model that constructs dynamic knowledge graphs from procedural text. It builds these graphs recurrently for each step of the described procedure, and uses them to track the evolving states of participant entities. We harness and extend a recently proposed machine reading comprehension(MRC) model to query for entity states, since these states are generally communicated in spans of text and MRC models perform well in extracting entity-centric spans.   The  explicit,  structured,  and  evolving  knowledge  graph  representations that our model constructs can be used in downstream question answering tasks to improve machine comprehension of text, as we demonstrate empirically.  On two comprehension tasks from the recently proposed  ProPara dataset,  our model achieves state-of-the-art results. We further show that our model is competitive on the Recipes dataset, suggesting it may be generally applicable.","keywords":["recurrent graph networks","dynamic knowledge base construction","entity state tracking","machine reading comprehension"],"authorids":["ICLR.cc/2019/Conference/Paper1207/Authors"],"authors":["Anonymous"],"pdf":"/pdf/49f782e9058edf091ac3baedde93e9f4246f1520.pdf","paperhash":"anonymous|building_dynamic_knowledge_graphs_from_text_using_machine_reading_comprehension","_bibtex":"@inproceedings{    \nanonymous2019building,    \ntitle={Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lhbnRqF7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hyghb2Rct7","original":"BJlc-Z9qtQ","number":1208,"cdate":1538087939732,"ddate":null,"tcdate":1538087939732,"tmdate":1538155968560,"tddate":null,"forum":"Hyghb2Rct7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"SIMILE: Introducing Sequential Information towards More Effective Imitation Learning","abstract":"Reinforcement learning (RL) is a metaheuristic aiming at teaching an agent to interact with an environment and maximizing the reward in a complex task. RL algorithms often encounter the difficulty in defining a reward function in a sparse solution space. Imitation learning (IL) deals with this issue by providing a few expert demonstrations, and then either mimicking the expert's behavior (behavioral cloning, BC) or recovering the reward function by assuming the optimality of the expert (inverse reinforcement learning, IRL). Conventional IL approaches formulate the agent policy by mapping one single state to a distribution over actions, which did not consider sequential information. This strategy can be less accurate especially in IL, a weakly supervised learning environment, especially when the number of expert demonstrations is limited.\n\nThis paper presents an effective approach named Sequential IMItation LEarning (SIMILE). The core idea is to introduce sequential information, so that an agent can refer to both the current state and past state-action pairs to make a decision. We formulate our approach into a recurrent model, and instantiate it using LSTM so as to fuse both long-term and short-term information. SIMILE is a generalized IL framework which is easily applied to BL and IRL, two major types of IL algorithms. Experiments are performed on several robot controlling tasks in OpenAI Gym. SIMILE not only achieves performance gain over the baseline approaches, but also enjoys the benefit of faster convergence and better stability of testing performance. These advantages verify a higher learning efficiency of SIMILE, and implies its potential applications in real-world scenarios, i.e., when the agent-environment interaction is more difficult and/or expensive.","keywords":["Reinforcement Learning","Imitation Learning","Sequential Information"],"authorids":["ICLR.cc/2019/Conference/Paper1208/Authors"],"authors":["Anonymous"],"TL;DR":"This paper introduces sequential information to improve inverse reinforcement learning algorithms","pdf":"/pdf/b095a3ad08413e428a99de63b23602810e353f6c.pdf","paperhash":"anonymous|simile_introducing_sequential_information_towards_more_effective_imitation_learning","_bibtex":"@inproceedings{    \nanonymous2019simile:,    \ntitle={SIMILE: Introducing Sequential Information towards More Effective Imitation Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyghb2Rct7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkl3-hA5Y7","original":"S1lGWApqKX","number":1209,"cdate":1538087939903,"ddate":null,"tcdate":1538087939903,"tmdate":1538155968348,"tddate":null,"forum":"rkl3-hA5Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Towards Decomposed Linguistic Representation with Holographic Reduced Representation","abstract":"The vast majority of neural models in Natural Language Processing adopt a form of structureless distributed representations.  While these models are powerful at making predictions, the representational form is rather crude and does not provide insights into linguistic structures. In this paper we introduce novel language models with representations informed by the framework of Holographic Reduced Representation (HRR). This allows us to inject structures directly into our word-level and chunk-level representations.  Our analyses show that by using HRR as a structured compositional representation, our models are able to discover crude linguistic roles, which roughly resembles a classic division between syntax and semantics.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1209/Authors"],"authors":["Anonymous"],"TL;DR":"Holographic Reduced Representation enables language model to discover linguistic roles.","pdf":"/pdf/1f3b95a7c2fee0ff3bba0d21289763385a3593cc.pdf","paperhash":"anonymous|towards_decomposed_linguistic_representation_with_holographic_reduced_representation","_bibtex":"@inproceedings{    \nanonymous2019towards,    \ntitle={Towards Decomposed Linguistic Representation with Holographic Reduced Representation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkl3-hA5Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BkfhZnC9t7","original":"BkxXl7hcYm","number":1210,"cdate":1538087940078,"ddate":null,"tcdate":1538087940078,"tmdate":1538155968133,"tddate":null,"forum":"BkfhZnC9t7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Zero-shot Learning for Speech Recognition with Universal Phonetic Model","abstract":"There are more than 7,000 languages in the world, but due to the lack of training sets, only a small number of them have speech recognition systems. Multilingual speech recognition provides a solution if at least some audio training data is available. Often, however, phoneme inventories differ between the training languages and the target language, making this approach infeasible. In this work, we address the problem of building an acoustic model for languages with zero audio resources. Our model is able to recognize unseen phonemes in the target language, if only a small text corpus is available. We adopt the idea of zero-shot learning, and decompose phonemes into corresponding phonetic attributes such as vowel and consonant. Instead of predicting phonemes directly, we first predict distributions over phonetic attributes, and then compute phoneme distributions with a customized acoustic model. We extensively evaluate our model on 20 languages, and find that on average, it achieves 9.9% better phone error rate over the baseline model.\n","keywords":["zero-shot learning","speech recognition","acoustic modeling"],"authorids":["ICLR.cc/2019/Conference/Paper1210/Authors"],"authors":["Anonymous"],"TL;DR":"We apply zero-shot learning for speech recognition to recognize unseen phonemes","pdf":"/pdf/a326b4f07795aa98e522d3203aa49a621dd652eb.pdf","paperhash":"anonymous|zeroshot_learning_for_speech_recognition_with_universal_phonetic_model","_bibtex":"@inproceedings{    \nanonymous2019zero-shot,    \ntitle={Zero-shot Learning for Speech Recognition with Universal Phonetic Model},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkfhZnC9t7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyxnZh0ct7","original":"S1xHc_n5tQ","number":1211,"cdate":1538087940245,"ddate":null,"tcdate":1538087940245,"tmdate":1538155967916,"tddate":null,"forum":"HyxnZh0ct7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Meta-learning with differentiable closed-form solvers","abstract":"Adapting deep networks to new concepts from few examples is challenging, due to the high computational and data requirements of standard fine-tuning procedures.\nMost work on few-shot learning has thus focused on simple learning techniques for adaptation, such as nearest neighbours or gradient descent.\nNonetheless, the machine learning literature contains a wealth of methods that learn non-deep models very efficiently.\nIn this work we propose to use these fast convergent methods as the main adaptation mechanism for few-shot learning.\nThe main idea is to teach a deep network to use standard machine learning tools, such as logistic regression, as part of its own internal model, enabling it to quickly adapt to novel tasks.\nThis requires back-propagating errors through the solver steps.\nWhile normally the cost of the matrix operations involved in such process would be significant, by using the Woodbury identity we can make the small number of examples work to our advantage.\nWe propose both closed-form and iterative solvers, based on ridge regression and logistic regression components.\nOur methods constitute a simple and novel approach to the problem of few-shot learning and achieve performance competitive with or superior to the state of the art on three benchmarks.","keywords":["few-shot learning","one-shot learning","deep learning","ridge regression"],"authorids":["ICLR.cc/2019/Conference/Paper1211/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a simple meta-learning algorithm capable of adapting base learners such as ridge or logistic regression efficiently, by backpropagating through their closed-form solutions. We show strong performance on three few-shot learning benchmarks.","pdf":"/pdf/160de9665b808312ec3eaf756146a25b46eede9f.pdf","paperhash":"anonymous|metalearning_with_differentiable_closedform_solvers","_bibtex":"@inproceedings{    \nanonymous2019meta-learning,    \ntitle={Meta-learning with differentiable closed-form solvers},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyxnZh0ct7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rklhb2R9Y7","original":"BklTWdpctX","number":1212,"cdate":1538087940419,"ddate":null,"tcdate":1538087940419,"tmdate":1538155967707,"tddate":null,"forum":"rklhb2R9Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Reinforced Imitation Learning from Observations","abstract":"Imitation learning is an effective alternative approach to learn a policy when the reward function is sparse. In this paper, we consider a challenging setting where an agent has access to a sparse reward function and state-only expert observations. We propose a method which gradually balances between the imitation learning cost and the reinforcement learning objective.~Built upon an existing imitation learning method, our approach works with state-only observations. We show, through navigation scenarios, that (i) an agent is able to efficiently leverage sparse rewards to outperform standard state-only imitation learning, (ii) it can learn a policy even when learner's actions are different from the expert, and (iii) the performance of the agent is not bounded by that of the expert due to the optimized usage of sparse rewards.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1212/Authors"],"authors":["Anonymous"],"pdf":"/pdf/7cdfca1d63ff1c60e780646e125daa1b155a9502.pdf","paperhash":"anonymous|reinforced_imitation_learning_from_observations","_bibtex":"@inproceedings{    \nanonymous2019reinforced,    \ntitle={Reinforced Imitation Learning from Observations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rklhb2R9Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJgTZ3C5FX","original":"BkgYsLU5t7","number":1213,"cdate":1538087940590,"ddate":null,"tcdate":1538087940590,"tmdate":1538155967492,"tddate":null,"forum":"BJgTZ3C5FX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Generative model based on minimizing exact empirical Wasserstein distance","abstract":"Generative Adversarial Networks (GANs) are a very powerful framework for generative modeling. However, they are often hard to train, and learning of GANs often becomes unstable. Wasserstein GAN (WGAN) is a promising framework to deal with the instability problem as it has a good convergence property. One drawback of the WGAN is that it evaluates the Wasserstein distance in the dual domain, which requires some approximation, so that it may fail to optimize the true Wasserstein distance. In this paper, we propose evaluating the exact empirical optimal transport cost efficiently in the primal domain and performing gradient descent with respect to its derivative to train the generator network. Experiments on the MNIST dataset show that our method is significantly stable to converge, and achieves the lowest Wasserstein distance among the WGAN variants at the cost of some sharpness of generated images. Experiments on the 8-Gaussian toy dataset show that better gradients for the generator are obtained in our method. In addition, the proposed method enables more flexible generative modeling than WGAN.","keywords":["Generative modeling","Generative Adversarial Networks (GANs)","Wasserstein GAN","Optimal transport"],"authorids":["ICLR.cc/2019/Conference/Paper1213/Authors"],"authors":["Anonymous"],"TL;DR":"We have proposed a flexible generative model that learns stably by directly minimizing exact empirical Wasserstein distance.","pdf":"/pdf/5fe5e5faaf322cf8b055489acbe0b29c6b833fb4.pdf","paperhash":"anonymous|generative_model_based_on_minimizing_exact_empirical_wasserstein_distance","_bibtex":"@inproceedings{    \nanonymous2019generative,    \ntitle={Generative model based on minimizing exact empirical Wasserstein distance},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgTZ3C5FX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rklaWn0qK7","original":"HJlk5EpcYQ","number":1214,"cdate":1538087940765,"ddate":null,"tcdate":1538087940765,"tmdate":1538155967279,"tddate":null,"forum":"rklaWn0qK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Neural PDE Solvers with Convergence Guarantees","abstract":"Partial differential equations (PDEs) are widely used across the physical and computational sciences. Decades of research and engineering went into designing fast iterative solution methods. Existing solvers are general purpose, but may be sub-optimal for specific classes of problems. In contrast to existing hand-crafted solutions, we propose an approach to learn a fast iterative solver tailored to a specific domain. We achieve this goal by learning to modify the updates of an existing solver using a deep neural network. Crucially, our approach is proven to preserve strong correctness and convergence guarantees. After training on a single geometry, our model generalizes to a wide variety of geometries and boundary conditions, and achieves 2-3 times speedup compared to state-of-the-art solvers.","keywords":["Partial differential equation","deep learning"],"authorids":["ICLR.cc/2019/Conference/Paper1214/Authors"],"authors":["Anonymous"],"TL;DR":"We learn a fast neural solver for PDEs that has convergence guarantees.","pdf":"/pdf/5d43056428ee97ca74c5a1758c9fb7a0332395ff.pdf","paperhash":"anonymous|learning_neural_pde_solvers_with_convergence_guarantees","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Neural PDE Solvers with Convergence Guarantees},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rklaWn0qK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SkGpW3C5KX","original":"HJgpxmT9FX","number":1215,"cdate":1538087940934,"ddate":null,"tcdate":1538087940934,"tmdate":1538155967059,"tddate":null,"forum":"SkGpW3C5KX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Heated-Up Softmax Embedding","abstract":"Metric learning aims at learning a distance which is consistent with the semantic meaning of the samples. The problem is generally solved by learning an embedding, such that the samples of the same category are close (compact) while samples from different categories are far away (spread-out) in the embedding space. One popular way of generating such embeddings is to use the second-to-last layer of a deep neural network trained as a classifier with the softmax cross-entropy loss. In this paper, we show that training classifiers with different temperatures of the softmax function lead to different distributions of the embedding space. And finding a balance between the compactness, 'spread-out' and the generalization ability of the feature is critical in metric learning. Leveraging these insights, we propose a 'heating-up' strategy to train a classifier with increasing temperatures. Extensive experiments show that the proposed method achieves state-of-the-art embeddings on a variety of metric learning benchmarks. ","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1215/Authors"],"authors":["Anonymous"],"pdf":"/pdf/f3d00b63bef3d368d2757c2c40b7982781ff6398.pdf","paperhash":"anonymous|heatedup_softmax_embedding","_bibtex":"@inproceedings{    \nanonymous2019heated-up,    \ntitle={Heated-Up Softmax Embedding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkGpW3C5KX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1M6Z2Cctm","original":"HklRMC_FYm","number":1216,"cdate":1538087941110,"ddate":null,"tcdate":1538087941110,"tmdate":1538155966843,"tddate":null,"forum":"S1M6Z2Cctm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Harmonic Unpaired Image-to-image Translation","abstract":"The recent direction of unpaired image-to-image translation is on one hand very exciting as it alleviates the big burden in obtaining label-intensive pixel-to-pixel supervision, but it is on the other hand not fully satisfactory due to the presence of artifacts and degenerated transformations. In this paper, we take a manifold view of the problem by introducing a smoothness constraint over the sample graph to attain harmonic functions to enforce consistent mappings during the translation. We develop HarmonicGAN to learn bi-directional translations between the source and the target domain. With the help of similarity-consistency, the inherent self-consistency property of samples can be maintained. Distance metrics defined on two types of features including histogram and CNN are exploited. Under an identical problem setting as CycleGAN without additional manual inputs, HarmonicGAN demonstrates a significant qualitative and quantitative improvement over the state of the art, as well as improved interpretability. We show experimental results in a number of applications including medical imaging, object transfiguration, and semantic labeling. We outperform the competing methods in all tasks, and for a medical imaging task in particular our method turns CycleGAN from a failure to a success, halving the mean-squared error, and generating images that radiologists prefer over competing methods in 95% of cases.","keywords":["unpaired image-to-image translation","cyclegan","smoothness constraint"],"authorids":["ICLR.cc/2019/Conference/Paper1216/Authors"],"authors":["Anonymous"],"TL;DR":"Smooth regularization over sample graph for unpaired image-to-image translation results in significantly improved consistency","pdf":"/pdf/400b3e523a2f82db22d804c457c7aae337aafb40.pdf","paperhash":"anonymous|harmonic_unpaired_imagetoimage_translation","_bibtex":"@inproceedings{    \nanonymous2019harmonic,    \ntitle={Harmonic Unpaired Image-to-image Translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1M6Z2Cctm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1gabhRcYX","original":"BkllYFTqYm","number":1217,"cdate":1538087941275,"ddate":null,"tcdate":1538087941275,"tmdate":1538155966632,"tddate":null,"forum":"B1gabhRcYX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"BA-Net: Dense Bundle Adjustment Networks","abstract":"This paper introduces a network architecture to solve the structure-from-motion (SfM) problem via feature bundle adjustment (BA), which explicitly enforces multi-view geometry constraints in the form of feature reprojection error. The whole pipeline is differentiable so that the network can learn suitable feature representations that make the BA problem more tractable. Furthermore, this work introduces a novel depth parameterization to recover dense per-pixel depth. The network first generates some bases depth maps according to the input image and optimizes the final depth as a linear combination of these bases via feature BA. The bases depth map generator is also learned via end-to-end training. \nThe whole system nicely combines domain knowledge (i.e. hard-coded multi-view geometry constraints) and machine learning (i.e. feature learning and basis depth map generator learning) to address the challenging SfM problem. Experiments on large scale real data prove the success of the proposed method.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1217/Authors"],"authors":["Anonymous"],"TL;DR":"This paper introduces a network architecture to solve the structure-from-motion (SfM) problem via feature bundle adjustment (BA)","pdf":"/pdf/9268df439f6f9254123b75946675c6683ec0611f.pdf","paperhash":"anonymous|banet_dense_bundle_adjustment_networks","_bibtex":"@inproceedings{    \nanonymous2019ba-net:,    \ntitle={BA-Net: Dense Bundle Adjustment Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1gabhRcYX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryeaZhRqFm","original":"Syesige5FX","number":1218,"cdate":1538087941445,"ddate":null,"tcdate":1538087941445,"tmdate":1538155966416,"tddate":null,"forum":"ryeaZhRqFm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Link Prediction in Hypergraphs using Graph Convolutional Networks","abstract":"Link prediction in simple graphs is a fundamental problem in which new links between nodes are predicted based on the observed structure of the graph. However, in many real-world applications, there is a need to model relationships among nodes which go beyond pairwise associations. For example, in a chemical reaction, relationship among the reactants and products is inherently higher-order. Additionally, there is need to represent the direction from reactants to products. Hypergraphs provide a natural way to represent such complex higher-order relationships. Even though Graph Convolutional Networks (GCN) have recently emerged as a powerful deep learning-based approach for link prediction over simple graphs, their suitability for link prediction in hypergraphs is unexplored -- we fill this gap in this paper and propose Neural Hyperlink Predictor (NHP). NHP adapts GCNs for link prediction in hypergraphs. We propose two variants of NHP --NHP-U and NHP-D -- for link prediction over undirected and directed hypergraphs, respectively. To the best of our knowledge, NHP-D is the first method for link prediction over directed hypergraphs. Through extensive experiments on multiple real-world datasets, we show NHP's effectiveness.","keywords":["Graph convolution","hypergraph","hyperlink prediction"],"authorids":["ICLR.cc/2019/Conference/Paper1218/Authors"],"authors":["Anonymous"],"TL;DR":"We propose Neural Hyperlink Predictor (NHP). NHP adapts graph convolutional networks for link prediction in hypergraphs","pdf":"/pdf/b8630d71eb258b12f8ec5c57fecd03ded7aad4db.pdf","paperhash":"anonymous|link_prediction_in_hypergraphs_using_graph_convolutional_networks","_bibtex":"@inproceedings{    \nanonymous2019link,    \ntitle={Link Prediction in Hypergraphs using Graph Convolutional Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryeaZhRqFm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1lCbhAqKX","original":"B1xB2aaqFQ","number":1219,"cdate":1538087941619,"ddate":null,"tcdate":1538087941619,"tmdate":1538155966207,"tddate":null,"forum":"S1lCbhAqKX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Structured Content Preservation for Unsupervised Text Style Transfer","abstract":"Text style transfer aims to modify the style of a sentence while keeping its content unchanged. Recent style transfer systems often fail to faithfully preserve the content after changing the style. This paper proposes a structured content preserving model that leverages linguistic information in the structured fine-grained supervisions to better preserve the style-independent content \\footnote{Henceforth, we refer to style-independent content as content, for simplicity.} during style transfer. In particular, we achieve the goal by devising rich model objectives based on both the sentence's lexical information and a language model that conditions on content. The resulting model therefore is encouraged to retain the semantic meaning of the target sentences. We perform extensive experiments that compare our model to other existing approaches in the tasks of sentiment and political slant transfer. Our model achieves significant improvement in terms of both content preservation and style transfer in automatic and human evaluation.","keywords":["Unsupervised text style transfer"],"authorids":["ICLR.cc/2019/Conference/Paper1219/Authors"],"authors":["Anonymous"],"pdf":"/pdf/c520ef8b60693cf7f2edc44f109207a3aaa10537.pdf","paperhash":"anonymous|structured_content_preservation_for_unsupervised_text_style_transfer","_bibtex":"@inproceedings{    \nanonymous2019structured,    \ntitle={Structured Content Preservation for Unsupervised Text Style Transfer},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lCbhAqKX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1e0-30qKm","original":"BJxzYbO5F7","number":1220,"cdate":1538087941800,"ddate":null,"tcdate":1538087941800,"tmdate":1538155965985,"tddate":null,"forum":"H1e0-30qKm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Unlabeled Disentangling of GANs with Guided Siamese Networks","abstract":"Adversarial learning has greatly improved the abilities of generative models to learn from data (e.g. images) and generate convincing data samples by sampling from simple latent noise distributions. However, applications which could benefit from this generative power, such as image manipulation, are hindered by the lack of controlling specific interpretable factors in the latent space of the learned models. Guiding the sampling process to produce sample variation which is semantically disentangled and meaningful for humans is not possible with current generative models unless large amounts of attribute labelled data are available. In this paper, we propose Unlabeled Disentangling GAN (UD-GAN), which decomposes the latent noise space into semantically meaningful dimensions, using only weak supervision, and without using labels or explicit attributes. When we sample a new data point we can independently control each latent noise slice of UD-GAN and manipulate in a targeted fashion the properties of generated data. Our contributions encompass the introduction of our novel architecture combining an adversarial with contrastive loss, an analysis and probabilistic interpretation of the loss function, and multiple experiments to illustrate the capabilities of our method.","keywords":["GAN","disentange","siamese networks","semantic"],"authorids":["ICLR.cc/2019/Conference/Paper1220/Authors"],"authors":["Anonymous"],"TL;DR":"We use Siamese Networks to control and disentangle the generation process in GANs without labeled data.","pdf":"/pdf/bb273ab05040107e6d65e5373e8318cc4290e701.pdf","paperhash":"anonymous|unlabeled_disentangling_of_gans_with_guided_siamese_networks","_bibtex":"@inproceedings{    \nanonymous2019unlabeled,    \ntitle={Unlabeled Disentangling of GANs with Guided Siamese Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1e0-30qKm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1xRW3A9YX","original":"BkeNpqTttm","number":1221,"cdate":1538087941982,"ddate":null,"tcdate":1538087941982,"tmdate":1538155965769,"tddate":null,"forum":"r1xRW3A9YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Riemannian TransE: Multi-relational Graph Embedding in Non-Euclidean Space","abstract":"Multi-relational graph embedding has wide applications for social network analysis, recommendation systems, and knowledge base completion. The problem is to obtain embeddings that are beneficial for tasks with low-dimensional parameters.\nThis paper proposes a novel framework, called Riemannian TransE for multi-relational graph embedding. \nOur method realizes embedding in non-Euclidean space, where the loss function is based on the distance.\nThus, our model can use a non-Euclidean space that has good compatibility with the data, and achieves good performance with low-dimensional parameters. \nAn evaluation on real knowledge base data shows that with an appropriate choice of manifold, our method achieves comparable accuracy in graph completion with low-dimensional parameters.\n","keywords":["Riemannian TransE","graph embedding","multi-relational graph","Riemannian manifold","TransE","hyperbolic space","sphere","knowledge base"],"authorids":["ICLR.cc/2019/Conference/Paper1221/Authors"],"authors":["Anonymous"],"TL;DR":"We extended TransE in Riemannian manifolds. ","pdf":"/pdf/0f41a3fdfdc3826dcaa495200e8bf21861a24fda.pdf","paperhash":"anonymous|riemannian_transe_multirelational_graph_embedding_in_noneuclidean_space","_bibtex":"@inproceedings{    \nanonymous2019riemannian,    \ntitle={Riemannian TransE: Multi-relational Graph Embedding in Non-Euclidean Space},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xRW3A9YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1g0Z3A9Fm","original":"S1l27ARYF7","number":1222,"cdate":1538087942152,"ddate":null,"tcdate":1538087942152,"tmdate":1538155965557,"tddate":null,"forum":"H1g0Z3A9Fm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Supervised Community Detection with Line Graph Neural Networks","abstract":"We study data-driven methods for community detection on graphs, an inverse problem that is typically solved in terms of the spectrum of certain operators or via posterior inference under certain probabilistic graphical models. Focusing on random graph families such as the stochastic block model, recent research has unified both approaches and identified both statistical and computational signal-to-noise detection thresholds. \nThis graph inference task can be recast as a node-wise graph classification problem, and, as such, computational detection thresholds can be studied in terms of learning within appropriate models. We present a novel family of Graph Neural Networks (GNNs) and show that they can reach those detection thresholds in a purely data-driven manner without access to the underlying generative models, and even \nimprove upon current computational thresholds in hard regimes. For that purpose, we propose to augment GNNs with the non-backtracking operator, defined on the line graph of edge adjacencies. We also perform the first analysis of optimization landscape on using GNNs to solve community detection problems, demonstrating that under certain simplifications and assumptions, the loss value at the local minima is close to the loss value at the global minimum/minima. Finally, the resulting model is also tested on real datasets, performing significantly better than previous models. \n","keywords":["community detection","graph neural networks","belief propagation","energy landscape","non-backtracking operator"],"authorids":["ICLR.cc/2019/Conference/Paper1222/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a novel graph neural network architecture based on the non-backtracking operator defined over edge adjacencies and demonstrate its effectiveness on community detection tasks on graphs.","pdf":"/pdf/938029835478578edcd1b2a917d861f3189492e8.pdf","paperhash":"anonymous|supervised_community_detection_with_line_graph_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019supervised,    \ntitle={Supervised Community Detection with Line Graph Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1g0Z3A9Fm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyxAb30cY7","original":"BJg7Ees5FQ","number":1223,"cdate":1538087942316,"ddate":null,"tcdate":1538087942316,"tmdate":1538155965352,"tddate":null,"forum":"SyxAb30cY7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Robustness May Be at Odds with Accuracy","abstract":"We show that there exists an inherent tension between the goal of adversarial robustness and that of standard generalization. Specifically, training robust models may not only be more resource-consuming, but also lead to a reduction of standard accuracy. We demonstrate that this trade-off between the standard accuracy of a model and its robustness to adversarial perturbations provably exists even in a fairly simple and natural setting. These findings also corroborate a similar phenomenon observed in practice. Further, we argue that this phenomenon is a consequence of robust classifiers learning fundamentally different feature representations than standard classifiers. These differences, in particular, seem to result in unexpected benefits: the representations learned by robust models tend to align better with salient data characteristics and human perception.","keywords":["adversarial examples","robust machine learning","robust optimization","deep feature representations"],"authorids":["ICLR.cc/2019/Conference/Paper1223/Authors"],"authors":["Anonymous"],"TL;DR":"We show that adversarial robustness might come at the cost of standard classification performance, but also yields unexpected benefits.","pdf":"/pdf/2373293e5196ed7f0f668acaf55e2717d761bcdd.pdf","paperhash":"anonymous|robustness_may_be_at_odds_with_accuracy","_bibtex":"@inproceedings{    \nanonymous2019robustness,    \ntitle={Robustness May Be at Odds with Accuracy},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyxAb30cY7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJxA-h05KQ","original":"BJe7XG05Ym","number":1224,"cdate":1538087942480,"ddate":null,"tcdate":1538087942480,"tmdate":1538155965143,"tddate":null,"forum":"rJxA-h05KQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Inhibited Softmax for Uncertainty Estimation in Neural Networks","abstract":"We present a new method for uncertainty estimation and out-of-distribution detection in neural networks with softmax output. We extend softmax layer with an additional constant input. The corresponding additional output is able to represent the uncertainty of the network. The proposed method requires neither additional parameters nor multiple forward passes nor input preprocessing nor out-of-distribution datasets. We show that our method performs comparably to more computationally expensive methods and outperforms baselines on our experiments from image recognition and sentiment analysis domains.","keywords":["uncertainty  estimation","out-of-distribution detection","inhibited softmax"],"authorids":["ICLR.cc/2019/Conference/Paper1224/Authors"],"authors":["Anonymous"],"TL;DR":"Uncertainty estimation in a single forward pass without additional learnable parameters.","pdf":"/pdf/72a13c7c4514a7933774cdb8c012b6fc07f61873.pdf","paperhash":"anonymous|inhibited_softmax_for_uncertainty_estimation_in_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019inhibited,    \ntitle={Inhibited Softmax for Uncertainty Estimation in Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJxA-h05KQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJlyznAcFm","original":"S1eS9Ea9tX","number":1225,"cdate":1538087942646,"ddate":null,"tcdate":1538087942646,"tmdate":1538155964923,"tddate":null,"forum":"BJlyznAcFm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Advocacy Learning","abstract":"We introduce advocacy learning, a novel supervised training scheme for classification problems. This training scheme applies to a framework consisting of two connected networks: 1) the Advocates, composed of one subnetwork per class, which take the input and provide a convincing class-conditional argument in the form of an attention map, and 2) a Judge, which predicts the inputs class label based on these arguments. Each Advocate aims to convince the Judge that the input example belongs to their corresponding class. In contrast to a standard network, in which all subnetworks are trained to jointly cooperate, we train the Advocates to competitively argue for their class, even when the input belongs to a different class. We also explore a variant, honest advocacy learning, where the Advocates are only trained on data corresponding to their class. Applied to several different classification tasks,  we show that advocacy learning can lead to small improvements in classification accuracy over an identical supervised baseline. Through a series of follow-up experiments, we analyze when and how Advocates improve discriminative performance. Though it may seem counter-intuitive, a framework in which subnetworks are trained to competitively provide evidence in support of their class shows promise, performing as well as or better than standard approaches. This provides a foundation for further exploration into the effect of competition and class-conditional representations.","keywords":["competition","supervision","deep learning","adversarial","debate"],"authorids":["ICLR.cc/2019/Conference/Paper1225/Authors"],"authors":["Anonymous"],"TL;DR":"We introduce a method that encourages different components in a networks to compete, and show that this can improve attention quality.","pdf":"/pdf/8d12979535562eb4f369c3bda11690464b3adb13.pdf","paperhash":"anonymous|advocacy_learning","_bibtex":"@inproceedings{    \nanonymous2019advocacy,    \ntitle={Advocacy Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJlyznAcFm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HklyMhCqYQ","original":"rJefbka5t7","number":1226,"cdate":1538087942827,"ddate":null,"tcdate":1538087942827,"tmdate":1538155964717,"tddate":null,"forum":"HklyMhCqYQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Super-Resolution via Conditional Implicit Maximum Likelihood Estimation","abstract":"Single-image super-resolution (SISR) is a canonical problem with diverse applications. Leading methods like SRGAN produce images that contain various artifacts, such as high-frequency noise, hallucinated colours and shape distortions, which adversely affect the realism of the result. In this paper, we propose an alternative approach based on an extension of the method of Implicit Maximum Likelihood Estimation (IMLE). We demonstrate greater effectiveness at noise reduction and preservation of the original colours and shapes, yielding more realistic super-resolved images. ","keywords":["super-resolution"],"authorids":["ICLR.cc/2019/Conference/Paper1226/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a new method for image super-resolution based on IMLE. ","pdf":"/pdf/632cb2f452acf3a2b1f3c4e911514968f9a2bafb.pdf","paperhash":"anonymous|superresolution_via_conditional_implicit_maximum_likelihood_estimation","_bibtex":"@inproceedings{    \nanonymous2019super-resolution,    \ntitle={Super-Resolution via Conditional Implicit Maximum Likelihood Estimation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HklyMhCqYQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hyg1G2AqtQ","original":"rkl05pFGKX","number":1227,"cdate":1538087942994,"ddate":null,"tcdate":1538087942994,"tmdate":1538155964509,"tddate":null,"forum":"Hyg1G2AqtQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Variance Reduction for Reinforcement Learning in Input-Driven Environments","abstract":"We consider reinforcement learning in input-driven environments, where an exogenous, stochastic input process affects the dynamics of the system. Input processes arise in many applications, including queuing systems, robotics control with disturbances, and object tracking. Since the state dynamics and rewards depend on the input process, the state alone provides limited information for the expected future returns. Therefore, policy gradient methods with standard state-dependent baselines suffer high variance during training. We derive a bias-free, input-dependent baseline to reduce this variance, and analytically show its benefits over state-dependent baselines. We then propose a meta-learning approach to overcome the complexity of learning a baseline that depends on a long sequence of inputs. Our experimental results show that across environments from queuing systems, computer networks, and MuJoCo robotic locomotion, input-dependent baselines consistently improve training stability and result in better eventual policies.","keywords":["reinforcement learning","policy gradient","input-driven environments","variance reduction","baseline"],"authorids":["ICLR.cc/2019/Conference/Paper1227/Authors"],"authors":["Anonymous"],"TL;DR":"For environments dictated partially by external input processes, we derive an input-dependent baseline that provably reduces the variance for policy gradient methods and improves the policy performance in a wide range of RL tasks.","pdf":"/pdf/dbf95c409fc18778f749704544bb32c417193ac9.pdf","paperhash":"anonymous|variance_reduction_for_reinforcement_learning_in_inputdriven_environments","_bibtex":"@inproceedings{    \nanonymous2019variance,    \ntitle={Variance Reduction for Reinforcement Learning in Input-Driven Environments},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyg1G2AqtQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1GkMhAqYm","original":"SkewPbn5F7","number":1228,"cdate":1538087943160,"ddate":null,"tcdate":1538087943160,"tmdate":1538155964299,"tddate":null,"forum":"r1GkMhAqYm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"CoDraw: Collaborative Drawing as a Testbed for Grounded Goal-driven Communication","abstract":"In this work, we propose a goal-driven collaborative task that contains language, vision, and action in a virtual environment as its core components. Specifically, we develop a Collaborative image-Drawing game between two agents, called CoDraw. Our game is grounded in a virtual world that contains movable clip art objects. The game involves two players: a Teller and a Drawer. The Teller sees an abstract scene containing multiple clip art pieces in a semantically meaningful configuration, while the Drawer tries to reconstruct the scene on an empty canvas using available clip art pieces. The two players communicate via two-way communication using natural language. We collect the CoDraw dataset of ~10K dialogs consisting of ~138K messages exchanged between human agents. We define protocols and metrics to evaluate the effectiveness of learned agents on this testbed, highlighting the need for a novel \"crosstalk\" condition which pairs agents trained independently on disjoint subsets of the training data for evaluation. We present models for our task, including simple but effective baselines and neural network approaches trained using a combination of imitation learning and goal-driven training. All models are benchmarked using both fully automated evaluation and by playing the game with live human agents.","keywords":["CoDraw","collaborative drawing","grounded language"],"authorids":["ICLR.cc/2019/Conference/Paper1228/Authors"],"authors":["Anonymous"],"TL;DR":"We introduce a dataset, models, and training + evaluation protocols for a collaborative drawing task that allows studying goal-driven and perceptually + actionably grounded language generation and understanding. ","pdf":"/pdf/18e93a65693a0baa1b04ad3336f3a7c0fda01943.pdf","paperhash":"anonymous|codraw_collaborative_drawing_as_a_testbed_for_grounded_goaldriven_communication","_bibtex":"@inproceedings{    \nanonymous2019codraw:,    \ntitle={CoDraw: Collaborative Drawing as a Testbed for Grounded Goal-driven Communication},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1GkMhAqYm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BylkG20qYm","original":"SkgWzyAcYQ","number":1229,"cdate":1538087943324,"ddate":null,"tcdate":1538087943324,"tmdate":1538155964093,"tddate":null,"forum":"BylkG20qYm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"On Meaning-Preserving Adversarial Perturbations for Sequence-to-Sequence Models","abstract":"Adversarial examples have been shown to be an effective way of assessing the robustness of neural sequence-to-sequence (seq2seq) models, by applying perturbations to the input of a model leading to large degradation in performance. However, these perturbations are only indicative of a weakness in the model if they do not change the semantics of the input in a way that would change the expected output. Using the example of machine translation (MT), we propose a new evaluation framework for adversarial attacks on seq2seq models taking meaning preservation into account and demonstrate that existing methods may not preserve meaning in general. Based on these findings, we propose new constraints for attacks on word-based MT systems and show, via human and automatic evaluation, that they produce more semantically similar adversarial inputs. Furthermore, we show that performing adversarial training with meaning-preserving attacks is beneficial to the model in terms of adversarial robustness without hurting test performance.","keywords":["Sequence-to-sequence","adversarial attacks","evaluation","meaning preservation","machine translation"],"authorids":["ICLR.cc/2019/Conference/Paper1229/Authors"],"authors":["Anonymous"],"TL;DR":"How you should evaluate adversarial attacks on seq2seq","pdf":"/pdf/16396c476c971c95c871925a5f3131693be2fcc4.pdf","paperhash":"anonymous|on_meaningpreserving_adversarial_perturbations_for_sequencetosequence_models","_bibtex":"@inproceedings{    \nanonymous2019on,    \ntitle={On Meaning-Preserving Adversarial Perturbations for Sequence-to-Sequence Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BylkG20qYm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkekMnR5Ym","original":"BkemFt6ctQ","number":1230,"cdate":1538087943500,"ddate":null,"tcdate":1538087943500,"tmdate":1538155963871,"tddate":null,"forum":"HkekMnR5Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Meta-Learning Neural Bloom Filters","abstract":"There has been a recent trend in training neural networks to replace data structures that have been crafted by hand, with an aim for faster execution, better accuracy, or greater compression.  In this setting, a neural data structure is instantiated by training a network over many epochs of its inputs until convergence. In many applications this expensive initialization is not practical, for example streaming algorithms --- where inputs are ephemeral and can only be inspected a small number of times.  In this paper we explore the learning of approximate set membership over a stream of data in one-shot via meta-learning. We propose a novel memory architecture, the Neural Bloom Filter, which we show to be more compressive than Bloom Filters and several existing memory-augmented neural networks in scenarios of skewed data or structured sets.","keywords":["meta-learning","memory","one-shot learning","bloom filter","set membership","familiarity","compression"],"authorids":["ICLR.cc/2019/Conference/Paper1230/Authors"],"authors":["Anonymous"],"TL;DR":"We investigate the space efficiency of memory-augmented neural nets when learning set membership.","pdf":"/pdf/f4e848658a4d7e83acae3fb84b1e80a70f50d5a4.pdf","paperhash":"anonymous|metalearning_neural_bloom_filters","_bibtex":"@inproceedings{    \nanonymous2019meta-learning,    \ntitle={Meta-Learning Neural Bloom Filters},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkekMnR5Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SygeznA9YX","original":"S1ls-2a9KX","number":1231,"cdate":1538087943663,"ddate":null,"tcdate":1538087943663,"tmdate":1538155963659,"tddate":null,"forum":"SygeznA9YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Data Interpretation and Reasoning Over Scientific Plots","abstract":"Data Interpretation is an important part of Quantitative Aptitude exams and requires an individual to answer questions grounded in plots such as bar charts, line graphs, scatter plots, \\textit{etc}. Recently, there has been an increasing interest in building models which can perform this task by learning from datasets containing triplets of the form \\{plot, question, answer\\}. Two such datasets have been proposed in the recent past which contain plots generated from synthetic data with limited (i) $x-y$ axes variables (ii) question templates and (iii) answer vocabulary and hence do not adequately capture the challenges posed by this task. To overcome these limitations of existing datasets, we introduce a new dataset containing $9.7$ million question-answer pairs grounded over $270,000$ plots with three main differentiators. First, the plots in our dataset contain a wide variety of realistic $x$-$y$ variables such as CO2 emission, fertility rate, \\textit{etc.} extracted from  real word data sources such as World Bank, government sites, \\textit{etc}. Second, the questions in our dataset are more complex as they are based on templates extracted from interesting questions asked by a crowd of workers using a fraction of these plots. Lastly, the answers in our dataset are not restricted to a small vocabulary and a large fraction of the answers seen at test time are not present in the training vocabulary. As a result, existing models for Visual Question Answering which largely use end-to-end models in a multi-class classification framework cannot be used for this task. We establish initial results on this dataset and emphasize the complexity of the task using a multi-staged modular pipeline with various sub-components to (i) extract relevant data from the plot and convert it to a semi-structured table (ii) combine the question with this table and use compositional semantic parsing to arrive at a logical form from which the answer can be derived. We believe that such a modular framework is the best way to go forward as it would enable the research community to independently make progress on all the sub-tasks involved in plot question answering.","keywords":["VQA","Data Interpretation","Parsing","Object Detection"],"authorids":["ICLR.cc/2019/Conference/Paper1231/Authors"],"authors":["Anonymous"],"TL;DR":"We created a new dataset for data interpretation over plots and also propose a baseline for the same.","pdf":"/pdf/f7650966e80b2718ccdad847dc1649795f4dc44c.pdf","paperhash":"anonymous|data_interpretation_and_reasoning_over_scientific_plots","_bibtex":"@inproceedings{    \nanonymous2019data,    \ntitle={Data Interpretation and Reasoning Over Scientific Plots},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SygeznA9YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJxgz2R9t7","original":"SJe0W6c5Ym","number":1232,"cdate":1538087943837,"ddate":null,"tcdate":1538087943837,"tmdate":1538155963445,"tddate":null,"forum":"BJxgz2R9t7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning To Solve Circuit-SAT: An Unsupervised Differentiable Approach","abstract":"Recent efforts to combine Representation Learning with Formal Methods, commonly known as the Neuro-Symbolic Methods, have given rise to a new trend of applying rich neural architectures to solve classical combinatorial optimization problems. In this paper, we propose a neural framework that can learn to solve the Circuit Satisfiability problem. Our framework is built upon two fundamental contributions: a rich embedding architecture that encodes the problem structure and an end-to-end differentiable training procedure that mimics Reinforcement Learning and trains the model directly toward solving the SAT problem. The experimental results show the superior out-of-sample generalization performance of our framework compared to the recently developed NeuroSAT method.","keywords":["Neuro-Symbolic Methods","Circuit Satisfiability","Neural SAT Solver","Graph Neural Networks"],"authorids":["ICLR.cc/2019/Conference/Paper1232/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a neural framework that can learn to solve the Circuit Satisfiability problem from (unlabeled) circuit instances.","pdf":"/pdf/892d621494841b138b46e4cf190a0632e29c978b.pdf","paperhash":"anonymous|learning_to_solve_circuitsat_an_unsupervised_differentiable_approach","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning To Solve Circuit-SAT: An Unsupervised Differentiable Approach},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJxgz2R9t7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkMlGnC9KQ","original":"r1e1RJncY7","number":1233,"cdate":1538087944009,"ddate":null,"tcdate":1538087944009,"tmdate":1538155963239,"tddate":null,"forum":"HkMlGnC9KQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"On Regularization and Robustness of Deep Neural Networks","abstract":"Despite their success, deep neural networks suffer from several drawbacks: they lack robustness to small changes of input data known as \"adversarial examples\" and training them with small amounts of annotated data is challenging.  In this work, we study the connection between regularization and robustness by viewing neural networks as elements of a reproducing kernel Hilbert space (RKHS) of functions and by regularizing them using the RKHS norm. Even though this norm cannot be computed, we consider various approximations based on upper and lower bounds.  These approximations lead to new strategies for regularization, but also to existing ones such as spectral norm penalties or constraints, gradient penalties, or adversarial training. Besides, the kernel framework allows us to obtain margin-based bounds on adversarial generalization.  We study the obtained algorithms for learning on small datasets, learning adversarially robust models, and discuss implications for learning implicit generative models.","keywords":["regularization","robustness","deep learning","convolutional networks","kernel methods"],"authorids":["ICLR.cc/2019/Conference/Paper1233/Authors"],"authors":["Anonymous"],"pdf":"/pdf/dca0d01664be6726ceea96213a3dbb4856f62fde.pdf","paperhash":"anonymous|on_regularization_and_robustness_of_deep_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019on,    \ntitle={On Regularization and Robustness of Deep Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkMlGnC9KQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1MeM2RcFm","original":"rJxHiidqF7","number":1234,"cdate":1538087944181,"ddate":null,"tcdate":1538087944181,"tmdate":1538155963027,"tddate":null,"forum":"S1MeM2RcFm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"BlackMarks: Black-box Multi-bit Watermarking for Deep Neural Networks","abstract":"Deep Neural Networks (DNNs) are increasingly deployed in cloud servers and autonomous agents due to their superior performance. The deployed DNN is either leveraged in a white-box setting (model internals are publicly known) or a black-box setting (only model outputs are known) depending on the application. A practical concern in the rush to adopt DNNs is protecting the models against Intellectual Property (IP) infringement. We propose BlackMarks, the first end-to-end multi-bit watermarking framework that is applicable in the black-box scenario. BlackMarks takes the pre-trained unmarked model and the owner’s binary signature as inputs. The output is the corresponding marked model with specific keys that can be later used to trigger the embedded watermark. To do so, BlackMarks first designs a model-dependent encoding scheme that maps all possible classes in the task to bit ‘0’ and bit ‘1’. Given the owner’s watermark signature (a binary string), a set of key image and label pairs is designed using targeted adversarial attacks. The watermark (WM) is then encoded in the distribution of output activations of the DNN by fine-tuning the model with a WM-specific regularized loss. To extract the WM, BlackMarks queries the model with the WM key images and decodes the owner’s signature from the corresponding predictions using the designed encoding scheme. We perform a comprehensive evaluation of BlackMarks’ performance on MNIST, CIFAR-10, ImageNet datasets and corroborate its effectiveness and robustness. BlackMarks preserves the functionality of the original DNN and incurs negligible WM embedding overhead as low as 2.054%.","keywords":["Digital Watermarking","IP Protection","Deep Neural Networks"],"authorids":["ICLR.cc/2019/Conference/Paper1234/Authors"],"authors":["Anonymous"],"TL;DR":"Proposing the first watermarking framework for multi-bit signature embedding and extraction using the outputs of the DNN. ","pdf":"/pdf/c4b4f13d0cba7ac0db7e3239ce7f1b794a1131a6.pdf","paperhash":"anonymous|blackmarks_blackbox_multibit_watermarking_for_deep_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019blackmarks:,    \ntitle={BlackMarks: Black-box Multi-bit Watermarking for Deep Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1MeM2RcFm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1VeG309Fm","original":"rkgxNzCcK7","number":1235,"cdate":1538087944354,"ddate":null,"tcdate":1538087944354,"tmdate":1538155962817,"tddate":null,"forum":"S1VeG309Fm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Teaching Machine How to Think by Natural Language: A study on Machine Reading Comprehension","abstract":"Deep learning ends up as a black box, in which how it makes the decision cannot be directly understood by humans, let alone guide the reasoning process of deep network. In this work, we seek the possibility to guide the learning of network in reading comprehension task by natural language. Two approaches are proposed. In the first approach, the latent representation in the neural network is deciphered into text by a decoder; in the second approach, deep network uses text as latent representation. Human tutor provides ground truth for the output of the decoder or latent representation represented by text. On the bAbI QA tasks, we found that with the guidance on a few examples, the model can achieve the same performance with remarkably less training examples.","keywords":["Machine Reading Comprehension"],"authorids":["ICLR.cc/2019/Conference/Paper1235/Authors"],"authors":["Anonymous"],"pdf":"/pdf/cf7f29b037e500917b49650ad1a51ec4b09313af.pdf","paperhash":"anonymous|teaching_machine_how_to_think_by_natural_language_a_study_on_machine_reading_comprehension","_bibtex":"@inproceedings{    \nanonymous2019teaching,    \ntitle={Teaching Machine How to Think by Natural Language: A study on Machine Reading Comprehension},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1VeG309Fm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJgbzhC5Ym","original":"ryxoHTT5Fm","number":1236,"cdate":1538087944520,"ddate":null,"tcdate":1538087944520,"tmdate":1538155962613,"tddate":null,"forum":"BJgbzhC5Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"NECST: Neural Joint Source-Channel Coding","abstract":"For reliable transmission across a noisy communication channel, classical results from information theory show that it is asymptotically optimal to separate out the source and channel coding processes. However, this decomposition can fall short in the finite bit-length regime, as it requires non-trivial tuning of hand-crafted codes and assumes infinite computational power for decoding. In this work, we propose Neural Error Correcting and Source Trimming (NECST) codes to jointly learn the encoding and decoding processes in an end-to-end fashion. By adding noise into the latent codes to simulate the channel during training, we learn to both compress and error-correct given a fixed bit-length and computational budget. We obtain codes that are not only competitive against several capacity-approaching channel codes, but also learn useful robust representations of the data for downstream tasks such as classification. Finally, we learn an extremely fast neural decoder, yielding almost an order of magnitude in speedup compared to standard decoding methods based on iterative belief propagation. ","keywords":["joint source-channel coding","deep generative models","unsupervised learning"],"authorids":["ICLR.cc/2019/Conference/Paper1236/Authors"],"authors":["Anonymous"],"TL;DR":"jointly learn compression + error correcting codes with deep learning","pdf":"/pdf/467382024015be4c8339c9cd132e6ed5b4ba778b.pdf","paperhash":"anonymous|necst_neural_joint_sourcechannel_coding","_bibtex":"@inproceedings{    \nanonymous2019necst:,    \ntitle={NECST: Neural Joint Source-Channel Coding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgbzhC5Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1gWz2CcKX","original":"HJlj3-E9KX","number":1237,"cdate":1538087944748,"ddate":null,"tcdate":1538087944748,"tmdate":1538155962395,"tddate":null,"forum":"S1gWz2CcKX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Neural MMO: A massively multiplayer game environment for intelligent agents","abstract":"We present an artificial intelligence research platform inspired by the human game genre of MMORPGs (Massively Multiplayer Online Role-Playing Games, a.k.a. MMOs). We demonstrate how this platform can be used to study behavior and learning in large populations of neural agents. Unlike currently popular game environments, our platform supports persistent environments, with variable number of agents, and open-ended task descriptions. The emergence of complex life on Earth is often attributed to the arms race that ensued from a huge number of organisms all competing for finite resources. Our platform aims to simulate this setting in microcosm: we conduct a series of experiments to test how large-scale multiagent competition can incentivize the development of skillful behavior. We find that population size magnifies the complexity of the behaviors that emerge and results in agents that out-compete agents trained in smaller populations.","keywords":["MMO","Multiagent","Game","Reinforcement Learning","Platform","Framework","Niche Formation","Exploration"],"authorids":["ICLR.cc/2019/Conference/Paper1237/Authors"],"authors":["Anonymous"],"TL;DR":"An MMO-inspired research game platform for studying emergent behaviors of large populations in a complex environment","pdf":"/pdf/c698be855cc6db286de1773e95caa8adc2ca671f.pdf","paperhash":"anonymous|neural_mmo_a_massively_multiplayer_game_environment_for_intelligent_agents","_bibtex":"@inproceedings{    \nanonymous2019neural,    \ntitle={Neural MMO: A massively multiplayer game environment for intelligent agents},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1gWz2CcKX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJzbG20cFQ","original":"HkgSbMnIt7","number":1238,"cdate":1538087944935,"ddate":null,"tcdate":1538087944935,"tmdate":1538155962184,"tddate":null,"forum":"BJzbG20cFQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Towards Metamerism via Foveated Style Transfer","abstract":"The problem of visual metamerism is defined as finding a family of perceptually\nindistinguishable, yet physically different images. In this paper, we propose our\nNeuroFovea metamer model, a foveated generative model that is based on a mixture\nof peripheral representations and style transfer forward-pass algorithms. Our\ngradient-descent free model is parametrized by a foveated VGG19 encoder-decoder\nwhich allows us to encode images in high dimensional space and interpolate\nbetween the content and texture information with adaptive instance normalization\nanywhere in the visual field. Our contributions include: 1) A framework for\ncomputing metamers that resembles a noisy communication system via a foveated\nfeed-forward encoder-decoder network – We observe that metamerism arises as a\nbyproduct of noisy perturbations that partially lie in the perceptual null space; 2)\nA perceptual optimization scheme as a solution to the hyperparametric nature of\nour metamer model that requires tuning of the image-texture tradeoff coefficients\neverywhere in the visual field which are a consequence of internal noise; 3) An\nABX psychophysical evaluation of our metamers where we also find that the rate\nof growth of the receptive fields in our model match V1 for reference metamers\nand V2 between synthesized samples. Our model also renders metamers at roughly\na second, presenting a ×1000 speed-up compared to the previous work, which now\nallows for tractable data-driven metamer experiments.","keywords":["Metamerism","foveation","perception","style transfer","psychophysics"],"authorids":["ICLR.cc/2019/Conference/Paper1238/Authors"],"authors":["Anonymous"],"TL;DR":"We introduce a novel feed-forward framework to generate visual metamers","pdf":"/pdf/d8e9c0fdef1e913e25b6acfd98208e7e9aafd60a.pdf","paperhash":"anonymous|towards_metamerism_via_foveated_style_transfer","_bibtex":"@inproceedings{    \nanonymous2019towards,    \ntitle={Towards Metamerism via Foveated Style Transfer},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJzbG20cFQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1GbfhRqF7","original":"B1lhu3wUFm","number":1239,"cdate":1538087945109,"ddate":null,"tcdate":1538087945109,"tmdate":1538155961974,"tddate":null,"forum":"r1GbfhRqF7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Kernel Change-point Detection with Auxiliary Deep Generative Models","abstract":"Detecting the emergence of abrupt property changes in time series is a challenging problem. Kernel two-sample test has been studied for this task which makes fewer assumptions on the distributions than traditional parametric approaches. However, selecting kernels is non-trivial in practice. Although kernel selection for the two-sample test has been studied, the insufficient samples in change point detection problem hinder the success of those developed kernel selection algorithms. In this paper, we propose KL-CPD, a novel kernel learning framework for time series CPD that optimizes a lower bound of test power via an auxiliary generative model. With deep kernel parameterization, KL-CPD endows kernel two-sample test with the data-driven kernel to detect different types of change-points in real-world applications. The proposed approach significantly outperformed other state-of-the-art methods in our comparative evaluation of benchmark datasets and simulation studies.","keywords":["deep kernel learning","generative models","kernel two-sample test","time series change-point detection"],"authorids":["ICLR.cc/2019/Conference/Paper1239/Authors"],"authors":["Anonymous"],"TL;DR":"In this paper, we propose KL-CPD, a novel kernel learning framework for time series CPD that optimizes a lower bound of test power via an auxiliary generative model as a surrogate to the abnormal distribution. ","pdf":"/pdf/97c701f44f56beb1d2fadc0c01236e221adb720d.pdf","paperhash":"anonymous|kernel_changepoint_detection_with_auxiliary_deep_generative_models","_bibtex":"@inproceedings{    \nanonymous2019kernel,    \ntitle={Kernel Change-point Detection with Auxiliary Deep Generative Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1GbfhRqF7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyN-M2Rctm","original":"rkxv5M_cKQ","number":1240,"cdate":1538087945282,"ddate":null,"tcdate":1538087945282,"tmdate":1538155961759,"tddate":null,"forum":"HyN-M2Rctm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Mode Normalization","abstract":"Normalization methods are a central building block in the deep learning toolbox. They accelerate and stabilize training, while decreasing the dependence on manually tuned learning rate schedules. When learning from multi-modal distributions, the effectiveness of batch normalization (BN), arguably the most prominent normalization method, is reduced. As a remedy, we propose a more flexible approach: by extending the normalization to more than a single mean and variance, we detect modes of data on-the-fly, jointly normalizing samples that share common features. We demonstrate that our method outperforms BN and other widely used normalization techniques in several experiments, including single and multi-task datasets.","keywords":["Deep Learning","Expert Models","Normalization","Computer Vision"],"authorids":["ICLR.cc/2019/Conference/Paper1240/Authors"],"authors":["Anonymous"],"TL;DR":"We present a novel normalization method for deep neural networks that is robust to multi-modalities in intermediate feature distributions.","pdf":"/pdf/c1c188bd5eeb4e05b65cf4d0c74e0b5af3fe098f.pdf","paperhash":"anonymous|mode_normalization","_bibtex":"@inproceedings{    \nanonymous2019mode,    \ntitle={Mode Normalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyN-M2Rctm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rk4Wf30qKQ","original":"BylhVGR9KQ","number":1241,"cdate":1538087945447,"ddate":null,"tcdate":1538087945447,"tmdate":1538155961542,"tddate":null,"forum":"rk4Wf30qKQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Security Analysis of Deep Neural Networks Operating in the Presence of Cache Side-Channel Attacks","abstract":"Recent work has introduced attacks that extract the architecture information of deep neural networks (DNN), as this knowledge enhances an adversary’s capability to conduct black-box attacks against the model. This paper presents the first in-depth security analysis of DNN fingerprinting attacks that exploit cache side-channels.  First, we define the threat model for these attacks:  our adversary does not need the ability to query the victim model; instead, she runs a co-located process on the host machine victim ’s deep learning  (DL) system is running and passively monitors the accesses of the target functions in the shared framework.  Second, we introduce DeepRecon, an attack that reconstructs the architecture of the victim network by using the internal information extracted via Flush+Reload, a cache side-channel technique. Once the attacker observes function invocations that map directly to architecture attributes of the victim network, the attacker can reconstruct the victim’s entire network architecture.  In our evaluation, we demonstrate that an attacker can accurately reconstruct two complex networks (VGG19 and ResNet50) having only observed one forward propagation. Based on the extracted architecture attributes, we also demonstrate that an attacker can build a meta-model that accurately fingerprints the architecture and family of the pre-trained model in a transfer learning setting. From this meta-model,  we evaluate the importance of the observed attributes in the fingerprinting process. Third, we propose and evaluate new framework-level defense techniques that obfuscate our attacker’s observations. Our empirical security analysis represents a step toward understanding the DNNs’ vulnerability to cache side-channel attacks.","keywords":["DNN Security Analysis","Fingerprinting Attacks","Cache Side-Channel"],"authorids":["ICLR.cc/2019/Conference/Paper1241/Authors"],"authors":["Anonymous"],"TL;DR":"We conduct the first in-depth security analysis of DNN fingerprinting attacks that exploit cache side-channels, which represents a step toward understanding the DNN’s vulnerability to side-channel attacks.","pdf":"/pdf/1956563e1e67368e2362b74febaa42c41682de8a.pdf","paperhash":"anonymous|security_analysis_of_deep_neural_networks_operating_in_the_presence_of_cache_sidechannel_attacks","_bibtex":"@inproceedings{    \nanonymous2019security,    \ntitle={Security Analysis of Deep Neural Networks Operating in the Presence of Cache Side-Channel Attacks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rk4Wf30qKQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkezfhA5Y7","original":"rkezZeC5YX","number":1242,"cdate":1538087945618,"ddate":null,"tcdate":1538087945618,"tmdate":1538155961322,"tddate":null,"forum":"HkezfhA5Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A Rate-Distortion Theory of Adversarial Examples","abstract":"The generalization ability of deep neural networks (DNNs) is interwined with model complexity, robustness and capacity.\nWe employ information theory to establish an equivalence between a DNN and a noisy communication channel,\nand obtain a notion of capacity that allows us characterize generalization behavior of DNNs for adversarial inputs.","keywords":["adversarial examples","information bottleneck","robustness"],"authorids":["ICLR.cc/2019/Conference/Paper1242/Authors"],"authors":["Anonymous"],"TL;DR":"We suggest that rate-distortion theory precisely characterizes the accuracy versus robustness to adversarial examples trade-off","pdf":"/pdf/0473ef6e1e66d07d41c3d220889747183f55dc44.pdf","paperhash":"anonymous|a_ratedistortion_theory_of_adversarial_examples","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A Rate-Distortion Theory of Adversarial Examples},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkezfhA5Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJlfzhA9Y7","original":"HJxAC-C5tX","number":1243,"cdate":1538087945790,"ddate":null,"tcdate":1538087945790,"tmdate":1538155961113,"tddate":null,"forum":"rJlfzhA9Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Distributed Deep Policy Gradient for Competitive Adversarial Environment","abstract":"This work considers the problem of cooperative learners in partially observable, stochastic environment, receiving feedback in the form of joint reward. The paper presents a flexible multi-agent competitive environment for online training and direct policy performance comparison. This forms a formal problem of a multi-agent Reinforcement Learning (RL) under partial observability, where the goal is to maximize the score performance measured in a direct confrontation. To address the complexity of the problem we propose a distributed deep stochastic policy gradient with individual observations, experience replay, policy transfer, and self-play.","keywords":["multi-agent","partially observable","reinforcement learning","deepRL","self play","competitive environment"],"authorids":["ICLR.cc/2019/Conference/Paper1243/Authors"],"authors":["Anonymous"],"pdf":"/pdf/73466fd3e435fcb744ab600396b1afc1b4653374.pdf","paperhash":"anonymous|distributed_deep_policy_gradient_for_competitive_adversarial_environment","_bibtex":"@inproceedings{    \nanonymous2019distributed,    \ntitle={Distributed Deep Policy Gradient for Competitive Adversarial Environment},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJlfzhA9Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkxMG209K7","original":"rJeyrWA5K7","number":1244,"cdate":1538087945970,"ddate":null,"tcdate":1538087945970,"tmdate":1538155960898,"tddate":null,"forum":"HkxMG209K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"An Alarm System for Segmentation Algorithm Based on Shape Model","abstract":"It is usually hard for a learning system to predict correctly on the rare events, and there is no exception for segmentation algorithms. Therefore, we hope to build an alarm system to set off alarms when the segmentation result is possibly unsatisfactory. One plausible solution is to project the segmentation results into a low dimensional feature space, and then learn classifiers/regressors in the feature space to predict the qualities of segmentation results. In this paper, we form the feature space using shape feature which is a strong prior information shared among different data, so it is capable to predict the qualities of segmentation results given different segmentation algorithms on different datasets. The shape feature of a segmentation result is captured using the value of loss function when the segmentation result is tested using a Variational Auto-Encoder(VAE). The VAE is trained using only the ground truth masks, therefore the bad segmentation results with bad shapes become the rare events for VAE and will result in large loss value. By utilizing this fact, the VAE is able to detect all kinds of shapes that are out of the distribution of normal shapes in ground truth (GT). Finally, we learn the representation in the one-dimensional feature space to predict the qualities of segmentation results. We evaluate our alarm system on several recent segmentation algorithms for the medical segmentation task. The segmentation algorithms perform differently on different datasets, but our system consistently provides reliable prediction on the qualities of segmentation results.\n","keywords":["segmentation evaluation","shape feature","variational auto-encoder"],"authorids":["ICLR.cc/2019/Conference/Paper1244/Authors"],"authors":["Anonymous"],"TL;DR":"We use VAE to capture the shape feature for automatic segmentation evaluation","pdf":"/pdf/691df8145f7ab9a2464b11146ecc364f8174a8f8.pdf","paperhash":"anonymous|an_alarm_system_for_segmentation_algorithm_based_on_shape_model","_bibtex":"@inproceedings{    \nanonymous2019an,    \ntitle={An Alarm System for Segmentation Algorithm Based on Shape Model},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkxMG209K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJxMM2C5K7","original":"r1guQco9Fm","number":1245,"cdate":1538087946152,"ddate":null,"tcdate":1538087946152,"tmdate":1538155960686,"tddate":null,"forum":"rJxMM2C5K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Nested Dithered Quantization for Communication Reduction in Distributed Training","abstract":"In distributed training, the communication cost due to the transmission of gradients\nor the parameters of the deep model is a major bottleneck in scaling up the number\nof processing nodes. To address this issue, we propose dithered quantization for\nthe transmission of the stochastic gradients and show that training with Dithered\nQuantized Stochastic Gradients (DQSG) is similar to the training with unquantized\nSGs perturbed by an independent bounded uniform noise, in contrast to the other\nquantization methods where the perturbation depends on the gradients and hence,\ncomplicating the convergence analysis. We study the convergence of training\nalgorithms using DQSG and the trade off between the number of quantization\nlevels and the training time. Next, we observe that there is a correlation among the\nSGs computed by workers that can be utilized to further reduce the communication\noverhead without any performance loss. Hence, we develop a simple yet effective\nquantization scheme, nested dithered quantized SG (NDQSG), that can reduce the\ncommunication significantly without requiring the workers communicating extra\ninformation to each other. We prove that although NDQSG requires significantly\nless bits, it can achieve the same quantization variance bound as DQSG. Our\nsimulation results confirm the effectiveness of training using DQSG and NDQSG\nin reducing the communication bits or the convergence time compared to the\nexisting methods without sacrificing the accuracy of the trained model.","keywords":["machine learning","distributed training","dithered quantization","nested quantization","distributed compression"],"authorids":["ICLR.cc/2019/Conference/Paper1245/Authors"],"authors":["Anonymous"],"TL;DR":"The paper proposes and analyzes two quantization schemes for communicating Stochastic Gradients in distributed learning which would reduce communication costs compare to the state of the art while maintaining the same accuracy.  ","pdf":"/pdf/c3b6766c0523c7a525928aca2b4f3cb21258a5c1.pdf","paperhash":"anonymous|nested_dithered_quantization_for_communication_reduction_in_distributed_training","_bibtex":"@inproceedings{    \nanonymous2019nested,    \ntitle={Nested Dithered Quantization for Communication Reduction in Distributed Training},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJxMM2C5K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ByWMz305FQ","original":"BklBHz09FQ","number":1246,"cdate":1538087946320,"ddate":null,"tcdate":1538087946320,"tmdate":1538155960474,"tddate":null,"forum":"ByWMz305FQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"The Missing Ingredient in Zero-Shot Neural Machine Translation","abstract":"Multilingual Neural Machine Translation (NMT) systems are capable of translating between multiple source and target languages within a single system. An important indicator of generalization within these systems is the quality of zero-shot translation - translating between language pairs that the system has never seen during training. However, until now, the zero-shot performance of multilingual models has lagged far behind the quality that can be achieved by using a two step translation process that pivots through an intermediate language (usually English). In this work, we diagnose why multilingual models under-perform in zero shot settings. We propose explicit language invariance losses that guide an NMT encoder towards learning language agnostic representations. Our proposed strategies significantly improve zero-shot translation performance on WMT English-French-German and on the IWSLT 2017 shared task, and for the first time, match the performance of pivoting approaches while maintaining performance on supervised directions.","keywords":["Machine Translation","Multi-lingual processing","Zero-Shot translation"],"authorids":["ICLR.cc/2019/Conference/Paper1246/Authors"],"authors":["Anonymous"],"TL;DR":"Simple similarity constraints on top of multilingual NMT enables high quality translation between unseen language pairs for the first time.","pdf":"/pdf/225e5c63da4bdd08cc6bf77cdd1c7de0b4d3e32e.pdf","paperhash":"anonymous|the_missing_ingredient_in_zeroshot_neural_machine_translation","_bibtex":"@inproceedings{    \nanonymous2019the,    \ntitle={The Missing Ingredient in Zero-Shot Neural Machine Translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByWMz305FQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkGGfhC5Y7","original":"B1gm5Ea8YQ","number":1247,"cdate":1538087946492,"ddate":null,"tcdate":1538087946492,"tmdate":1538155960267,"tddate":null,"forum":"HkGGfhC5Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Towards a better understanding of Vector Quantized Autoencoders","abstract":"Deep neural networks with discrete latent variables offer the promise of better symbolic reasoning, and learning abstractions that are more useful to new tasks. There has been a surge in interest in discrete latent variable models, however, despite several recent improvements, the training of discrete latent variable models has remained  challenging and their performance has mostly failed to match their continuous counterparts. Recent work on vector quantized autoencoders (VQ-VAE) has made substantial progress in this direction, with its perplexity almost matching that of a VAE on datasets such as CIFAR-10. In this work, we investigate an alternate training technique for VQ-VAE, inspired by its connection to the Expectation Maximization (EM) algorithm. Training the discrete bottleneck with EM helps us achieve better image generation results on CIFAR-10, and together with knowledge distillation, allows us to develop a non-autoregressive machine translation model whose accuracy almost matches a strong greedy autoregressive baseline Transformer, while being 3.3 times faster at inference.","keywords":["machine translation","vector quantized autoencoders","non-autoregressive","NMT"],"authorids":["ICLR.cc/2019/Conference/Paper1247/Authors"],"authors":["Anonymous"],"TL;DR":"Understand the VQ-VAE discrete autoencoder systematically using EM and use it to design non-autogressive translation model matching a strong autoregressive baseline.","pdf":"/pdf/d05101e0bae5fd8760883e2c673f976ddf8a8cbb.pdf","paperhash":"anonymous|towards_a_better_understanding_of_vector_quantized_autoencoders","_bibtex":"@inproceedings{    \nanonymous2019towards,    \ntitle={Towards a better understanding of Vector Quantized Autoencoders},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkGGfhC5Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkgmzhC5F7","original":"H1ll-BT9Fm","number":1248,"cdate":1538087946656,"ddate":null,"tcdate":1538087946656,"tmdate":1538155960060,"tddate":null,"forum":"HkgmzhC5F7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A Modern Take on the Bias-Variance Tradeoff in Neural Networks","abstract":"We revisit the bias-variance tradeoff for neural networks in light of modern empirical findings. The traditional bias-variance tradeoff in machine learning suggests that as model complexity grows, variance increases. Classical bounds in statistical learning theory point to the number of parameters in a model as a measure of model complexity, which means the tradeoff would indicate that variance increases with the size of neural networks. However, we empirically find that variance due to training set sampling is roughly constant (with both width and depth) in practice. Variance caused by the non-convexity of the loss landscape is different. We find that it decreases with width and increases with depth, in our setting. We provide theoretical analysis, in a simplified setting inspired by linear models, that is consistent with our empirical findings for width. We view bias-variance as a useful lens to study generalization through and encourage further theoretical explanation from this perspective.","keywords":["bias-variance tradeoff","deep learning theory","generalization","concentration"],"authorids":["ICLR.cc/2019/Conference/Paper1248/Authors"],"authors":["Anonymous"],"TL;DR":"We revisit empirically and theoretically the bias-variance tradeoff for neural networks to shed more light on their generalization properties.","pdf":"/pdf/e3367be861b58154d691cf455634d4b540e65eac.pdf","paperhash":"anonymous|a_modern_take_on_the_biasvariance_tradeoff_in_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A Modern Take on the Bias-Variance Tradeoff in Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkgmzhC5F7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJlQfnCqKX","original":"HJl4QbjtKm","number":1249,"cdate":1538087946831,"ddate":null,"tcdate":1538087946831,"tmdate":1538155959844,"tddate":null,"forum":"HJlQfnCqKX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Predicting the Generalization Gap in Deep Networks with Margin Distributions","abstract":"As shown in recent research, deep neural networks can perfectly fit randomly labeled data, but with very poor accuracy on held out data. This phenomenon indicates that loss functions such as cross-entropy are not a reliable indicator of generalization. This leads to the crucial question of how generalization gap should be predicted from the training data and network parameters. In this paper, we propose such a measure, and conduct extensive empirical studies on how well it can predict the generalization gap. Our measure is based on the concept of margin distribution, which are the distances of training points to the decision boundary. We find that it is necessary to use margin distributions at multiple layers of a deep network. On the CIFAR-10 and the CIFAR-100 datasets, our proposed measure correlates very strongly with the generalization gap. In addition, we find the following other factors to be of importance: normalizing margin values for scale independence, using characterizations of margin distribution rather than just the margin (closest distance to decision boundary), and working in log space instead of linear space (effectively using a product of margins rather than a sum).\nOur measure can be easily applied to feedforward deep networks with any architecture and may point towards new training loss functions that could enable better generalization.","keywords":["Deep learning","large margin","generalization bounds","generalization gap."],"authorids":["ICLR.cc/2019/Conference/Paper1249/Authors"],"authors":["Anonymous"],"TL;DR":"We develop a new scheme to predict the generalization gap in deep networks with high accuracy.","pdf":"/pdf/215470066deac4c7a2984eb537946fae8970bbb0.pdf","paperhash":"anonymous|predicting_the_generalization_gap_in_deep_networks_with_margin_distributions","_bibtex":"@inproceedings{    \nanonymous2019predicting,    \ntitle={Predicting the Generalization Gap in Deep Networks with Margin Distributions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJlQfnCqKX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1MXz20cYQ","original":"HklMDB2qKQ","number":1250,"cdate":1538087947025,"ddate":null,"tcdate":1538087947025,"tmdate":1538155959624,"tddate":null,"forum":"B1MXz20cYQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Explaining Image Classifiers by Counterfactual Generation","abstract":"When a black-box classifier processes an input example to render a prediction, which input features are relevant and why? We propose to answer this question by efficiently marginalizing over the universe of plausible alternative values for a subset of features by conditioning a generative model of the input distribution on the remaining features. In contrast with recent approaches that compute alternative feature values ad-hoc---generating counterfactual inputs far from the natural data distribution---our model-agnostic method produces realistic explanations, generating plausible inputs that either preserve or alter the classification confidence. When applied to image classification, our method produces more compact and relevant per-feature saliency assignment, with fewer artifacts compared to previous methods.","keywords":["Explainability","Interpretability","Generative Models","Saliency Map","Machine Learning","Deep Learning"],"authorids":["ICLR.cc/2019/Conference/Paper1250/Authors"],"authors":["Anonymous"],"TL;DR":"We compute saliency by using a strong generative model to efficiently marginalize over plausible alternative inputs, revealing concentrated pixel areas that preserve label information.","pdf":"/pdf/ac89217127ab08bc4a01b88cf5c135c4203259fc.pdf","paperhash":"anonymous|explaining_image_classifiers_by_counterfactual_generation","_bibtex":"@inproceedings{    \nanonymous2019explaining,    \ntitle={Explaining Image Classifiers by Counterfactual Generation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1MXz20cYQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJzmzn0ctX","original":"r1xj-16ctm","number":1251,"cdate":1538087947200,"ddate":null,"tcdate":1538087947200,"tmdate":1538155959414,"tddate":null,"forum":"BJzmzn0ctX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Scalable Neural Theorem Proving on Knowledge Bases and Natural Language","abstract":"Reasoning over text and Knowledge Bases (KBs) is a major challenge for ArtificialIntelligence, with applications in machine reading, dialogue, and question answering.  Transducing text to logical forms which can be operated on is a brittle and error-prone process. Operating directly on text by jointly learning representations and transformations thereof by means of neural architectures that lack the ability to learn and exploit general rules can be very data-inefficient and not generalise correctly. These issues are addressed by Neural Theorem Provers (NTPs) (Rocktäschel & Riedel, 2017), neuro-symbolic systems based on a continuous relaxation of Prolog’s backward chaining algorithm, where symbolic unification between atoms is replaced by a differentiable operator computing the similarity between their embedding representations. In this paper, we first propose Neighbourhood-approximated Neural Theorem Provers (NaNTPs) consisting of two extensions toNTPs, namely a) a method for drastically reducing the previously prohibitive time and space complexity during inference and learning, and b) an attention mechanism for improving the rule learning process, deeming them usable on real-world datasets. Then, we propose a novel approach for jointly reasoning over KB facts and textual mentions, by jointly embedding them in a shared embedding space. The proposed method is able to extract rules and provide explanations—involving both textual patterns and KB relations—from large KBs and text corpora. We show thatNaNTPs perform on par with NTPs at a fraction of a cost, and can achieve competitive link prediction results on challenging large-scale datasets, including WN18, WN18RR, and FB15k-237 (with and without textual mentions) while being able to provide explanations for each prediction and extract interpretable rules.","keywords":["Machine Reading","Natural Language Processing","Neural Theorem Proving","Representation Learning","First Order Logic"],"authorids":["ICLR.cc/2019/Conference/Paper1251/Authors"],"authors":["Anonymous"],"TL;DR":"We scale Neural Theorem Provers to large datasets, improve the rule learning process, and extend it to jointly reason over text and Knowledge Bases.","pdf":"/pdf/8243bbcc53a586820186f9250dd9ade8925cb7e7.pdf","paperhash":"anonymous|scalable_neural_theorem_proving_on_knowledge_bases_and_natural_language","_bibtex":"@inproceedings{    \nanonymous2019scalable,    \ntitle={Scalable Neural Theorem Proving on Knowledge Bases and Natural Language},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJzmzn0ctX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1lXGnRctX","original":"SyxGNb09YQ","number":1252,"cdate":1538087947369,"ddate":null,"tcdate":1538087947369,"tmdate":1538155959204,"tddate":null,"forum":"B1lXGnRctX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Classification in the dark using tactile exploration","abstract":"Combining information from different sensory modalities to execute goal directed actions is a key aspect of human intelligence. Specifically, human agents are very easily able to translate the task communicated in one sensory domain (say vision) into a representation that enables them to complete this task when they can only sense their environment using a separate sensory modality (say touch). In order to build agents with similar capabilities, in this work we consider the problem of a retrieving a target object from a drawer. The agent is provided with an image of a previously unseen object and it explores objects in the drawer using only tactile sensing to retrieve the object that was shown in the image without receiving any visual feedback. Success at this task requires close integration of visual and tactile sensing. We present a method for performing this task in a simulated environment using an anthropomorphic hand. We hope that future research in the direction of combining sensory signals for acting will find the object retrieval from a drawer to be a useful benchmark problem","keywords":["tactile sensing","multimodal representations","vision","object identification"],"authorids":["ICLR.cc/2019/Conference/Paper1252/Authors"],"authors":["Anonymous"],"TL;DR":"In this work, we study the problem of learning representations to identify novel objects by exploring objects using tactile sensing. Key point here is that the query is provided in image domain.","pdf":"/pdf/f45a4ba2821dc271070e94959752b3fb440e5af8.pdf","paperhash":"anonymous|classification_in_the_dark_using_tactile_exploration","_bibtex":"@inproceedings{    \nanonymous2019classification,    \ntitle={Classification in the dark using tactile exploration},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1lXGnRctX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkl4M3R5K7","original":"HkgoKh6tt7","number":1253,"cdate":1538087947543,"ddate":null,"tcdate":1538087947543,"tmdate":1538155958995,"tddate":null,"forum":"rkl4M3R5K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Optimal Attacks against Multiple Classifiers","abstract":"We study the problem of designing provably optimal adversarial noise algorithms that induce misclassification in settings where a learner aggregates decisions from multiple classifiers. Given the demonstrated vulnerability of state-of-the-art models to adversarial examples, recent efforts within the field of robust machine learning have focused on the use of ensemble classifiers as a way of boosting the robustness of individual models. In this paper, we design provably optimal attacks against a set of classifiers. We demonstrate how this problem can be framed as finding strategies at equilibrium in a two player, zero sum game between a learner and an adversary and consequently illustrate the need for randomization in adversarial attacks. The main technical challenge we consider is the design of best response oracles that can be implemented in a Multiplicative Weight Updates framework to find equilibrium strategies in the zero-sum game. We develop a series of scalable noise generation algorithms for deep neural networks, and show that it outperforms state-of-the-art attacks on various image classification tasks. Although there are generally no guarantees for deep learning, we show this is a well-principled approach in that it is provably optimal for linear classifiers. The main insight is a geometric characterization of the decision space that reduces the problem of designing best response oracles to minimizing a quadratic function over a set of convex polytopes.","keywords":["online learning","nonconvex optimization","robust optimization"],"authorids":["ICLR.cc/2019/Conference/Paper1253/Authors"],"authors":["Anonymous"],"TL;DR":"Paper analyzes the problem of designing adversarial attacks against multiple classifiers, introducing algorithms that are optimal for linear classifiers and which provide state-of-the-art results for deep learning.","pdf":"/pdf/8b6730a932d8c35e7203ff8c676ba6c763467587.pdf","paperhash":"anonymous|optimal_attacks_against_multiple_classifiers","_bibtex":"@inproceedings{    \nanonymous2019optimal,    \ntitle={Optimal Attacks against Multiple Classifiers},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkl4M3R5K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1eEG20qKQ","original":"B1gYhkRcYX","number":1254,"cdate":1538087947712,"ddate":null,"tcdate":1538087947712,"tmdate":1538155958781,"tddate":null,"forum":"r1eEG20qKQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions","abstract":"Hyperparameter optimization is a bi-level optimization problem, where the optimal parameters on the training set depend on the current hyperparameters. The best-response function which maps hyperparameters to these optimal parameters allows gradient-based hyperparameter optimization but is difficult to represent and compute when the parameters are high dimensional, as in neural networks. We develop efficient best-response approximations for neural networks by applying insights from the structure of the optimal response in a Jacobian-regularized two-layer linear network to deep, nonlinear networks. The approximation works by scaling and shifting the hidden units by amounts which depend on the current hyperparameters.  We use our approximation for a gradient-based hyperparameter optimization algorithm which alternates between approximating the best-response in a neighborhood around the current hyperparameters and optimizing the hyperparameters using the approximate best-response. We show this method outperforms competing hyperparameter optimization methods on large-scale deep learning problems. We call our networks, which update their own hyperparameters online during training, Self-Tuning Networks.","keywords":["hyperparameter optimization","game theory","optimization"],"authorids":["ICLR.cc/2019/Conference/Paper1254/Authors"],"authors":["Anonymous"],"TL;DR":"We use a hypernetwork to predict optimal weights given hyperparameters, and jointly train everything together.","pdf":"/pdf/8a385e37d274b9e6d6105e4f42b3ec4f4ff3438f.pdf","paperhash":"anonymous|selftuning_networks_bilevel_optimization_of_hyperparameters_using_structured_bestresponse_functions","_bibtex":"@inproceedings{    \nanonymous2019self-tuning,    \ntitle={Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1eEG20qKQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJl4f2A5tQ","original":"Hkl2ZHZFd7","number":1255,"cdate":1538087947878,"ddate":null,"tcdate":1538087947878,"tmdate":1538155958567,"tddate":null,"forum":"BJl4f2A5tQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Surprising Negative Results for Generative  Adversarial Tree Search ","abstract":"Although many recent advances in deep reinforcement learning consist of model- free methods, model-based approaches remain an alluring prospect owing to their potential to exploit unsupervised data to learn environment dynamics. Moreover, with new breakthroughs on image-to-image transduction, Pix2Pix GANs are a natural choice for learning to predict the dynamics of environments where ob- servations consist of images (like Atari games). Inspired by AlphaGo, which combines model-based and model-free RL, we propose generative adversarial tree search (GATS), simulating roll-outs with a learned GAN-based dynamics model and reward predictor. We theoretically prove some favorable properties of GATS vis-a-vis the bias-variance trade-off. The approach combines model-based planning via MCTS with model-free learning with DQNs. Empirically, on 5 popular Atari games, despite the dynamics and reward predictors converging quickly to accurate solutions GATS fails to outperform DQNs. We present a hypothesis for why tree search with short roll-outs can fail even given perfect modelling.","keywords":["Deep Reinforcement Learning","Generative Adversarial Nets"],"authorids":["ICLR.cc/2019/Conference/Paper1255/Authors"],"authors":["Anonymous"],"TL;DR":"Surprising negative results on Model Based + Model deep RL","pdf":"/pdf/0ea4761fcbea0d1b66c26f2858fc1ccbf0160b2d.pdf","paperhash":"anonymous|surprising_negative_results_for_generative_adversarial_tree_search","_bibtex":"@inproceedings{    \nanonymous2019surprising,    \ntitle={Surprising Negative Results for Generative  Adversarial Tree Search },    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJl4f2A5tQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1eVMnA9K7","original":"BJlGIzC5Fm","number":1256,"cdate":1538087948048,"ddate":null,"tcdate":1538087948048,"tmdate":1538155958359,"tddate":null,"forum":"r1eVMnA9K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Unsupervised Control Through Non-Parametric Discriminative Rewards","abstract":"Learning to control an environment without hand-crafted rewards or expert data remains challenging and is at the frontier of reinforcement learning research. We present an unsupervised learning algorithm to train agents to achieve perceptually-specified goals using only a stream of observations and actions. Our agent simultaneously learns a goal-conditioned policy and a goal achievement reward function that measures how similar a state is to the goal state. This dual optimization leads to a co-operative game, giving rise to a learned reward function that reflects similarity in controllable aspects of the environment instead of distance in the space of observations. We demonstrate the efficacy of our agent to learn, in an unsupervised manner, to reach a diverse set of goals on three domains -- Atari, the DeepMind Control Suite and DeepMind Lab.","keywords":["deep reinforcement learning","goals","UVFA","mutual information"],"authorids":["ICLR.cc/2019/Conference/Paper1256/Authors"],"authors":["Anonymous"],"TL;DR":"Unsupervised reinforcement learning method for learning a policy to robustly achieve perceptually specified goals.","pdf":"/pdf/83bd865b60cfbd8c742a7495ec84929eb81ce5da.pdf","paperhash":"anonymous|unsupervised_control_through_nonparametric_discriminative_rewards","_bibtex":"@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Control Through Non-Parametric Discriminative Rewards},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1eVMnA9K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HklVMnR5tQ","original":"BJgqW-AcYm","number":1257,"cdate":1538087948216,"ddate":null,"tcdate":1538087948216,"tmdate":1538155958143,"tddate":null,"forum":"HklVMnR5tQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Exploring the interpretability of LSTM neural networks over multi-variable data","abstract":"In learning a predictive model over multivariate time series consisting of target and exogenous variables, the forecasting performance and interpretability of the model are both essential for deployment and uncovering knowledge behind the data. To this end, we propose the interpretable multi-variable LSTM recurrent neural network (IMV-LSTM) capable of providing accurate forecasting as well as both temporal and variable level importance interpretation. In particular, IMVLSTM is equipped with tensorized hidden states and update process, so as tolearn variables-wise hidden states. On top of it, we develop a mixture attention mechanism and associated summarization methods to quantify the temporal and variable importance in data. Extensive experiments using real datasets demonstrate the prediction performance and interpretability of IMV-LSTM in comparison to a variety of baselines. It also exhibits the prospect as an end-to-end framework for both forecasting and knowledge extraction over multi-variate data.\n","keywords":["Interpretability","recurrent neural network","attention"],"authorids":["ICLR.cc/2019/Conference/Paper1257/Authors"],"authors":["Anonymous"],"pdf":"/pdf/e44fe0ff79eda3b1db85b21fbc0e3cda023e01ec.pdf","paperhash":"anonymous|exploring_the_interpretability_of_lstm_neural_networks_over_multivariable_data","_bibtex":"@inproceedings{    \nanonymous2019exploring,    \ntitle={Exploring the interpretability of LSTM neural networks over multi-variable data},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HklVMnR5tQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyGEM3C9KQ","original":"rkgF-0HqK7","number":1258,"cdate":1538087948383,"ddate":null,"tcdate":1538087948383,"tmdate":1538155957930,"tddate":null,"forum":"HyGEM3C9KQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Improving the Differentiable Neural Computer Through Memory Masking, De-allocation, and Link Distribution Sharpness Control","abstract":"The Differentiable Neural Computer (DNC) can learn algorithmic and question answering tasks. An analysis of its internal activation patterns reveals three problems: Most importantly, content based look-up results in flat and noisy address distributions, because the lack of key-value separation makes the DNC unable to ignore memory content which is not present in the key and need to be retrieved. Second, DNC's de-allocation of memory results in aliasing, which is a problem for content-based look-up. Thirdly, chaining memory reads with the temporal linkage matrix exponentially degrades the quality of the address distribution. Our  proposed fixes of these problems yield improved performance on arithmetic tasks, and also improve the mean error rate on the bAbI question answering dataset by 43%. ","keywords":["rnn","dnc","memory augmented neural networks","mann"],"authorids":["ICLR.cc/2019/Conference/Paper1258/Authors"],"authors":["Anonymous"],"pdf":"/pdf/2f98ab4405de875be68055562a20df852c2046ef.pdf","paperhash":"anonymous|improving_the_differentiable_neural_computer_through_memory_masking_deallocation_and_link_distribution_sharpness_control","_bibtex":"@inproceedings{    \nanonymous2019improving,    \ntitle={Improving the Differentiable Neural Computer Through Memory Masking, De-allocation, and Link Distribution Sharpness Control},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyGEM3C9KQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HklSf3CqKm","original":"rkg8amQqK7","number":1259,"cdate":1538087948550,"ddate":null,"tcdate":1538087948550,"tmdate":1538155957710,"tddate":null,"forum":"HklSf3CqKm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Subgradient Descent Learns Orthogonal Dictionaries","abstract":"This paper concerns dictionary learning, viz., sparse coding, a fundamental representation learning problem. We show that a subgradient descent algorithm, with random initialization, can recover orthogonal dictionaries on a natural nonsmooth, nonconvex L1 minimization formulation of the problem, under mild statistical assumption on the data. This is in contrast to previous provable methods that require either expensive computation or delicate initialization schemes. Our analysis develops several tools for characterizing landscapes of nonsmooth functions, which might be of independent interest for provable training of deep networks with nonsmooth activations (e.g., ReLU), among other applications. Preliminary experiments corroborate our analysis and show that our algorithm works well empirically in recovering orthogonal dictionaries.","keywords":["Dictionary learning","Sparse coding","Non-convex optimization","Theory"],"authorids":["ICLR.cc/2019/Conference/Paper1259/Authors"],"authors":["Anonymous"],"TL;DR":"Efficient dictionary learning by L1 minimization via a novel analysis of the non-convex non-smooth geometry.","pdf":"/pdf/466b410624a7098c52f3fe8841e59f849c9b4007.pdf","paperhash":"anonymous|subgradient_descent_learns_orthogonal_dictionaries","_bibtex":"@inproceedings{    \nanonymous2019subgradient,    \ntitle={Subgradient Descent Learns Orthogonal Dictionaries},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HklSf3CqKm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BylBfnRqFm","original":"S1eGYFpqtm","number":1260,"cdate":1538087948717,"ddate":null,"tcdate":1538087948717,"tmdate":1538155957493,"tddate":null,"forum":"BylBfnRqFm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"CAML: Fast Context Adaptation via Meta-Learning","abstract":"We propose CAML, a meta-learning method for fast adaptation that partitions the model parameters into two parts: context parameters that serve as additional input to the model and are adapted on individual tasks, and shared parameters that are meta-trained and shared across tasks. At test time, the context parameters are updated with one or several gradient steps on a task-specific loss that is backpropagated through the shared part of the network. Compared to approaches that adjust all parameters on a new task (e.g., MAML), our method can be scaled up to larger networks without overfitting on a single task, is easier to implement, and saves memory writes during training and network communication at test time for distributed machine learning systems. We show empirically that this approach outperforms MAML, is less sensitive to the task-specific learning rate, can capture meaningful task embeddings with the context parameters, and outperforms alternative partitionings of the parameter vectors.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1260/Authors"],"authors":["Anonymous"],"pdf":"/pdf/d967f5e4216937e359dc2e2b57dac4456b763511.pdf","paperhash":"anonymous|caml_fast_context_adaptation_via_metalearning","_bibtex":"@inproceedings{    \nanonymous2019caml:,    \ntitle={CAML: Fast Context Adaptation via Meta-Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BylBfnRqFm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1eBzhRqK7","original":"ByxjA-0ctm","number":1261,"cdate":1538087948889,"ddate":null,"tcdate":1538087948889,"tmdate":1538155957273,"tddate":null,"forum":"S1eBzhRqK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Evolutionary-Neural Hybrid Agents for Architecture Search","abstract":"Neural Architecture Search has recently shown potential to automate the design of Neural Networks. The use of Neural Network agents trained with Reinforcement Learning can offer the possibility to learn complex patterns, as well as the ability to explore a vast and compositional search space. On the other hand, evolutionary algorithms offer the greediness and sample efficiency needed for such an application, as each sample requires a considerable amount of resources. We propose a class of Evolutionary-Neural hybrid agents (Evo-NAS), that retain the best qualities of the two approaches. We show that the Evo-NAS agent can outperform both Neural and Evolutionary agents, both on a synthetic task, and on architecture search for a suite of text classification datasets.","keywords":["Evolutionary","Architecture Search","NAS"],"authorids":["ICLR.cc/2019/Conference/Paper1261/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a class of Evolutionary-Neural hybrid agents, that retain the best qualities of the two approaches.","pdf":"/pdf/9974bcace4c723c6b05b6bda8c6fbdcfc0a0ab61.pdf","paperhash":"anonymous|evolutionaryneural_hybrid_agents_for_architecture_search","_bibtex":"@inproceedings{    \nanonymous2019evolutionary-neural,    \ntitle={Evolutionary-Neural Hybrid Agents for Architecture Search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1eBzhRqK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SygHGnRqK7","original":"HylZBn6qKm","number":1262,"cdate":1538087949066,"ddate":null,"tcdate":1538087949066,"tmdate":1538155957061,"tddate":null,"forum":"SygHGnRqK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Probabilistic Federated Neural Matching","abstract":"In federated learning problems, data is scattered across different servers and exchanging or pooling it is often impractical or prohibited. We develop a Bayesian nonparametric framework for federated learning with neural networks. Each data server is assumed to train local neural network weights, which are modeled through our framework. We then develop an inference approach that allows us to synthesize a more expressive global network without additional supervision or data pooling. We then demonstrate the efficacy of our approach on federated learning problems simulated from two popular image classification datasets.","keywords":["Bayesian nonparametrics","Indian Buffet Process","Federated Learning"],"authorids":["ICLR.cc/2019/Conference/Paper1262/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a Bayesian nonparametric model for federated learning with neural networks.","pdf":"/pdf/9ed5608e8fd12e4ad4ae9eb7c9e78a4ff03ab372.pdf","paperhash":"anonymous|probabilistic_federated_neural_matching","_bibtex":"@inproceedings{    \nanonymous2019probabilistic,    \ntitle={Probabilistic Federated Neural Matching},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SygHGnRqK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1gBz2C9tX","original":"r1esu-Cqtm","number":1263,"cdate":1538087949238,"ddate":null,"tcdate":1538087949238,"tmdate":1538155956847,"tddate":null,"forum":"S1gBz2C9tX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Importance Resampling for Off-policy Policy Evaluation","abstract":"Importance sampling is a common approach to off-policy learning in reinforcement learning.  While it is consistent and unbiased, it can result in high variance updates to the parameters for the value function. Weighted importance sampling (WIS) has been explored to reduce variance for off-policy policy evaluation, but only for linear value function approximation. In this work, we explore a resampling strategy to reduce variance, rather than a reweighting strategy. We propose Importance Resampling (IR) for off-policy learning, that resamples experience from the replay buffer and applies a standard on-policy update. The approach avoids using importance sampling ratios directly in the update, instead correcting the distribution over transitions before the update. We characterize the bias and consistency of the our estimator, particularly compared to WIS. We then demonstrate in several toy domains that IR has improved sample efficiency and parameter sensitivity, as compared to several baseline WIS estimators and to IS. We conclude with a demonstration showing IR improves over IS for learning a value function from images in a racing car simulator.","keywords":["Reinforcement Learning","Off-policy policy evaluation","importance resampling","importance sampling"],"authorids":["ICLR.cc/2019/Conference/Paper1263/Authors"],"authors":["Anonymous"],"TL;DR":"A resampling approach for off-policy policy evaluation in reinforcement learning.","pdf":"/pdf/a7e41f6cea5c6b25dfb81658254363fb0aa15a44.pdf","paperhash":"anonymous|importance_resampling_for_offpolicy_policy_evaluation","_bibtex":"@inproceedings{    \nanonymous2019importance,    \ntitle={Importance Resampling for Off-policy Policy Evaluation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1gBz2C9tX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJMBM2RqKQ","original":"HJgLez65FQ","number":1264,"cdate":1538087949426,"ddate":null,"tcdate":1538087949426,"tmdate":1538155956635,"tddate":null,"forum":"SJMBM2RqKQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Uncertainty-guided Lifelong Learning in Bayesian Networks","abstract":"The ability to learn in a setting where tasks arrive in a sequence without access to previous task data is difficult for learning algorithms when restricted in capacity.  In this lifelong learning setting a single model is challenged to learning a new task, while at the same time not forgetting about previous tasks and freeing up capacity for future tasks. We argue that the ability to identify network parameters which are most critical for a learned task plays a critical role to decide which ones to remember. In this work we propose to rely on Bayesian Networks, which inherently model the distribution of a parameter rather than a single value of a parameter.  More specifically, we formulate lifelong learning in the Bayesian-by-Backprop framework, exploiting the parameter uncertainty for two lifelong learning directions. First, weight pruning, where a hard selection is made on which parameters to select per task and, second, weight regularization which can be seen as a softer version to keep important parameters, respectively.  We show the benefit of our approach using diverse object classification datasets in both cases.","keywords":["lifelong learning","continual learning","sequential learning"],"authorids":["ICLR.cc/2019/Conference/Paper1264/Authors"],"authors":["Anonymous"],"TL;DR":"We formulate lifelong learning in the Bayesian-by-Backprop framework, exploiting the parameter uncertainty in two settings: for pruning network parameters and in importance weight based continual learning.","pdf":"/pdf/8883837e6dee2f537035d71d2a723f05ad4312a4.pdf","paperhash":"anonymous|uncertaintyguided_lifelong_learning_in_bayesian_networks","_bibtex":"@inproceedings{    \nanonymous2019uncertainty-guided,    \ntitle={Uncertainty-guided Lifelong Learning in Bayesian Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJMBM2RqKQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SkeUG30cFQ","original":"r1giUzRqY7","number":1265,"cdate":1538087949594,"ddate":null,"tcdate":1538087949594,"tmdate":1538155956424,"tddate":null,"forum":"SkeUG30cFQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"The Expressive Power of Deep Neural Networks with Circulant Matrices","abstract":"Recent results from linear algebra stating that any matrix can be decomposed into products of diagonal and circulant matrices has lead to the design of compact deep neural network architectures that perform well in practice. In this paper, we bridge the gap between these good empirical results \nand the theoretical approximation capabilities of Deep diagonal-circulant ReLU networks. More precisely, we first demonstrate  that a Deep diagonal-circulant ReLU networks of\nbounded width and small depth can approximate a deep ReLU network in which the dense matrices are\nof low rank. Based on this result, we provide new bounds on the expressive power and universal approximativeness of this type of networks. We support our experimental results with thorough experiments on a large, real world video classification problem.","keywords":["deep learning","circulant matrices","universal approximation"],"authorids":["ICLR.cc/2019/Conference/Paper1265/Authors"],"authors":["Anonymous"],"TL;DR":"We provid a theoretical study of the properties of Deep circulant-diagonal ReLU Networks and demonstrated that they are bounded width universal approximators.","pdf":"/pdf/6640b3c1a3ecb4248b3fbb31ce90ec578e2ab4b0.pdf","paperhash":"anonymous|the_expressive_power_of_deep_neural_networks_with_circulant_matrices","_bibtex":"@inproceedings{    \nanonymous2019the,    \ntitle={The Expressive Power of Deep Neural Networks with Circulant Matrices},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkeUG30cFQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1gIf305Ym","original":"HJxX1Xi5KQ","number":1266,"cdate":1538087949761,"ddate":null,"tcdate":1538087949761,"tmdate":1538155956205,"tddate":null,"forum":"B1gIf305Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"NSGA-Net: A Multi-Objective Genetic Algorithm for Neural Architecture Search","abstract":"This paper introduces NSGA-Net, an evolutionary approach for neural architecture search (NAS). NSGA-Net is designed with three goals in mind: (1) a NAS procedure for multiple, possibly conflicting, objectives, (2) efficient exploration and exploitation of the space of potential neural network architectures, and (3) output of a diverse set of network architectures spanning a trade-off frontier of the objectives in a single run. NSGA-Net is a population-based search algorithm that explores a space of potential neural network architectures in three steps, namely, a population initialization step that is based on prior-knowledge from hand-crafted architectures, an exploration step comprising crossover and mutation of architectures and finally an exploitation step that applies the entire history of evaluated neural architectures in the form of a Bayesian Network prior. Experimental results suggest that combining the objectives of minimizing both an error metric and computational complexity, as measured by FLOPS, allows NSGA-Net to find competitive neural architectures near the Pareto front of both objectives on two different tasks, object classification and object alignment. NSGA-Net obtains networks that achieve 3.72% (at 4.5 million FLOP) error on CIFAR-10 classification and 8.64% (at 26.6 million FLOP) error on the CMU-Car alignment task.","keywords":["neural architecture search","evolutionary algorithms"],"authorids":["ICLR.cc/2019/Conference/Paper1266/Authors"],"authors":["Anonymous"],"TL;DR":"An efficient multi-objective neural architecture search algorithm using NSGA-II","pdf":"/pdf/f541b25829c22fc27ed58ab01655cd1459e394c3.pdf","paperhash":"anonymous|nsganet_a_multiobjective_genetic_algorithm_for_neural_architecture_search","_bibtex":"@inproceedings{    \nanonymous2019nsga-net:,    \ntitle={NSGA-Net: A Multi-Objective Genetic Algorithm for Neural Architecture Search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1gIf305Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyfIfnC5Ym","original":"HygMqg65F7","number":1267,"cdate":1538087949928,"ddate":null,"tcdate":1538087949928,"tmdate":1538155955995,"tddate":null,"forum":"SyfIfnC5Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Improving the Generalization of Adversarial Training with Domain Adaptation","abstract":"By injecting adversarial examples into training data, the adversarial training method is promising for improving the robustness of deep learning models. However, most existing adversarial training approaches are based on a specific type of adversarial attack. It may not provide sufficiently representative samples from the adversarial domain, leading to a weak generalization ability on adversarial examples from other attacks. To scale to large datasets, perturbations on inputs to generate adversarial examples are usually crafted using fast single-step attacks. This work is mainly focused on the adversarial training with the single-step yet efficient FGSM adversary. In this scenario, it is difficult to train a model with great generalization due to the lack of representative adversarial samples, aka the samples are unable to accurately reflect the adversarial domain. To address this problem, we propose a novel Adversarial Training with Domain Adaptation (ATDA) method by regarding the adversarial training with FGSM adversary as a domain adaption task with limited number of target domain samples. The main idea is to learn a representation that is semantically meaningful and domain invariant on the clean domain as well as the adversarial domain. Empirical evaluations demonstrate that ATDA can greatly improve the generalization of adversarial training and achieves state-of-the-art results on standard benchmark datasets.","keywords":["adversarial training","domain adaptation","adversarial example","deep learning"],"authorids":["ICLR.cc/2019/Conference/Paper1267/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a novel adversarial training with domain adaptation method that significantly improves the generalization ability on adversarial examples from different attacks.","pdf":"/pdf/2bf9a01d7f9b1461e4222c501707891eaa0bd1f5.pdf","paperhash":"anonymous|improving_the_generalization_of_adversarial_training_with_domain_adaptation","_bibtex":"@inproceedings{    \nanonymous2019improving,    \ntitle={Improving the Generalization of Adversarial Training with Domain Adaptation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyfIfnC5Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1lIzhC9FX","original":"S1gBPMAcFm","number":1268,"cdate":1538087950096,"ddate":null,"tcdate":1538087950096,"tmdate":1538155955787,"tddate":null,"forum":"H1lIzhC9FX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning to remember: Dynamic Generative Memory for Continual Learning","abstract":"Continuously trainable models should be able to learn from a stream of data over an undefined period of time. This becomes even more difficult in a strictly incremental context, where data access to previously seen categories is not possible. To that end, we propose making use of a conditional generative adversarial model where the generator is used as a memory module through neural masking to emulate neural plasticity in the human brain. This memory module is further associated with a dynamic capacity expansion mechanism. Taken together, this method facilitates a resource efficient capacity adaption to accommodate new tasks, while retaining previously attained knowledge. The proposed approach outperforms state-of-the-art algorithms on publicly available datasets, overcoming catastrophic forgetting.","keywords":["Continual Learning","Catastrophic Forgetting","Dynamic Network Expansion"],"authorids":["ICLR.cc/2019/Conference/Paper1268/Authors"],"authors":["Anonymous"],"pdf":"/pdf/3ff418cd6b4e2ef142c2202d9db66522cba73ca1.pdf","paperhash":"anonymous|learning_to_remember_dynamic_generative_memory_for_continual_learning","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to remember: Dynamic Generative Memory for Continual Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1lIzhC9FX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryxLG2RcYX","original":"HJl8UjpqKX","number":1269,"cdate":1538087950272,"ddate":null,"tcdate":1538087950272,"tmdate":1538155955580,"tddate":null,"forum":"ryxLG2RcYX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Abstract Models for Long-Horizon Exploration","abstract":"Despite recent progress in reinforcement learning (RL), state-of-the-art RL algorithms\ncontinue to struggle with high-dimensional, long-horizon, sparse-reward\ntasks. Even with a perfect model, model-based RL can be intractable because the state\nspace is often high-dimensional (e.g. over 10^100 states). We address this by automatically\nconstructing an abstract Markov Decision Process (MDP) with an exponentially\nsmaller number of states (e.g. 10^5), where the actions are skills learned\nby a worker policy. We learn a near-optimal policy on the resulting abstract MDP,\nwhich maps to a near-optimal policy on the original MDP. Our approach provably\nmakes monotonic progress and is guaranteed to learn a near-optimal policy.\nWe empirically evaluate our approach on three of the hardest games from the\nArcade Learning Environment: Montezuma’s Revenge, Pitfall!, and Private Eye,\nand outperform the previous state-of-the-art by over a factor of 2 in\neach game. In Pitfall!, our approach is the first to achieve superhuman performance\nwithout demonstrations","keywords":["Reinforcement Learning","Hierarchical Reinforcement Learning","Model-based Reinforcement Learning","Exploration"],"authorids":["ICLR.cc/2019/Conference/Paper1269/Authors"],"authors":["Anonymous"],"TL;DR":"We automatically construct and explore a small abstract Markov Decision Process, enabling us to achieve state-of-the-art results on Montezuma's Revenge, Pitfall!, and Private Eye by a significant margin.","pdf":"/pdf/d6de0bafc1fae1e054439e0c8a3c733cd477cb2a.pdf","paperhash":"anonymous|learning_abstract_models_for_longhorizon_exploration","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Abstract Models for Long-Horizon Exploration},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxLG2RcYX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1lIMn05F7","original":"rkxbK0a9YX","number":1270,"cdate":1538087950450,"ddate":null,"tcdate":1538087950450,"tmdate":1538155955368,"tddate":null,"forum":"S1lIMn05F7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A Direct Approach to Robust Deep Learning Using Adversarial Networks","abstract":"Deep neural networks have been shown to perform well in many classical machine learning problems, especially in image classification tasks. However, researchers have found that neural networks can be easily fooled, and they are surprisingly sensitive to small perturbations imperceptible to humans.  Carefully crafted input images (adversarial examples) can force a well-trained neural network to provide arbitrary outputs.  Including adversarial examples during training is a popular defense mechanism against adversarial attacks. In this paper we propose a new defensive mechanism under the generative adversarial network~(GAN) framework. We model the adversarial noise using a generative network, trained jointly with a classification discriminative network as a minimax game. We show empirically that our adversarial network approach works well against black box attacks, with performance on par with state-of-art methods such as ensemble adversarial training and adversarial training with projected gradient descent.\n","keywords":["deep learning","adversarial learning","generative adversarial networks"],"authorids":["ICLR.cc/2019/Conference/Paper1270/Authors"],"authors":["Anonymous"],"TL;DR":"Jointly train an adversarial noise generating network with a classification network to provide better robustness to adversarial attacks.","pdf":"/pdf/85e28fff82c7b31e41cea4011ea85d544d14f18f.pdf","paperhash":"anonymous|a_direct_approach_to_robust_deep_learning_using_adversarial_networks","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A Direct Approach to Robust Deep Learning Using Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lIMn05F7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJgvf3RcFQ","original":"HklvwfC5YQ","number":1271,"cdate":1538087950617,"ddate":null,"tcdate":1538087950617,"tmdate":1538155955160,"tddate":null,"forum":"rJgvf3RcFQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"On Inductive Biases in Deep Reinforcement Learning","abstract":"Many deep reinforcement learning algorithms contain inductive biases that sculpt the agent's objective and its interface to the environment. These inductive biases can take many forms, including domain knowledge and pretuned hyper-parameters. In general, there is a trade-off between generality and performance when we use such biases. Stronger biases can lead to faster learning, but weaker biases can potentially lead to more general algorithms that work on a wider class of problems.\nThis trade-off is relevant because these inductive biases are not free; substantial effort may be required to obtain relevant domain knowledge or to tune hyper-parameters effectively. In this paper, we re-examine several domain-specific components that modify the agent's objective and environmental interface.  We investigated whether the performance deteriorates when all these fixed components are replaced with adaptive solutions from the literature.  In our experiments, performance sometimes decreased with the adaptive components, as one might expect when comparing to components crafted for the domain, but sometimes the adaptive components performed better. We then investigated the main benefit of having fewer domain-specific components, by comparing the learning performance of the two systems on a different set of continuous control problems, without additional tuning of either system.  As hypothesized, the system with adaptive components performed better on many of the tasks.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1271/Authors"],"authors":["Anonymous"],"pdf":"/pdf/cb4e289ebf704d6b7d066a967dc219cc0a67a7f9.pdf","paperhash":"anonymous|on_inductive_biases_in_deep_reinforcement_learning","_bibtex":"@inproceedings{    \nanonymous2019on,    \ntitle={On Inductive Biases in Deep Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJgvf3RcFQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ByxPz2C9Ym","original":"Bye15F-cYm","number":1272,"cdate":1538087950789,"ddate":null,"tcdate":1538087950789,"tmdate":1538155954946,"tddate":null,"forum":"ByxPz2C9Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"AIM: Adversarial Inference by Matching Priors and Conditionals","abstract":"Effective inference for a generative adversarial model remains an important and challenging problem. We propose a novel framework, Adversarial Inference by Matching priors and conditionals (AIM), which explicitly matches prior and conditional distributions in both data and code spaces, and puts a direct constraint on the dependency structure of the generative model. We derive an equivalent form of the prior and conditional matching objective that can be optimized efficiently without any parametric assumption on the data. We validate the effectiveness of AIM on the MNIST, CIFAR-10, and CelebA datasets by conducting quantitative and qualitative evaluations. Results show that AIM significantly improves both reconstruction and generation compared with other adversarial inference models.","keywords":["generative adversarial network","generative model","inference"],"authorids":["ICLR.cc/2019/Conference/Paper1272/Authors"],"authors":["Anonymous"],"pdf":"/pdf/f423eb88596d4f1fa941f008cdef630f960c70c9.pdf","paperhash":"anonymous|aim_adversarial_inference_by_matching_priors_and_conditionals","_bibtex":"@inproceedings{    \nanonymous2019aim:,    \ntitle={AIM: Adversarial Inference by Matching Priors and Conditionals},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByxPz2C9Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkevMnRqYQ","original":"ByxW5sTcKX","number":1273,"cdate":1538087950959,"ddate":null,"tcdate":1538087950959,"tmdate":1538155954731,"tddate":null,"forum":"rkevMnRqYQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"The Implicit Information in an Initial State","abstract":"Reinforcement learning (RL) agents optimize only the features specified in a reward function and are indifferent to anything left out inadvertently. This means that we must not only tell a household robot what to do, but also prevent it from knocking over a vase or stepping on a toy train. It is easy to forget these preferences, since we are so used to having them satisfied. Our key insight is that when a robot is deployed in an environment that humans act in, the state of the environment is already optimized for what humans want. We can therefore use this implicit information from the state to fill in the blanks. We develop an algorithm based on Maximum Causal Entropy IRL and use it to evaluate the idea in a suite of proof-of-concept environments designed to show its properties. We find that information from the initial state can be used to infer both side effects that should be avoided as well as preferences for how the environment should be organized.","keywords":["Preference learning","Inverse reinforcement learning","Inverse optimal stochastic control","Maximum entropy reinforcement learning","Apprenticeship learning"],"authorids":["ICLR.cc/2019/Conference/Paper1273/Authors"],"authors":["Anonymous"],"TL;DR":"When a robot is deployed in an environment that humans have been acting in, the state of the environment is already optimized for what humans want, and we can use this to infer human preferences.","pdf":"/pdf/b89300a7ba6b8a18cbe576482aa2d7d533450c0b.pdf","paperhash":"anonymous|the_implicit_information_in_an_initial_state","_bibtex":"@inproceedings{    \nanonymous2019the,    \ntitle={The Implicit Information in an Initial State},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkevMnRqYQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rylDfnCqF7","original":"HyxuP0h9F7","number":1274,"cdate":1538087951133,"ddate":null,"tcdate":1538087951133,"tmdate":1538155954507,"tddate":null,"forum":"rylDfnCqF7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Lagging Inference Networks and Posterior Collapse in Variational Autoencoders","abstract":"The variational autoencoder (VAE) is an efficient method to learn probabilistic latent variable models by the use of an inference network, which predicts a distribution over latent variables given the input. However, VAEs are known to suffer from ``posterior collapse'' when combined with flexible neural autoregressive generators such as LSTMs or PixelCNNs, where the generator tends to ignore the latent variables and the variational posterior collapses to the prior. In this paper, we investigate this problem from the perspective of training dynamics. We find that the approximated posterior distribution lags far behind the model's true posterior in the initial stages of training, which pressures the generator to ignore the latent encoding. To address this issue, we propose an extremely simple training procedure for VAE models that mitigates the lagging issue: aggressively optimizing the inference network with more updates before reverting back to basic VAE training. Despite introducing neither new components nor significant complexity over basic VAEs, our approach is able to circumvent the collapse problem that has plagued a large amount of previous work using VAE-based models.\nEmpirically, our approach outperforms strong autoregressive baselines on text and image benchmarks in terms of density estimation, land achieves results competitive to more complicated previous methods. Our method also trains 5x faster on average than the most comparable state-of-the-art method, the semi-amortized VAE.","keywords":["variational autoencoders","posterior collapse","generative models"],"authorids":["ICLR.cc/2019/Conference/Paper1274/Authors"],"authors":["Anonymous"],"TL;DR":"To address posterior collapse in VAEs, we propose a simple yet effective training algorithm that aggressively optimizes inference network with more updates","pdf":"/pdf/276fd60afc6d12da882024786a293dfb659cbaab.pdf","paperhash":"anonymous|lagging_inference_networks_and_posterior_collapse_in_variational_autoencoders","_bibtex":"@inproceedings{    \nanonymous2019lagging,    \ntitle={Lagging Inference Networks and Posterior Collapse in Variational Autoencoders},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rylDfnCqF7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hyewf3AqYX","original":"ryx6Ob0cFX","number":1275,"cdate":1538087951307,"ddate":null,"tcdate":1538087951307,"tmdate":1538155954296,"tddate":null,"forum":"Hyewf3AqYX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A Frank-Wolfe Framework for Efficient and Effective Adversarial Attacks","abstract":"Depending on how much information an adversary can access to, adversarial attacks can be classified as white-box attack and black-box attack. In both cases, optimization-based attack algorithms can achieve relatively low distortions and high attack success rates. However, they usually suffer from poor time and query complexities, thereby limiting their practical usefulness. In this work, we focus on the problem of developing efficient and effective optimization-based adversarial attack algorithms. In particular, we propose a novel adversarial attack framework for both white-box and black-box settings based on the non-convex Frank-Wolfe algorithm. We show in theory that the proposed attack algorithms are efficient with an O(1/\\sqrt{T}) convergence rate, which, to our knowledge, is the first convergence rate analysis for the zeroth-order non-convex Frank-Wolfe type algorithm. The empirical results on attacking Inception V3 model with the ImageNet dataset also verify the efficiency and effectiveness of the proposed algorithms. They attain a 100% attack success rate in both white-box and  black-box attacks, and are more time and query efficient than the state-of-the-art baseline algorithms.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1275/Authors"],"authors":["Anonymous"],"pdf":"/pdf/8551f7f30e2acf4760fa2de2b1cd2fd737a4b4fd.pdf","paperhash":"anonymous|a_frankwolfe_framework_for_efficient_and_effective_adversarial_attacks","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A Frank-Wolfe Framework for Efficient and Effective Adversarial Attacks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyewf3AqYX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SylPMnR9Ym","original":"Byl9P2wpu7","number":1276,"cdate":1538087951481,"ddate":null,"tcdate":1538087951481,"tmdate":1538155954085,"tddate":null,"forum":"SylPMnR9Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning what you can do before doing anything","abstract":"Intelligent agents are able to learn and understand the action spaces of other agents by simply observing them act. Such representations could help them to quickly learn to predict effects of their own actions on the environment and plan complex interaction sequences. Current deep learning methods can capture the structured representations needed for such predictive capabilities, but only when given abundant, action-labeled data. We propose an unsupervised method to learn representations of an agent’s action space purely from visual observations. Our method uses stochastic future prediction to learn a latent variable that captures (i) the dynamic properties of scenes while being minimally sensitive to static scene content and (ii) the compositional structure of actions, reflecting the fact that changes they induce can be composed to produce a cumulative effect on the environment. We show the applicability of our method to synthetic settings and its potential to capture action spaces in complex, realistic visual settings. Our learned representations perform comparably to existing supervised methods on tasks such as action-conditioned video prediction and visual servoing, while requiring orders of magnitude fewer action-labeled videos. ","keywords":["unsupervised learning","vision","motion","action space","video prediction","variational models"],"authorids":["ICLR.cc/2019/Conference/Paper1276/Authors"],"authors":["Anonymous"],"TL;DR":"We learn a representation of an agent's action space from pure visual observations. We use a recurrent latent variable approach with a novel compositionality loss.","pdf":"/pdf/c4d4f703ae75c64c84c33b8f4a6d5c73d4208190.pdf","paperhash":"anonymous|learning_what_you_can_do_before_doing_anything","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning what you can do before doing anything},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SylPMnR9Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJeOMhA5K7","original":"BkeWVd3qK7","number":1277,"cdate":1538087951648,"ddate":null,"tcdate":1538087951648,"tmdate":1538155953870,"tddate":null,"forum":"HJeOMhA5K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Human-Guided Column Networks: Augmenting Deep Learning with Advice","abstract":"While extremely successful in several applications, especially with low-level representations; sparse, noisy samples and structured domains (with multiple objects and interactions) are some of the open challenges in most deep models. Column Networks, a deep architecture, can succinctly capture such domain structure and interactions, but may still be prone to sub-optimal learning from sparse and noisy samples. Inspired by the success of human-advice guided learning in AI, especially in data-scarce domains, we propose Knowledge-augmented Column Networks that leverage human advice/knowledge for better learning with noisy/sparse samples. Our experiments demonstrate how our approach leads to either superior overall performance or faster convergence.","keywords":["Knowledge-guided learning","Human advice","Column Networks","Knowledge-based relational deep model","Collective classification"],"authorids":["ICLR.cc/2019/Conference/Paper1277/Authors"],"authors":["Anonymous"],"TL;DR":"Guiding relation-aware deep models towards better learning with human knowledge.","pdf":"/pdf/53505ad692482326a1037a294abfd45a8ef112ba.pdf","paperhash":"anonymous|humanguided_column_networks_augmenting_deep_learning_with_advice","_bibtex":"@inproceedings{    \nanonymous2019human-guided,    \ntitle={Human-Guided Column Networks: Augmenting Deep Learning with Advice},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJeOMhA5K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJldzhA5tQ","original":"HkxxGZ39Km","number":1278,"cdate":1538087951817,"ddate":null,"tcdate":1538087951817,"tmdate":1538155953666,"tddate":null,"forum":"HJldzhA5tQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning powerful policies and better generative models by interaction","abstract":"Model-based reinforcement learning approaches have the promise of being sample efficient. Much of the progress in learning dynamics models in RL has been made by learning models via supervised learning. There is enough evidence that humans build a model of the environment, not only by observing the environment but also by interacting with the environment. Interaction with the environment allows humans to carry out  \\textit{experiments}: taking actions that help uncover true casual relationships which in turn can be used for building better dynamics models. Analogously, we would expect such interaction to be helpful for a learning agent while it learns to model the dynamics of the environment. In this paper, we build upon this intuition, by using an auxiliary cost function to ensure consistency between what the agent observes (by actually performing actions in the real world) and what it hallucinates (by imagining to have taken actions in the environment). Our empirical analysis shows that the proposed approach helps to train powerful policies as well as better dynamics models. ","keywords":["model-based reinforcement learning","deep learning","generative agents","policy gradient","imitation learning"],"authorids":["ICLR.cc/2019/Conference/Paper1278/Authors"],"authors":["Anonymous"],"TL;DR":"In this paper, we formulate a way to ensure consistency between the predictions of dynamics model and the real observations from the environment. Thus allowing us to learn powerful policies, as well as better dynamics models.","pdf":"/pdf/ee279634592f8129e2529b57f2244636b38853eb.pdf","paperhash":"anonymous|learning_powerful_policies_and_better_generative_models_by_interaction","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning powerful policies and better generative models by interaction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJldzhA5tQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJg_fnRqF7","original":"H1llo5DFFX","number":1279,"cdate":1538087951984,"ddate":null,"tcdate":1538087951984,"tmdate":1538155953442,"tddate":null,"forum":"BJg_fnRqF7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Deep clustering based on a mixture of autoencoders","abstract":"In this paper we propose a Deep Autoencoder Mixture Clustering (DAMIC) algorithm. It is based on a mixture of deep autoencoders where each cluster is represented by an autoencoder. A clustering network transforms the data into another space and then selects one of the clusters. Next, the autoencoder associated with this cluster is used to reconstruct the data-point. The clustering algorithm jointly learns the nonlinear data representation and the set of autoencoders. The optimal clustering is found by minimizing the reconstruction loss of the mixture of autoencoder network. Unlike other deep clustering algorithms, no regularization term is needed to avoid data collapsing to a single point. Our experimental evaluations on image and text corpora show significant improvement over state-of-the-art methods.","keywords":["deep clustering","mixture of experts","mixture of autoencoders"],"authorids":["ICLR.cc/2019/Conference/Paper1279/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a deep clustering method where instead of a centroid each cluster is represented by an autoencoder","pdf":"/pdf/a71fe2eb4a08b69562465509f78c87f8a844cf53.pdf","paperhash":"anonymous|deep_clustering_based_on_a_mixture_of_autoencoders","_bibtex":"@inproceedings{    \nanonymous2019deep,    \ntitle={Deep clustering based on a mixture of autoencoders},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJg_fnRqF7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Bkeuz20cYm","original":"BklK1fqcY7","number":1280,"cdate":1538087952156,"ddate":null,"tcdate":1538087952156,"tmdate":1538155953237,"tddate":null,"forum":"Bkeuz20cYm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Double Neural Counterfactual Regret Minimization","abstract":"Counterfactual regret minimization (CRF) is a fundamental and effective technique for solving imperfect information games. However, the original CRF algorithm only works for discrete state and action spaces, and the resulting strategy is maintained as a tabular representation. Such tabular representation limits the method from being directly applied to large games and continuing to improve from a poor strategy profile. In this paper, we propose a double neural representation for the Imperfect Information Games, where one neural network represents the cumulative regret, and the other represents the average strategy. Furthermore, we adopt the counterfactual regret minimization algorithm to optimize this double neural representation. To make neural learning efficient, we also developed several novel techniques including a robust sampling method, mini-batch  Monte Carlo counterfactual regret minimization (MCCFR) and Monte Carlo counterfactual regret minimization plus (MCCFR+) which may be of independent interests. Experimentally, we demonstrate that the proposed double neural algorithm converges significantly better than the reinforcement learning counterpart. ","keywords":["Counterfactual Regret Minimization","Imperfect Information game"],"authorids":["ICLR.cc/2019/Conference/Paper1280/Authors"],"authors":["Anonymous"],"TL;DR":"We proposed a double neural CFR which can match the performance of tabular based CFR and opens up the possibility for a purely neural approach to directly solve large imperfect information game.","pdf":"/pdf/47070abd615fb10886a0e0330a9f15a1bf676d05.pdf","paperhash":"anonymous|double_neural_counterfactual_regret_minimization","_bibtex":"@inproceedings{    \nanonymous2019double,    \ntitle={Double Neural Counterfactual Regret Minimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkeuz20cYm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BkedznAqKQ","original":"B1xKkFKcFQ","number":1281,"cdate":1538087952326,"ddate":null,"tcdate":1538087952326,"tmdate":1538155953035,"tddate":null,"forum":"BkedznAqKQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"LanczosNet: Multi-Scale Deep Graph Convolutional Networks","abstract":"We propose Lanczos network (LanczosNet) which uses the Lanczos algorithm to construct low rank approximations of the graph Laplacian for graph convolution.\nRelying on the tridiagonal decomposition of the Lanczos algorithm, we not only efficiently exploit multi-scale information via fast approximated computation of matrix power but also design learnable spectral filters.\nBeing fully differentiable, LanczosNet facilitates both graph kernel learning as well as learning node embeddings. \nWe show the connection between our LanczosNet and graph based manifold learning, especially diffusion maps.\nWe benchmark our model against $8$ recent deep graph networks on citation datasets and QM8 quantum chemistry dataset. \nExperimental results show that our model achieves the state-of-the-art performance in most tasks.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1281/Authors"],"authors":["Anonymous"],"pdf":"/pdf/8eed39aad14cffc65648f0167b66763c33f43241.pdf","paperhash":"anonymous|lanczosnet_multiscale_deep_graph_convolutional_networks","_bibtex":"@inproceedings{    \nanonymous2019lanczosnet:,    \ntitle={LanczosNet: Multi-Scale Deep Graph Convolutional Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkedznAqKQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SkGuG2R5tm","original":"HJgNfW6qtm","number":1282,"cdate":1538087952502,"ddate":null,"tcdate":1538087952502,"tmdate":1538155952827,"tddate":null,"forum":"SkGuG2R5tm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Spreading vectors for similarity search","abstract":"Discretizing floating-point vectors is a fundamental step of modern indexing methods. State-of-the-art techniques learn parameters of the quantizers on training data for optimal performance, thus adapting quantizers to the data. In this work, we propose to reverse this paradigm and adapt the data to the quantizer: we train a neural net whose last layers form a fixed parameter-free quantizer, such as pre-defined points of a sphere. As a proxy objective, we design and train a neural network that favors uniformity in the spherical latent space, while preserving the neighborhood structure after the mapping.  For this purpose, we propose a new regularizer derived from the Kozachenko-Leonenko differential entropy estimator and combine it with a locality-aware triplet loss. \nExperiments show that our end-to-end approach outperforms most learned quantization methods, and is competitive with the state of the art on widely adopted benchmarks. Further more, we show that training without the quantization step results in almost no difference in accuracy, but yields a generic catalyser that can be applied with any subsequent quantization technique.\n","keywords":["dimensionality reduction","similarity search","indexing","differential entropy"],"authorids":["ICLR.cc/2019/Conference/Paper1282/Authors"],"authors":["Anonymous"],"TL;DR":"We learn a neural network that uniformizes the input distribution, which leads to competitive indexing performance in high-dimensional space","pdf":"/pdf/338ff2b1aa988edef5dea485f0806d94ccd2ceed.pdf","paperhash":"anonymous|spreading_vectors_for_similarity_search","_bibtex":"@inproceedings{    \nanonymous2019spreading,    \ntitle={Spreading vectors for similarity search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkGuG2R5tm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SkgKzh0cY7","original":"Hyxm3vaqKQ","number":1283,"cdate":1538087952672,"ddate":null,"tcdate":1538087952672,"tmdate":1538155952619,"tddate":null,"forum":"SkgKzh0cY7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Unsupervised Video-to-Video Translation","abstract":"Unsupervised image-to-image translation is a recently proposed task of translating an image to a different style or domain given only unpaired image examples at training time. In this paper, we formulate a new task of unsupervised video-to-video translation, which poses its own unique challenges. Translating video implies learning not only the appearance of objects and scenes but also realistic motion and transitions between consecutive frames. We investigate the performance of per-frame video-to-video translation using existing image-to-image translation networks, and propose a spatio-temporal 3D translator as an alternative solution to this problem. We evaluate our 3D method on multiple synthetic datasets, such as moving colorized digits, as well as the realistic segmentation-to-video GTA dataset and a new CT-to-MRI volumetric images translation dataset. Our results show that frame-wise translation produces realistic results on a single frame level but underperforms significantly on the scale of the whole video compared to our three-dimensional translation approach, which is better able to learn the complex structure of video and motion and continuity of object appearance. ","keywords":["Generative Adversarial Networks","Computer Vision","Deep Learning"],"authorids":["ICLR.cc/2019/Conference/Paper1283/Authors"],"authors":["Anonymous"],"TL;DR":"Proposed new task, datasets and baselines; 3D Conv CycleGAN preserves object properties across frames; batch structure in frame-level methods matters.","pdf":"/pdf/09123844b56e4f98240b819d1ba3c83b8cd7a6f2.pdf","paperhash":"anonymous|unsupervised_videotovideo_translation","_bibtex":"@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised Video-to-Video Translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkgKzh0cY7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyeKf30cFQ","original":"ryej0CJ5Km","number":1284,"cdate":1538087952836,"ddate":null,"tcdate":1538087952836,"tmdate":1538155952408,"tddate":null,"forum":"SyeKf30cFQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A theoretical framework for deep locally connected ReLU network","abstract":"Understanding theoretical properties of deep and locally connected nonlinear network, such as deep convolutional neural network (DCNN), is still a hard problem despite its empirical success. In this paper, we propose a novel theoretical framework for such networks with ReLU nonlinearity. The framework explicitly formulates data distribution, favors disentangled representations and is compatible with common regularization techniques such as Batch Norm. The framework is built upon teacher-student setting, by expanding the student forward/backward propagation onto the teacher's computational graph. The resulting model does not impose unrealistic assumptions (e.g., Gaussian inputs, independence of activation, etc). Our framework could help facilitate theoretical analysis of many practical issues, e.g. overfitting, generalization, disentangled representations in deep networks. ","keywords":["theoretical analysis","deep network","optimization","disentangled representation"],"authorids":["ICLR.cc/2019/Conference/Paper1284/Authors"],"authors":["Anonymous"],"TL;DR":"This paper presents a theoretical framework that models data distribution explicitly for deep and locally connected ReLU network","pdf":"/pdf/c2704888888ccc31bc82bcca70404e2798af4de3.pdf","paperhash":"anonymous|a_theoretical_framework_for_deep_locally_connected_relu_network","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A theoretical framework for deep locally connected ReLU network},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyeKf30cFQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ByetGn0cYX","original":"BkxPW-T9F7","number":1285,"cdate":1538087953011,"ddate":null,"tcdate":1538087953011,"tmdate":1538155952198,"tddate":null,"forum":"ByetGn0cYX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Probabilistic Planning with Sequential Monte Carlo","abstract":"Planning is a fundamental ability of intelligent agents, which allows them to reason about their future\nbehavior and efficiently learn new tasks. Despite its importance, planning remains an open problem\nin complex environments. Current challenges include model compounding errors in roll-outs and\nexponential search space over trajectories. In this work, we propose a novel formulation of planning,\nwhich views it as a probabilistic inference problem over future optimal trajectories.  This enabled\nus to use sampling methods, and thus, tackle planning in continuous and high-dimensional spaces\nusing a fixed computational budget. We designed a new algorithm, Sequential Monte Carlo Planning\n(SMCP), by leveraging modern methods in Sequential Monte Carlo (SMC), Bayesian smoothing,\nand control as inference. Following, we draw parallels between our algorithm and popular planning\nmethods such as Monte Carlo Tree Search (MCTS) (Kearns et al., 2002) and Random Shooting\nmethods (Rubinstein & Kroese, 2004). Furthermore, we present experimental results competitive to\nstate-of-the-art methods on standard continuous control tasks. To conclude, we provide direction for\nfuture research in hopes of encouraging new lines of work in this domain.","keywords":["control as inference","probabilistic planning","sequential monte carlo","model based reinforcement learning"],"authorids":["ICLR.cc/2019/Conference/Paper1285/Authors"],"authors":["Anonymous"],"TL;DR":"Leveraging control as inference and Sequential Monte Carlo methods, we proposed a probabilistic planning algorithm.","pdf":"/pdf/6579f9cca92eb994d6cbe250af1f45134f086d44.pdf","paperhash":"anonymous|probabilistic_planning_with_sequential_monte_carlo","_bibtex":"@inproceedings{    \nanonymous2019probabilistic,    \ntitle={Probabilistic Planning with Sequential Monte Carlo},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByetGn0cYX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJlYzhR9tm","original":"rklwCKT9FX","number":1286,"cdate":1538087953184,"ddate":null,"tcdate":1538087953184,"tmdate":1538155951989,"tddate":null,"forum":"HJlYzhR9tm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Language Modeling with Graph Temporal Convolutional Networks","abstract":"Recently, there have been some attempts to use non-recurrent neural models for language modeling. \nHowever, a noticeable performance gap still remains. \nWe propose a non-recurrent neural language model, dubbed graph temporal convolutional network (GTCN), that relies on graph neural network blocks and convolution operations. While the standard recurrent neural network language models encode sentences sequentially without modeling higher-level structural information, our model regards sentences as graphs and processes input words within a message propagation framework, aiming to learn better syntactic information by inferring skip-word connections. Specifically, the graph network blocks operate in parallel and learn the underlying graph structures in sentences without any additional annotation pertaining to structure knowledge. Experiments demonstrate that the model without recurrence can achieve comparable perplexity results in language modeling tasks and successfully learn syntactic information.","keywords":["Graph Neural Network","Language Modeling","Convolution"],"authorids":["ICLR.cc/2019/Conference/Paper1286/Authors"],"authors":["Anonymous"],"pdf":"/pdf/dce702241e936d676a30c8986b5621fca6b240ab.pdf","paperhash":"anonymous|language_modeling_with_graph_temporal_convolutional_networks","_bibtex":"@inproceedings{    \nanonymous2019language,    \ntitle={Language Modeling with Graph Temporal Convolutional Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJlYzhR9tm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ByftGnR9KX","original":"Skl3B3octQ","number":1287,"cdate":1538087953361,"ddate":null,"tcdate":1538087953361,"tmdate":1538155951778,"tddate":null,"forum":"ByftGnR9KX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"FlowQA: Grasping Flow in History for Conversational Machine Comprehension","abstract":"Conversational machine comprehension requires the understanding of the conversation history, such as previous question/answer pairs,  the document context, and the current question.  To enable existing machine comprehension models to encode the history comprehensively, we introduce a general mechanism, Flow, which incorporates effectively and efficiently the intermediate representations generated during the process of answering previous questions, through an alternating parallel processing structure. Our final model, FlowQA, shows superior performances on multiple datasets and domains, including two recently proposed conversational challenge datasets (QuAC and CoQA) and a sequential instruction understanding task (all three domains in SCONE), outperforming the state-of-the-art models.","keywords":["Machine Comprehension","Conversational Agent","Natural Language Processing","Deep Learning"],"authorids":["ICLR.cc/2019/Conference/Paper1287/Authors"],"authors":["Anonymous"],"TL;DR":"We propose the Flow mechanism and an end-to-end architecture, FlowQA, that achieves SotA on two conversational QA datasets and a sequential instruction understanding task.","pdf":"/pdf/20b667e841dcb432089b9d1b70a6ec02f37329fa.pdf","paperhash":"anonymous|flowqa_grasping_flow_in_history_for_conversational_machine_comprehension","_bibtex":"@inproceedings{    \nanonymous2019flowqa:,    \ntitle={FlowQA: Grasping Flow in History for Conversational Machine Comprehension},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByftGnR9KX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJx9f305t7","original":"H1g8vyA5Ym","number":1288,"cdate":1538087953529,"ddate":null,"tcdate":1538087953529,"tmdate":1538155951568,"tddate":null,"forum":"BJx9f305t7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"W2GAN: RECOVERING AN OPTIMAL TRANSPORTMAP WITH A GAN","abstract":"Understanding and improving Generative Adversarial Networks (GAN) using notions\nfrom Optimal Transportation (OT) theory has been a successful area of study,\noriginally established by the introduction of the Wasserstein GAN (WGAN). An\nincreasing number of GANs incorporate OT for improving their discriminators,\nbut that is so far the sole way for the two domains to cross-fertilize. We consolidate\nthe bridge between GANs and OT with one model: W2GAN, where the\ndiscriminator approximates the second Wasserstein distance. This model exhibits a\ntwofold connection: the discriminator implicitly computes an optimal map and the\ngenerator follows an optimal transport map during training. Perhaps surprisingly,\nwe also provide empirical evidence that other GANs also approximately following\nthe Optimal Transport.","keywords":["Optimal Transportation","Deep Learning","Generative Adversarial Networks","Wasserstein Distance"],"authorids":["ICLR.cc/2019/Conference/Paper1288/Authors"],"authors":["Anonymous"],"TL;DR":"\"A GAN-style model to recover a solution of the Monge Problem\"","pdf":"/pdf/29f1de658f3a4e193a281de93616d1ca6c469fff.pdf","paperhash":"anonymous|w2gan_recovering_an_optimal_transportmap_with_a_gan","_bibtex":"@inproceedings{    \nanonymous2019w2gan:,    \ntitle={W2GAN: RECOVERING AN OPTIMAL TRANSPORTMAP WITH A GAN},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJx9f305t7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJxqMhC5YQ","original":"ryeTLW05FX","number":1289,"cdate":1538087953696,"ddate":null,"tcdate":1538087953696,"tmdate":1538155951359,"tddate":null,"forum":"HJxqMhC5YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"End-to-End Multi-Lingual Multi-Speaker Speech Recognition","abstract":"The expressive power of end-to-end automatic speech recognition (ASR) systems enables direct estimation of the character or word label sequence from  a sequence of acoustic features. Direct optimization of the whole system is advantageous because it not only eliminates the internal linkage necessary for hybrid systems,  but also extends the scope of potential application use cases by training the model for multiple objectives. Several multi-lingual ASR systems were recently proposed based on a monolithic neural network architecture without language-dependent modules, showing that modeling of multiple languages is well within the capabilities of an end-to-end framework. There has also been growing interest in multi-speaker speech recognition, which enables generation of multiple label sequences from single-channel mixed speech. In particular, a multi-speaker end-to-end ASR system that can directly model one-to-many mappings without additional auxiliary clues was recently proposed. In this paper, we propose an all-in-one end-to-end multi-lingual multi-speaker ASR system that integrates the capabilities of these two systems.  The proposed model is evaluated using mixtures of two speakers generated by using 10 languages, including mixed-language utterances. ","keywords":["end-to-end ASR","multi-lingual ASR","multi-speaker ASR","code-switching","encoder-decoder","connectionist temporal classification"],"authorids":["ICLR.cc/2019/Conference/Paper1289/Authors"],"authors":["Anonymous"],"pdf":"/pdf/5a2417c87058d260939b1619f5b703feeaf2e6b3.pdf","paperhash":"anonymous|endtoend_multilingual_multispeaker_speech_recognition","_bibtex":"@inproceedings{    \nanonymous2019end-to-end,    \ntitle={End-to-End Multi-Lingual Multi-Speaker Speech Recognition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxqMhC5YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkg5fh0ctQ","original":"Bye0wyhqKX","number":1290,"cdate":1538087953870,"ddate":null,"tcdate":1538087953870,"tmdate":1538155951152,"tddate":null,"forum":"rkg5fh0ctQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Transferring SLU Models in Novel Domains","abstract":"Spoken language understanding (SLU) is a critical component in building dialogue systems. When building models for novel natural language domains, a major challenge is the lack of data in in the new domains, no matter whether the data is annotated or not. Recognizing and annotating \"intent\" and \"slot\" of natural languages is a time-consuming process. Therefore, spoken language understanding in low resource domains remains a crucial problem to address. In this paper, we address this problem by proposing a transfer-learning method, whereby an SLU model is transferred to a novel but data-poor domain via a deep neural network framework. We  also introduce meta-learning in our work to bridge the semantic relations between seen and unseen data, allowing new intents to be recognized and new slots to be filled with much lower new training effort. We show the performance improvement via analytical and experimental results for spoken language understanding in low resource domains. We show that our method can also handle novel intent recognition and slot-filling tasks. Our methodology provides a feasible solution for alleviating data shortages in spoken language understanding.","keywords":["transfer learning","semantic representation","spoken language understanding"],"authorids":["ICLR.cc/2019/Conference/Paper1290/Authors"],"authors":["Anonymous"],"TL;DR":"v1","pdf":"/pdf/62ed174f38d18302d8df65ec8c2694602dccda4f.pdf","paperhash":"anonymous|transferring_slu_models_in_novel_domains","_bibtex":"@inproceedings{    \nanonymous2019transferring,    \ntitle={Transferring SLU Models in Novel Domains},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkg5fh0ctQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1lcM3AcKm","original":"BkxHz6ncKm","number":1291,"cdate":1538087954045,"ddate":null,"tcdate":1538087954045,"tmdate":1538155950942,"tddate":null,"forum":"r1lcM3AcKm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"RNNs with Private and Shared Representations for Semi-Supervised Sequence Learning","abstract":"Training recurrent neural networks (RNNs) on long sequences using backpropagation through time (BPTT) remains a fundamental challenge. \nIt has been shown that adding a local unsupervised loss term into the optimization objective makes the training of RNNs on long sequences more effective. \nWhile the importance of an unsupervised task can in principle be controlled by a coefficient in the objective function, the gradients with respect to the unsupervised loss term still influence all the hidden state dimensions, which might cause important information about the supervised task to be degraded or erased. \nCompared to existing semi-supervised sequence learning methods, this paper focuses upon a traditionally overlooked mechanism -- an architecture with explicitly designed private and shared hidden units designed to mitigate the detrimental influence of the auxiliary unsupervised loss over the main supervised task.\nWe achieve this by dividing RNN hidden space into a private space for the supervised task and a shared space for both the supervised and unsupervised tasks. We present extensive experiments with the proposed framework on several long sequence modeling benchmark datasets. Results indicate that the proposed framework can yield performance gains in RNN models where long term dependencies are notoriously challenging to deal with. ","keywords":["recurrent neural network","semi-supervised learning"],"authorids":["ICLR.cc/2019/Conference/Paper1291/Authors"],"authors":["Anonymous"],"TL;DR":"This paper focuses upon a traditionally overlooked mechanism -- an architecture with explicitly designed private and shared hidden units designed to mitigate the detrimental influence of the auxiliary unsupervised loss over the main supervised task.","pdf":"/pdf/b845dfbee6c7106841ddce3748ea671dc2ce68a3.pdf","paperhash":"anonymous|rnns_with_private_and_shared_representations_for_semisupervised_sequence_learning","_bibtex":"@inproceedings{    \nanonymous2019rnns,    \ntitle={RNNs with Private and Shared Representations for Semi-Supervised Sequence Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1lcM3AcKm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1g5Gh05KQ","original":"BJeuxc6cKX","number":1292,"cdate":1538087954218,"ddate":null,"tcdate":1538087954218,"tmdate":1538155950730,"tddate":null,"forum":"r1g5Gh05KQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Advanced Neuroevolution: A gradient-free algorithm to train Deep Neural Networks","abstract":"In this paper we present a novel optimization algorithm called Advanced Neuroevolution. The aim for this algorithm is to train deep neural networks, and eventually act as an alternative to Stochastic Gradient Descent (SGD) and its variants as needed.We evaluated our algorithm on the MNIST dataset, as well as on several global optimization problems such as the Ackley function. We find the algorithm performing relatively well for both cases, overtaking other global optimization algorithms such as Particle Swarm Optimization (PSO) and Evolution Strategies (ES).\n","keywords":["Evolutionary Algorithm","Optimization","MNIST"],"authorids":["ICLR.cc/2019/Conference/Paper1292/Authors"],"authors":["Anonymous"],"TL;DR":"A new algorithm to train deep neural networks. Tested on optimization functions and MNIST.","pdf":"/pdf/2ae00ab0d742f5c97e9625ad257b7fcac027ad0b.pdf","paperhash":"anonymous|advanced_neuroevolution_a_gradientfree_algorithm_to_train_deep_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019advanced,    \ntitle={Advanced Neuroevolution: A gradient-free algorithm to train Deep Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1g5Gh05KQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1lqMn05Ym","original":"BygZzp35YX","number":1293,"cdate":1538087954394,"ddate":null,"tcdate":1538087954394,"tmdate":1538155950512,"tddate":null,"forum":"S1lqMn05Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Information asymmetry in KL-regularized RL","abstract":"Many real world tasks exhibit rich structure that is repeated across different parts of the state space or in time. In this work we study the possibility of leveraging such repeated structure to speed up and regularize learning. We start from the KL regularized expected reward objective which introduces an additional component, a default policy. Instead of relying on a fixed default policy, we learn it from data. But crucially, we restrict the amount of information the default policy receives, forcing it to learn reusable behaviors that help the policy learn faster. We formalize this strategy and discuss connections to information bottleneck approaches and to the variational EM algorithm. We present empirical results in both discrete and continuous action domains and demonstrate that, for certain tasks, learning a default policy alongside the policy can significantly speed up and improve learning.\nPlease watch the video demonstrating learned experts and default policies on several continuous control tasks ( https://youtu.be/U2qA3llzus8 ).","keywords":["Deep Reinforcement Learning","Continuous Control","RL as Inference"],"authorids":["ICLR.cc/2019/Conference/Paper1293/Authors"],"authors":["Anonymous"],"TL;DR":"Limiting state information for the default policy can improvement performance, in a KL-regularized RL framework where both agent and default policy are optimized together","pdf":"/pdf/85df266a4edb147aa87e619ef37844404d225536.pdf","paperhash":"anonymous|information_asymmetry_in_klregularized_rl","_bibtex":"@inproceedings{    \nanonymous2019information,    \ntitle={Information asymmetry in KL-regularized RL},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lqMn05Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJlif3C5FQ","original":"Syg1k6J5KX","number":1294,"cdate":1538087954564,"ddate":null,"tcdate":1538087954564,"tmdate":1538155950305,"tddate":null,"forum":"BJlif3C5FQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning to Attend On Essential Terms: An Enhanced Retriever-Reader Model for Open-domain Question Answering","abstract":"Open-domain question answering remains a challenging task as it requires models that are capable of understanding questions and answers, collecting useful information, and reasoning over evidence. Previous work typically formulates this task as a reading comprehension or entailment problem given evidence retrieved from search engines. However, existing techniques struggle to retrieve indirectly related evidence when no directly related evidence is provided, especially for complex questions where it is hard to parse precisely what the question asks. In this paper we propose a retriever-reader model that learns to attend on essential terms during the question answering process. We build (1) an essential term selector which first identifies the most important words in a question, then reformulates the query and searches for related evidence; and (2) an enhanced reader that distinguishes between essential terms and distracting words to predict the answer. We evaluate our model on multiple open-domain QA datasets where it outperforms the existing state-of-the-art, notably leading to an improvement of 8.1% on the AI2 Reasoning Challenge (ARC) dataset.","keywords":["Open-domain question answering"],"authorids":["ICLR.cc/2019/Conference/Paper1294/Authors"],"authors":["Anonymous"],"pdf":"/pdf/dee21fa5763055629b0e8bfa7b9123e9eeac0a37.pdf","paperhash":"anonymous|learning_to_attend_on_essential_terms_an_enhanced_retrieverreader_model_for_opendomain_question_answering","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Attend On Essential Terms: An Enhanced Retriever-Reader Model for Open-domain Question Answering},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJlif3C5FQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BkgiM20cYX","original":"r1lCFGCqKX","number":1295,"cdate":1538087954725,"ddate":null,"tcdate":1538087954725,"tmdate":1538155950094,"tddate":null,"forum":"BkgiM20cYX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A Self-Supervised Method for Mapping Human Instructions to Robot Policies","abstract":"In this paper, we propose a modular approach which separates the instruction-to-action mapping procedure into two separate stages. The two stages are bridged via an intermediate representation called a goal, which stands for the result after a robot performs a specific task. \nThe first stage maps an input instruction to a goal, while the second stage maps the goal to an appropriate policy selected from a set of robot policies.  The policy is selected with an aim to guide the robot to reach the goal as close as possible.  We implement the above two stages as a framework consisting of two distinct modules: an instruction-goal mapping module and a goal-policy mapping module.  Given a human instruction in the evaluation phase, the instruction-goal mapping module first translates the instruction to a robot-interpretable goal.  Once a goal is derived by the instruction-goal mapping module, the goal-policy mapping module then follows up to search through the goal-policy pairs to look for policy to be mapped by the instruction.  Our experimental results show that the proposed method is able to learn an effective instruction-to-action mapping procedure in an environment with a given instruction set more efficiently than the baselines.   In addition to the impressive data-efficiency, the results also show that our method can be adapted to a new instruction set and a new robot action space much faster than the baselines.  The evidence suggests that our modular approach does lead to better adaptability and efficiency.  ","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1295/Authors"],"authors":["Anonymous"],"pdf":"/pdf/7c55071f6be1ffb6af48db8d2bfe7b6a77ef5595.pdf","paperhash":"anonymous|a_selfsupervised_method_for_mapping_human_instructions_to_robot_policies","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A Self-Supervised Method for Mapping Human Instructions to Robot Policies},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkgiM20cYX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJliMh09F7","original":"B1xcGa1qY7","number":1296,"cdate":1538087954886,"ddate":null,"tcdate":1538087954886,"tmdate":1538155949886,"tddate":null,"forum":"rJliMh09F7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Diversity-Sensitive Conditional Generative Adversarial Networks","abstract":"We propose a simple yet highly effective method that addresses the mode-collapse problem in the Conditional Generative  Adversarial  Network (cGAN). Although conditional distributions are multi-modal (i.e., having many modes) in practice, most cGAN approaches tend to learn an overly simplified distribution where an input is always mapped to a single output regardless of variations in latent code. To address such issue, we propose to explicitly regularize the generator to produce diverse outputs depending on latent codes. The proposed regularization is simple, general, and can be easily integrated into most conditional GAN objectives. Additionally, explicit regularization on generator allows our method to control a balance between visual quality and diversity. We demonstrate the effectiveness of our method on three conditional generation tasks: image-to-image translation, image inpainting, and future video prediction. We show that simple addition of our regularization to existing models leads to surprisingly diverse generations, substantially outperforming the previous approaches for multi-modal conditional generation specifically designed in each individual task.","keywords":["Conditional Generative Adversarial Network","mode-collapse","multi-modal generation"],"authorids":["ICLR.cc/2019/Conference/Paper1296/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a simple and general approach that avoids a mode collapse problem in various conditional GANs.","pdf":"/pdf/77db08ff55c7097e49db8f2a66831980911aa357.pdf","paperhash":"anonymous|diversitysensitive_conditional_generative_adversarial_networks","_bibtex":"@inproceedings{    \nanonymous2019diversity-sensitive,    \ntitle={Diversity-Sensitive Conditional Generative Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJliMh09F7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1gsz30cKX","original":"HJxQcfC9tX","number":1297,"cdate":1538087955054,"ddate":null,"tcdate":1538087955054,"tmdate":1538155949677,"tddate":null,"forum":"H1gsz30cKX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"The Unreasonable Effectiveness of (Zero) Initialization in Deep Residual Learning","abstract":"Normalization layers are a staple in state-of-the-art deep neural network architectures. They are widely believed to stabilize training, enable higher learning rate, accelerate convergence and improve generalization, though the reason for their effectiveness is still an active research topic. In this work, we challenge the commonly-held beliefs by showing that none of the perceived benefits is unique to normalization. Specifically, we propose ZeroInit, an initialization motivated by solving the exploding and vanishing gradient problem at the beginning of training by initializing as a zero function. We find training residual networks with ZeroInit to be as stable as training with normalization - even for networks with 10,000 layers. Furthermore, with proper regularization, ZeroInit without normalization matches or exceeds the performance of state-of-the-art residual networks in image classification and machine translation.","keywords":["deep learning","residual networks","initialization"],"authorids":["ICLR.cc/2019/Conference/Paper1297/Authors"],"authors":["Anonymous"],"TL;DR":"All you need to train deep residual networks is a good initialization; normalization layers are not necessary.","pdf":"/pdf/faaa7e9038f851aa079427a5f3c85a002b2aa0b8.pdf","paperhash":"anonymous|the_unreasonable_effectiveness_of_zero_initialization_in_deep_residual_learning","_bibtex":"@inproceedings{    \nanonymous2019the,    \ntitle={The Unreasonable Effectiveness of (Zero) Initialization in Deep Residual Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1gsz30cKX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BkesGnCcFX","original":"HkxAheGEYX","number":1298,"cdate":1538087955226,"ddate":null,"tcdate":1538087955226,"tmdate":1538155949469,"tddate":null,"forum":"BkesGnCcFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Goal-Conditioned Value Functions with one-step Path rewards rather than Goal-Rewards","abstract":"Multi-goal reinforcement learning (MGRL) addresses tasks where the desired goal state can change for every trial. State-of-the-art algorithms model these problems such that the reward formulation depends on the goals, to associate them with high reward. This dependence introduces additional goal reward resampling steps in algorithms like Hindsight Experience Replay (HER) that reuse trials in which the agent fails to reach the goal by recomputing rewards as if reached states were psuedo-desired goals. We propose a reformulation of goal-conditioned value functions for MGRL that yields a similar algorithm, while removing the dependence of reward functions on the goal. Our formulation thus obviates the requirement of reward-recomputation that is needed by HER and its extensions. We also extend a closely related algorithm, Floyd-Warshall Reinforcement Learning, from tabular domains to deep neural networks for use as a baseline. Our results are competetive with HER while substantially improving sampling efficiency in terms of reward computation. \n","keywords":["Floyd-Warshall","Reinforcement learning","goal conditioned value functions","multi-goal"],"authorids":["ICLR.cc/2019/Conference/Paper1298/Authors"],"authors":["Anonymous"],"TL;DR":"Do Goal-Conditioned Value Functions need Goal-Rewards to Learn?","pdf":"/pdf/a5d20758e48df1a2e3cc19a35fbbb2366d9cc085.pdf","paperhash":"anonymous|learning_goalconditioned_value_functions_with_onestep_path_rewards_rather_than_goalrewards","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Goal-Conditioned Value Functions with one-step Path rewards rather than Goal-Rewards},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkesGnCcFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HygsfnR9Ym","original":"rJxDGe59K7","number":1299,"cdate":1538087955390,"ddate":null,"tcdate":1538087955390,"tmdate":1538155949255,"tddate":null,"forum":"HygsfnR9Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Recall Traces: Backtracking Models for Efficient Reinforcement Learning","abstract":"In many environments only a tiny subset of all states yield high reward.  In these cases, few of the interactions with the environment provide a relevant learning signal. Hence, we may want to preferentially train on those high-reward states and the probable trajectories leading to them. \nTo this end, we advocate for the use of a \\textit{backtracking model} that predicts the preceding states that terminate at a given high-reward state.  We can train a model which, starting from a high value state (or one that is estimated to have high value), predicts and samples which (state, action)-tuples may have led to that high value state. These traces of (state, action) pairs, which we refer to as Recall Traces, sampled from this backtracking model starting from a high value state, are informative as they terminate in good states, and hence we can use these traces to improve a policy. We provide a variational interpretation for this idea and a practical algorithm in which the backtracking model samples from an approximate posterior distribution over trajectories which lead to large rewards. Our method improves the sample efficiency of both on- and off-policy RL algorithms across several environments and tasks.  ","keywords":["Model free RL","Variational Inference"],"authorids":["ICLR.cc/2019/Conference/Paper1299/Authors"],"authors":["Anonymous"],"TL;DR":"A backward model of previous (state, action) given the next state, i.e. P(s_t, a_t | s_{t+1}), can be used to simulate additional trajectories terminating at states of interest! Improves RL learning efficiency.","pdf":"/pdf/f91f9160721e63013ee94602aa6393338bede99d.pdf","paperhash":"anonymous|recall_traces_backtracking_models_for_efficient_reinforcement_learning","_bibtex":"@inproceedings{    \nanonymous2019recall,    \ntitle={Recall Traces: Backtracking Models for Efficient Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HygsfnR9Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyehMhC9Y7","original":"S1ewNGRcYQ","number":1300,"cdate":1538087955556,"ddate":null,"tcdate":1538087955556,"tmdate":1538155949047,"tddate":null,"forum":"SyehMhC9Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Imitative Models: Perception-Driven Forecasting for Flexible Planning and Control","abstract":"Imitation learning provides an appealing framework for autonomous control: in many tasks, demonstrations can be readily obtained from human experts, and using demonstration data removes the need for costly and potentially dangerous on-policy trials in the real world. On the other hand, model-based reinforcement learning offers considerably more flexibility: a model learned from data can be reused at test-time to achieve a wide variety of goals. In this paper, we aim to combine these benefits to learn imitative models: predictive models that can be used to plan behaviors at test-time that achieve user specified goals, while remaining close to the distribution of behaviors seen in the demonstration data. We find that this method substantially improves on the performance of both direct imitation and model-based RL in a simulated driving task, and can be learned efficiently and safely using only demonstration data without on-policy data collection.","keywords":["imitation learning","forecasting","computer vision"],"authorids":["ICLR.cc/2019/Conference/Paper1300/Authors"],"authors":["Anonymous"],"TL;DR":"Hybrid Vision-Driven Imitation Learning and Model-Based Reinforcement Learning for Planning, Forecasting, and Control","pdf":"/pdf/e7f06a9d6c29d2a4170ecc522e99891059f5388b.pdf","paperhash":"anonymous|imitative_models_perceptiondriven_forecasting_for_flexible_planning_and_control","_bibtex":"@inproceedings{    \nanonymous2019imitative,    \ntitle={Imitative Models: Perception-Driven Forecasting for Flexible Planning and Control},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyehMhC9Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HklnzhR9YQ","original":"r1lX-a5cYX","number":1301,"cdate":1538087955715,"ddate":null,"tcdate":1538087955715,"tmdate":1538155948836,"tddate":null,"forum":"HklnzhR9YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks","abstract":"We develop new approximation and statistical learning theories of convolutional neural networks (CNNs) via the ResNet-type structure where the channel size, width, and filter size are fixed. It is shown that a ResNet-type CNN is a universal approximator and its expression ability is no worse than fully connected neural networks (FNNs) with a \\textit{block-sparse} structure even if the size of each layer in the CNN is fixed. Our result is general in the sense that we can automatically translate any approximation rate achieved by block-sparse FNNs into that by CNNs. Thanks to the general theory, it is shown that learning on CNNs satisfies optimality in approximation and estimation of several important function classes.\n\nAs applications, we consider two types of function classes to be estimated: the Barron class and the H\\\"older class. We prove the regularized empirical risk minimization (ERM) estimator can achieve the same rate as FNNs even the channel size, filter size, and width of CNNs are constant with respect to the sample size. This is minimax optimal (up to logarithmic factors) for the H\\\"older class. Our proof is based on sophisticated evaluations of the covering number of CNNs and the non-trivial parameter rescaling technique to control the Lipschitz constant of CNNs to be constructed.","keywords":["CNN","ResNet","learning theory","approximation theory","non-parametric estimation","block-sparse"],"authorids":["ICLR.cc/2019/Conference/Paper1301/Authors"],"authors":["Anonymous"],"TL;DR":"It is shown that ResNet-type CNNs are a universal approximator and its expression ability is not worse than fully connected neural networks (FNNs) with a \\textit{block-sparse} structure even if the size of each layer in the CNN is fixed.","pdf":"/pdf/5d1049a39e663fc5bab274ddf45840b2b757b2c9.pdf","paperhash":"anonymous|approximation_and_nonparametric_estimation_of_resnettype_convolutional_neural_networks_via_blocksparse_fullyconnected_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019approximation,    \ntitle={Approximation and non-parametric estimation of ResNet-type convolutional neural networks via block-sparse fully-connected neural networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HklnzhR9YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Skl3M20qYQ","original":"rye_cGAcY7","number":1302,"cdate":1538087955935,"ddate":null,"tcdate":1538087955935,"tmdate":1538155948622,"tddate":null,"forum":"Skl3M20qYQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Non-Synergistic Variational Autoencoders","abstract":"Learning disentangling representations of the independent factors of variations that explain the data in an unsupervised setting is still a major challenge. In the following paper we address the task of disentanglement and introduce a new state-of-the-art approach called Non-synergistic variational Autoencoder (Non-Syn VAE). Our model draws inspiration from population coding, where the notion of synergy arises when we describe the encoded information by neurons in the form of responses from the stimuli. If those responses convey more information together than separate as independent sources of encoding information, they are acting synergetically. By penalizing the synergistic mutual information within the latents we encourage information independence and by doing that disentangle the latent factors. Notably, our approach could be added to the VAE framework easily, where the new ELBO function is still a lower bound on the log likelihood. In addition, we qualitatively compare our model with Factor VAE and show that this one implicitly minimises the synergy of the latents.","keywords":["vae","unsupervised learning"],"authorids":["ICLR.cc/2019/Conference/Paper1302/Authors"],"authors":["Anonymous"],"TL;DR":"Minimising the synergistic mutual information within the latents and the data for the task of disentanglement using the VAE framework.","pdf":"/pdf/7833c73abe14c35964bbb956520e8c6c895bcb80.pdf","paperhash":"anonymous|nonsynergistic_variational_autoencoders","_bibtex":"@inproceedings{    \nanonymous2019non-synergistic,    \ntitle={Non-Synergistic Variational Autoencoders},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Skl3M20qYQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rygnfn0qF7","original":"SygEdbAqY7","number":1303,"cdate":1538087956100,"ddate":null,"tcdate":1538087956100,"tmdate":1538155948410,"tddate":null,"forum":"rygnfn0qF7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Language Model Pre-training for Hierarchical Document Representations","abstract":"Hierarchical neural architectures can efficiently capture long-distance dependencies and have been used for many document-level tasks such as summarization, document segmentation, and fine-grained sentiment analysis. However, effective usage of such a large context can difficult to learn, especially in the case where there is limited labeled data available.\nBuilding on the recent success of language model pretraining methods for learning flat representations of text, we propose algorithms for pre-training hierarchical document representations from unlabeled data. Unlike prior work, which has focused on pre-training contextual token representations or context-independent sentence/paragraph representations, our hierarchical document representations include fixed-length sentence/paragraph representations which integrate contextual information from the entire documents. Experiments on document segmentation, document-level question answering, and extractive document summarization demonstrate the effectiveness of the proposed pre-training algorithms.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1303/Authors"],"authors":["Anonymous"],"pdf":"/pdf/faa5383f7b5d890e51ce4ee6fe7f34b51ed18887.pdf","paperhash":"anonymous|language_model_pretraining_for_hierarchical_document_representations","_bibtex":"@inproceedings{    \nanonymous2019language,    \ntitle={Language Model Pre-training for Hierarchical Document Representations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rygnfn0qF7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1lnzn0ctQ","original":"B1xa-XacFQ","number":1304,"cdate":1538087956274,"ddate":null,"tcdate":1538087956274,"tmdate":1538155948200,"tddate":null,"forum":"B1lnzn0ctQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"ALISTA: Analytic Weights Are As Good As Learned Weights in LISTA","abstract":"Deep neural networks based on unfolding an iterative algorithm, for example, LISTA (learned iterative shrinkage thresholding algorithm), have been an empirical success for sparse signal recovery. The weights of these neural networks are currently determined by data-driven “black-box” training. In this work, we propose Analytic LISTA (ALISTA), where the weight matrix in LISTA is computed as the solution to a data-free optimization problem, leaving only the stepsize and threshold parameters to data-driven learning. This signiﬁcantly simpliﬁes the training. Speciﬁcally, the data-free optimization problem is based on coherence minimization. We show our ALISTA retains the optimal linear convergence proved in (Chen et al., 2018) and has a performance comparable to LISTA. Furthermore, we extend ALISTA to convolutional linear operators, again determined in a data-free manner. We also propose a feed-forward framework that combines the data-free optimization and ALISTA networks from end to end, one that can be jointly trained to gain robustness to small perturbations in the encoding model.","keywords":["sparse recovery","neural networks"],"authorids":["ICLR.cc/2019/Conference/Paper1304/Authors"],"authors":["Anonymous"],"pdf":"/pdf/aeeda1abcbe10553a9dfe965bcb3f7fa6891436d.pdf","paperhash":"anonymous|alista_analytic_weights_are_as_good_as_learned_weights_in_lista","_bibtex":"@inproceedings{    \nanonymous2019alista:,    \ntitle={ALISTA: Analytic Weights Are As Good As Learned Weights in LISTA},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1lnzn0ctQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJMnG2C9YX","original":"Syes4fOqF7","number":1305,"cdate":1538087956443,"ddate":null,"tcdate":1538087956443,"tmdate":1538155947993,"tddate":null,"forum":"SJMnG2C9YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Complementary-label learning for arbitrary losses and models","abstract":"In contrast to the standard classification paradigm where the true (or possibly noisy) class is given to each training pattern, complementary-label learning only uses training patterns each equipped with a complementary label. This only specifies one of the classes that the pattern does not belong to. The seminal paper on complementary-label learning proposed an unbiased estimator of the classification risk that can be computed only from complementarily labeled data. How- ever, it required a restrictive condition on the loss functions, making it impossible to use popular losses such as the softmax cross-entropy loss. Recently, another formulation with the softmax cross-entropy loss was proposed with consistency guarantee. However, this formulation does not explicitly involve a risk estimator. Thus model/hyper-parameter selection is not possible by cross-validation— we may need additional ordinarily labeled data for validation purposes, which is not available in the current setup. In this paper, we give a novel general framework of complementary-label learning, and derive an unbiased risk estimator for arbitrary losses and models. We further improve the risk estimator by non-negative correction and demonstrate its superiority through experiments.","keywords":["complementary labels","weak supervision"],"authorids":["ICLR.cc/2019/Conference/Paper1305/Authors"],"authors":["Anonymous"],"TL;DR":"From now on, you can train ResNet and DenseNet, even if no class label given for training is correct!","pdf":"/pdf/e98a6e24cbb3e2d9545a12aa83f4115c1bc1f800.pdf","paperhash":"anonymous|complementarylabel_learning_for_arbitrary_losses_and_models","_bibtex":"@inproceedings{    \nanonymous2019complementary-label,    \ntitle={Complementary-label learning for arbitrary losses and models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJMnG2C9YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Byxpfh0cFm","original":"r1gFusacKQ","number":1306,"cdate":1538087956613,"ddate":null,"tcdate":1538087956613,"tmdate":1538155947783,"tddate":null,"forum":"Byxpfh0cFm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Efficient Augmentation via Data Subsampling","abstract":"Data augmentation is commonly used to encode invariances in learning methods. However, this process is often performed in an inefficient manner, as artificial examples are created by applying a number of transformations to all points in the training set. The resulting explosion of the dataset size can be an issue in terms of storage and training costs, as well as in selecting and tuning the optimal set of transformations to apply. In this work, we demonstrate that it is possible to significantly reduce the number of data points included in data augmentation while realizing the same accuracy and invariance benefits of augmenting the entire dataset. We propose a novel set of subsampling policies, based on model influence and loss, that can achieve a 90% reduction in augmentation set size while maintaining the accuracy gains of standard data augmentation.","keywords":["data augmentation","invariance","subsampling","influence"],"authorids":["ICLR.cc/2019/Conference/Paper1306/Authors"],"authors":["Anonymous"],"TL;DR":"Selectively augmenting difficult to classify points results in efficient training.","pdf":"/pdf/ac8b94c652d10b2e0b242084d51b5f67b594057d.pdf","paperhash":"anonymous|efficient_augmentation_via_data_subsampling","_bibtex":"@inproceedings{    \nanonymous2019efficient,    \ntitle={Efficient Augmentation via Data Subsampling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byxpfh0cFm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJl6M2C5Y7","original":"BJeEYCa5KQ","number":1307,"cdate":1538087956774,"ddate":null,"tcdate":1538087956774,"tmdate":1538155947569,"tddate":null,"forum":"rJl6M2C5Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Online Hyperparameter Adaptation via Amortized Proximal Optimization","abstract":"Effective performance of neural networks depends criticially on effective tuning of optimization hyperparameters, especially learning rates (and schedules thereof). We present Amortized Proximal Optimization, which takes the perspective that each optimization step should approximately minimize a proximal objective (similar to the ones used to motivate natural gradient and trust region policy optimization). Optimization hyperparameters are adapted to best minimize the proximal objective after one weight update. We show that an idealized version of APO (where an oracle minimizes the proximal objective exactly) achieves second-order convergence rates for neural networks. APO incurs minimal computational overhead. We experiment with using APO to adapt a variety of optimization hyperparameters online during training, including (possibly layer-specific) learning rates, damping coefficients, and gradient variance exponents. For a variety of network architectures and optimization algorithms (including SGD, RMSprop, and K-FAC), we show that with minimal tuning, APO performs competitively with carefully tuned optimizers.","keywords":["hyperparameters","optimization","learning rate adaptation"],"authorids":["ICLR.cc/2019/Conference/Paper1307/Authors"],"authors":["Anonymous"],"TL;DR":"We introduce amortized proximal optimization (APO), a method to adapt a variety of optimization hyperparameters online during training, including learning rates, damping coefficients, and gradient variance exponents.","pdf":"/pdf/54389c41f62c3d2de7733b9c7097351bca85ea9c.pdf","paperhash":"anonymous|online_hyperparameter_adaptation_via_amortized_proximal_optimization","_bibtex":"@inproceedings{    \nanonymous2019online,    \ntitle={Online Hyperparameter Adaptation via Amortized Proximal Optimization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJl6M2C5Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJG6G2RqtX","original":"SJeBFnFcK7","number":1308,"cdate":1538087956938,"ddate":null,"tcdate":1538087956938,"tmdate":1538155947353,"tddate":null,"forum":"SJG6G2RqtX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Value Propagation Networks","abstract":"We present Value Propagation (VProp), a set of parameter-efficient differentiable planning modules built on Value Iteration which can successfully be trained using reinforcement learning to solve unseen tasks, has the capability to generalize to larger map sizes, and can learn to navigate in dynamic environments. We show that the modules enable learning to plan when the environment also includes stochastic elements, providing a cost-efficient learning system to build low-level size-invariant planners for a variety of interactive navigation problems. We evaluate on static and dynamic configurations of MazeBase grid-worlds, with randomly generated environments of several different sizes, and on a StarCraft navigation scenario, with more complex dynamics, and pixels as input.","keywords":["Reinforcement Learning","Value Iteration","Navigation","Convolutional Neural Networks","Learning to plan"],"authorids":["ICLR.cc/2019/Conference/Paper1308/Authors"],"authors":["Anonymous"],"TL;DR":"We present planners based on convnets that are sample-efficient and that generalize to larger instances of navigation and pathfinding problems.","pdf":"/pdf/40394ed5977d4585c5d85198e47dc93de9443168.pdf","paperhash":"anonymous|value_propagation_networks","_bibtex":"@inproceedings{    \nanonymous2019value,    \ntitle={Value Propagation Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJG6G2RqtX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJz6MnC5YQ","original":"HylebAT5Ym","number":1309,"cdate":1538087957108,"ddate":null,"tcdate":1538087957108,"tmdate":1538155947138,"tddate":null,"forum":"SJz6MnC5YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"DEEP GRAPH TRANSLATION","abstract":"The tremendous success of deep generative models on generating continuous data\nlike image and audio has been achieved; however, few deep graph generative models\nhave been proposed to generate discrete data such as graphs. The recently proposed\napproaches are typically unconditioned generative models which have no\ncontrol over modes of the graphs being generated. Differently, in this paper, we\nare interested in a new problem named Deep Graph Translation: given an input\ngraph, the goal is to infer a target graph by learning their underlying translation\nmapping. Graph translation could be highly desirable in many applications such\nas disaster management and rare event forecasting, where the rare and abnormal\ngraph patterns (e.g., traffic congestions and terrorism events) will be inferred prior\nto their occurrence even without historical data on the abnormal patterns for this\nspecific graph (e.g., a road network or human contact network). To this end, we\npropose a novel Graph-Translation-Generative Adversarial Networks (GT-GAN)\nwhich translates one mode of the input graphs to its target mode. GT-GAN consists\nof a graph translator where we propose new graph convolution and deconvolution\nlayers to learn the global and local translation mapping. A new conditional\ngraph discriminator has also been proposed to classify target graphs by conditioning\non input graphs. Extensive experiments on multiple synthetic and real-world\ndatasets demonstrate the effectiveness and scalability of the proposed GT-GAN.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1309/Authors"],"authors":["Anonymous"],"pdf":"/pdf/f086f09adc7973bd5cbdba350b6ee6ed5ad281b4.pdf","paperhash":"anonymous|deep_graph_translation","_bibtex":"@inproceedings{    \nanonymous2019deep,    \ntitle={DEEP GRAPH TRANSLATION},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJz6MnC5YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1g6zn09tm","original":"H1xk8RpcYm","number":1310,"cdate":1538087957286,"ddate":null,"tcdate":1538087957286,"tmdate":1538155946721,"tddate":null,"forum":"S1g6zn09tm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Latent Transformations for View Synthesis with Conditional Convolutional Networks","abstract":"We propose a fully-convolutional conditional generative model, the latent transformation neural network (LTNN), capable of view synthesis using a light-weight neural network suited for real-time applications. In contrast to existing conditional\ngenerative models which incorporate conditioning information via concatenation, we introduce a dedicated network component, the conditional transformation unit (CTU), designed to learn the latent space transformations corresponding to specified target views. In addition, a consistency loss term is defined to guide the network toward learning the desired latent space mappings, a task-divided decoder is constructed to refine the quality of generated views, and an adaptive discriminator is introduced to improve the adversarial training process. The generality of the proposed methodology is demonstrated on a collection of three diverse tasks: multi-view reconstruction on real hand depth images, view synthesis of real and synthetic faces, and the rotation of rigid objects. The proposed model is shown to exceed state-of-the-art results in each category while simultaneously achieving a reduction in the computational demand required for inference by 30% on average.","keywords":["conditional generative model","deep learning","fully-convolutional network","image attribute modification","multi-view reconstruction","view sythesis"],"authorids":["ICLR.cc/2019/Conference/Paper1310/Authors"],"authors":["Anonymous"],"TL;DR":"We introduce an effective, general framework for incorporating conditioning information into inference-based generative models.","pdf":"/pdf/14e16fecd8cd1c66370d30c6c0c6a2d5e531d7fa.pdf","paperhash":"anonymous|latent_transformations_for_view_synthesis_with_conditional_convolutional_networks","_bibtex":"@inproceedings{    \nanonymous2019latent,    \ntitle={Latent Transformations for View Synthesis with Conditional Convolutional Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1g6zn09tm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJlpM3RqKQ","original":"Byg0eunKFQ","number":1311,"cdate":1538087957456,"ddate":null,"tcdate":1538087957456,"tmdate":1538155946512,"tddate":null,"forum":"SJlpM3RqKQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Expanding the Reach of Federated Learning by Reducing Client Resource Requirements","abstract":"Communication on heterogeneous edge networks is a fundamental bottleneck in Federated Learning (FL), restricting both model capacity and user participation. To address this issue, we introduce two novel strategies to reduce communication costs: (1) the use of lossy compression on the global model sent server-to-client; and (2) Federated Dropout, which allows users to efficiently train locally on smaller subsets of the global model and also provides a reduction in both client-to-server communication and local computation. We empirically show that these strategies, combined with existing compression approaches for client-to-server communication, collectively provide up to a 9.6x reduction in server-to-client communication, a 1.5x reduction in local computation, and a 24x reduction in upload communication, all without degrading the quality of the final model. We thus comprehensively reduce FL's impact on client device resources, allowing higher capacity models to be trained, and a more diverse set of users to be reached.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1311/Authors"],"authors":["Anonymous"],"pdf":"/pdf/df01b90d345d69095417a8e88486a112eacbb7de.pdf","paperhash":"anonymous|expanding_the_reach_of_federated_learning_by_reducing_client_resource_requirements","_bibtex":"@inproceedings{    \nanonymous2019expanding,    \ntitle={Expanding the Reach of Federated Learning by Reducing Client Resource Requirements},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJlpM3RqKQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJgAfh09tm","original":"ByxD1WActX","number":1312,"cdate":1538087957627,"ddate":null,"tcdate":1538087957627,"tmdate":1538155946287,"tddate":null,"forum":"BJgAfh09tm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Bilingual-GAN: Neural Text Generation and Neural Machine Translation as Two Sides of the Same Coin","abstract":"Latent space based GAN methods and attention based encoder-decoder architectures have achieved impressive results in text generation and Unsupervised NMT respectively. Leveraging the two domains, we propose an adversarial latent space based architecture capable of generating parallel sentences in two languages concurrently and translating bidirectionally. The bilingual generation goal is achieved by sampling from the latent space that is adversarially constrained to be shared between both languages. First an NMT model is trained, with back-translation and an adversarial setup, to enforce a latent state between the two languages. The encoder and decoder are shared for the two translation directions. Next, a GAN is trained to generate ‘synthetic’ code mimicking the languages’ shared latent space. This code is then fed into the decoder to generate text in either language. We perform our experiments on Europarl and Multi30k datasets, on the English-French language pair, and document our performance using both Supervised and Unsupervised NMT.","keywords":["Text Generation","Machine Translation","Deep Learning","GAN"],"authorids":["ICLR.cc/2019/Conference/Paper1312/Authors"],"authors":["Anonymous"],"TL;DR":"We present a novel method for Bilingual Text Generation producing parallel concurrent sentences in two languages.","pdf":"/pdf/0b8cbbd7c568ec67b6b6135d588e1f1a0154c853.pdf","paperhash":"anonymous|bilingualgan_neural_text_generation_and_neural_machine_translation_as_two_sides_of_the_same_coin","_bibtex":"@inproceedings{    \nanonymous2019bilingual-gan:,    \ntitle={Bilingual-GAN: Neural Text Generation and Neural Machine Translation as Two Sides of the Same Coin},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgAfh09tm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BkeAf2CqY7","original":"SJlxGPLctX","number":1313,"cdate":1538087957792,"ddate":null,"tcdate":1538087957792,"tmdate":1538155946075,"tddate":null,"forum":"BkeAf2CqY7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Efficient Federated Learning via Variational Dropout","abstract":"As an emerging field, federated learning has recently attracted considerable attention.\nCompared to distributed learning in the datacenter setting, federated learning\nhas more strict constraints on computate efficiency of the learned model and communication\ncost during the training process. In this work, we propose an efficient\nfederated learning framework based on variational dropout. Our approach is able\nto jointly learn a sparse model while reducing the amount of gradients exchanged\nduring the iterative training process. We demonstrate the superior performance\nof our approach on achieving significant model compression and communication\nreduction ratios with no accuracy loss.","keywords":["federated learning","communication efficient","variational dropout","sparse model"],"authorids":["ICLR.cc/2019/Conference/Paper1313/Authors"],"authors":["Anonymous"],"TL;DR":"a joint model and gradient sparsification method for federated learning","pdf":"/pdf/c41dd33dfd4a894f2150995ab3092a9a031cd16f.pdf","paperhash":"anonymous|efficient_federated_learning_via_variational_dropout","_bibtex":"@inproceedings{    \nanonymous2019efficient,    \ntitle={Efficient Federated Learning via Variational Dropout},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkeAf2CqY7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1gRM2A5YX","original":"Hkl7z7Gdt7","number":1314,"cdate":1538087957958,"ddate":null,"tcdate":1538087957958,"tmdate":1538155945866,"tddate":null,"forum":"H1gRM2A5YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Analysis of Memory Organization for Dynamic Neural Networks","abstract":"An increasing number of neural memory networks have been developed, leading to the need for a systematic approach to analyze and compare their underlying memory structures. Thus, in this paper, we first create a framework for memory organization and then compare four popular dynamic models: vanilla recurrent neural network, long short term memory, neural stack and neural RAM. This analysis helps to open the dynamic neural network' black box from the memory usage prospective. Accordingly, a taxonomy for these networks and their variants is proposed and proved using a unifying architecture. With the taxonomy, both network architectures and learning tasks are classified into four classes. And a one-to-one mapping is built between them to help practitioners select the appropriate architecture. To exemplify each task type, four synthetic tasks with different memory requirements are developed. Moreover, we use two natural language processing applications to apply the methodology in a realistic setting. ","keywords":["memory analysis","recurrent neural network","LSTM","neural Turing machine","neural stack","differentiable neural computers"],"authorids":["ICLR.cc/2019/Conference/Paper1314/Authors"],"authors":["Anonymous"],"pdf":"/pdf/d786de70476d3e6b1734fd951e6afd3d195cb2da.pdf","paperhash":"anonymous|analysis_of_memory_organization_for_dynamic_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019analysis,    \ntitle={Analysis of Memory Organization for Dynamic Neural Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1gRM2A5YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyxAfnA5tm","original":"rJ0ngAqF7","number":1315,"cdate":1538087958132,"ddate":null,"tcdate":1538087958132,"tmdate":1538155945654,"tddate":null,"forum":"HyxAfnA5tm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Deep Online Learning Via Meta-Learning: Continual Adaptation for Model-Based RL","abstract":"Humans and animals can learn complex predictive models that allow them to accurately and reliably reason about real-world phenomena, and they can adapt such models extremely quickly in the face of unexpected changes. Deep neural network models allow us to represent very complex functions, but lack this capacity for rapid online adaptation. The goal in this paper is to develop a method for continual online learning from an incoming stream of data, using deep neural network models. We formulate an online learning procedure that uses stochastic gradient descent to update model parameters, and an expectation maximization algorithm with a Chinese restaurant process prior to develop and maintain a mixture of models to handle non-stationary task distributions. This allows for all models to be adapted as necessary, with new models instantiated for task changes and old models recalled when previously seen tasks are encountered again. Furthermore, we observe that meta-learning can be used to meta-train a model such that this direct online adaptation with SGD is effective, which is otherwise not the case for large function approximators. We apply our method to model-based reinforcement learning, where adapting the predictive model is critical for control; we demonstrate that our online learning via meta-learning algorithm outperforms alternative prior methods, and enables effective continuous adaptation in non-stationary task distributions such as varying terrains, motor failures, and unexpected disturbances.","keywords":["meta-learning","model-based","reinforcement learning","online learning","adaptation"],"authorids":["ICLR.cc/2019/Conference/Paper1315/Authors"],"authors":["Anonymous"],"pdf":"/pdf/b76c692a12aaf0efd05ec67fd50a60a5d64c98cb.pdf","paperhash":"anonymous|deep_online_learning_via_metalearning_continual_adaptation_for_modelbased_rl","_bibtex":"@inproceedings{    \nanonymous2019deep,    \ntitle={Deep Online Learning Via Meta-Learning: Continual Adaptation for Model-Based RL},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyxAfnA5tm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJe0Gn0cY7","original":"Hye6yRp5t7","number":1316,"cdate":1538087958299,"ddate":null,"tcdate":1538087958299,"tmdate":1538155945429,"tddate":null,"forum":"BJe0Gn0cY7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Fixing Posterior Collapse with delta-VAEs","abstract":"Due to the phenomenon of “posterior collapse”, current latent variable generativemodels pose a challenging design choice which trades-off optimizing the ELBObut handicapping the decoders’ capacity and expressivity, or changing the loss tosomething that is not directly minimizing the description length. In this paper wepropose an alternative that utilizes the best, most powerful generative models asdecoders, whilst optimizing the proper variational lower bound all while ensuringthat  the  latent  variables  preserve  and  encode  useful  information. delta-VAEs  pro-posed here achieve this by constraining the variational family for the posterior tohave a minimum distance to the prior, which resembles the classic representationlearning approach of slow feature analysis. We demonstrate the efficacy of our ap-proach at modeling images:  learning representations, improving sample quality,and improving state of the art log-likelihood on CIFAR-10 and ImageNet32×32.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1316/Authors"],"authors":["Anonymous"],"TL;DR":" Avoid posterior collapse by lower bounding the rate.","pdf":"/pdf/d6121649ba7ee554e5b281306b577614625cc9c0.pdf","paperhash":"anonymous|fixing_posterior_collapse_with_deltavaes","_bibtex":"@inproceedings{    \nanonymous2019fixing,    \ntitle={Fixing Posterior Collapse with delta-VAEs},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJe0Gn0cY7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Syx0Mh05YQ","original":"S1e47365Y7","number":1317,"cdate":1538087958462,"ddate":null,"tcdate":1538087958462,"tmdate":1538155945218,"tddate":null,"forum":"Syx0Mh05YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning Grid-like Units with Vector Representation of Self-Position and Matrix Representation of Self-Motion","abstract":"This paper proposes a simple model for learning grid-like units for spatial awareness and navigation. In this model, the self-position of the agent is represented by a vector, and the self-motion of the agent is represented by a block-diagonal matrix. Each component of the vector is a unit (or a cell). The model consists of the following two sub-models. (1) Motion sub-model. The movement from the current position to the next position is modeled by matrix-vector multiplication, i.e., multiplying the matrix representation of the motion to the current vector representation of the position in order to  obtain the vector representation of the next position. (2) Localization sub-model. The adjacency between any two positions is a monotone decreasing function of their Euclidean distance, and the adjacency is modeled by the inner product between the vector representations of the two positions. Both sub-models can be implemented by neural networks. The motion sub-model is a recurrent network with dynamic weight matrix, and the localization sub-model is a feedforward network. The model can be learned by minimizing a loss function that combines the loss functions of the two sub-models. The learned units exhibit grid-like patterns (as well as stripe patterns) in both 2D and 3D environments. The learned model can be used for path integral and path planning. Moreover, the learned representation is capable of error correction.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1317/Authors"],"authors":["Anonymous"],"pdf":"/pdf/b18016473ef02a374ee59cbc72b4bbe38d312da7.pdf","paperhash":"anonymous|learning_gridlike_units_with_vector_representation_of_selfposition_and_matrix_representation_of_selfmotion","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning Grid-like Units with Vector Representation of Self-Position and Matrix Representation of Self-Motion},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syx0Mh05YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Byey7n05FQ","original":"ByetyWp5Ym","number":1318,"cdate":1538087958644,"ddate":null,"tcdate":1538087958644,"tmdate":1538155945009,"tddate":null,"forum":"Byey7n05FQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Plan Online, Learn Offline: Efficient Learning and Exploration via Model-Based Control","abstract":"We propose a plan online and learn offline framework for the setting where an agent with an internal model needs to continually act and learn in the world. Our work builds on the synergistic relationship between local trajectory optimization, global value function learning, and exploration. We study how trajectory optimization can cope with approximation errors in the value function, and can stabilize and accelerate value function learning. Conversely, we also study how approximate value functions can help reduce the planning horizon and allow for better policies beyond local solutions. Finally, we also demonstrate how trajectory optimization can be used to perform temporally coordinated exploration in conjunction with estimating uncertainty in value function approximation. Combining these components enable solutions to complex complex control tasks like humanoid locomotion and dexterous in-hand manipulation in the equivalent of a few minutes of experience in the real world.","keywords":["deep reinforcement learning","exploration","model-based"],"authorids":["ICLR.cc/2019/Conference/Paper1318/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a framework that incorporates planning for efficient exploration and learning in complex environments.","pdf":"/pdf/6a8c01511a837155fda637d9184d19481d64f987.pdf","paperhash":"anonymous|plan_online_learn_offline_efficient_learning_and_exploration_via_modelbased_control","_bibtex":"@inproceedings{    \nanonymous2019plan,    \ntitle={Plan Online, Learn Offline: Efficient Learning and Exploration via Model-Based Control},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byey7n05FQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkx1m2C5YQ","original":"rklhjGAqKm","number":1319,"cdate":1538087958815,"ddate":null,"tcdate":1538087958815,"tmdate":1538155944803,"tddate":null,"forum":"rkx1m2C5YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Recurrent Kalman Networks: Factorized Inference in High-Dimensional Deep Feature Spaces","abstract":"State estimation together with state prediction is a crucial task for many applications. Typically, sensory observations give only partial and noisy information about the state of the environment. A well-known tool for performing state estimation under these conditions is the Kalman filter (Kalman et al., 1960). However, the Kalman filter is limited to problems with known, linear models and good estimates about the system noise. Recent deep learning approaches integrate a non-linear encoder into the KF equations that maps the high-dimensional observation to the typically low-dimensional state of the system (Haarnoja et al., 2016). However, these approaches are still limited to systems with known dynamics that\nare either linear or it requires approximations such as an extended Kalman filter. In contrast, our approach does not use a pre-defined state representation but learns a high-dimensional factorized representation that is used for inference us-\ning locally linear models. While our locally linear modelling and factorization assumptions are in general not true for the original low-dimensional state space of the system, the network finds a high-dimensional latent space where these as-\nsumptions hold to perform efficient inference. This state representation is learned jointly with the transition and noise models by backpropagation. The resulting network architecture, which we call Recurrent Kalman Network (RKN), can be\nused for any time-series data, similar to a LSTM (Hochreiter and Schmidhuber, 1997) but uses an explicit representation of uncertainty. As shown by our experiments, the RKN obtains much more accurate uncertainty estimates than an LSTM\nor Gated Recurrent Units (GRUs) (Cho et al., 2014) while also showing a slightly improved prediction performance.","keywords":["state estimation","recurrent neural networks","Kalman Filter","deep learning"],"authorids":["ICLR.cc/2019/Conference/Paper1319/Authors"],"authors":["Anonymous"],"TL;DR":"Kalman Filter based recurrent model for efficient state estimation,  principled uncertainty handling and end to end learning of dynamic models in high dimensional spaces.","pdf":"/pdf/9a57fcd21b712dc647087480b95175ac84709ebd.pdf","paperhash":"anonymous|recurrent_kalman_networks_factorized_inference_in_highdimensional_deep_feature_spaces","_bibtex":"@inproceedings{    \nanonymous2019recurrent,    \ntitle={Recurrent Kalman Networks: Factorized Inference in High-Dimensional Deep Feature Spaces},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkx1m2C5YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkzyX3CcFQ","original":"rygR1UpcY7","number":1320,"cdate":1538087958989,"ddate":null,"tcdate":1538087958989,"tmdate":1538155944591,"tddate":null,"forum":"HkzyX3CcFQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Contextual Recurrent Convolutional Model for Robust Visual Learning","abstract":"Feedforward convolutional neural network has achieved a great success in many computer vision tasks. While it validly imitates the hierarchical structure of biological visual system, it still lacks one essential architectural feature: contextual recurrent connections with feedback, which widely exists in biological visual system. In this work, we designed a Contextual Recurrent Convolutional Network with this feature embedded in a standard CNN structure. We found that such feedback connections could enable lower layers to ``rethink\" about their representations given the top-down contextual information. We carefully studied the components of this network, and showed its robustness and superiority over feedforward baselines in such tasks as noise image classification, partially occluded object recognition and fine-grained image classification. We believed this work could be an important step to help bridge the gap between computer vision models and real biological visual system.","keywords":["contextual modulation","recurrent convolutional network","robust visual learning"],"authorids":["ICLR.cc/2019/Conference/Paper1320/Authors"],"authors":["Anonymous"],"TL;DR":"we proposed a novel contextual recurrent convolutional network with robust property of visual learning ","pdf":"/pdf/1bd07381b3435c7e8acfe726f13928318cde013b.pdf","paperhash":"anonymous|contextual_recurrent_convolutional_model_for_robust_visual_learning","_bibtex":"@inproceedings{    \nanonymous2019contextual,    \ntitle={Contextual Recurrent Convolutional Model for Robust Visual Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkzyX3CcFQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyG1QnRqF7","original":"ByxPS-CqFm","number":1321,"cdate":1538087959166,"ddate":null,"tcdate":1538087959166,"tmdate":1538155944374,"tddate":null,"forum":"SyG1QnRqF7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Towards Resisting Large Data Variations via Introspective Learning","abstract":"Learning deep networks which can resist large variations between training andtesting data is essential to build accurate and robust image classifiers.  Towardsthis end, a typical strategy is to apply data augmentation to enlarge the trainingset.   However,  standard  data  augmentation  is  essentially  a  brute-force  strategywhich is inefficient,  as it performs all the pre-defined transformations  to everytraining sample. In this paper, we propose a principled approach to train networkswith  significantly  improved  resistance  to  large  variations  between  training  andtesting data.  This is achieved by embedding a learnable transformation moduleinto the introspective networks (Jin et al., 2017; Lazarow et al., 2017; Lee et al.,2018), which is a convolutional neural network (CNN) classifier empowered withgenerative capabilities.  Our approach alternatively synthesizes pseudo-negativesamples with learned transformations and enhances the classifier by retraining itwith synthesized samples.  Experimental results verify that our approach signif-icantly improves the ability of deep networks to resist large variations betweentraining and testing data and achieves classification accuracy improvements onseveral benchmark datasets, including MNIST, affNIST, SVHN and CIFAR-10.","keywords":["Introspective learning","Large variations resistance","Image classification","Generative models"],"authorids":["ICLR.cc/2019/Conference/Paper1321/Authors"],"authors":["Anonymous"],"TL;DR":"We propose a principled approach that endows classifiers with the ability to resist larger variations between training and testing data in an intelligent and efficient manner.","pdf":"/pdf/d4eb9f4a639aa5465cf1f78ce7f013fb572766ba.pdf","paperhash":"anonymous|towards_resisting_large_data_variations_via_introspective_learning","_bibtex":"@inproceedings{    \nanonymous2019towards,    \ntitle={Towards Resisting Large Data Variations via Introspective Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyG1QnRqF7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hk41X2AqtQ","original":"B1lUKFp5YQ","number":1322,"cdate":1538087959336,"ddate":null,"tcdate":1538087959336,"tmdate":1538155944165,"tddate":null,"forum":"Hk41X2AqtQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Hierarchically-Structured Variational Autoencoders for Long Text Generation","abstract":"Variational autoencoders (VAEs) have received much attention recently as an end-to-end architecture for text generation. Existing methods primarily focus on synthesizing relatively short sentences (with less than twenty words). In this paper, we propose a novel framework, hierarchically-structured variational autoencoder (hier-VAE), for generating long and coherent units of text. To enhance the model’s plan-ahead ability, intermediate sentence representations are introduced into the generative networks to guide the word-level predictions. To alleviate the typical optimization challenges associated with textual VAEs, we further employ a hierarchy of stochastic layers between the encoder and decoder networks. Extensive experiments are conducted to evaluate the proposed method, where hier-VAE is shown to make effective use of the latent codes and achieve lower perplexity relative to language models. Moreover, the generated samples from hier-VAE also exhibit superior quality according to both automatic and human evaluations. ","keywords":["Natural Language Processing","Text Generation","Variational Autoencoders"],"authorids":["ICLR.cc/2019/Conference/Paper1322/Authors"],"authors":["Anonymous"],"TL;DR":"Propose a hierarchically-structured variational autoencoder for generating long and coherent units of text","pdf":"/pdf/5d6572096e206d68a63549e58e53a7122d3388bd.pdf","paperhash":"anonymous|hierarchicallystructured_variational_autoencoders_for_long_text_generation","_bibtex":"@inproceedings{    \nanonymous2019hierarchically-structured,    \ntitle={Hierarchically-Structured Variational Autoencoders for Long Text Generation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hk41X2AqtQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJ4km2R5t7","original":"SJl9k0TrYQ","number":1323,"cdate":1538087959516,"ddate":null,"tcdate":1538087959516,"tmdate":1538155943958,"tddate":null,"forum":"rJ4km2R5t7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding","abstract":"For natural language understanding (NLU) technology to be maximally useful, it must be able to process language in a way that is not exclusive to a single task, genre, or dataset. In pursuit of this objective, we introduce the General Language Understanding Evaluation (GLUE) benchmark, a collection of tools for evaluating the performance of models across a diverse set of existing NLU tasks. By including tasks with limited training data, GLUE is designed to favor and encourage models that share general linguistic knowledge across tasks. GLUE also includes a hand-crafted diagnostic test suite that enables detailed linguistic analysis of models. We evaluate baselines based on current methods for transfer and representation learning and find that multi-task training on all tasks performs better than training a separate model per task. However, the low absolute performance of our best model indicates the need for improved general NLU systems.","keywords":["natural language understanding","multi-task learning","evaluation"],"authorids":["ICLR.cc/2019/Conference/Paper1323/Authors"],"authors":["Anonymous"],"TL;DR":"We present a multi-task benchmark and analysis platform for evaluating generalization in natural language understanding systems.","pdf":"/pdf/2336608494f9c402b2b168d485ac0ce569f1cfd8.pdf","paperhash":"anonymous|glue_a_multitask_benchmark_and_analysis_platform_for_natural_language_understanding","_bibtex":"@inproceedings{    \nanonymous2019glue:,    \ntitle={GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJ4km2R5t7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1gl7hC5Km","original":"r1gi0vp9Km","number":1324,"cdate":1538087959691,"ddate":null,"tcdate":1538087959691,"tmdate":1538155943743,"tddate":null,"forum":"r1gl7hC5Km","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Adapting Auxiliary Losses Using Gradient Similarity","abstract":"One approach to deal with the statistical inefficiency of neural networks is to rely on auxiliary losses that help building useful representations. However is not  always trivial to know if an auxiliary task will be helpful for the main task and when it could start  hurting.  We explore using gradient cosine similarity as an adaptive  weight for the  auxiliary loss, and demonstrate the usefulness of the proposed algorithm in a few domains,  including multi-task supervised learning using subsets of ImageNet, and reinforcement learning using Atari games.  Additionally, we show that our approach is guaranteed to converge to critical points of the main task. This is not guaranteed otherwise, and in principle adding a mis-matched auxiliary loss can lead to divergence on the main task.\n","keywords":["auxiliary losses","transfer learning","task similarity","deep learning","deep reinforcement learning"],"authorids":["ICLR.cc/2019/Conference/Paper1324/Authors"],"authors":["Anonymous"],"TL;DR":"Auxiliary tasks need to match the main task to improve learning; we propose to use cosine distance between gradients of an unknown auxiliary task to protect from negative interference with learning the main task.","pdf":"/pdf/814bb3277e2e356cafa11b9ab372a2e2e91b97e4.pdf","paperhash":"anonymous|adapting_auxiliary_losses_using_gradient_similarity","_bibtex":"@inproceedings{    \nanonymous2019adapting,    \ntitle={Adapting Auxiliary Losses Using Gradient Similarity},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1gl7hC5Km},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1lgm3C5t7","original":"HJxBnMR5Y7","number":1325,"cdate":1538087959857,"ddate":null,"tcdate":1538087959857,"tmdate":1538155943531,"tddate":null,"forum":"r1lgm3C5t7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Universal discriminative quantum neural networks","abstract":"Quantum mechanics fundamentally forbids deterministic discrimination of quantum states and 9b8d to discriminate among various pure and mixed quantum states exhibiting a trade-off between minimizing erroneous and inconclusive outcomes with comparable performance to theoretically optimal POVMs. We train the circuit on different classes of quantum data and evaluate the generalization error on unseen mixed quantum states. This generalization power hence distinguishes our work from standard circuit optimization and provides an example of quantum machine learning for a task that has inherently no classical analog.","keywords":["quantum machine learning","quantum data classification"],"authorids":["ICLR.cc/2019/Conference/Paper1325/Authors"],"authors":["Anonymous"],"pdf":"/pdf/c49955d35d428925168604330d0ad2bc4f713261.pdf","paperhash":"anonymous|universal_discriminative_quantum_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019universal,    \ntitle={Universal discriminative quantum neural networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1lgm3C5t7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJlxm30cKm","original":"SJelTc6cFm","number":1326,"cdate":1538087960022,"ddate":null,"tcdate":1538087960022,"tmdate":1538155943319,"tddate":null,"forum":"BJlxm30cKm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"An Empirical Study of Example Forgetting during Deep Neural Network Learning","abstract":"Inspired by the phenomenon of catastrophic forgetting, we investigate the learning dynamics of neural networks as they train on single classification tasks. Our goal is to understand whether a related phenomenon occurs when data does not undergo a clear distributional shift. We define a ``forgetting event'' to have occurred when an individual training example transitions from being classified correctly to incorrectly over the course of learning. Across several benchmark data sets, we find that: (i) certain examples are forgotten with high frequency, and some not at all; (ii) a data set's (un)forgettable examples generalize across neural architectures; and (iii) based on forgetting dynamics, a significant fraction of examples can be omitted from the training data set while still maintaining state-of-the-art generalization performance.","keywords":["catastrophic forgetting","sample weighting","deep generalization"],"authorids":["ICLR.cc/2019/Conference/Paper1326/Authors"],"authors":["Anonymous"],"TL;DR":"We show that catastrophic forgetting occurs within what is considered to be a single task and find that examples that are not prone to forgetting can be removed from the training set without loss of generalization.","pdf":"/pdf/30f382ab018756169c8432a8750ccb219a8ad985.pdf","paperhash":"anonymous|an_empirical_study_of_example_forgetting_during_deep_neural_network_learning","_bibtex":"@inproceedings{    \nanonymous2019an,    \ntitle={An Empirical Study of Example Forgetting during Deep Neural Network Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJlxm30cKm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJeem3C9F7","original":"Byg4dbo5YQ","number":1327,"cdate":1538087960186,"ddate":null,"tcdate":1538087960186,"tmdate":1538155943108,"tddate":null,"forum":"BJeem3C9F7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Pix2Scene: Learning Implicit 3D Representations from Images","abstract":"Modelling 3D scenes from 2D images is a long-standing problem in computer vision with implications in, e.g., simulation and robotics. We propose pix2scene, a deep generative-based approach that implicitly models the geometric properties of a scene from images. Our method learns the depth and orientation of scene points visible in images. Our model can then predict the structure of a scene from various, previously unseen view points. It relies on a bi-directional adversarial learning mechanism to generate scene representations from a latent code, inferring the 3D representation of the underlying scene geometry. We showcase a novel differentiable renderer to train the 3D model in an end-to-end fashion, using only images. We demonstrate the generative ability of our model qualitatively on both a custom dataset and on ShapeNet. Finally, we evaluate the effectiveness of the learned 3D scene representation in supporting a 3D spatial reasoning.","keywords":["Representation learning","generative model","adversarial learning","implicit 3D generation","scene generation"],"authorids":["ICLR.cc/2019/Conference/Paper1327/Authors"],"authors":["Anonymous"],"TL;DR":"pix2scene: a deep generative based approach for implicitly modelling the geometrical properties of a 3D scene from images","pdf":"/pdf/d11ba55bcc452a1d2744a304d538f2cdcda8cfa5.pdf","paperhash":"anonymous|pix2scene_learning_implicit_3d_representations_from_images","_bibtex":"@inproceedings{    \nanonymous2019pix2scene:,    \ntitle={Pix2Scene: Learning Implicit 3D Representations from Images},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJeem3C9F7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1zlmnA5K7","original":"Bkeo84aqFm","number":1328,"cdate":1538087960355,"ddate":null,"tcdate":1538087960355,"tmdate":1538155942902,"tddate":null,"forum":"S1zlmnA5K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Batch-Constrained Reinforcement Learning","abstract":"This work examines batch reinforcement learning--the task of maximally exploiting a given batch of off-policy data, without further data collection. Due to errors introduced by extrapolation, we find that standard off-policy deep reinforcement learning algorithms such as DQN and DDPG are only capable of learning with data correlated to their current policy, making them ineffective for most off-policy applications. We introduce a novel class of off-policy algorithms, batch-constrained reinforcement learning, which restricts the action space to force the agent towards behaving on-policy with respect to a subset of the given data. We extend this notion to deep reinforcement learning, and to the best of our knowledge, present the first continuous control deep reinforcement learning algorithm which can learn effectively from uncorrelated off-policy data.","keywords":["reinforcement learning","off-policy","imitation","batch reinforcement learning"],"authorids":["ICLR.cc/2019/Conference/Paper1328/Authors"],"authors":["Anonymous"],"TL;DR":"We describe conditions where off-policy deep reinforcements algorithms fail and present a solution.","pdf":"/pdf/52cffbb6a6921179986a920bb0edaa6e8e0b96e5.pdf","paperhash":"anonymous|batchconstrained_reinforcement_learning","_bibtex":"@inproceedings{    \nanonymous2019batch-constrained,    \ntitle={Batch-Constrained Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1zlmnA5K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1g-X3RqKm","original":"ryln1AP5Ym","number":1329,"cdate":1538087960527,"ddate":null,"tcdate":1538087960527,"tmdate":1538155942695,"tddate":null,"forum":"B1g-X3RqKm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A Proposed Hierarchy of Deep Learning Tasks","abstract":"As the pace of deep learning innovation accelerates, it becomes increasingly important to organize the space of problems by relative difficultly.  Looking to other fields for inspiration, we see analogies to the Chomsky Hierarchy in computational linguistics and time and space complexity in theoretical computer science.\n\nAs a complement to prior theoretical work on the data and computational requirements of learning, this paper presents an empirical approach. We introduce a methodology for measuring validation error scaling with data and model size and test tasks in natural language, vision, and speech domains. We find that power-law validation error scaling exists across a breadth of factors and that model size scales sublinearly with data size, suggesting that simple learning theoretic models offer insights into the scaling behavior of realistic deep learning settings, and providing a new perspective on how to organize the space of  problems. \n\nWe measure the power-law exponent---the \"steepness\" of the learning curve---and propose using this metric to sort problems by degree of difficulty.  There is no data like more data, but some tasks are more effective at taking advantage of more data.  Those that are more effective are easier on the proposed scale. \n\nUsing this approach, we can observe that studied tasks in speech and vision domains scale faster than those in the natural language domain, offering insight into the observation that progress in these areas has proceeded more rapidly than in natural language.","keywords":["Deep learning","scaling with data","computational complexity","learning curves","speech recognition","image recognition","machine translation","language modeling"],"authorids":["ICLR.cc/2019/Conference/Paper1329/Authors"],"authors":["Anonymous"],"TL;DR":"We use 50 GPU years of compute time to study how deep learning scales with more data, and propose a new way to organize the space of problems by difficulty.","pdf":"/pdf/cf2d05da49f06b82d0f3d7def5639e560da0e8ab.pdf","paperhash":"anonymous|a_proposed_hierarchy_of_deep_learning_tasks","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A Proposed Hierarchy of Deep Learning Tasks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1g-X3RqKm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJlWXhC5Km","original":"SyxTCZAct7","number":1330,"cdate":1538087960710,"ddate":null,"tcdate":1538087960710,"tmdate":1538155942475,"tddate":null,"forum":"HJlWXhC5Km","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning to Control Visual Abstractions for Structured Exploration in Deep Reinforcement Learning","abstract":"Exploration in environments with sparse rewards, even in simple environments, is a key challenge. How do we design agents with generic inductive biases so that they can temporally explore instead of just location exploration schemes? We propose an unsupervised reinforcement learning agent which simultaneously learns a discrete pixel abstractions model that preserves spatial geometry of the environment, derives geometric intrinsic reward functions from such abstractions to induce a basis set of behaviors (options) trained with off-policy learning, and finally learns to compose and explore in this options space to optimize for extrinsically defined tasks. We propose an agent that learns a structured exploration algorithm end-to-end using discrete visual abstractions model from raw pixels. We show that our approach can scale to a variety of domains with competitive performance, including navigation in 3D environments and Atari games with sparse rewards.","keywords":["exploration","deep reinforcement learning","intrinsic motivation","unsupervised learning"],"authorids":["ICLR.cc/2019/Conference/Paper1330/Authors"],"authors":["Anonymous"],"TL;DR":"structured exploration in deep reinforcement learning via unsupervised visual abstraction discovery and control","pdf":"/pdf/07e0069d18d307acce4f5a36913dc8c0970c916c.pdf","paperhash":"anonymous|learning_to_control_visual_abstractions_for_structured_exploration_in_deep_reinforcement_learning","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Control Visual Abstractions for Structured Exploration in Deep Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJlWXhC5Km},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1fWmnR5tm","original":"SJed-otcFm","number":1331,"cdate":1538087960881,"ddate":null,"tcdate":1538087960881,"tmdate":1538155942262,"tddate":null,"forum":"r1fWmnR5tm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning to Search Efficient DenseNet with Layer-wise Pruning","abstract":"Deep neural networks have achieved outstanding performance in many real-world applications with the expense of huge computational resources. The DenseNet, one of the recently proposed neural network architecture, has achieved the state-of-the-art performance in many visual tasks. However, it has great redundancy due to the dense connections of the internal structure, which leads to high computational costs in training such dense networks. To address this issue,  we design a reinforcement learning framework to search for efficient DenseNet architectures with layer-wise pruning (LWP) for different tasks, while retaining the original advantages of DenseNet, such as feature reuse, short paths, etc. In this framework, an agent evaluates the importance of each connection between any two block layers, and prunes the redundant connections. In addition, a novel reward-shaping trick is introduced to make DenseNet reach a better trade-off between accuracy and float point operations (FLOPs). Our experiments show that DenseNet with LWP is more compact and efficient than existing alternatives.  ","keywords":["reinforcement learning","DenseNet","neural network compression"],"authorids":["ICLR.cc/2019/Conference/Paper1331/Authors"],"authors":["Anonymous"],"pdf":"/pdf/6e55047547d4f5968ef74ad2955621e858d6222a.pdf","paperhash":"anonymous|learning_to_search_efficient_densenet_with_layerwise_pruning","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Search Efficient DenseNet with Layer-wise Pruning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1fWmnR5tm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1MW72AcK7","original":"B1gGTliYYm","number":1332,"cdate":1538087961051,"ddate":null,"tcdate":1538087961051,"tmdate":1538155942055,"tddate":null,"forum":"H1MW72AcK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Optimal Control Via Neural Networks: A Convex Approach","abstract":"Control of complex systems involves both system identification and controller design. Deep neural networks have proven to be successful in many identification tasks, however, from model-based control perspective, these networks are difficult to work with because they are typically nonlinear and nonconvex. Therefore many systems are still identified and controlled based on simple linear models despite their poor representation capability.\n\nIn this paper we bridge the gap between model accuracy and control tractability faced by neural networks, by explicitly constructing networks that are convex with respect to their inputs. We show that these input convex networks can be trained to obtain accurate models of complex physical systems. In particular, we design input convex recurrent neural networks to capture temporal behavior of dynamical systems. Then optimal controllers can be achieved via solving a convex model predictive control problem. Experiment results demonstrate the good potential of the proposed input convex neural network based approach in a variety of control applications. In particular we show that in the MuJoCo locomotion tasks, we could achieve over 10% higher performance using 5 times less time compared with state-of-the-art model-based reinforcement learning method; and in the building HVAC control example, our method achieved up to 20% energy reduction compared with classic linear models.\n","keywords":["optimal control","input convex neural network","convex optimization"],"authorids":["ICLR.cc/2019/Conference/Paper1332/Authors"],"authors":["Anonymous"],"pdf":"/pdf/8f480ab940d384c795d6dbf71718a8d2382b6b32.pdf","paperhash":"anonymous|optimal_control_via_neural_networks_a_convex_approach","_bibtex":"@inproceedings{    \nanonymous2019optimal,    \ntitle={Optimal Control Via Neural Networks: A Convex Approach},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1MW72AcK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJ4Z72Rctm","original":"Hklsyep9t7","number":1333,"cdate":1538087961217,"ddate":null,"tcdate":1538087961217,"tmdate":1538155941846,"tddate":null,"forum":"SJ4Z72Rctm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Composing Entropic Policies using Divergence Correction","abstract":"Deep reinforcement learning (RL) algorithms have made great strides in recent years. An important remaining challenge is the ability to quickly transfer existing skills to novel tasks, and to combine existing skills with newly acquired ones. In domains where tasks are solved by composing skills this capacity holds the promise of dramatically reducing the data requirements of deep RL algorithms, and hence of greatly increasing their applicability. Recent work has studied ways of composing behaviors represented in the form of action-value functions. We analyze these methods to highlight their strengths and weaknesses, and point out situations where each of them is susceptible to poor performance. To perform this analysis we extend generalized policy improvement to the max-entropy framework and introduce a method for the practical implementation of successor features in continuous action spaces. Then we propose a novel approach which achieves an approximately optimal result. This method works by explicitly learning the (discounted, future) divergence between policies. We study this approach in the  tabular case and propose a scalable variant that is applicable in multi-dimensional continuous action spaces.\nWe compare our novel approach with existing ones on a range of non-trivial continuous control problems with compositional structure, and demonstrate near-optimal performance despite requiring less information than competing approaches.","keywords":["maximum entropy RL","policy composition","deep rl"],"authorids":["ICLR.cc/2019/Conference/Paper1333/Authors"],"authors":["Anonymous"],"TL;DR":"Two new methods for combining entropic policies: maximum entropy generalized policy improvement, and divergence correction.","pdf":"/pdf/a9b657797522440b9e0ca93d7d1fd9103ff119cd.pdf","paperhash":"anonymous|composing_entropic_policies_using_divergence_correction","_bibtex":"@inproceedings{    \nanonymous2019composing,    \ntitle={Composing Entropic Policies using Divergence Correction},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJ4Z72Rctm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ByxZX20qFQ","original":"HJlqU5j5Ym","number":1334,"cdate":1538087961393,"ddate":null,"tcdate":1538087961393,"tmdate":1538155941637,"tddate":null,"forum":"ByxZX20qFQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Adaptive Input Representations for Neural Language Modeling","abstract":"We introduce adaptive input representations for neural language modeling which extend the adaptive softmax of Grave et al. (2017) to input representations of variable capacity. There are several choices on how to factorize the input and output layers, and whether to model words, characters or sub-word units. We perform a systematic comparison of popular choices for a self-attentional architecture. Our experiments show that models equipped with adaptive embeddings are more than twice as fast to train than the popular character input CNN while having a lower number of parameters. We achieve a new state of the art on the WikiText-103 benchmark of 20.51 perplexity, improving the next best known result by 8.7 perplexity.  On the Billion-Word benchmark, we achieve a state of the art of 24.14 perplexity.","keywords":["Neural language modeling"],"authorids":["ICLR.cc/2019/Conference/Paper1334/Authors"],"authors":["Anonymous"],"TL;DR":"Variable capacity input word embeddings and SOTA on WikiText-103, Billion Word benchmarks.","pdf":"/pdf/a94f22b8d82d18f26dce21beeac38bb4f7ab175b.pdf","paperhash":"anonymous|adaptive_input_representations_for_neural_language_modeling","_bibtex":"@inproceedings{    \nanonymous2019adaptive,    \ntitle={Adaptive Input Representations for Neural Language Modeling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByxZX20qFQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkezXnA9YX","original":"rJlWru6qKm","number":1335,"cdate":1538087961565,"ddate":null,"tcdate":1538087961565,"tmdate":1538155941429,"tddate":null,"forum":"HkezXnA9YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Systematic Generalization: What Is Required and Can It Be Learned?","abstract":"Numerous models for grounded language understanding have been recently proposed, including (i) generic modules that can be used easily adapted to any given task with little adaptation and (ii) intuitively appealing modular models that require background knowledge to be instantiated. We compare generic and modular models in how much they lend themselves to a particular form of systematic generalization. Using a synthetic VQA test, we evaluate which models are capable of reasoning about all possible object pairs after training on only a small subset of them. Our findings show that the generalization of modular models is much more systematic and that it is highly sensitive to the module layout, i.e. to how exactly the modules are connected. We furthermore investigate if modular models that generalize well could be made more end-to-end by learning their layout and parametrization. We show how end-to-end methods  from prior work often learn a wrong layout and a spurious parametrization that do not facilitate systematic generalization.\n","keywords":["systematic generalization","language understanding","visual questions answering","neural module networks"],"authorids":["ICLR.cc/2019/Conference/Paper1335/Authors"],"authors":["Anonymous"],"TL;DR":"We show that modular structured models are the best in terms of systematic generalization and that their end-to-end versions don't generalize as well.","pdf":"/pdf/46033bce3d5357765425d81e21f216ee68bf6cc6.pdf","paperhash":"anonymous|systematic_generalization_what_is_required_and_can_it_be_learned","_bibtex":"@inproceedings{    \nanonymous2019systematic,    \ntitle={Systematic Generalization: What Is Required and Can It Be Learned?},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkezXnA9YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJxfm2CqKm","original":"ByxtLbC9F7","number":1336,"cdate":1538087961739,"ddate":null,"tcdate":1538087961739,"tmdate":1538155941220,"tddate":null,"forum":"HJxfm2CqKm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Discovering General-Purpose Active Learning Strategies","abstract":"We propose a general-purpose approach to discovering active learning (AL) strategies from data. These strategies are transferable from one domain to another and can be used in conjunction with many machine learning models. To this end, we formalize the annotation process as a Markov decision process, design universal state and action spaces and introduce a new reward function that precisely reflects the AL objective of minimizing the annotation cost We seek to find an optimal (non-myopic) AL strategy using reinforcement learning. We evaluate the learned strategies on multiple unrelated domains and show that they consistently outperform state-of-the-art baselines.","keywords":["active learning","meta learning","reinforcement learning"],"authorids":["ICLR.cc/2019/Conference/Paper1336/Authors"],"authors":["Anonymous"],"pdf":"/pdf/04b1cd8910a3ae131e3819cacefdbbd0be8a36f5.pdf","paperhash":"anonymous|discovering_generalpurpose_active_learning_strategies","_bibtex":"@inproceedings{    \nanonymous2019discovering,    \ntitle={Discovering General-Purpose Active Learning Strategies},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxfm2CqKm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryxMX2R9YQ","original":"HyxNVyAct7","number":1337,"cdate":1538087961915,"ddate":null,"tcdate":1538087961915,"tmdate":1538155941012,"tddate":null,"forum":"ryxMX2R9YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"CGNF: Conditional Graph Neural Fields","abstract":"Graph convolutional networks have achieved tremendous success in the tasks of graph node classification. These models could learn a better node representation through encoding the graph structure and node features. However, the correlation between the node labels are not considered. In this paper, we propose a novel architecture for graph node classification, named conditional graph neural fields (CGNF). By integrating the conditional random fields (CRF) in the graph convolutional networks, we explicitly model a joint probability of the entire set of node labels, thus taking advantage of neighborhood label information in the node label prediction task. \nOur model could have both the representation capacity of graph neural networks and the prediction power of CRFs. Experiments on several graph datasets demonstrate effectiveness of CGNF.","keywords":["graph neural networks","energy models","conditional random fields","label correlation"],"authorids":["ICLR.cc/2019/Conference/Paper1337/Authors"],"authors":["Anonymous"],"pdf":"/pdf/7d6089ce80f44da1391e4148600714bb5e1ca739.pdf","paperhash":"anonymous|cgnf_conditional_graph_neural_fields","_bibtex":"@inproceedings{    \nanonymous2019cgnf:,    \ntitle={CGNF: Conditional Graph Neural Fields},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxMX2R9YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BkgGmh09FQ","original":"BkgDNZC5YQ","number":1338,"cdate":1538087962078,"ddate":null,"tcdate":1538087962078,"tmdate":1538155940796,"tddate":null,"forum":"BkgGmh09FQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Understanding Opportunities for Efficiency in Single-image Super Resolution Networks","abstract":"A successful application of convolutional architectures is to increase the resolution of single low-resolution images -- a vision task called super-resolution (SR). Naturally, SR is of value to resource constrained devices like mobile phones, electronic photograph frames and hoe televisions to enhance image quality. However, SR demands perhaps the most extreme amounts of memory and compute operations of any mainstream vision task known today. And this in-turn prevents SR from being deployed to devices that require them. In this paper, we perform one of the only systematic studies of system resource efficiency for SR, within the context of a variety of architectural and low-precision approaches originally developed for discriminative neural networks. We present a rich set of insights, representative SR architectures and efficiency trade-offs; for example, highly compact SR models suitable for DSPs and FPGAs -- along with SR models suitable for smartphones that are 3x smaller than those of comparable quality found in the literature. Collectively, we believe these results provides the foundation for further research into the little explored area of resource efficiency for SR. ","keywords":["Super-Resolution","Resource-Efficiency"],"authorids":["ICLR.cc/2019/Conference/Paper1338/Authors"],"authors":["Anonymous"],"TL;DR":"We build an understanding of resource-efficient techniques on Super-Resolution","pdf":"/pdf/0757b2bd9ce64d5086437bf6ed1f896e7e89e580.pdf","paperhash":"anonymous|understanding_opportunities_for_efficiency_in_singleimage_super_resolution_networks","_bibtex":"@inproceedings{    \nanonymous2019understanding,    \ntitle={Understanding Opportunities for Efficiency in Single-image Super Resolution Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkgGmh09FQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryfz73C9KQ","original":"SyxBGV9cKX","number":1339,"cdate":1538087962248,"ddate":null,"tcdate":1538087962248,"tmdate":1538155940589,"tddate":null,"forum":"ryfz73C9KQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Neural Predictive Belief Representations","abstract":"Unsupervised representation learning has succeeded with excellent results in many applications. It is an especially powerful tool  to learn a good representation of environments with partial or noisy observations. In partially observable domains it is important for the representation to encode a belief state---a sufficient statistic of the observations seen so far. In this paper, we investigate whether it is possible to learn such a belief representation using modern neural architectures. Specifically, we focus on one-step frame prediction and two variants of contrastive predictive coding (CPC)  as the objective functions to learn the representations. To evaluate these learned representations, we test how well they can predict various pieces of information about the underlying state of the environment, e.g., position of the agent in a 3D maze. We show that all three methods are able to learn belief representations of the environment---they encode not only the state information, but also its uncertainty, a crucial aspect of belief states. We also find that for CPC multi-step predictions and action-conditioning are critical for accurate belief representations in visually complex environments. The ability of neural representations to capture the belief information has the potential to spur new advances for learning and planning in partially observable domains, where leveraging uncertainty is essential for optimal decision making.","keywords":["belief states","representation learning","contrastive predictive coding","reinforcement learning","predictive state representations","deep reinforcement learning"],"authorids":["ICLR.cc/2019/Conference/Paper1339/Authors"],"authors":["Anonymous"],"TL;DR":"We investigate the quality of belief state representations of partially observable dynamic environments learned with modern neural architectures.","pdf":"/pdf/2d1b7f6ace37536396c202d694eebf126f4d250c.pdf","paperhash":"anonymous|neural_predictive_belief_representations","_bibtex":"@inproceedings{    \nanonymous2019neural,    \ntitle={Neural Predictive Belief Representations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryfz73C9KQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1ffQnRcKX","original":"rJlr9aj5Y7","number":1340,"cdate":1538087962408,"ddate":null,"tcdate":1538087962408,"tmdate":1538155940375,"tddate":null,"forum":"B1ffQnRcKX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Automatically Composing Representation Transformations as a Means for Generalization","abstract":"How can we build a learner that can capture the essence of what makes a hard problem more complex than a simple one, break the hard problem along characteristic lines into smaller problems it knows how to solve, and sequentially solve the smaller problems until the larger one is solved?  To work towards this goal, we focus on learning to generalize in a particular family of problems that exhibit compositional and recursive structure: their solutions can be found by composing in sequence a set of reusable partial solutions.  Our key idea is to recast the problem of generalization as a problem of learning algorithmic procedures: we can formulate a solution to this family as a sequential decision-making process over transformations between representations.  Our formulation enables the learner to learn the structure and parameters of its own computation graph with sparse supervision, make analogies between problems by transforming one problem representation to another, and exploit modularity and reuse to scale to problems of varying complexity. Experiments on solving a variety of multilingual arithmetic problems demonstrate that our method discovers the hierarchical decomposition of a problem into its subproblems, generalizes out of distribution to unseen problem classes, and extrapolates to harder versions of the same problem, yielding a 10-fold reduction in sample complexity compared to a monolithic recurrent neural network. We further show that our method can compose learned spatial transformations to recover canonical MNIST digits from transformed ones.","keywords":["compositionality","deep learning","metareasoning"],"authorids":["ICLR.cc/2019/Conference/Paper1340/Authors"],"authors":["Anonymous"],"TL;DR":"We explore the problem of compositional generalization and propose a means for endowing neural network architectures with the ability to compose themselves to solve these problems.","pdf":"/pdf/2c71181ecbe21a70a4347e735adba87a870b6aeb.pdf","paperhash":"anonymous|automatically_composing_representation_transformations_as_a_means_for_generalization","_bibtex":"@inproceedings{    \nanonymous2019automatically,    \ntitle={Automatically Composing Representation Transformations as a Means for Generalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1ffQnRcKX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1xQQhAqKX","original":"rJgJYSk5FQ","number":1341,"cdate":1538087962574,"ddate":null,"tcdate":1538087962574,"tmdate":1538155940161,"tddate":null,"forum":"r1xQQhAqKX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Modeling Uncertainty with Hedged Instance Embeddings","abstract":"Instance embeddings are an efficient and versatile image representation that facilitates applications like recognition, verification, retrieval, and clustering. Many metric learning methods represent the input as a single point in the embedding space. Often the distance between points is used as a proxy for match confidence. However, this can fail to represent uncertainty which can arise when the input is ambiguous, e.g., due to occlusion or blurriness. This work addresses this issue and explicitly models the uncertainty by “hedging” the location of each input in the embedding space. We introduce the hedged instance embedding (HIB) in which embeddings are modeled as random variables and the model is trained under the variational information bottleneck principle (Alemi et al., 2016; Achille & Soatto, 2018). Empirical results on our new N-digit MNIST dataset show that our method leads to the desired behavior of “hedging its bets” across the embedding space upon encountering ambiguous inputs. This results in improved performance for image matching and classification tasks, more structure in the learned embedding space, and an ability to compute a per-exemplar uncertainty measure which is correlated with downstream performance.","keywords":["uncertainty","instance embedding"],"authorids":["ICLR.cc/2019/Conference/Paper1341/Authors"],"authors":["Anonymous"],"TL;DR":"The paper proposes using probability distributions instead of points for instance embeddings tasks such as recognition and verification.","pdf":"/pdf/27e900bd78f6c132042637891cf50735adc070fa.pdf","paperhash":"anonymous|modeling_uncertainty_with_hedged_instance_embeddings","_bibtex":"@inproceedings{    \nanonymous2019modeling,    \ntitle={Modeling Uncertainty with Hedged Instance Embeddings},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1xQQhAqKX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJemQ209FQ","original":"S1gzuKpctX","number":1342,"cdate":1538087962748,"ddate":null,"tcdate":1538087962748,"tmdate":1538155939951,"tddate":null,"forum":"BJemQ209FQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning to Navigate the Web","abstract":"Learning in environments with large state and action spaces as well as sparse\nrewards can hinder the ability of a Reinforcement Learning (RL) agent to learn\nthrough trial-and-error. For instance, the problem of following natural language\ninstructions on theWeb (such as booking a flight ticket) leads to RL settings where\ninput vocabulary and number of actionable elements on a page can grow very\nlarge. Even though recent approaches improve the success rate on relatively simpler\nenvironments with the help of human demonstrations to guide the exploration,\nthey still fail in environments where the set of possible instructions can reach millions.\nWe approach the aforementioned problems from a different perspective and\npropose a meta-trainer that can generate unbounded amount of experience for an\nagent to learn from. Instead of learning from a complicated instruction with a\nlarge vocabulary, we decompose it into multiple sub-instructions and schedule a\ncurriculum in which an agent is tasked with gradually increasing subset of these\nrelatively easier sub-instructions. We train DQN, deep reinforcement learning\nagent, with Q-value function approximated with a novel QWeb neural network\narchitecture on these smaller, synthetic instructions. We evaluate the ability of\nour agent to generalize to new instructions on World of Bits benchmark, on forms\nwith 100 elements, supporting 14 million possible instructions. The QWeb agent\noutperforms the baseline without using any human demonstration achieving 100%\nsuccess rate on several difficult environments.","keywords":["navigating web pages","reinforcement learning","q learning","curriculum learning","meta training"],"authorids":["ICLR.cc/2019/Conference/Paper1342/Authors"],"authors":["Anonymous"],"TL;DR":"We train reinforcement learning policies using reward augmentation, curriculum learning, and meta-learning  to successfully navigate web pages.","pdf":"/pdf/d0d1fe0dbaeda1a374824148055434ede528f322.pdf","paperhash":"anonymous|learning_to_navigate_the_web","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Navigate the Web},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJemQ209FQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJG7m2AcF7","original":"BJxZ1T69Fm","number":1343,"cdate":1538087962921,"ddate":null,"tcdate":1538087962921,"tmdate":1538155939740,"tddate":null,"forum":"HJG7m2AcF7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Is Wasserstein all you need?","abstract":"We propose a unified framework for building unsupervised representations of entities and their compositions, by viewing each entity as a histogram over its contexts. This enables us to take advantage of optimal transport and construct representations that effectively harness the geometry of the underlying space containing the contexts. Our method captures uncertainty via modelling the entities as distributions and simultaneously provides interpretability with the optimal transport map, hence giving a novel perspective for building rich and powerful feature representations. As a guiding example, we formulate unsupervised representations for text, and demonstrate it on tasks such as sentence similarity and word entailment detection. Empirical results show strong advantages gained through the proposed framework. This approach can be used for any unsupervised or supervised problem (on text or other modalities) with a co-occurrence structure, such as any sequence data. The key tools at the core of this framework are Wasserstein distances and Wasserstein barycenters, hence raising the question from our title.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1343/Authors"],"authors":["Anonymous"],"pdf":"/pdf/c0a4f3e71ac67f1aef0a9bb602115bc9f233eb6d.pdf","paperhash":"anonymous|is_wasserstein_all_you_need","_bibtex":"@inproceedings{    \nanonymous2019is,    \ntitle={Is Wasserstein all you need?},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJG7m2AcF7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJxmXhRcK7","original":"rJxdAB3qYm","number":1344,"cdate":1538087963080,"ddate":null,"tcdate":1538087963080,"tmdate":1538155939532,"tddate":null,"forum":"BJxmXhRcK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"TENSOR RING NETS ADAPTED DEEP MULTI-TASK LEARNING","abstract":"Recent deep multi-task learning (MTL) has been shown to be quite successful in alleviating data scarcity of some task by utilizing domain-specific knowledge from related tasks. In this work, we propose a novel knowledge sharing mechanism for linking task-specific models, namely tensor ring multi-task learning (TRMTL). TRMTL models each task with one separate DNN and encodes DNN’s parameters with a sequence of latent tensor cores. Meanwhile, the parameter sharing scheme is carried out among the subsets of latent tensor cores of multiple tasks in a distributed manner. Our model has a highly compact representation and is efficient in transferring the task-invariant knowledge, while being super flexible in learning the task-specific features. TRMTL is a general framework that readily subsumes other tensor factorization based deep MTL methods. TRMTL also allows each individual task to have its own distinct input and output feature dimensionality of each layer. Experiments on a variety of datasets demonstrate our model is capable of significantly improving each single task’s performance, particularly favourable in scenarios where some of the tasks have insufficient data.","keywords":["deep learning","deep multi-task learning","tensor factorization","tensor ring nets"],"authorids":["ICLR.cc/2019/Conference/Paper1344/Authors"],"authors":["Anonymous"],"TL;DR":"a deep multi-task learning model adapting tensor ring representation","pdf":"/pdf/b4f2d0c44a47f74f9c414bfbb8fa2dd1ca507537.pdf","paperhash":"anonymous|tensor_ring_nets_adapted_deep_multitask_learning","_bibtex":"@inproceedings{    \nanonymous2019tensor,    \ntitle={TENSOR RING NETS ADAPTED DEEP MULTI-TASK LEARNING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJxmXhRcK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ByxmXnA9FQ","original":"Bkgt9qZ9K7","number":1345,"cdate":1538087963250,"ddate":null,"tcdate":1538087963250,"tmdate":1538155939321,"tddate":null,"forum":"ByxmXnA9FQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A variational Dirichlet framework for out-of-distribution detection","abstract":"With the recently rapid development in deep learning, deep neural networks have been widely adopted in many real-life applications. However, deep neural networks are known to have very little control over its uncertainty for test examples, which can potentially cause very harmful and annoying consequences in practical scenarios. In this paper, we are particularly interested in designing a higher-order uncertainty metric for deep neural networks and investigate its performance on the out-of-distribution detection task proposed by~\\cite{hendrycks2016baseline}. Our method is based on a variational inference framework where we interpret the output distribution $p(x)$ as a stochastic variable $z$ lying on a simplex of multi-dimensional space and represent the higher-order uncertainty via the entropy of the latent distribution $p(z)$. Under the variational Bayesian framework with a given dataset $D$, we propose to adopt Dirichlet distribution as the approximate posterior $F_{\\theta}(z|x)$ to approach the true posterior distribution $p(z|D)$ by maximizing the evidence lower bound of marginal likelihood. By identifying the over-concentration issue in the Dirichlet framework, we further design a log-scaling smoothing function to avert such issue and greatly increase the robustness of the entropy-based uncertainty measure. Through comprehensive experiments on various datasets and architectures, our proposed variational Dirichlet framework is observed to yield state-of-the-art results for out-of-distribution detection.","keywords":["out-of-distribution detection","variational inference","Dirichlet distribution","deep learning","uncertainty measure"],"authorids":["ICLR.cc/2019/Conference/Paper1345/Authors"],"authors":["Anonymous"],"TL;DR":"A new framework based variational inference for out-of-distribution detection","pdf":"/pdf/13850e29724b6b6b354956865505d1ee41c4f57d.pdf","paperhash":"anonymous|a_variational_dirichlet_framework_for_outofdistribution_detection","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A variational Dirichlet framework for out-of-distribution detection},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByxmXnA9FQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rye7XnRqFm","original":"BJexWx05FX","number":1346,"cdate":1538087963425,"ddate":null,"tcdate":1538087963425,"tmdate":1538155939104,"tddate":null,"forum":"rye7XnRqFm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Q-map: a Convolutional Approach for Goal-Oriented Reinforcement Learning","abstract":"Goal-oriented learning has become a core concept in the reinforcement learning (RL) framework, extending the reward signal as a sole way to define tasks. Generalized value functions (GVFs) utilize an array of independent value functions, each trained for a specific goal, while universal value function approximators (UVFAs) enable generalization between goals by providing them in input. As parameterizing value functions with goals increases the learning complexity, efficiently reusing past experience to update estimates towards several goals at once becomes desirable, but requires independent updates per goal for both GVFs and UVFAs.\nConsidering that a significant number of RL environments can support spatial coordinates as goals - such as on-screen location of the character in ATARI or SNES games, we propose a novel goal-oriented agent called Q-map that utilizes an autoencoder-like neural network to predict the minimum number of steps towards each coordinate in a single forward pass. This architecture is similar to Horde with parameter sharing and allows the agent to discover correlations between visual patterns and navigation. For example learning how to use a ladder in a game could be transferred to other ladders later.\nWe show how this network can be efficiently trained with a 3D variant of Q-learning to update the estimates towards all goals at once. While the Q-map agent could be used for a wide range of applications, we propose a novel exploration mechanism in place of epsilon-greedy that relies on goal selection at a predicted target distance followed by several steps taken towards it, thus allowing the agent to take much longer and coherent exploratory steps in the environment.\nWe demonstrate the accuracy and generalization qualities of the Q-map agent on a grid-world environment and then demonstrate how the proposed exploration mechanism allows the agent to explore much further than random walks on the notoriously difficult Montezuma's Revenge game and finally show how the combination of Q-map with a task-learner DQN agent improves the performance on the Super Mario All-Stars game.","keywords":["reinforcement learning","goal-oriented","convolutions","off-policy"],"authorids":["ICLR.cc/2019/Conference/Paper1346/Authors"],"authors":["Anonymous"],"TL;DR":"Q-map is a reinforcement learning agent that uses a convolutional autoencoder-like architecture to efficiently learn to navigate its environment.","pdf":"/pdf/7f32bf362b19e61379f115fe3f03ccb3c75bc8ab.pdf","paperhash":"anonymous|qmap_a_convolutional_approach_for_goaloriented_reinforcement_learning","_bibtex":"@inproceedings{    \nanonymous2019q-map:,    \ntitle={Q-map: a Convolutional Approach for Goal-Oriented Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rye7XnRqFm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkgEQnRqYQ","original":"BJgQjZiqtX","number":1347,"cdate":1538087963607,"ddate":null,"tcdate":1538087963607,"tmdate":1538155938895,"tddate":null,"forum":"HkgEQnRqYQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space","abstract":"We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. The success of such a task heavily relies on the ability of modeling and inferring the patterns of (or between) the relations. In this paper, we present a new approach for knowledge graph embedding called RotatE, which is able to model and infer various relation patterns including: symmetry/antisymmetry, inversion, and composition. Specifically, the RotatE model defines each relation as a rotation from the source entity to the target entity in the complex vector space. Experimental results on multiple benchmark knowledge graphs show that the proposed RotatE model is not only scalable, but also able to infer and model various relation patterns and significantly outperform existing state-of-the-art models for link prediction.","keywords":["knowledge graph embedding","knowledge graph completion","adversarial sampling"],"authorids":["ICLR.cc/2019/Conference/Paper1347/Authors"],"authors":["Anonymous"],"TL;DR":"A new state-of-the-art approach for knowledge graph embedding.","pdf":"/pdf/7ac19a9a6e63fd627ec30ac08dc89d6aa62b3b76.pdf","paperhash":"anonymous|rotate_knowledge_graph_embedding_by_relational_rotation_in_complex_space","_bibtex":"@inproceedings{    \nanonymous2019rotate:,    \ntitle={RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkgEQnRqYQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1eEmn05tQ","original":"SkxfTq65FX","number":1348,"cdate":1538087963780,"ddate":null,"tcdate":1538087963780,"tmdate":1538155938687,"tddate":null,"forum":"S1eEmn05tQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Uncertainty in Multitask Transfer Learning","abstract":"Using variational Bayes neural networks, we develop an algorithm capable of accumulating knowledge into a prior from multiple different tasks. This results in a rich prior capable of few-shot learning on new tasks. The posterior can go beyond the mean field approximation and yields good uncertainty on the performed experiments. Analysis on toy tasks show that it can learn from significantly different tasks while finding similarities among them. Experiments on Mini-Imagenet reach state of the art with 74.5% accuracy on 5 shot learning. Finally, we provide two new benchmarks, each showing a failure mode of existing meta learning algorithms such as MAML and prototypical Networks.","keywords":["Multi Task","Transfer Learning","Hierarchical Bayes","Variational Bayes","Meta Learning","Few Shot learning"],"authorids":["ICLR.cc/2019/Conference/Paper1348/Authors"],"authors":["Anonymous"],"TL;DR":"A scalable method for learning an expressive prior over neural networks across multiple tasks.","pdf":"/pdf/17b5166ce21f3d47f1889b2f256be1290f92d5cf.pdf","paperhash":"anonymous|uncertainty_in_multitask_transfer_learning","_bibtex":"@inproceedings{    \nanonymous2019uncertainty,    \ntitle={Uncertainty in Multitask Transfer Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1eEmn05tQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJGVX3CqYm","original":"SJleNcaqYX","number":1349,"cdate":1538087963950,"ddate":null,"tcdate":1538087963950,"tmdate":1538155938480,"tddate":null,"forum":"BJGVX3CqYm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Mixed Precision Quantization of ConvNets via Differentiable Neural Architecture Search","abstract":"Recent work in network quantization has substantially reduced the time and space complexity of neural network inference, enabling their deployment on embedded and mobile devices with limited computational and memory resources. However, existing quantization methods often represent all weights and activations with the same precision (bit-width). In this paper, we explore a new dimension of the design space: quantizing different layers with different bit-widths. We formulate this problem as a neural architecture search problem and propose a novel differentiable neural architecture search (DNAS) framework to efficiently explore its exponential search space with gradient-based optimization. Experiments show we surpass the state-of-the-art compression of ResNet on CIFAR-10 and ImageNet. Our quantized models with 21.1x smaller model size or 103.9x lower computational cost can still outperform baseline quantized or even full precision models.","keywords":["Neural Net Quantization","Neural Architecture Search"],"authorids":["ICLR.cc/2019/Conference/Paper1349/Authors"],"authors":["Anonymous"],"TL;DR":"A novel differentiable neural architecture search framework for mixed quantization of ConvNets.","pdf":"/pdf/c28f925c389b2212e02c426c60439e409aef7401.pdf","paperhash":"anonymous|mixed_precision_quantization_of_convnets_via_differentiable_neural_architecture_search","_bibtex":"@inproceedings{    \nanonymous2019mixed,    \ntitle={Mixed Precision Quantization of ConvNets via Differentiable Neural Architecture Search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJGVX3CqYm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkzNXhC9KQ","original":"S1g2BGAFY7","number":1350,"cdate":1538087964121,"ddate":null,"tcdate":1538087964121,"tmdate":1538155938277,"tddate":null,"forum":"HkzNXhC9KQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"NASAP Coding:  Neural-Network-Based Adaptive Sample-Space & Adaptive Probability Lossy Coding","abstract":"We propose Adaptive Sample-space & Adaptive Probability (ASAP) coding, an efficient neural-network based method for lossy data compression.\nOur ASAP coding distinguishes itself from the conventional method based on adaptive arithmetic coding in that it models the probability distribution for the quantization process in such a way that one can conduct back-propagation for the quantization width that determines the support of the distribution. \nOur ASAP also trains the model with a novel, hyper-parameter free multiplicative loss for the rate-distortion tradeoff.  \nWith our ASAP encoder, we are able to compress the image files in the Kodak dataset to as low as one fifth the size of the JPEG-compressed image without compromising their visual quality, and achieved the state-of-the-art result in terms of MS-SSIM based rate-distortion tradeoff. ","keywords":["Data compression","Image compression","Deep Learning","Convolutional neural networks"],"authorids":["ICLR.cc/2019/Conference/Paper1350/Authors"],"authors":["Anonymous"],"pdf":"/pdf/cb16e04502c94b04767dc362479fb71acb54b6f6.pdf","paperhash":"anonymous|nasap_coding_neuralnetworkbased_adaptive_samplespace_adaptive_probability_lossy_coding","_bibtex":"@inproceedings{    \nanonymous2019nasap,    \ntitle={NASAP Coding:  Neural-Network-Based Adaptive Sample-Space & Adaptive Probability Lossy Coding},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkzNXhC9KQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkNN7nR5Ym","original":"HyxujC65tQ","number":1351,"cdate":1538087964286,"ddate":null,"tcdate":1538087964286,"tmdate":1538155938067,"tddate":null,"forum":"HkNN7nR5Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Associate Normalization","abstract":"Normalization is a key technique for training deep neural networks. It improves the stability of the training process and thus makes the networks easier to train. However, in typical normalization methods, the rescaling parameters that control the mean and variance of the output do not associate with any input information during the forward phase. Therefore, inputs of different types are treated as from the exact same distribution, which may limit the feature expressiveness of normalization module. We present Associate Normalization (AssocNorm) to overcome the above limitation. AssocNorm extracts the key information from input features and connects them with rescaling parameters by an auto-encoder-like neural network in the normalization module. Furthermore, AssocNorm normalizes the features of each example individually, so the accuracy is relatively stable for different batch sizes. The experimental results show that AssocNorm achieves better performance than Batch Normalization on several benchmark datasets under various hyper-parameter settings.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1351/Authors"],"authors":["Anonymous"],"pdf":"/pdf/dafadd0d99988dd952ac6d854e9bf8a3c2e6ba4e.pdf","paperhash":"anonymous|associate_normalization","_bibtex":"@inproceedings{    \nanonymous2019associate,    \ntitle={Associate Normalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkNN7nR5Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1V4QhAqYQ","original":"SyeJpwEqtQ","number":1352,"cdate":1538087964448,"ddate":null,"tcdate":1538087964448,"tmdate":1538155937855,"tddate":null,"forum":"H1V4QhAqYQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Augment your batch: better training with larger batches","abstract":"Recently, there is regained interest in large batch training of neural networks, both of theory and practice. New insights and methods allowed certain models to be trained using large batches with no adverse impact on performance. Most works focused on accelerating wall clock training time by modifying the learning rate schedule, without introducing accuracy degradation. \nWe propose to use large batch training to boost accuracy and accelerate convergence by combining it with data augmentation. Our method, \"batch augmentation\", suggests using multiple instances of each sample at the same large batch. We show empirically that this simple yet effective method improves convergence and final generalization accuracy. We further suggest possible reasons for its success.","keywords":["Large Batch Training","Augmentation","Deep Learning"],"authorids":["ICLR.cc/2019/Conference/Paper1352/Authors"],"authors":["Anonymous"],"TL;DR":"Improve accuracy by large batches composed of multiple instances of each sample at the same batch","pdf":"/pdf/5b132b0574207bd1950cf7ebb9e7371ec673de4e.pdf","paperhash":"anonymous|augment_your_batch_better_training_with_larger_batches","_bibtex":"@inproceedings{    \nanonymous2019augment,    \ntitle={Augment your batch: better training with larger batches},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1V4QhAqYQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HyeS73ActX","original":"SJl6f8p9t7","number":1353,"cdate":1538087964608,"ddate":null,"tcdate":1538087964608,"tmdate":1538155937648,"tddate":null,"forum":"HyeS73ActX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Multi-Objective Value Iteration with Parameterized Threshold-Based Safety Constraints","abstract":"We consider an environment with multiple reward functions. One of them represents goal achievement and the others represent instantaneous safety conditions. We consider a scenario where the safety rewards should always be above some thresholds. The thresholds are parameters with values that differ between users.\n%The thresholds are not known at the time the policy is being designed.\nWe efficiently compute a family of policies that cover all threshold-based constraints and maximize the goal achievement reward. We introduce a new parameterized threshold-based scalarization method of the reward vector that encodes our objective. We present novel data structures to store the value functions of the Bellman equation that allow their efficient computation using the value iteration algorithm. We present results for both discrete and continuous state spaces. ","keywords":["reinforcement learning","Markov decision processes","safety constraints","multi-objective optimization","geometric analysis"],"authorids":["ICLR.cc/2019/Conference/Paper1353/Authors"],"authors":["Anonymous"],"pdf":"/pdf/caf28a8d07a76b1da53dc1c5e5de2a800e5c035c.pdf","paperhash":"anonymous|multiobjective_value_iteration_with_parameterized_thresholdbased_safety_constraints","_bibtex":"@inproceedings{    \nanonymous2019multi-objective,    \ntitle={Multi-Objective Value Iteration with Parameterized Threshold-Based Safety Constraints},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HyeS73ActX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Byxr73R5FQ","original":"Hye8Ba2qF7","number":1354,"cdate":1538087964771,"ddate":null,"tcdate":1538087964771,"tmdate":1538155937441,"tddate":null,"forum":"Byxr73R5FQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Successor Options : An Option Discovery Algorithm for Reinforcement Learning","abstract":"Hierarchical Reinforcement Learning is a popular method to exploit temporal abstractions in order to tackle the curse of dimensionality. The options framework is one such hierarchical framework that models the notion of skills or options. However, learning a collection of task-agnostic transferable skills is a challenging task. Option discovery typically entails using heuristics, the majority of which revolve around discovering bottleneck states. In this work, we adopt a method complementary to the idea of discovering bottlenecks. Instead, we attempt to discover ``landmark\" sub-goals which are prototypical states of well connected regions. These sub-goals are points from which densely connected set of states are easily accessible. We propose a new model called Successor options that leverages Successor Representations to achieve the same. We also design a novel pseudo-reward for learning the intra-option policies. Additionally, we describe an Incremental Successor options model that iteratively builds options and explores in environments where exploration through primitive actions is inadequate to form the Successor Representations. Finally, we demonstrate the efficacy of our approach on a collection of grid worlds and on complex high dimensional environments like Deepmind-Lab.\n","keywords":["Hierarchical Reinforcement Learning"],"authorids":["ICLR.cc/2019/Conference/Paper1354/Authors"],"authors":["Anonymous"],"TL;DR":"An option discovery method for Reinforcement Learning using the Successor Representation","pdf":"/pdf/21e0dbd50ac3ac600480379c855eb645cf47d8ef.pdf","paperhash":"anonymous|successor_options_an_option_discovery_algorithm_for_reinforcement_learning","_bibtex":"@inproceedings{    \nanonymous2019successor,    \ntitle={Successor Options : An Option Discovery Algorithm for Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byxr73R5FQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryzHXnR5Y7","original":"BkxAFx05Y7","number":1355,"cdate":1538087964947,"ddate":null,"tcdate":1538087964947,"tmdate":1538155937235,"tddate":null,"forum":"ryzHXnR5Y7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"SELECT VIA PROXY: EFFICIENT DATA SELECTION FOR TRAINING DEEP NETWORKS","abstract":"At internet scale, applications collect a tremendous amount of data by logging user events, analyzing text, and collecting images. This data powers a variety of machine learning models for tasks such as image classification, language modeling, content recommendation, and advertising. However, training large models over all available data can be computationally expensive, creating a bottleneck in the development of new machine learning models. In this work, we develop a novel approach to efficiently select a subset of training data to achieve faster training with no loss in model predictive performance. In our approach, we first train a small proxy model quickly, which we then use to estimate the utility of individual training data points, and then select the most informative ones for training the large target model. Extensive experiments show that our approach leads to a 1.6x and 1.8x speed-up on CIFAR10 and SVHN by selecting 60% and 50% subsets of the data, while maintaining the predictive performance of the model trained on the entire dataset. Further, our method is robust to design choices.","keywords":["data selection","deep learning","uncertainty sampling"],"authorids":["ICLR.cc/2019/Conference/Paper1355/Authors"],"authors":["Anonymous"],"TL;DR":"we develop an efficient method for selecting training data to quickly and efficiently learn large machine learning models.","pdf":"/pdf/d38914765bdec3c9a9662f8144bca10a2df73212.pdf","paperhash":"anonymous|select_via_proxy_efficient_data_selection_for_training_deep_networks","_bibtex":"@inproceedings{    \nanonymous2019select,    \ntitle={SELECT VIA PROXY: EFFICIENT DATA SELECTION FOR TRAINING DEEP NETWORKS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryzHXnR5Y7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkzSQhCcK7","original":"r1gQfcp9Fm","number":1356,"cdate":1538087965114,"ddate":null,"tcdate":1538087965114,"tmdate":1538155937024,"tddate":null,"forum":"HkzSQhCcK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"STCN: Stochastic Temporal Convolutional Networks","abstract":"Convolutional architectures have recently been shown to be competitive on many sequence modelling tasks when compared to the de-facto standard for sequence modeling of recurrent neural networks (RNNs), while providing significant computational advantages due to inherent parallelism.  However, there currently remains a performance gap to more expressive stochastic RNN variants, especially those with several layers of dependent random variables.  In this work, we propose stochastic temporal convolutional networks (STCNs) a novel architecture that combines the computational advantages of temporal convolutional networks (TCN) with the representational power and robustness of stochastic latent spaces.  In particular, we propose a hierarchy of latent variables, tightly integrated with blocks of dilated convolutions, that captures temporal dependencies at different time-scales. We show that the proposed architecture achieves state of the art log-likelihoods across several tasks.  Finally, we show that the model is capable of predicting high-quality synthetic samples over a long-range temporal horizon in a variety of tasks including modeling of handwritten individual digits and text.    ","keywords":["latent variables","variational inference","temporal convolutional networks","sequence modeling","auto-regressive modeling"],"authorids":["ICLR.cc/2019/Conference/Paper1356/Authors"],"authors":["Anonymous"],"TL;DR":"We combine the computational advantages of temporal convolutional architectures with the expressiveness of stochastic latent variables.","pdf":"/pdf/65976db707fd967c8e2ead6e69e5c3e4bdff7885.pdf","paperhash":"anonymous|stcn_stochastic_temporal_convolutional_networks","_bibtex":"@inproceedings{    \nanonymous2019stcn:,    \ntitle={STCN: Stochastic Temporal Convolutional Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkzSQhCcK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HygS7n0cFQ","original":"BJgsSv6qFm","number":1357,"cdate":1538087965285,"ddate":null,"tcdate":1538087965285,"tmdate":1538155936815,"tddate":null,"forum":"HygS7n0cFQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Fast Exploration with Simplified Models and Approximately Optimistic Planning in Model Based Reinforcement Learning","abstract":"Humans learn to play video games significantly faster than the state-of-the-art reinforcement learning (RL) algorithms. People seem to build simple models that are easy to learn to support planning and strategic exploration. Inspired by this, we investigate two issues in leveraging model-based RL for sample efficiency. First we investigate how to perform strategic exploration when exact planning is not feasible and empirically show that optimistic Monte Carlo Tree Search outperforms posterior sampling methods. Second we show how to learn simple deterministic models to support fast learning using object representation. We illustrate the benefit of these ideas by introducing a novel algorithm, Strategic Object Oriented Reinforcement Learning (SOORL), that outperforms state-of-the-art algorithms in the game of Pitfall! in less than 50 episodes.","keywords":["Reinforcement Learning","Strategic Exploration","Model Based Reinforcement Learning"],"authorids":["ICLR.cc/2019/Conference/Paper1357/Authors"],"authors":["Anonymous"],"TL;DR":"We studied exploration with imperfect planning and used object representation to learn simple models and introduced a new sample efficient RL algorithm that achieves state of the art results on Pitfall!","pdf":"/pdf/55f6170d303ecb98c0eb5a6bded7145f616e4227.pdf","paperhash":"anonymous|fast_exploration_with_simplified_models_and_approximately_optimistic_planning_in_model_based_reinforcement_learning","_bibtex":"@inproceedings{    \nanonymous2019fast,    \ntitle={Fast Exploration with Simplified Models and Approximately Optimistic Planning in Model Based Reinforcement Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HygS7n0cFQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJlSQnR5t7","original":"HJekaeTqKQ","number":1358,"cdate":1538087965454,"ddate":null,"tcdate":1538087965454,"tmdate":1538155936607,"tddate":null,"forum":"BJlSQnR5t7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Deepström Networks","abstract":"Recent work has focused on combining kernel methods and deep learning. With this in mind, we introduce Deepström networks -- a new architecture of neural networks which we use to replace top dense layers of standard convolutional architectures with an approximation of a kernel function by relying on the Nyström approximation. \nOur approach is easy highly flexible. It is compatible with any kernel function and it allows exploiting multiple kernels. \nWe show that Deepström networks reach state-of-the-art performance on standard datasets like SVHN and CIFAR100. One benefit of the method lies in its limited number of learnable parameters which make it particularly suited for small training set sizes, e.g. from 5 to 20 samples per class. Finally we illustrate two ways of using multiple kernels, including a multiple Deepström  setting, that exploits a kernel on each feature map output by the convolutional part of the model.    ","keywords":["kernels","Nyström approximation","deep convnets"],"authorids":["ICLR.cc/2019/Conference/Paper1358/Authors"],"authors":["Anonymous"],"TL;DR":"A new neural architecture where top dense layers of standard convolutional architectures are replaced with an approximation of a kernel function by relying on the Nyström approximation.","pdf":"/pdf/58aa26133d794a545700320dfeed0cfbda47e6ea.pdf","paperhash":"anonymous|deepström_networks","_bibtex":"@inproceedings{    \nanonymous2019deepström,    \ntitle={Deepström Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJlSQnR5t7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ByeLmn0qtX","original":"HkeW1mCcF7","number":1359,"cdate":1538087965619,"ddate":null,"tcdate":1538087965619,"tmdate":1538155936399,"tddate":null,"forum":"ByeLmn0qtX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Variational Domain Adaptation","abstract":"This paper proposes variational domain adaptation, a uniﬁed, scalable, simple\nframework for learning multiple distributions through variational inference. Un-\nlike the existing methods on domain transfer through deep generative models, such\nas CycleGAN (Zhu et al., 2017a) and StarGAN (Choi et al., 2017), the variational\ndomain adaptation has three advantages. Firstly, the samples from the target are\nnot required. Instead, the framework requries one known source as a prior p(x)\nand binary discriminators, p(D i |x), discriminating the target domain D i from oth-\ners. Consequently, the framework regards a target as a posterior that can be ex-\nplicitly formulated through the Bayesian inference, p(x|D i ) ∝ p(D i |x)p(x), as\nexhibited by a further proposed model of multi-domain variational autoencoder\n(MD-VAE). Secondly, the framework is scablable to large-scale domains. MD-\nVAE sophisticatedly puts together all the domains as well as the samples drawn\nfrom the prior into normal distributions in the same latent space as embeddings.\nThe model enables us to expand the method to uncountable inﬁnite domains such\nas continuous domains as well as interpolation. Thirdly, with MD-VAE, no need\nto search hyperparameter anymore. Although several domain transfer based on\nadversarial learning need sophisticated automatic/manual hyperparameter search,\nMD-VAE fast converges with less tuning because it has only one trainable matrix\nin addition to VAE. In the experiment part, we experimentally demonstrate the\nbeneﬁt with multi-domain image generation task on CelebA and facial image data\nthat are obtained based on evaluation by 60 users, the model generates an ideal\nimage that can be evaluated to be good by multiple users. Additionally, our exper-\nimental result exhibits that our model outperforms several state-of-the-art models.","keywords":["domain adaptation","variational inference","multi-domain"],"authorids":["ICLR.cc/2019/Conference/Paper1359/Authors"],"authors":["Anonymous"],"TL;DR":"This paper proposes variational domain adaptation, a uniﬁed, scalable, simple framework for learning multiple distributions through variational inference","pdf":"/pdf/2eb5ef07fa824dfff298134f8a268592f0a5a4a6.pdf","paperhash":"anonymous|variational_domain_adaptation","_bibtex":"@inproceedings{    \nanonymous2019variational,    \ntitle={Variational Domain Adaptation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByeLmn0qtX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Bkl87h09FX","original":"r1gsiO4BF7","number":1360,"cdate":1538087965790,"ddate":null,"tcdate":1538087965790,"tmdate":1538155936187,"tddate":null,"forum":"Bkl87h09FX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Looking for ELMo's friends: Sentence-Level Pretraining Beyond Language Modeling","abstract":"Work on the problem of contextualized word representation—the development of reusable neural network components for sentence understanding—has recently seen a  surge of progress centered on the unsupervised pretraining task of language modeling with methods like ELMo (Peters et al., 2018). This paper contributes the first large-scale systematic study comparing different pretraining tasks in this context, both as complements to language modeling and as potential alternatives. The primary results of the study support the use of language modeling as a pretraining task and set a new state of the art among comparable models using multitask learning with language models. However, a closer look at these results reveals worryingly strong baselines and strikingly varied results across target tasks, suggesting that the widely-used paradigm of pretraining and freezing sentence encoders may not be an ideal platform for further work.\n","keywords":["natural language processing","transfer learning","multitask learning"],"authorids":["ICLR.cc/2019/Conference/Paper1360/Authors"],"authors":["Anonymous"],"TL;DR":"We compare many tasks and task combinations for pretraining sentence-level BiLSTMs for NLP tasks. Language modeling is the best single pretraining task, but simple baselines also do well.","pdf":"/pdf/6fc8c16b4ec6a15f9f86d559fcb492cbb8712449.pdf","paperhash":"anonymous|looking_for_elmos_friends_sentencelevel_pretraining_beyond_language_modeling","_bibtex":"@inproceedings{    \nanonymous2019looking,    \ntitle={Looking for ELMo's friends: Sentence-Level Pretraining Beyond Language Modeling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Bkl87h09FX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkxLXnAcFQ","original":"H1lN44aqt7","number":1361,"cdate":1538087965960,"ddate":null,"tcdate":1538087965960,"tmdate":1538155935978,"tddate":null,"forum":"HkxLXnAcFQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A Closer Look at Few-shot Classification","abstract":"Few-shot classiﬁcation aims to learn a classiﬁer to recognize unseen classes during training with limited labeled examples. While signiﬁcant progress has been made, the growing complexity of network designs, meta-learning algorithms, and differences in implementation details make a fair comparison difﬁcult. In this paper, we present 1) a consistent comparative analysis of several representative few-shot classiﬁcation algorithms, with results showing that deeper backbones signiﬁcantly reduce the gap across methods including the baseline, 2) a slightly modiﬁed baseline method that surprisingly achieves competitive performance when compared with the state-of-the-art on both the mini-ImageNet and the CUB datasets, and 3) a new experimental setting for evaluating the cross-domain generalization ability for few-shot classiﬁcation algorithms. Our results reveal that reducing intra-class variation is an important factor when the feature backbone is shallow, but not as critical when using deeper backbones. In a realistic, cross-domain evaluation setting, we show that a baseline method with a standard ﬁne-tuning practice compares favorably against other state-of-the-art few-shot learning algorithms.","keywords":["few shot classification","meta-learning"],"authorids":["ICLR.cc/2019/Conference/Paper1361/Authors"],"authors":["Anonymous"],"TL;DR":" A detailed empirical study in few-shot classification that revealing challenges in standard evaluation setting and showing a new direction.","pdf":"/pdf/5a2a6a27a00dc2a8640a6da572404cb2e6efedf0.pdf","paperhash":"anonymous|a_closer_look_at_fewshot_classification","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A Closer Look at Few-shot Classification},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkxLXnAcFQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJxUX2C9Ym","original":"rylEgRTcFQ","number":1362,"cdate":1538087966126,"ddate":null,"tcdate":1538087966126,"tmdate":1538155935768,"tddate":null,"forum":"HJxUX2C9Ym","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Iterative Binary Decisions","abstract":"The complexity of functions a neural network approximates make it hard to explain what the classification decision is based on. In this work, we present a framework that exposes more information about this decision-making process. Instead of producing a classification in a single step, our model iteratively makes binary sub-decisions which, when combined as a whole, ultimately produces the same classification result while revealing a decision tree as thought process. While there is generally a trade-off between interpretability and accuracy, the insights our model generates come at a negligible loss in accuracy. The decision tree resulting from the sequence of binary decisions of our model reveal a hierarchical clustering of the data and can be used as learned attributes in zero-shot learning.","keywords":["explainable AI","interpretability","deep learning","decision tree","zero-shot learning"],"authorids":["ICLR.cc/2019/Conference/Paper1362/Authors"],"authors":["Anonymous"],"pdf":"/pdf/a66e6bbdcf336d21c6d37985525568e0e3a48402.pdf","paperhash":"anonymous|iterative_binary_decisions","_bibtex":"@inproceedings{    \nanonymous2019iterative,    \ntitle={Iterative Binary Decisions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJxUX2C9Ym},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1GIQhCcYm","original":"ryerFq35F7","number":1363,"cdate":1538087966304,"ddate":null,"tcdate":1538087966304,"tmdate":1538155935557,"tddate":null,"forum":"B1GIQhCcYm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Unsupervised  one-to-many image translation","abstract":"We perform completely unsupervised one-sided image to image translation between a source domain $X$ and a target domain $Y$ such that we preserve relevant underlying shared semantics (e.g., class, size, shape, etc). \nIn particular, we are interested in a more difficult case than those typically addressed in the literature, where the source and target are ``far\" enough that reconstruction-style or pixel-wise approaches fail.\nWe argue that transferring (i.e., \\emph{translating}) said relevant information should involve both discarding source domain-specific information while incorporate target domain-specific information, the latter of which we model with a noisy prior distribution. \nIn order to avoid the degenerate case where the generated samples are only explained by the prior distribution, we propose to minimize an estimate of the mutual information between the generated sample and the sample from the prior distribution. We discover that the architectural choices are an important factor to consider in order to preserve the shared semantic between $X$ and $Y$. \nWe show state of the art results on the MNIST to SVHN task for unsupervised image to image translation.","keywords":["Image-to-image","Translation","Unsupervised","Generation","Adversarial","Learning"],"authorids":["ICLR.cc/2019/Conference/Paper1363/Authors"],"authors":["Anonymous"],"TL;DR":"We train an image to image translation network that take as input the source image and a sample from a prior distribution to generate a sample from the target distribution","pdf":"/pdf/91fe2252aae23d28681a05d8039bf213989a7fd1.pdf","paperhash":"anonymous|unsupervised_onetomany_image_translation","_bibtex":"@inproceedings{    \nanonymous2019unsupervised,    \ntitle={Unsupervised  one-to-many image translation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1GIQhCcYm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1GLm2R9Km","original":"S1giBny9YX","number":1364,"cdate":1538087966470,"ddate":null,"tcdate":1538087966470,"tmdate":1538155935349,"tddate":null,"forum":"H1GLm2R9Km","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning More Interpretable, Backpropagation-Free Deep Architectures with Kernels","abstract":"One can substitute each neuron in any neural network with a kernel machine and obtain a counterpart powered by kernel machines. The new network inherits the expressive power and architecture of the original but works in a more intuitive way since each node enjoys the simple interpretation as a hyperplane (in a reproducing kernel Hilbert space). Further, using the kernel multilayer perceptron as an example, we prove that in classification, an optimal representation that minimizes the risk of the network can be characterized for each hidden layer. This result removes the need of backpropagation in learning the model and can be generalized to any feedforward kernel network. Moreover, unlike backpropagation, which turns models into black boxes, the optimal hidden representation enjoys an intuitive geometric interpretation, making the dynamics of learning in a deep kernel network simple to understand. Empirical results are provided to validate our theory.","keywords":["supervised learning","backpropagation-free deep architecture","kernel method","model interpretability"],"authorids":["ICLR.cc/2019/Conference/Paper1364/Authors"],"authors":["Anonymous"],"TL;DR":"We combine kernel method with connectionist models and show that the resulting deep architectures can be trained layer-wise and have more transparent learning dynamics. ","pdf":"/pdf/542a263967cbdcfd2e268a922aeffb6ebe7f7d66.pdf","paperhash":"anonymous|learning_more_interpretable_backpropagationfree_deep_architectures_with_kernels","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning More Interpretable, Backpropagation-Free Deep Architectures with Kernels},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1GLm2R9Km},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJgP7hR5YQ","original":"ryeBGLT5FX","number":1365,"cdate":1538087966632,"ddate":null,"tcdate":1538087966632,"tmdate":1538155935143,"tddate":null,"forum":"rJgP7hR5YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"COMPOSITION AND DECOMPOSITION OF GANS","abstract":"In this work, we propose a composition/decomposition framework for adversarially training generative models on composed data - data where each sample can be thought of as being constructed from a fixed number of components. In our framework, samples are generated by sampling components from component generators and feeding these components to a composition function which combines them into a “composed sample”. This compositional training approach improves the modularity, extensibility and interpretability of Generative Adversarial Networks (GANs) - providing a principled way to incrementally construct complex models out of simpler component models, and allowing for explicit “division of responsibility” between these components. Using this framework, we define a family of learning tasks and evaluate their feasibility on two datasets in two different data modalities (image and text). Lastly, we derive sufficient conditions such that these compositional generative models are identifiable. Our work provides a principled approach to building on pretrained generative models or for exploiting the compositional nature of data distributions to train extensible and interpretable models.\n","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1365/Authors"],"authors":["Anonymous"],"TL;DR":"GANs can be composed to build more complex models and decomposed to obtain building blocks","pdf":"/pdf/bfcefc69929a83938abc3b753b4eea0b68b47466.pdf","paperhash":"anonymous|composition_and_decomposition_of_gans","_bibtex":"@inproceedings{    \nanonymous2019composition,    \ntitle={COMPOSITION AND DECOMPOSITION OF GANS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJgP7hR5YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BkewX2C9tX","original":"SylcW6T5FX","number":1366,"cdate":1538087966805,"ddate":null,"tcdate":1538087966805,"tmdate":1538155934934,"tddate":null,"forum":"BkewX2C9tX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Analyzing Federated Learning through an Adversarial Lens","abstract":"Federated learning distributes model training among a multitude of agents, who, guided by privacy concerns, perform training using their local data but share only the parameter updates, for iterative aggregation at the server. In this work,  we operate within the confines of the federated learning paradigm, and explore the threat of targeted backdoor attacks on the global model, via model poisoning(as opposed to data poisoning) initiated by a single malicious agent with no collusion. Specifically, we consider a highly constrained adversary that (i) has partial observability into the model parameter space due to lack of knowledge of other agents’ updates;  (ii) operates in an environment where training data are i.i.d. between the agents (hence spurious updates will easily standout among benign ones); and(iii) has its single malicious update (mostly) cancelled by multiple benign updates.For this highly constrained adversary, we propose a sequence of model poisoning strategies that starting with malicious update boosting,  incrementally introduce various forms of regularization, followed by parameter estimation to improve on both attack success and stealth.  For each strategy, we analyze its impact on the model parameter space, design possible detection approaches and incorporate the insights for gaining stealth. Finally, we use a suite of interpretability techniques to generate visual explanations of the decision boundary and internal feature representations of a benign and malicious model and show that the explanations are nearly visually indistinguishable. Our evaluation results indicate that even a highly constrained adversary can generate successful model poisoning attacks while simultaneously maintaining stealth, thus highlighting the vulnerability of the federated learning setting and the need for effective defense strategies.","keywords":["federated learning","model poisoning"],"authorids":["ICLR.cc/2019/Conference/Paper1366/Authors"],"authors":["Anonymous"],"pdf":"/pdf/5db8d199242000d2a0c2f6af54a8a436ebb27bb0.pdf","paperhash":"anonymous|analyzing_federated_learning_through_an_adversarial_lens","_bibtex":"@inproceedings{    \nanonymous2019analyzing,    \ntitle={Analyzing Federated Learning through an Adversarial Lens},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BkewX2C9tX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Sylw7nCqFQ","original":"Syx_JFvoOm","number":1367,"cdate":1538087966981,"ddate":null,"tcdate":1538087966981,"tmdate":1538155934724,"tddate":null,"forum":"Sylw7nCqFQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"IMAGE DEFORMATION META-NETWORK FOR ONE-SHOT LEARNING","abstract":"Humans can robustly learn novel visual concepts even when images undergo various deformations and loose certain information. Incorporating this ability to synthesize deformed instances of new concepts might help visual recognition systems perform better one-shot learning, i.e., learning concepts from one or few examples. Our key insight is that, while the deformed images might not be visually realistic, they still maintain critical semantic information and contribute significantly in formulating classifier decision boundaries. Inspired by the recent progress on meta-learning, we combine a meta-learner with an image deformation network that produces additional training examples, and optimize both models in an endto- end manner. The deformation network learns to synthesize images by fusing a pair of images—a probe image that keeps the visual content and a gallery image that diversifies the deformations. We demonstrate results on the widely used oneshot learning benchmarks (miniImageNet and ImageNet 1K challenge datasets), which significantly outperform the previous state-of-the-art approaches.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1367/Authors"],"authors":["Anonymous"],"pdf":"/pdf/ed2810a0ec8c3f74e4f1404d164ca5c6bdfb07c6.pdf","paperhash":"anonymous|image_deformation_metanetwork_for_oneshot_learning","_bibtex":"@inproceedings{    \nanonymous2019image,    \ntitle={IMAGE DEFORMATION META-NETWORK FOR ONE-SHOT LEARNING},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Sylw7nCqFQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyMDXnCcF7","original":"B1euLbAqF7","number":1368,"cdate":1538087967148,"ddate":null,"tcdate":1538087967148,"tmdate":1538155934519,"tddate":null,"forum":"SyMDXnCcF7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A Mean Field Theory of Batch Normalization","abstract":"We develop a mean field theory for batch normalization in fully-connected feedforward neural networks. In so doing, we provide a precise characterization of signal propagation and gradient backpropagation in wide batch-normalized networks at initialization. We find that gradient signals grow exponentially in depth and that these exploding gradients cannot be eliminated by tuning the initial weight variances or by adjusting the nonlinear activation function. Indeed, batch normalization itself is the cause of gradient explosion. As a result, vanilla batch-normalized networks without skip connections are not trainable at large depths for common initialization schemes, a prediction that we verify with a variety of empirical simulations. While gradient explosion cannot be eliminated, it can be reduced by tuning the network close to the linear regime, which improves the trainability of deep batch-normalized networks without residual connections. Finally, we investigate the learning dynamics of batch-normalized networks and observe that after a single step of optimization the networks achieve a relatively stable equilibrium in which gradients have dramatically smaller dynamic range.","keywords":["theory","batch normalization","mean field theory","trainability"],"authorids":["ICLR.cc/2019/Conference/Paper1368/Authors"],"authors":["Anonymous"],"TL;DR":"Batch normalization causes exploding gradients in vanilla feedforward networks.","pdf":"/pdf/6e50613b991606e617800256ca9f5e3935db63f3.pdf","paperhash":"anonymous|a_mean_field_theory_of_batch_normalization","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A Mean Field Theory of Batch Normalization},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyMDXnCcF7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkMD73A5FX","original":"BJl1mFacKX","number":1369,"cdate":1538087967316,"ddate":null,"tcdate":1538087967316,"tmdate":1538155934312,"tddate":null,"forum":"rkMD73A5FX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Can I trust you more? Model-Agnostic Hierarchical Explanations","abstract":"Interactions such as double negation in sentences and scene interactions in images are common forms of complex dependencies captured by state-of-the-art machine learning models. We propose Mahé, a novel approach to provide Model-Agnostic Hierarchical Explanations of how powerful machine learning models, such as deep neural networks, capture these dependencies, either context-dependent or context-free.  Specifically, Mahé provides context-dependent explanations by a novel local interpretation algorithm that effectively captures any-order interactions, and obtains context-free explanations through generalizing context-dependent interactions to explain global behaviors. Experimental results show that Mahé obtains improved local interaction interpretations over state-of-the-art methods and successfully provides explanations of interactions that are context-free.","keywords":["interpretability","interactions","context-dependent","context-free"],"authorids":["ICLR.cc/2019/Conference/Paper1369/Authors"],"authors":["Anonymous"],"TL;DR":"A new framework for context-dependent and context-free explanations of predictions","pdf":"/pdf/7111a5cb3269fc51ca7ba3714765358c14ea4006.pdf","paperhash":"anonymous|can_i_trust_you_more_modelagnostic_hierarchical_explanations","_bibtex":"@inproceedings{    \nanonymous2019can,    \ntitle={Can I trust you more? Model-Agnostic Hierarchical Explanations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkMD73A5FX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1lvm305YQ","original":"S1x6TbRcFX","number":1370,"cdate":1538087967507,"ddate":null,"tcdate":1538087967507,"tmdate":1538155934105,"tddate":null,"forum":"S1lvm305YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"TimbreTron: A WaveNet(CycleGAN(CQT(Audio))) Pipeline for Musical Timbre Transfer","abstract":"In this work, we address the problem of musical timbre transfer, where the goal is to manipulate the timbre of a sound sample from one instrument to match another instrument while preserving other musical content, such as pitch, rhythm, and loudness. In principle, one could apply image-based style transfer techniques to a time-frequency representation of an audio signal, but this depends on having a representation that allows independent manipulation of timbre as well as high-quality waveform generation. We introduce TimbreTron, an audio processing pipeline which combines three powerful ideas from different domains: Constant Q Transform (CQT) spectrogram for audio representation, a variant of CycleGAN for timbre transfer and WaveNet-Synthesizer for high quality audio generation. We verified that CQT TimbreTron in principle and in practice is more suitable than its STFT counterpart, even though STFT is more commonly used for audio representation. Based on human perceptual evaluations, we confirmed that timbre was transferred recognizably while the musical content was preserved by TimbreTron.","keywords":["Generative models","Timbre Transfer","Wavenet","CycleGAN"],"authorids":["ICLR.cc/2019/Conference/Paper1370/Authors"],"authors":["Anonymous"],"TL;DR":"We present the TimbreTron, a pipeline for perfoming high-quality timbre transfer on musicalwaveforms using CQT-domain style transfer.","pdf":"/pdf/96506a9dc1eb087864205da3fe2c5e098aab19cc.pdf","paperhash":"anonymous|timbretron_a_wavenetcyclegancqtaudio_pipeline_for_musical_timbre_transfer","_bibtex":"@inproceedings{    \nanonymous2019timbretron:,    \ntitle={TimbreTron: A WaveNet(CycleGAN(CQT(Audio))) Pipeline for Musical Timbre Transfer},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1lvm305YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1gd7nCcF7","original":"S1e5Z7T5F7","number":1372,"cdate":1538087967846,"ddate":null,"tcdate":1538087967846,"tmdate":1538155933901,"tddate":null,"forum":"S1gd7nCcF7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Self-Supervised Generalisation with Meta Auxiliary Learning","abstract":"Auxiliary learning has been shown to improve the generalisation performance of a principal task. But typically, this requires manually-defined auxiliary tasks based on domain knowledge. In this paper, we consider that it may be possible to automatically learn these auxiliary tasks to best suit the principal task, towards optimum auxiliary tasks without any human knowledge. We propose a novel method, Meta Auxiliary Learning (MAXL), which we design for the task of image classification, where the auxiliary task is hierarchical sub-class image classification. The role of the meta learner is to determine sub-class target labels to train a multi-task evaluator, such that these labels improve the generalisation performance on the principal task. Experiments on three different CIFAR datasets show that MAXL outperforms baseline auxiliary learning methods, and is competitive even with a method which uses human-defined sub-class hierarchies. MAXL is self-supervised and general, and therefore offers a promising new direction towards automated generalisation.","keywords":["meta learning","auxiliary learning","multi-task learning","self-supervised learning"],"authorids":["ICLR.cc/2019/Conference/Paper1372/Authors"],"authors":["Anonymous"],"TL;DR":"We propose Meta AuXiliary Learning (MAXL), a learning framework which can automatically generate auxiliary tasks to improve generalisation of the principal task in a self-supervised manner. ","pdf":"/pdf/a1ec729447ebde35fed52f6adbe392725c0fa310.pdf","paperhash":"anonymous|selfsupervised_generalisation_with_meta_auxiliary_learning","_bibtex":"@inproceedings{    \nanonymous2019self-supervised,    \ntitle={Self-Supervised Generalisation with Meta Auxiliary Learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1gd7nCcF7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SJf_XhCqKm","original":"SJgZ-z0qt7","number":1373,"cdate":1538087968021,"ddate":null,"tcdate":1538087968021,"tmdate":1538155933700,"tddate":null,"forum":"SJf_XhCqKm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Open Loop Hyperparameter Optimization and Determinantal Point Processes","abstract":"Driven by the need for parallelizable hyperparameter optimization methods, this paper studies open loop search methods: sequences that are predetermined and can be generated before a single configuration is evaluated. Examples include grid search, uniform random search, low discrepancy sequences, and other sampling distributions.\nIn particular, we propose the use of k-determinantal point processes in  hyperparameter optimization via random search. Compared to conventional uniform random search where hyperparameter settings are sampled independently, a k-DPP promotes diversity.  We describe an approach that transforms hyperparameter search spaces for efficient use with a k-DPP. In addition, we introduce a novel Metropolis-Hastings algorithm which can sample from k-DPPs defined over any space from which uniform samples can be drawn, including spaces with a mixture of discrete and continuous dimensions or tree structure. Our experiments show significant benefits  in realistic scenarios with a limited budget for training supervised learners, whether in serial or parallel.","keywords":["hyperparameter optimization","black box optimization"],"authorids":["ICLR.cc/2019/Conference/Paper1373/Authors"],"authors":["Anonymous"],"TL;DR":"We address fully parallel hyperparameter optimization with Determinantal Point Processes. ","pdf":"/pdf/3531cd38c529efc4f988285026fa60bc6ffe9575.pdf","paperhash":"anonymous|open_loop_hyperparameter_optimization_and_determinantal_point_processes","_bibtex":"@inproceedings{    \nanonymous2019open,    \ntitle={Open Loop Hyperparameter Optimization and Determinantal Point Processes},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SJf_XhCqKm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJfOXnActQ","original":"SJgrzW05FX","number":1374,"cdate":1538087968189,"ddate":null,"tcdate":1538087968189,"tmdate":1538155933487,"tddate":null,"forum":"BJfOXnActQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Learning to Learn with Conditional Class Dependencies","abstract":"Neural networks can learn to extract statistical properties from data, but they seldom make use of structured information from the label space to help representation learning. Although some label structure can implicitly be obtained when training on huge amounts of data, in a few-shot learning context where little data is available, making explicit use of the label structure can inform the model to reshape the representation space to reflect a global sense of class dependencies.  We propose a meta-learning framework, Conditional class-Aware Meta-Learning (CAML), that conditionally transforms feature representations based on a metric space that is trained to capture inter-class dependencies. This enables a conditional modulation of the feature representations of the base-learner to impose regularities informed by the label space. Experiments show that the conditional transformation in CAML leads to more disentangled representations and achieves competitive results on the miniImageNet benchmark.","keywords":["meta-learning","learning to learn","few-shot learning"],"authorids":["ICLR.cc/2019/Conference/Paper1374/Authors"],"authors":["Anonymous"],"TL;DR":"CAML is an instance of MAML with conditional class dependencies.","pdf":"/pdf/adf2c8167eb2cc07c43f236b3914f88210758c6d.pdf","paperhash":"anonymous|learning_to_learn_with_conditional_class_dependencies","_bibtex":"@inproceedings{    \nanonymous2019learning,    \ntitle={Learning to Learn with Conditional Class Dependencies},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJfOXnActQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkVOXhAqY7","original":"HJerTRnqtX","number":1375,"cdate":1538087968365,"ddate":null,"tcdate":1538087968365,"tmdate":1538155933286,"tddate":null,"forum":"rkVOXhAqY7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"The Conditional Entropy Bottleneck","abstract":"We present a new family of objective functions, which we term the Conditional Entropy Bottleneck (CEB). We demonstrate the application of CEB to classification tasks. In our experiments, CEB gives: well-calibrated predictions; essentially perfect detection of challenging out-of-distribution examples and powerful whitebox adversarial examples; and natural robustness to the same. Finally, we report that CEB fails to learn a dataset with fixed random labels, providing a possible resolution to the problem of generalization observed in Zhang et al. (2016).","keywords":["representation learning","information theory","uncertainty","out-of-distribution detection","adversarial example robustness","generalization","objective function"],"authorids":["ICLR.cc/2019/Conference/Paper1375/Authors"],"authors":["Anonymous"],"TL;DR":"The Conditional Entropy Bottleneck is an information-theoretic objective function for learning optimal representations.","pdf":"/pdf/3303528454f54a58ebb10d2cc4e1fbee51bf41a9.pdf","paperhash":"anonymous|the_conditional_entropy_bottleneck","_bibtex":"@inproceedings{    \nanonymous2019the,    \ntitle={The Conditional Entropy Bottleneck},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkVOXhAqY7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1ltQ3R9KQ","original":"B1eP38n9Y7","number":1376,"cdate":1538087968533,"ddate":null,"tcdate":1538087968533,"tmdate":1538155933075,"tddate":null,"forum":"H1ltQ3R9KQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Causal Reasoning from Meta-learning","abstract":"Discovering and exploiting the causal structure in data is a crucial challenge for intelligent agents. Though powerful formalisms for causal reasoning have been developed, applying them in real-world domains is often difficult because the frameworks make idealized assumptions. Here we explore whether modern deep reinforcement learning can be used to train agents to perform causal reasoning, without incorporating explicit principles of causal reasoning. We adopt a meta-learning approach, where the agent learns a policy for conducting experiments via causal interventions, in order to support a subsequent task which rewards making accurate causal inferences. We also found the agent could make sophisticated counterfactual predictions, as well as learn to draw causal inferences from passive observational data, when such inferences were possible. Our results suggest that applied causal reasoning in complex settings may benefit from powerful learning-based approaches. More generally, this work may offer new strategies for structured exploration in reinforcement learning, by providing agents with the ability to perform and interpret experiments.","keywords":["meta-learning","causal reasoning","deep reinforcement learning","artificial intelligence"],"authorids":["ICLR.cc/2019/Conference/Paper1376/Authors"],"authors":["Anonymous"],"TL;DR":"meta-learn a learning algorithm capable of causal reasoning","pdf":"/pdf/e5ec5eb9f534d19da6a41b820d116296e25986c0.pdf","paperhash":"anonymous|causal_reasoning_from_metalearning","_bibtex":"@inproceedings{    \nanonymous2019causal,    \ntitle={Causal Reasoning from Meta-learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1ltQ3R9KQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJlt7209Km","original":"HkxQDfAqtQ","number":1377,"cdate":1538087968704,"ddate":null,"tcdate":1538087968704,"tmdate":1538155932868,"tddate":null,"forum":"HJlt7209Km","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Theoretical and Empirical Study of Adversarial Examples","abstract":"Many techniques are developed to defend against adversarial examples at scale. So far, the most successful defenses generate adversarial examples during each training step and add them to the training data. Yet, this brings significant computational overhead.  In this paper, we investigate defenses against adversarial attacks. First, we propose feature smoothing, a simple data augmentation method with little computational overhead. Essentially, feature smoothing trains a neural network on virtual training data as an interpolation of features from a pair of samples, with the new label remaining the same as the dominant data point.  The intuition behind feature smoothing is to generate virtual data points as close as adversarial examples, and to avoid the computational burden of generating data during training. Our experiments on MNIST and CIFAR10 datasets explore different combinations of known regularization and data augmentation methods and show that feature smoothing with logit squeezing performs best for both adversarial and clean accuracy. Second, we propose an unified framework to understand the connections and differences among different efficient methods by analyzing the biases and variances of decision boundary. We show that under some symmetrical assumptions, label smoothing, logit squeezing, weight decay, mix up and feature smoothing all produce an unbiased estimation of the decision boundary with smaller estimated variance. All of those methods except weight decay are also stable when the assumptions no longer hold.","keywords":["Adversarial examples","Feature smoothing","Data augmentation","Decision boundary"],"authorids":["ICLR.cc/2019/Conference/Paper1377/Authors"],"authors":["Anonymous"],"pdf":"/pdf/76464c5355c85e5069dc29348781f264867a321e.pdf","paperhash":"anonymous|theoretical_and_empirical_study_of_adversarial_examples","_bibtex":"@inproceedings{    \nanonymous2019theoretical,    \ntitle={Theoretical and Empirical Study of Adversarial Examples},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJlt7209Km},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkgYmhR9KX","original":"rkeG6Xi9FQ","number":1378,"cdate":1538087968875,"ddate":null,"tcdate":1538087968875,"tmdate":1538155932656,"tddate":null,"forum":"HkgYmhR9KX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"AD-VAT: An Asymmetric Dueling mechanism for learning Visual Active Tracking","abstract":"Visual active tracking (VAT) aims at following a target object by autonomously controlling the motion system of a tracker given visual observations. In this paper, we propose a novel method which adopts an asymmetric dueling mechanism for learning visual active tracking, namely AD-VAT. In AD-VAT, the target and the tracker are mutual opponents, i.e, the tracker manages to lockup the target, and the target tries to escape from the tracker. In the implementation, both the tracker and the target are approximated by deep networks, and their policies that map environment observations to control actions can be learned via reinforcement learning in an end-to-end manner. The tracker and the target are asymmetric in observations, network structures and reward functions. Different from the tracker, the target is modeled with a tracker-aware network, i.e, besides its own observation, the tracker's observations and actions are also fed as input to the network. In addition, it learns to predict the tracker's reward as an auxiliary task.  We argue that such an asymmetric adversarial mechanism is able to learn a stronger target,  which vice versa induces a more robust tracker. The experimental results, in both 2D and 3D environments, demonstrate that the proposed method leads to a faster convergence in training the tracker and more robust tracking behaviors in different testing scenarios.","keywords":["Active tracking","reinforcement learning","adversarial learning","multi agent"],"authorids":["ICLR.cc/2019/Conference/Paper1378/Authors"],"authors":["Anonymous"],"TL;DR":"We propose AD-VAT, where the tracker and the target object, viewed as two learnable agents, are opponents and can mutually enhance during training.","pdf":"/pdf/8fec03cfa2542493a50e891efa398ffbb21569c9.pdf","paperhash":"anonymous|advat_an_asymmetric_dueling_mechanism_for_learning_visual_active_tracking","_bibtex":"@inproceedings{    \nanonymous2019ad-vat:,    \ntitle={AD-VAT: An Asymmetric Dueling mechanism for learning Visual Active Tracking},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkgYmhR9KX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rygFmh0cKm","original":"H1lqdpT9KX","number":1379,"cdate":1538087969052,"ddate":null,"tcdate":1538087969052,"tmdate":1538155932439,"tddate":null,"forum":"rygFmh0cKm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"On Difficulties of Probability Distillation","abstract":"Probability distillation has recently been of interest to deep learning practitioners as it presents a practical solution for sampling from autoregressive models for deployment in real-time applications. We identify a pathological optimization issue with the commonly adopted stochastic minimization of the (reverse) KL divergence, owing to sparse gradient signal from the teacher model due to curse of dimensionality. We also explore alternative principles for distillation, and show that one can achieve qualitatively better results than with KL minimization. \n","keywords":["Probability distillation","Autoregressive models","normalizing flows","wavenet","pixelcnn"],"authorids":["ICLR.cc/2019/Conference/Paper1379/Authors"],"authors":["Anonymous"],"TL;DR":"We point out an optimization issue of distillation with KL divergence, and explore different alternatives","pdf":"/pdf/332c8efc16bd5dd346473190cbd34ce6dedfe5a4.pdf","paperhash":"anonymous|on_difficulties_of_probability_distillation","_bibtex":"@inproceedings{    \nanonymous2019on,    \ntitle={On Difficulties of Probability Distillation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rygFmh0cKm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryxY73AcK7","original":"BJxFw76qF7","number":1380,"cdate":1538087969222,"ddate":null,"tcdate":1538087969222,"tmdate":1538155932226,"tddate":null,"forum":"ryxY73AcK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Universal Lipschitz Functions","abstract":"Training neural networks with a Lipschitz constraint provides improved generalization, robustness, and interpretability. However, existing techniques either fail to guarantee a Lipschitz constraint or are unable to universally approximate Lipschitz functions. Often, a small Lipschitz constant is enforced by considering constraints on the network weights, but little attention is payed to the choice of activation function. We identify Jacobian norm of network layers as a scarce resource in representing Lipschitz functions and show that common activation functions are unable to effectively utilize this. We show that with common activation functions networks are unable to learn even the simplest Lipschitz functions, such as the absolute value function. With this insight, we introduce a novel activation function, the GroupSort activation, which partitions the hidden layer and sorts the units within each partition. Empirically, we identify pathologies of common activation functions and confirm that these theoretical observations are relevant in practice. ","keywords":["deep learning","lipschitz neural networks","generalization","universal approximation","adversarial examples","generative models","optimal transport"],"authorids":["ICLR.cc/2019/Conference/Paper1380/Authors"],"authors":["Anonymous"],"TL;DR":"We identify pathologies in existing activation functions when learning neural networks with Lipschitz constraints and use these insights to design neural networks which are universal Lipschitz function approximators.","pdf":"/pdf/a6742db599d34a12d7f1129fd9fee909d1354ced.pdf","paperhash":"anonymous|universal_lipschitz_functions","_bibtex":"@inproceedings{    \nanonymous2019universal,    \ntitle={Universal Lipschitz Functions},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryxY73AcK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJxF73R9tX","original":"Bkx26o69Km","number":1381,"cdate":1538087969392,"ddate":null,"tcdate":1538087969392,"tmdate":1538155932017,"tddate":null,"forum":"rJxF73R9tX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Knows When it Doesn’t Know: Deep Abstaining Classifiers","abstract":"We introduce the deep abstaining classifier -- a deep neural network trained with a novel loss function that provides an abstention option during training. This allows  the DNN to abstain on confusing or difficult-to-learn examples while improving performance on the non-abstained samples. We show that such deep abstaining classifiers can: (i) learn representations for structured noise -- where noisy training labels or confusing examples are correlated with underlying features -- and then learn to abstain based on such features; (ii) enable robust learning in the presence of arbitrary or unstructured noise by identifying noisy samples; and (iii) be used as an effective out-of-category detector that learns to reliably abstain when presented with samples from  unknown classes. We provide analytical results on loss function behavior that enable automatic tuning of accuracy and coverage. We demonstrate the utility of the deep abstaining classifier using multiple image benchmarks.","keywords":["deep learning","robust learning","abstention","representation learning","abstaining classifier","open-set detection"],"authorids":["ICLR.cc/2019/Conference/Paper1381/Authors"],"authors":["Anonymous"],"TL;DR":"A deep abstaining neural network trained with a novel loss function that learns representations for when to abstain enabling robust learning in the presence of different types of noise.","pdf":"/pdf/dd755be26d271f0052f6ca432f9167ecab295802.pdf","paperhash":"anonymous|knows_when_it_doesnt_know_deep_abstaining_classifiers","_bibtex":"@inproceedings{    \nanonymous2019knows,    \ntitle={Knows When it Doesn’t Know: Deep Abstaining Classifiers},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJxF73R9tX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"S1ecm2C9K7","original":"SJxe0x0qFX","number":1382,"cdate":1538087969558,"ddate":null,"tcdate":1538087969558,"tmdate":1538155931809,"tddate":null,"forum":"S1ecm2C9K7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Feature-Wise Bias Amplification","abstract":"We study the phenomenon of bias amplification in classifiers, wherein a machine learning model learns to predict classes with a greater disparity than the underlying ground truth. We demonstrate that bias amplification can arise via inductive bias in gradient descent methods resulting in overestimation of importance of moderately-predictive ``weak'' features if insufficient training data is available. This overestimation gives rise to feature-wise bias amplification -- a previously unreported form of bias that can be traced back to the features of a trained model. Through analysis and experiments, we show that the while some bias cannot be mitigated without sacrificing accuracy, feature-wise bias amplification can be mitigated through targeted feature selection. We present two new feature selection algorithms for mitigating bias amplification in linear models, and show how they can be adapted to convolutional neural networks efficiently. Our experiments on synthetic and real data demonstrate that these algorithms consistently lead to reduced bias without harming accuracy, in some cases eliminating predictive bias altogether while providing modest gains in accuracy.","keywords":["bias","bias amplification","classification"],"authorids":["ICLR.cc/2019/Conference/Paper1382/Authors"],"authors":["Anonymous"],"pdf":"/pdf/6002968e345eb4774f3a8a861d1bfa414ea027e1.pdf","paperhash":"anonymous|featurewise_bias_amplification","_bibtex":"@inproceedings{    \nanonymous2019feature-wise,    \ntitle={Feature-Wise Bias Amplification},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=S1ecm2C9K7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"H1e572A5tQ","original":"S1g3_03qFm","number":1383,"cdate":1538087969720,"ddate":null,"tcdate":1538087969720,"tmdate":1538155931597,"tddate":null,"forum":"H1e572A5tQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"TarMAC: Targeted Multi-Agent Communication","abstract":"We explore the collaborative multi-agent setting where a team of deep reinforcement learning agents attempt to solve a shared task in partially observable environments. In this scenario, learning an effective communication protocol is key. We propose a communication protocol that allows for targeted communication, where agents learn \\emph{what} messages to send and \\emph{who} to send them to. Additionally, we introduce a multi-stage communication approach where the agents co-ordinate via several rounds of communication before taking an action in the environment. We evaluate our approach on several cooperative multi-agent tasks, of varying difficulties with varying number of agents, in a variety of environments ranging from 2D grid layouts of shapes and simulated traffic junctions to complex 3D indoor environments. We demonstrate the benefits of targeted as well as multi-stage communication. Moreover, we show that the targeted communication strategies learned by the agents are quite interpretable and intuitive.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1383/Authors"],"authors":["Anonymous"],"TL;DR":"Targeted communication in multi-agent cooperative reinforcement learning","pdf":"/pdf/3423bb3b9be8759b098b8e3b7d6a9f506eb042e3.pdf","paperhash":"anonymous|tarmac_targeted_multiagent_communication","_bibtex":"@inproceedings{    \nanonymous2019tarmac:,    \ntitle={TarMAC: Targeted Multi-Agent Communication},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=H1e572A5tQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Byg5QhR5FQ","original":"H1xeFkAqFX","number":1384,"cdate":1538087969893,"ddate":null,"tcdate":1538087969893,"tmdate":1538155931385,"tddate":null,"forum":"Byg5QhR5FQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Top-Down Neural Model For Formulae","abstract":"We present a simple neural model that given a formula and a property tries to answer the question whether the formula has the given property, for example whether a propositional formula is always true. A structure of formula is captured by a feedforward neural network build recursively for the given formula in a top-down manner. The results of this network are then processed by two recurrent neural networks. One of the interesting aspects of our model is that how propositional atoms are treated. They do not occur explicitly in our model, they only influence how the final model looks like, but for example their names are completely irrelevant.\n","keywords":["logic","formula","recursive neural networks","recurrent neural networks"],"authorids":["ICLR.cc/2019/Conference/Paper1384/Authors"],"authors":["Anonymous"],"TL;DR":"A top-down approach how to recursively represent propositional formulae by neural networks is presented.","pdf":"/pdf/d76822cfe465a30a52abaf380494ad62ec2344f7.pdf","paperhash":"anonymous|topdown_neural_model_for_formulae","_bibtex":"@inproceedings{    \nanonymous2019top-down,    \ntitle={Top-Down Neural Model For Formulae},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Byg5QhR5FQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Syf9Q209YQ","original":"rJe70FnqY7","number":1385,"cdate":1538087970125,"ddate":null,"tcdate":1538087970125,"tmdate":1538155931174,"tddate":null,"forum":"Syf9Q209YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Manifold regularization with GANs for semi-supervised learning","abstract":"Generative Adversarial Networks are powerful generative models that can model the manifold of natural images. We leverage this property to perform manifold regularization by approximating a variant of the Laplacian norm using a Monte Carlo approximation that is easily computed with the GAN. When incorporated into the semi-supervised feature-matching GAN we achieve state-of-the-art results for GAN-based semi-supervised learning on CIFAR-10 and SVHN benchmarks, with a method that is significantly easier to implement than competing methods. We find that manifold regularization improves the quality of generated images, and is affected by the quality of the GAN used to approximate the regularizer.","keywords":["semi-supervised learning","generative adversarial networks","manifold regularization"],"authorids":["ICLR.cc/2019/Conference/Paper1385/Authors"],"authors":["Anonymous"],"pdf":"/pdf/4422407e3fd49b67dda7a2364138fb84499a1086.pdf","paperhash":"anonymous|manifold_regularization_with_gans_for_semisupervised_learning","_bibtex":"@inproceedings{    \nanonymous2019manifold,    \ntitle={Manifold regularization with GANs for semi-supervised learning},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Syf9Q209YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ByGq7hRqKX","original":"Skx4sVgdKX","number":1386,"cdate":1538087970294,"ddate":null,"tcdate":1538087970294,"tmdate":1538155930964,"tddate":null,"forum":"ByGq7hRqKX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Cross-Task Knowledge Transfer for Visually-Grounded Navigation","abstract":"Recent efforts on training visual navigation agents conditioned on language using deep reinforcement learning have been successful in learning policies for two different tasks: learning to follow navigational instructions and embodied question answering. In this paper, we aim to learn a multitask model capable of jointly learning both tasks, and transferring knowledge of words and their grounding in visual objects across tasks. The proposed model uses a novel Dual-Attention unit to disentangle the knowledge of words in the textual representations and visual objects in the visual representations, and align them with each other. This disentangled task-invariant alignment of representations facilitates grounding and knowledge transfer across both tasks. We show that the proposed model outperforms a range of baselines on both tasks in simulated 3D environments. We also show that this disentanglement of representations makes our model modular, interpretable, and allows for zero-shot transfer to instructions containing new words by leveraging object detectors.","keywords":[],"authorids":["ICLR.cc/2019/Conference/Paper1386/Authors"],"authors":["Anonymous"],"pdf":"/pdf/5b3117cfa2e5e7780a0a15953dae10b9b027815a.pdf","paperhash":"anonymous|crosstask_knowledge_transfer_for_visuallygrounded_navigation","_bibtex":"@inproceedings{    \nanonymous2019cross-task,    \ntitle={Cross-Task Knowledge Transfer for Visually-Grounded Navigation},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ByGq7hRqKX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rJ4qXnCqFX","original":"HklagkpcKm","number":1387,"cdate":1538087970460,"ddate":null,"tcdate":1538087970460,"tmdate":1538155930746,"tddate":null,"forum":"rJ4qXnCqFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Probabilistic Knowledge Graph Embeddings","abstract":"We develop a probabilistic extension of state-of-the-art embedding models for link prediction in relational knowledge graphs. Knowledge graphs are collections of relational facts, where each fact states that a certain relation holds between two entities, such as people, places, or objects. We argue that knowledge graphs should be treated within a Bayesian framework because even large knowledge graphs typically contain only few facts per entity, leading effectively to a small data problem where parameter uncertainty matters. We introduce a probabilistic reinterpretation of the DistMult (Yang et al., 2015) and ComplEx (Trouillon et al., 2016) models and employ variational inference to estimate a lower bound on the marginal likelihood of the data. We find that the main benefit of the Bayesian approach is that it allows for efficient, gradient based optimization over hyperparameters, which would lead to divergences in a non-Bayesian treatment. Models with such learned hyperparameters improve over the state-of-the-art by a significant margin, as we demonstrate on several benchmarks.","keywords":["knowledge graph","variational inference","probabilistic models","representation learning"],"authorids":["ICLR.cc/2019/Conference/Paper1387/Authors"],"authors":["Anonymous"],"TL;DR":"Scalable hyperparameter learning for knowledge graph embedding models using variational EM","pdf":"/pdf/6177f277dc7b7f59c89807d4238042483f696387.pdf","paperhash":"anonymous|probabilistic_knowledge_graph_embeddings","_bibtex":"@inproceedings{    \nanonymous2019probabilistic,    \ntitle={Probabilistic Knowledge Graph Embeddings},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rJ4qXnCqFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SkgiX2Aqtm","original":"SklRPf05tm","number":1388,"cdate":1538087970694,"ddate":null,"tcdate":1538087970694,"tmdate":1538155930536,"tddate":null,"forum":"SkgiX2Aqtm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"PIE: Pseudo-Invertible Encoder","abstract":"We consider the problem of information compression from high dimensional data. Where many studies consider the problem of compression by non-invertible trans- formations, we emphasize the importance of invertible compression. We introduce new class of likelihood-based auto encoders with pseudo bijective architecture, which we call Pseudo Invertible Encoders. We provide the theoretical explanation of their principles. We evaluate Gaussian Pseudo Invertible Encoder on MNIST, where our model outperform WAE and VAE in sharpness of the generated images.","keywords":["Invertible Mappings","Bijectives","Dimensionality reduction","Autoencoder"],"authorids":["ICLR.cc/2019/Conference/Paper1388/Authors"],"authors":["Anonymous"],"TL;DR":"New Class of Autoencoders with pseudo invertible architecture","pdf":"/pdf/4a50784150a5a5917d0281159ab0819601cab6ba.pdf","paperhash":"anonymous|pie_pseudoinvertible_encoder","_bibtex":"@inproceedings{    \nanonymous2019pie:,    \ntitle={PIE: Pseudo-Invertible Encoder},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SkgiX2Aqtm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hyls7h05FQ","original":"ryx6bfCcFQ","number":1389,"cdate":1538087970863,"ddate":null,"tcdate":1538087970863,"tmdate":1538155930317,"tddate":null,"forum":"Hyls7h05FQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A Differentiable Self-disambiguated Sense Embedding Model via Scaled Gumbel Softmax","abstract":"We present a differentiable multi-prototype word representation model that disentangles senses of polysemous words and produces meaningful sense-specific embeddings without external resources. It jointly learns how to disambiguate senses given local context and how to represent senses using hard attention. Unlike previous multi-prototype models, our model approximates discrete sense selection in a differentiable manner via a modified Gumbel softmax. We also propose a novel human evaluation task that quantitatively measures (1) how meaningful the learned sense groups are to humans and (2) how well the model is able to disambiguate senses given a context sentence. Our model outperforms competing approaches on both human evaluations and multiple word similarity tasks.","keywords":["unsupervised representation learning","sense embedding","word sense disambiguation","human evaluation"],"authorids":["ICLR.cc/2019/Conference/Paper1389/Authors"],"authors":["Anonymous"],"TL;DR":"Disambiguate and embed word senses with a differentiable hard-attention model using Scaled Gumbel Softmax","pdf":"/pdf/4c1e637c66cb5275d8f08b9b8c4baae6c4e2dd47.pdf","paperhash":"anonymous|a_differentiable_selfdisambiguated_sense_embedding_model_via_scaled_gumbel_softmax","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A Differentiable Self-disambiguated Sense Embedding Model via Scaled Gumbel Softmax},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyls7h05FQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJej72AqF7","original":"HJempMC5YQ","number":1390,"cdate":1538087971038,"ddate":null,"tcdate":1538087971038,"tmdate":1538155930110,"tddate":null,"forum":"BJej72AqF7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"A MAX-AFFINE SPLINE PERSPECTIVE OF RECURRENT NEURAL NETWORKS","abstract":"We develop a framework for understanding and improving recurrent neural net-works (RNNs) using max-affine spline operators (MASO). We prove that RNNsusing piecewise affine and convex nonlinearities can be written as a simple piece-wise affine spline operator. The resulting representation provides several new per-spectives for analyzing RNNs, three of which we study in this paper.  First, weshow that an RNN internally partitions the input space during training using vec-tor quantization and that it builds up the partition through time. Second, we showthat the affine parameter of an RNN corresponds to an input-specific template,from which we can interpret an RNN as performing a simple template matching(matched filtering) given the input. Third, by closely examining the MASO RNN formula, we prove that injecting Gaussian noise in the initial hidden state in RNNs corresponds to an explicit L2regularization on the affine parameters, which links to exploding gradient issues and improves generalization.  Extensive experimentson several datasets of various modalities demonstrates and validates each of theabove analyses.  In particular, using initial hidden states elevates simple RNNs tostate-of-the-art performance on these datasets","keywords":["RNN","max-affine spline operators"],"authorids":["ICLR.cc/2019/Conference/Paper1390/Authors"],"authors":["Anonymous"],"TL;DR":"We provide new insights and interpretations of RNNs from a max-affine spline operators perspective","pdf":"/pdf/e7bf3e61149dc93d3bfd2e8782e1c45ccb929173.pdf","paperhash":"anonymous|a_maxaffine_spline_perspective_of_recurrent_neural_networks","_bibtex":"@inproceedings{    \nanonymous2019a,    \ntitle={A MAX-AFFINE SPLINE PERSPECTIVE OF RECURRENT NEURAL NETWORKS},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJej72AqF7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Sklsm20ctX","original":"S1l_Fc65KQ","number":1391,"cdate":1538087971209,"ddate":null,"tcdate":1538087971209,"tmdate":1538155929889,"tddate":null,"forum":"Sklsm20ctX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Competitive experience replay","abstract":"Deep learning has achieved remarkable successes in solving challenging reinforcement learning (RL) problems. However, it still often suffers from the need to engineer a reward function that not only reflects the task but is also carefully shaped. This limits the applicability of RL in the real world. It is therefore of great practical importance to develop algorithms which can learn from unshaped, sparse reward signals, e.g. a binary signal indicating successful task completion.\nWe propose a novel method called competitive experience replay, which efficiently supplements a sparse reward by placing learning in the context of an exploration competition between a pair of agents.\nOur method complements the recently proposed hindsight experience replay (HER) by inducing an automatic exploratory curriculum.\nWe evaluate our approach on the tasks of reaching various goal locations in an ant maze and manipulating objects with a robotic arm.\nEach task provides only binary rewards indicating whether or not the goal is completed.\nOur method asymmetrically augments these sparse rewards for a pair of agents each learning the same task, creating a competitive game designed to drive exploration.\nExtensive experiments demonstrate that this method leads to faster converge and improved task performance.","keywords":["reinforcement learning","sparse reward","goal-based learning"],"authorids":["ICLR.cc/2019/Conference/Paper1391/Authors"],"authors":["Anonymous"],"TL;DR":"a novel method to learn with sparse reward using adversarial reward re-labeling","pdf":"/pdf/84417b2347251f7b4846e8c45b6a9560c72af7fa.pdf","paperhash":"anonymous|competitive_experience_replay","_bibtex":"@inproceedings{    \nanonymous2019competitive,    \ntitle={Competitive experience replay},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Sklsm20ctX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"SyGjQ30qFX","original":"r1gNFzCctm","number":1392,"cdate":1538087971387,"ddate":null,"tcdate":1538087971387,"tmdate":1538155929678,"tddate":null,"forum":"SyGjQ30qFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"TopicGAN: Unsupervised Text Generation from Explainable Latent Topics","abstract":"Learning discrete representations of data and then generating data from the discovered representations have been increasingly studied, because the obtained discrete representations can benefit unsupervised learning. However, the performance of learning discrete representations of textual data with deep generative models has not been widely explored.  In this work, we propose TopicGAN, a two-step generative model on text generation, which is able to discover discrete latent topics of texts and generate natural language from the discovered latent topics in an unsupervised fashion. Promising results are shown on unsupervised text classification and text generation for both subjective and objective evaluation.","keywords":["unsupervised learning","topic model","text generation"],"authorids":["ICLR.cc/2019/Conference/Paper1392/Authors"],"authors":["Anonymous"],"pdf":"/pdf/50ee350f1abb2bd745d9b475326d525e408744fc.pdf","paperhash":"anonymous|topicgan_unsupervised_text_generation_from_explainable_latent_topics","_bibtex":"@inproceedings{    \nanonymous2019topicgan:,    \ntitle={TopicGAN: Unsupervised Text Generation from Explainable Latent Topics},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=SyGjQ30qFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1xhQhRcK7","original":"BJgBPch9KX","number":1393,"cdate":1538087971556,"ddate":null,"tcdate":1538087971556,"tmdate":1538155929468,"tddate":null,"forum":"B1xhQhRcK7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures","abstract":"This paper addresses the problem of evaluating learning systems in safety critical domains such as autonomous driving, where failures can have catastrophic consequences. To this end, we focus on two problems: searching for scenarios when learned agents fail and the related problem of assessing their probability of failure. The standard method for agent evaluation in reinforcement learning, Vanilla Monte Carlo, can severely underestimate agent failure probabilities, leading to the deployment of unsafe agents. In our experiments, we observe this even after allocating equal compute to training and evaluation. To address this shortcoming, we draw upon the rare event probability estimation literature and propose an adversarial evaluation approach. Our approach focuses evaluation on difficult scenarios that are selected adversarially, while still providing unbiased estimates of failure probabilities. To do this, we propose a continuation approach to learning a failure probability predictor. This leverages data from related agents to overcome issues of data sparsity and allows the adversary to reuse data gathered for training the agent. We demonstrate the efficacy of adversarial evaluation on two complex reinforcement learning domains (humanoid control and simulated driving). Experimental results show that our methods can find catastrophic failures and estimate failures rates of agents multiple orders of magnitude faster (hours instead of days) than standard evaluation schemes.","keywords":["agent evaluation","adversarial examples","robustness","safety","reinforcement learning"],"authorids":["ICLR.cc/2019/Conference/Paper1393/Authors"],"authors":["Anonymous"],"TL;DR":"We show that rare but catastrophic failures may be missed entirely by random testing, which poses issues for safe deployment. Our proposed approach for adversarial testing fixes this.","pdf":"/pdf/5f7943a45689cc4ba4427af30ab0b0cf3a8963b5.pdf","paperhash":"anonymous|rigorous_agent_evaluation_an_adversarial_approach_to_uncover_catastrophic_failures","_bibtex":"@inproceedings{    \nanonymous2019rigorous,    \ntitle={Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1xhQhRcK7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1gnQ20qYX","original":"Syxnl_Y9t7","number":1394,"cdate":1538087971732,"ddate":null,"tcdate":1538087971732,"tmdate":1538155929265,"tddate":null,"forum":"r1gnQ20qYX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Pearl: Prototype lEArning via Rule Lists","abstract":"Deep neural networks have demonstrated promising classification performance on many healthcare applications. However, the interpretability of those models are often lacking. On the other hand, classical interpretable models such as rule lists or decision trees do not lead to the same level of accuracy as deep neural networks. Despite their interpretable structures, the resulting rules are often too complex to be interpretable (due to the potentially large depth of rule lists). In this work, we present PEARL, short for Prototype lEArning via Rule Lists, which iteratively use rule lists to guide a neural network to learn representative data prototypes. The resulting prototype neural network provides  accurate prediction, and the prediction can be easily explained by  prototype and its guiding rule lists. Thanks to the prediction power of neural networks, the rule lists defining prototypes are more concise and hence provide better interpretability. On two real-world electronic healthcare records (EHR) datasets, PEARL consistently outperforms all baselines,  achieving performance improvement over conventional rule learning by up to 28% and over prototype learning by up to 3%. Experimental results also show the resulting interpretation of PEARL is simpler than the standard rule learning.","keywords":["rule list learning","prototype learning","interpretability","healthcare"],"authorids":["ICLR.cc/2019/Conference/Paper1394/Authors"],"authors":["Anonymous"],"TL;DR":"a method combining rule list learning and prototype learning ","pdf":"/pdf/e308f5746e0a3835396f9177cae53e7ef37a9222.pdf","paperhash":"anonymous|pearl_prototype_learning_via_rule_lists","_bibtex":"@inproceedings{    \nanonymous2019pearl:,    \ntitle={Pearl: Prototype lEArning via Rule Lists},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1gnQ20qYX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Skz3Q2CcFX","original":"r1elGLhqKm","number":1395,"cdate":1538087971922,"ddate":null,"tcdate":1538087971922,"tmdate":1538155929061,"tddate":null,"forum":"Skz3Q2CcFX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae","abstract":"Embeddings are a fundamental component of many modern machine learning and natural language processing models.\nUnderstanding them and visualizing them is essential for gathering insights about the information they capture and the behavior of the models.\nState of the art in analyzing embeddings consists in projecting them in two-dimensional planes without any interpretable semantics associated to the axes of the projection, which makes detailed analyses and comparison among multiple sets of embeddings challenging.\nIn this work, we propose to use explicit axes defined as algebraic formulae over embeddings to project them into a lower dimensional, but semantically meaningful subspace, as a simple yet effective analysis and visualization methodology.\nThis methodology assigns an interpretable semantics to the measures of variability and the axes of visualizations, allowing for both comparisons among different sets of embeddings and fine-grained inspection of the embedding spaces.\nWe demonstrate the power of the proposed methodology through a series of case studies that make use of visualizations constructed around the underlying methodology and through a user study. The results show how the methodology is effective at providing more profound insights than classical projection methods and how it is widely applicable to many other use cases.","keywords":["visualization","embeddings","representations","t-sne","natural","language","processing","machine","learning","algebra"],"authorids":["ICLR.cc/2019/Conference/Paper1395/Authors"],"authors":["Anonymous"],"TL;DR":"We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for task-oriented analysis tasks and it outperforms t-SNE in our user study.","pdf":"/pdf/177801d5438d9c9ce4dee7c8b2a13a0a06b495ff.pdf","paperhash":"anonymous|visualizing_and_understanding_the_semantics_of_embedding_spaces_via_algebraic_formulae","_bibtex":"@inproceedings{    \nanonymous2019visualizing,    \ntitle={Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Skz3Q2CcFX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkxn7nR5KX","original":"S1liVh3cF7","number":1396,"cdate":1538087972118,"ddate":null,"tcdate":1538087972118,"tmdate":1538155928854,"tddate":null,"forum":"rkxn7nR5KX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Incremental Few-Shot Learning with Attention Attractor Networks","abstract":"Machine learning classifiers are often trained to recognize a set of pre-defined classes. However,\nin many real applications, it is often desirable to have the flexibility of learning additional\nconcepts, without re-training on the full training set. This paper addresses this problem,\nincremental few-shot learning, where a regular classification network has already been trained to\nrecognize a set of base classes; and several extra novel classes are being considered, each with\nonly a few labeled examples. After learning the novel classes, the model is then evaluated on the\noverall performance of both base and novel classes. To this end, we propose a meta-learning model,\nthe Attention Attractor Network, which regularizes the learning of novel classes. In each episode,\nwe train a set of new weights to recognize novel classes until they converge, and we show that the\ntechnique of recurrent back-propagation can back-propagate through the optimization process and\nfacilitate the learning of the attractor network regularizer. We demonstrate that the learned\nattractor network can recognize novel classes while remembering old classes without the need to\nreview the original training set, outperforming baselines that do not rely on an iterative\noptimization process.","keywords":["meta-learning","few-shot learning","incremental learning"],"authorids":["ICLR.cc/2019/Conference/Paper1396/Authors"],"authors":["Anonymous"],"pdf":"/pdf/4d77c27d3e71c414017a176619d977eeebcd51bd.pdf","paperhash":"anonymous|incremental_fewshot_learning_with_attention_attractor_networks","_bibtex":"@inproceedings{    \nanonymous2019incremental,    \ntitle={Incremental Few-Shot Learning with Attention Attractor Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxn7nR5KX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJgnmhA5KQ","original":"H1gD8-n5Km","number":1397,"cdate":1538087972306,"ddate":null,"tcdate":1538087972306,"tmdate":1538155928640,"tddate":null,"forum":"BJgnmhA5KQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Diverse Machine Translation with a Single Multinomial Latent Variable","abstract":"There are many ways to translate a sentence into another language. Explicit modeling of such uncertainty may enable better model fitting to the data and it may enable users to express a preference for how to translate a piece of content. Latent variable models are a natural way to represent uncertainty. Prior work investigated the use of multivariate continuous and discrete latent variables, but their interpretation and use for generating a diverse set of hypotheses have been elusive. In this work, we drastically simplify the model, using just a single multinomial latent variable. The resulting mixture of experts model can be trained efficiently via hard-EM and can generate a diverse set of hypothesis by parallel greedy decoding. We perform extensive experiments on three WMT benchmark datasets that have multiple human references, and we show that our model provides a better trade-off between quality and diversity of generations compared to all baseline methods.\\footnote{Code to reproduce this work is available at: anonymized URL.}","keywords":["machine translation","latent variable models","diverse decoding"],"authorids":["ICLR.cc/2019/Conference/Paper1397/Authors"],"authors":["Anonymous"],"pdf":"/pdf/b78538bbb15c4fa456a7f6d269ae6e1302c4e52d.pdf","paperhash":"anonymous|diverse_machine_translation_with_a_single_multinomial_latent_variable","_bibtex":"@inproceedings{    \nanonymous2019diverse,    \ntitle={Diverse Machine Translation with a Single Multinomial Latent Variable},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJgnmhA5KQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"rkxhX209FX","original":"S1xpkDi5Fm","number":1398,"cdate":1538087972473,"ddate":null,"tcdate":1538087972473,"tmdate":1538155928430,"tddate":null,"forum":"rkxhX209FX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"An Active Learning Framework for Efficient Robust Policy Search","abstract":"Robust Policy Search is the problem of learning policies that do not degrade in performance when subject to unseen environment model parameters. It is particularly relevant for transferring policies learned in a simulation environment to the real world. Several existing approaches involve sampling large batches of trajectories which reflect the differences in various possible environments, and then selecting some subset of these to learn robust policies, such as the ones that  result in the worst performance. We propose an active learning based framework, EffAcTS, to selectively choose model parameters for this purpose so as to collect only as much data as necessary to select such a subset. We apply this framework to an existing method, namely EPOpt, and experimentally validate the gains in sample efficiency and the performance of our approach on standard continuous control tasks. We also present a Multi-Task Learning perspective to the problem of Robust Policy Search, and draw connections from our proposed framework to existing work on Multi-Task Learning.","keywords":["Deep Reinforcement Learning"],"authorids":["ICLR.cc/2019/Conference/Paper1398/Authors"],"authors":["Anonymous"],"TL;DR":"An Active Learning framework that leads to efficient robust RL and opens up possibilities in Multi-Task RL","pdf":"/pdf/5da20b0a1253f56b2728289c6fe9bc0c8b054ff4.pdf","paperhash":"anonymous|an_active_learning_framework_for_efficient_robust_policy_search","_bibtex":"@inproceedings{    \nanonymous2019an,    \ntitle={An Active Learning Framework for Efficient Robust Policy Search},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=rkxhX209FX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJepX2A9tX","original":"r1l1Cup5KQ","number":1399,"cdate":1538087972638,"ddate":null,"tcdate":1538087972638,"tmdate":1538155928221,"tddate":null,"forum":"BJepX2A9tX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Rotation Equivariant Networks via Conic Convolution and the DFT","abstract":"Performance of neural networks can be significantly improved by encoding known invariance for particular tasks. Many image classification tasks, such as those related to cellular imaging, exhibit invariance to rotation. In particular, to aid convolutional neural networks in learning rotation invariance, we consider a simple, efficient conic convolutional scheme that encodes rotational equivariance, along with a method for integrating the magnitude response of the 2D-discrete-Fourier transform (2D-DFT) to encode global rotational invariance. We call our new method the Conic Convolution and DFT Network (CFNet). We evaluated the efficacy of CFNet as compared to a standard CNN and group-equivariant CNN (G-CNN) for several different image classification tasks and demonstrated improved performance, including classification accuracy, computational efficiency, and its robustness to hyperparameter selection. Taken together, we believe CFNet represents a new scheme that has the potential to improve many imaging analysis applications.","keywords":["deep learning","rotation equivariance","bioimaging analysis"],"authorids":["ICLR.cc/2019/Conference/Paper1399/Authors"],"authors":["Anonymous"],"TL;DR":"We propose conic convolution and the 2D-DFT to encode rotation equivariance into an neural network.","pdf":"/pdf/2323f8059dbe38b3443ce8e04f93334e31dbf086.pdf","paperhash":"anonymous|rotation_equivariant_networks_via_conic_convolution_and_the_dft","_bibtex":"@inproceedings{    \nanonymous2019rotation,    \ntitle={Rotation Equivariant Networks via Conic Convolution and the DFT},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJepX2A9tX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1g6XnCcKQ","original":"HklclZ3qFX","number":1400,"cdate":1538087972806,"ddate":null,"tcdate":1538087972806,"tmdate":1538155928012,"tddate":null,"forum":"B1g6XnCcKQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Object-Contrastive Networks: Unsupervised Object Representations","abstract":"Discovering objects and their attributes is of great importance for autonomous agents to effectively operate in human environments. This task is particularly challenging due to the ubiquitousness of objects and all their nuances in perceptual and semantic detail. In this paper we present an unsupervised approach for learning disentangled representations of objects entirely from unlabeled monocular videos. These continuous representations are not biased by or limited by a discrete set of labels determined by human labelers. The proposed representation is trained with a metric learning loss, where objects with homogeneous features are pushed together, while those with heterogeneous features are pulled apart. We show these unsupervised embeddings allow to discover object attributes and can enable robots to self-supervise in previously unseen environments. We quantitatively evaluate performance on a large-scale synthetic dataset with 12k object models, as well as on a real dataset collected by a robot and show that our unsupervised object understanding generalizes to previously unseen objects. Specifically, we demonstrate the effectiveness of our approach on robotic manipulation tasks, such as pointing at and grasping of objects. An interesting and perhaps surprising finding in this approach is that given a limited set of objects, object correspondences will naturally emerge when using metric learning without requiring explicit positive pairs.","keywords":["self-supervised robotics","object understanding","object representations","metric learning","unsupervised vision"],"authorids":["ICLR.cc/2019/Conference/Paper1400/Authors"],"authors":["Anonymous"],"TL;DR":"An unsupervised approach for learning disentangled representations of objects entirely from unlabeled monocular videos.","pdf":"/pdf/de707f8d8cde22b31f14616b7200cb0b62d80870.pdf","paperhash":"anonymous|objectcontrastive_networks_unsupervised_object_representations","_bibtex":"@inproceedings{    \nanonymous2019object-contrastive,    \ntitle={Object-Contrastive Networks: Unsupervised Object Representations},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1g6XnCcKQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJz6QhR9YQ","original":"BJe9Eipctm","number":1401,"cdate":1538087972974,"ddate":null,"tcdate":1538087972974,"tmdate":1538155927799,"tddate":null,"forum":"HJz6QhR9YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Hierarchical Deep Reinforcement Learning Agent with Counter Self-play  on Competitive Games ","abstract":"Deep Reinforcement Learning algorithms lead to agents that can solve difficult decision making problems in complex environments. However, many difficult multi-agent competitive games, especially real-time strategy games are still considered beyond the capability of current deep reinforcement learning algorithms, although there has been a recent effort to change this \\citep{openai_2017_dota, vinyals_2017_starcraft}. Moreover, when the opponents in a competitive game are suboptimal, the current \\textit{Nash Equilibrium} seeking, self-play algorithms are often unable to generalize their strategies to opponents that play strategies vastly different from their own. This suggests that a learning algorithm that is beyond conventional self-play is necessary. We develop Hierarchical Agent with Self-play (HASP), a learning approach for obtaining hierarchically structured policies that can achieve higher performance than conventional self-play on competitive games through the use of a diverse pool of sub-policies we get from Counter Self-Play (CSP). We demonstrate that the ensemble policy generated by HASP can achieve better performance while facing unseen opponents that use sub-optimal policies. On a motivating iterated Rock-Paper-Scissor game and a partially observable real-time strategic game (http://generals.io/), we are led to the conclusion that HASP can perform better than conventional self-play as well as achieve 77% win rate against FloBot, an open-source agent which has ranked at position number 2 on the online leaderboards.","keywords":["deep reinforcement learning","self-play","real-time strategic game","multi-agent"],"authorids":["ICLR.cc/2019/Conference/Paper1401/Authors"],"authors":["Anonymous"],"TL;DR":"We develop Hierarchical Agent with Self-play (HASP), a learning approach for obtaining hierarchically structured policies that can achieve high performance than conventional self-play on competitive real-time strategic games.","pdf":"/pdf/fe7c68a56facc76cf105f3d936721c20a65d4c6c.pdf","paperhash":"anonymous|hierarchical_deep_reinforcement_learning_agent_with_counter_selfplay_on_competitive_games","_bibtex":"@inproceedings{    \nanonymous2019hierarchical,    \ntitle={Hierarchical Deep Reinforcement Learning Agent with Counter Self-play  on Competitive Games },    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJz6QhR9YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryza73R9tQ","original":"rJl4eu4qtQ","number":1402,"cdate":1538087973152,"ddate":null,"tcdate":1538087973152,"tmdate":1538155927579,"tddate":null,"forum":"ryza73R9tQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Machine Translation With Weakly Paired Bilingual Documents","abstract":"Neural machine translation, which achieves near human-level performance in some languages, strongly relies on the availability of large amounts of parallel sentences, which hinders its applicability to low-resource language pairs. Recent works explore the possibility of unsupervised machine translation with monolingual data only, leading to much lower accuracy compared with the supervised one. Observing that weakly paired bilingual documents are much easier to collect than bilingual sentences, e.g., from Wikipedia, news websites or books, in this paper, we investigate the training of translation models with weakly paired bilingual documents. Our approach contains two components/steps. First, we provide a simple approach to mine implicitly bilingual sentence pairs from document pairs which can then be used as supervised signals for training. Second, we leverage the topic consistency of two weakly paired documents and learn the sentence-to-sentence translation by constraining the word distribution-level alignments.  We evaluate our proposed method on weakly paired documents from Wikipedia on four tasks, the widely used WMT16 German$\\leftrightarrow$English and WMT13 Spanish$\\leftrightarrow$English tasks, and obtain $24.1$/$30.3$ and $28.0$/$27.6$ BLEU points separately, outperforming\nstate-of-the-art unsupervised results by more than 5 BLEU points and reducing the gap between unsupervised translation and supervised translation up to 50\\%. ","keywords":["Natural Language Processing","Machine Translation","Unsupervised Learning"],"authorids":["ICLR.cc/2019/Conference/Paper1402/Authors"],"authors":["Anonymous"],"pdf":"/pdf/9789c159392408e931564db1fd90c5a0b949cc69.pdf","paperhash":"anonymous|machine_translation_with_weakly_paired_bilingual_documents","_bibtex":"@inproceedings{    \nanonymous2019machine,    \ntitle={Machine Translation With Weakly Paired Bilingual Documents},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryza73R9tQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJE6X305Fm","original":"rklZ0zA9t7","number":1403,"cdate":1538087973322,"ddate":null,"tcdate":1538087973322,"tmdate":1538155927371,"tddate":null,"forum":"HJE6X305Fm","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Don't let your Discriminator  be fooled","abstract":"Generative Adversarial Networks are one of the leading tools in generative modeling, image editing and content creation. \nHowever, they are hard to train as they require a delicate balancing act between two deep networks fighting a never ending duel. Some of the most promising adversarial models today minimize a Wasserstein objective. It is smoother and more stable to optimize. In this paper, we show that the Wasserstein distance is just one out of a large family of objective functions that yield these properties. By making the discriminator of a GAN robust to adversarial attacks we can turn any GAN objective into a smooth and stable loss. We experimentally show that any GAN objective, including Wasserstein GANs, benefit from adversarial robustness both quantitatively and qualitatively. The training additionally becomes more robust to suboptimal choices of hyperparameters, model architectures, or objective functions.","keywords":["GAN","generative models","computer vision"],"authorids":["ICLR.cc/2019/Conference/Paper1403/Authors"],"authors":["Anonymous"],"TL;DR":"A discriminator that is not easily fooled by adversarial example makes GAN training more robust and leads to a smoother objective.","pdf":"/pdf/b6df3191a85b631afb160dbc752dd11f366df8ff.pdf","paperhash":"anonymous|dont_let_your_discriminator_be_fooled","_bibtex":"@inproceedings{    \nanonymous2019don't,    \ntitle={Don't let your Discriminator  be fooled},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJE6X305Fm},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HylTXn0qYX","original":"ryexB5jqtQ","number":1404,"cdate":1538087973493,"ddate":null,"tcdate":1538087973493,"tmdate":1538155927166,"tddate":null,"forum":"HylTXn0qYX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Efficiently testing local optimality and escaping saddles for ReLU networks","abstract":"We provide a theoretical algorithm for checking local optimality and escaping saddles at nondifferentiable points of empirical risks of two-layer ReLU networks. Our algorithm receives any parameter value and returns: local minimum, second-order stationary point, or a strict descent direction. The presence of M data points on the nondifferentiability of the ReLU divides the parameter space into at most 2^M regions, which makes analysis difficult. By exploiting polyhedral geometry, we reduce the total computation down to one convex quadratic program (QP) for each hidden node, O(M) (in)equality tests, and one (or a few) nonconvex QP. For the last QP, we show that our specific problem can be solved efficiently, in spite of nonconvexity. In the benign case, we solve one equality constrained QP, and we prove that projected gradient descent solves it exponentially fast. In the bad case, we have to solve a few more inequality constrained QPs, but we prove that the time complexity is exponential only in the number of inequality constraints. Our experiments show that either benign case or bad case with very few inequality constraints occurs, implying that our algorithm is efficient in most cases.","keywords":["local optimality","second-order stationary point","escaping saddle points","nondifferentiability","ReLU","empirical risk"],"authorids":["ICLR.cc/2019/Conference/Paper1404/Authors"],"authors":["Anonymous"],"TL;DR":"A theoretical algorithm for testing local optimality and extracting descent directions at nondifferentiable points of empirical risks of one-hidden-layer ReLU networks.","pdf":"/pdf/0b7968bb259c6d5e5869b3f6ee87e1073d564510.pdf","paperhash":"anonymous|efficiently_testing_local_optimality_and_escaping_saddles_for_relu_networks","_bibtex":"@inproceedings{    \nanonymous2019efficiently,    \ntitle={Efficiently testing local optimality and escaping saddles for ReLU networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HylTXn0qYX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"B1e0X3C9tQ","original":"BJevFIj9tX","number":1405,"cdate":1538087973665,"ddate":null,"tcdate":1538087973665,"tmdate":1538155926951,"tddate":null,"forum":"B1e0X3C9tQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Diagnosing and Enhancing VAE Models","abstract":"Although variational autoencoders (VAEs) represent a widely influential deep generative model, many aspects of the underlying energy function remain poorly understood.  In particular, it is commonly believed that Gaussian encoder/decoder assumptions reduce the effectiveness of VAEs in generating realistic samples.  In this regard, we rigorously analyze the VAE objective, differentiating situations where this belief is and is not actually true.  We then leverage the corresponding insights to develop a simple VAE enhancement that requires no additional hyperparameters or sensitive tuning.  Quantitatively, this proposal produces crisp samples and stable FID scores that are actually competitive with state-of-the-art GAN models, all while retaining desirable attributes of the original VAE architecture.","keywords":["variational autoencoder","generative models"],"authorids":["ICLR.cc/2019/Conference/Paper1405/Authors"],"authors":["Anonymous"],"TL;DR":"We closely analyze the VAE objective function and draw novel conclusions that lead to simple enhancements.","pdf":"/pdf/6dbb34132fd2f583559db43956a6be87ceb3905f.pdf","paperhash":"anonymous|diagnosing_and_enhancing_vae_models","_bibtex":"@inproceedings{    \nanonymous2019diagnosing,    \ntitle={Diagnosing and Enhancing VAE Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=B1e0X3C9tQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HJeRm3Aqt7","original":"rklVKWA5FQ","number":1406,"cdate":1538087973834,"ddate":null,"tcdate":1538087973834,"tmdate":1538155926736,"tddate":null,"forum":"HJeRm3Aqt7","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"GenEval: A Benchmark Suite for Evaluating Generative Models","abstract":"Generative models are important for several practical applications, from low level image processing tasks, to model-based planning in robotics. More generally,\nthe study of generative models is motivated by the long-standing endeavor to model uncertainty and to discover structure by leveraging unlabeled data.\nUnfortunately, the lack of an ultimate task of interest has hindered progress in the field, as there is no established way to\ncompare models and, often times, evaluation is based on mere visual inspection of samples drawn from such models.\n\nIn this work, we aim at addressing this problem by introducing a new benchmark evaluation suite, dubbed \\textit{GenEval}.\nGenEval hosts a large array of distributions capturing many important\nproperties of real datasets, yet in a controlled setting, such as lower intrinsic dimensionality, multi-modality, compositionality,\nindependence and causal structure. Any model can be easily plugged for evaluation, provided it can generate samples.\n\nOur extensive evaluation suggests that different models have different strenghts, and that GenEval is a great tool to gain insights about how models and metrics work.\nWe offer GenEval to the community~\\footnote{Available at: \\it{coming soon}.} and believe that this benchmark will facilitate comparison and development of\nnew generative models.","keywords":["generative models","GAN","VAE","Real NVP"],"authorids":["ICLR.cc/2019/Conference/Paper1406/Authors"],"authors":["Anonymous"],"TL;DR":"We introduce battery of synthetic distributions and metrics for measuring the success of generative models  ","pdf":"/pdf/61d5b0233e6a2eb97d766483d516f278a7201e54.pdf","paperhash":"anonymous|geneval_a_benchmark_suite_for_evaluating_generative_models","_bibtex":"@inproceedings{    \nanonymous2019geneval:,    \ntitle={GenEval: A Benchmark Suite for Evaluating Generative Models},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HJeRm3Aqt7},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"ryM07h0cYX","original":"rkl2qtPFY7","number":1407,"cdate":1538087973999,"ddate":null,"tcdate":1538087973999,"tmdate":1538155926520,"tddate":null,"forum":"ryM07h0cYX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Reinforced Pipeline Optimization: Behaving Optimally with Non-Differentiabilities","abstract":"Many machine learning systems are implemented as pipelines. A pipeline is essentially a chain/network of information processing units. As information flows in and out and gradients vice versa, ideally, a pipeline can be trained end-to-end via backpropagation provided with the right supervision and loss function. However, this is usually impossible in practice, because either the loss function itself may be non-differentiable, or there may exist some non-differentiable units. One popular way to superficially resolve this issue is to separate a pipeline into a set of differentiable sub-pipelines and train them with isolated loss functions. Yet, from a decision-theoretical point of view, this is equivalent to making myopic decisions using ad hoc heuristics along the pipeline while ignoring the real utility, which prevents the pipeline from behaving optimally. In this paper, we show that by converting a pipeline into a stochastic counterpart, it can then be trained end-to-end in the presence of non-differentiable parts. Thus, the resulting pipeline is optimal under certain conditions with respect to any criterion attached to it. In experiments, we apply the proposed approach - reinforced pipeline optimization - to Faster R-CNN, a state-of-the-art object detection pipeline, and obtain empirically near-optimal object detectors consistent with its base design in terms of mean average precision.","keywords":["Pipeline Optimization","Reinforcement Learning","Stochastic Computation Graph","Faster R-CNN"],"authorids":["ICLR.cc/2019/Conference/Paper1407/Authors"],"authors":["Anonymous"],"TL;DR":"By converting an originally non-differentiable pipeline into a stochastic counterpart, we can then train the converted pipeline completely end-to-end while optimizing any criterion attached to it.","pdf":"/pdf/c2e107946e5bf2053891096c2be8c71a19d822ee.pdf","paperhash":"anonymous|reinforced_pipeline_optimization_behaving_optimally_with_nondifferentiabilities","_bibtex":"@inproceedings{    \nanonymous2019reinforced,    \ntitle={Reinforced Pipeline Optimization: Behaving Optimally with Non-Differentiabilities},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=ryM07h0cYX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"HkzRQhR9YX","original":"Skx58XActm","number":1408,"cdate":1538087974177,"ddate":null,"tcdate":1538087974177,"tmdate":1538155926312,"tddate":null,"forum":"HkzRQhR9YX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Tree-Structured Recurrent Switching Linear Dynamical Systems for Multi-Scale Modeling","abstract":"Many real-world systems studied are governed by complex, nonlinear\n  dynamics.  By modeling these dynamics, we can gain insight into how\n  these systems work, make predictions about how they will behave, and\n  develop strategies for controlling them. While there are many\n  methods for modeling nonlinear dynamical systems, existing\n  techniques face a trade off between offering interpretable\n  descriptions and making accurate predictions.  Here, we develop a\n  class of models that aims to achieve both simultaneously, smoothly\n  interpolating between simple descriptions and more complex, yet also\n  more accurate models.  Our probabilistic model achieves this\n  multi-scale property through of a hierarchy of locally\n  linear dynamics that jointly approximate global nonlinear dynamics.\n  We call it the tree-structured recurrent switching linear dynamical system.\n  To fit this model, we present a fully-Bayesian sampling procedure using\n  P\\'{o}lya-Gamma data augmentation to allow for fast and\n  conjugate Gibbs sampling.  Through a variety of synthetic and real examples,\n  we show how these models outperform existing methods in both interpretability\n  and predictive capability.","keywords":["machine learning","bayesian statistics","dynamical systems"],"authorids":["ICLR.cc/2019/Conference/Paper1408/Authors"],"authors":["Anonymous"],"pdf":"/pdf/d01f10944207fadd987b682a3ac2d1355c276689.pdf","paperhash":"anonymous|treestructured_recurrent_switching_linear_dynamical_systems_for_multiscale_modeling","_bibtex":"@inproceedings{    \nanonymous2019tree-structured,    \ntitle={Tree-Structured Recurrent Switching Linear Dynamical Systems for Multi-Scale Modeling},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=HkzRQhR9YX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"r1V0m3C5YQ","original":"HygiBnh5Km","number":1409,"cdate":1538087974359,"ddate":null,"tcdate":1538087974359,"tmdate":1538155926084,"tddate":null,"forum":"r1V0m3C5YQ","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Coupled Recurrent Models for Polyphonic Music Composition","abstract":"This work describes a novel recurrent model for music composition, which accounts for the rich statistical structure of polyphonic music. There are many ways to factor the probability distribution over musical scores; we consider the merits of various approaches and propose a new factorization that decomposes a score into a collection of concurrent, coupled time series: \"parts.\" The model we propose borrows ideas from both convolutional neural models and recurrent neural models; we argue that these ideas are natural for capturing music's pitch invariances, temporal structure, and polyphony.\n\nWe train generative models for homophonic and polyphonic composition on the KernScores dataset (Sapp, 2005), a collection of 2,300 musical scores comprised of around 2.8 million notes spanning time from the Renaissance to the early 20th century. While evaluation of generative models is know to be hard (Theis et al., 2016), we present careful quantitative results using a unit-adjusted cross entropy metric that is independent of how we factor the distribution over scores. We also present qualitative results using a blind discrimination test.\n","keywords":["music composition","music generation","polyphonic music modeling"],"authorids":["ICLR.cc/2019/Conference/Paper1409/Authors"],"authors":["Anonymous"],"TL;DR":"New recurrent generative models for composition of rhythmically complex, polyphonic music.","pdf":"/pdf/54f3bc17d5303dd1080688e76e1fa2b584a48bad.pdf","paperhash":"anonymous|coupled_recurrent_models_for_polyphonic_music_composition","_bibtex":"@inproceedings{    \nanonymous2019coupled,    \ntitle={Coupled Recurrent Models for Polyphonic Music Composition},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=r1V0m3C5YQ},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"BJe1E2R5KX","original":"SJxgvWb9KQ","number":1410,"cdate":1538087974523,"ddate":null,"tcdate":1538087974523,"tmdate":1538155925852,"tddate":null,"forum":"BJe1E2R5KX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees","abstract":"Model-based reinforcement learning (RL) is considered to be a promising approach to reduce the sample complexity that hinders model-free RL. However, the theoretical understanding of such methods has been rather limited. This paper introduces a novel algorithmic framework for designing and analyzing model-based RL algorithms with theoretical guarantees. We design a meta-algorithm with a theoretical guarantee of monotone improvement to a local maximum of the expected reward. The meta-algorithm iteratively builds a lower bound of the expected reward based on the estimated dynamical model and sample trajectories, and then maximizes the lower bound jointly over the policy and the model. The framework extends the optimism-in-face-of-uncertainty principle to non-linear dynamical models in a way that requires no explicit uncertainty quantification. Instantiating our framework with simplification gives a  variant of model-based RL algorithms Stochastic Lower Bounds Optimization (SLBO). Experiments demonstrate that SLBO achieves the state-of-the-art performance when only 1M or fewer samples are permitted on a range of continuous control benchmark tasks.","keywords":["model-based reinforcement learning","sample efficiency","deep reinforcement learning"],"authorids":["ICLR.cc/2019/Conference/Paper1410/Authors"],"authors":["Anonymous"],"TL;DR":"We design model-based reinforcement learning algorithms with theoretical guarantees and achieve state-of-the-art results on Mujuco benchmark tasks when one million or fewer samples are permitted.","pdf":"/pdf/57fce953857713037cb49b9ddcc2ae83ff3eba36.pdf","paperhash":"anonymous|algorithmic_framework_for_modelbased_deep_reinforcement_learning_with_theoretical_guarantees","_bibtex":"@inproceedings{    \nanonymous2019algorithmic,    \ntitle={Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=BJe1E2R5KX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}},{"id":"Hyg_X2C5FX","original":"rkgTbxR9Ym","number":1371,"cdate":1538087967675,"ddate":null,"tcdate":1538087967675,"tmdate":1538155925635,"tddate":null,"forum":"Hyg_X2C5FX","replyto":null,"invitation":"ICLR.cc/2019/Conference/-/Blind_Submission","content":{"title":"Visualizing and Understanding Generative Adversarial Networks","abstract":"Generative Adversarial Networks (GANs) have recently achieved impressive results for many real-world applications.  As an active research topic, many GAN variants have emerged with immprovements in sample quality and training stability. However, visualization and understanding of GANs is largely missing. How does a GAN represent our visual world internally?  What causes the artifacts in GAN results?  How do architectural choices affect GAN learning?  Answering such questions could enable us to develop new insights and better models.\n\nIn this work, we present an analytic framework to visualize and understand GANs at the unit-, object-, and scene-level. We first identify a group of interpretable units that are closely related to \\concepts with a segmentation-based network dissection method. Then, we quantify the causal effect of interpretable units by measuring the ability of interventions to control objects in the output. Finally, we examine the contextual relationship between these units and their surrounding by inserting the discovered \\concepts into new images. We show several practical applications enabled by our framework, from comparing internal representations across different layers, models, and datasets, to improving GANs by locating and  removing ``artifacts'' units, to interactively manipulating objects in the scene.  We will open source our interactive online tools to help  researchers and practitioners better understand their models.","paperhash":"anonymous|visualizing_and_understanding_generative_adversarial_networks","TL;DR":"GAN representations are examined in detail, and sets of representation units are found that control the generation of semantic concepts in the output.","authorids":["ICLR.cc/2019/Conference/Paper1371/Authors"],"authors":["Anonymous"],"keywords":["GANs","representation","interpretability","causality"],"pdf":"/pdf/698fe867781c14123dddb0bc455a38cbcd6b67ac.pdf","_bibtex":"@inproceedings{    \nanonymous2019visualizing,    \ntitle={Visualizing and Understanding Generative Adversarial Networks},    \nauthor={Anonymous},    \njournal={International Conference on Learning Representations},    \nyear={2019},    \nurl={https://openreview.net/forums?id=Hyg_X2C5FX},    \nnote={under review}    \n}"},"signatures":["ICLR.cc/2019/Conference"],"readers":["everyone"],"nonreaders":[],"writers":["ICLR.cc/2019/Conference"],"details":{"tags":[]}}]}